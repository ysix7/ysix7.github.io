<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2Fp%2F0.html</url>
    <content type="text"><![CDATA[mean,imply,indicate,represent,denote,signify,suggest Ëøô‰∫õÂä®ËØçÂùáÂê´Êúâ‚ÄúË°®Á§∫‚Ä¶‚Ä¶ÁöÑÊÑèÊÄù‚Äù‰πãÊÑè„ÄÇ meanÊúÄÊôÆÈÄöÁî®ËØç„ÄÇÊåáÊñáÂ≠óÊàñÁ¨¶Âè∑Á≠âÊâÄË°®Á§∫ÁöÑÂêÑÁßçÊòéÁ°ÆÁöÑÊàñÂê´ËìÑÁöÑÊÑè‰πâ„ÄÇ imply‰æßÈáçÁî®ÊñáÂ≠óÊàñÁ¨¶Âè∑Ë°®Á§∫ÁöÑËÅîÊÉ≥ÔºåÊöóÁ§∫„ÄÇ indicateÊåáÊòéÊòæÁöÑË°®Á§∫„ÄÇ representÊåá‰ΩìÁé∞Êàñ‰ª£Ë°®„ÄÇ denoteÊåáÊüê‰∏ÄËØçÂ≠óÈù¢ÊàñÁã≠‰πâÁöÑÊÑèÊÄùÔºåÊàñÊåáÊüê‰∫õÁ¨¶Âè∑ÊàñËøπË±°ÁöÑÁâπÊåáÂê´‰πâ„ÄÇ signifyÊåáÁî®ÊñáÂ≠ó„ÄÅËØ¥ËØùÊàñË°®ÊÉÖÁ≠âË°®Á§∫ÂçïÁ∫ØÁöÑÊÑèÊÄù„ÄÇ suggestÈÄöÂ∏∏ÊåáÊöóÂê´Âú∞„ÄÅÈöêÊô¶Âú∞Ë°®ËææÊÑèÊÄù„ÄÇ]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Fp%2F0.html</url>
    <content type="text"><![CDATA[ÂêÑÁ±ªË°®Ëææ is of the order of 10^{-3}]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Fp%2F0.html</url>
    <content type="text"><![CDATA[Foodie TravelËâæÊ†ºÂêÉÈ•±‰∫ÜÔºö‰∏äÊµ∑È¶ÜÂ≠ê ËâæÊ†ºÂêÉÈ•±‰∫ÜÔºöÊù≠Â∑ûÈ¶ÜÂ≠ê]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Fp%2F0.html</url>
    <content type="text"><![CDATA[October ÁîüËØç utmost to the utmostÔºöÊûÅÂ§ßÈôêÂ∫¶ÁöÑ the utmost noun.:ÊúÄÂ§ßÁ®ãÂ∫¶ÁöÑ‰ªÄ‰πàÔºåÂèØÁøªËØë‰∏∫ÈùûÂ∏∏ drain ÂñùÂÖâÔºåÂñùÂπ≤Ôºõ ‰ΩøÔºàÁ≤æÂäõ„ÄÅÈáëÈí±Á≠âÔºâËÄóÂ∞ΩÔºõ ‰ΩøÊµÅÂá∫Ôºõ ÊéíÊéâÊ∞¥ e.g. I drain the pasta, then I share it out between two plates justfication ËÆ§‰∏∫ÊúâÈÅìÁêÜ e.g. A justiÔ¨Åcation for the choice of SSIM as a good Ô¨Ådelity measure instead of the traditional PSNR can be seen in Fig. 4. denote We denote apple by a. == a denote Apple. apple is denoted by a we denote by a apple denote that[Ë°®Á§∫ÔºåÊåáÁ§∫]: These signs denote that a crisis is approaching. Denote: Dark clouds denote a coming storm ËØçÁªÑThe University security personnel are under instruction to discharge their duty having regard to this principle.ÊåáÁ§∫‰∏ã„ÄÅÂ±•Ë°åËÅåË¥£„ÄÅÈâ¥‰∫éËøô‰∏™ÂáÜÂàô Given the escalating turmoil and violence across Hong Kong, as far as: (1) as far as I‚Äôm concerned Âú®ÊàëÁúãÊù•„ÄÇ Â∞±‰ªÄ‰πàËÄåËÆ∫ (2) Â∞±„ÄÇ„ÄÇÁöÑÁ®ãÂ∫¶=so far as as far as I know ÊçÆÊàëÊâÄÁü•Ôºõas far as the eye could see ÁõÆ‰πãÊâÄÂèäÔºõ‚Äôas far as sb can/could Á´≠Â∞ΩÊâÄËÉΩ not as far as I remember Êàë‰∏çËÆ∞Âæó (3) ËøúËá≥ I read as far as the third chapter. We walk as far as the edge of the forest. ËØ≠Ê≥ï ‰∏Ä‰∏™ËØ≠Ê≥ïÁΩëÁ´ô when,while,asÁöÑÂå∫Âà´ doing‚Ä¶ while doing../ doing when do ÂΩì ËΩ¨Êäò]]></content>
  </entry>
  <entry>
    <title><![CDATA[Êï∞Â≠¶_ËÅöÁ±ªÁÆóÊ≥ï]]></title>
    <url>%2Fp%2Fd0a2.html</url>
    <content type="text"><![CDATA[‰∏ªÊàêÂàÜÂàÜÊûê(Êú™ÂÆåÊàê) ‰ΩúÁî® Êï∞ÊçÆÈôçÁª¥ÂêéÂèØËßÜÂåñ„ÄÅÊï∞ÊçÆÂéãÁº©„ÄÇ ‰∏§ÁßçÂÆö‰πâÔºöÊúÄÂ§ßÂåñÊñπÂ∑ÆÔºå‰ΩøÊäïÂΩ±Êï∞ÊçÆÂ∞ΩÂèØËÉΩÂàÜÊï£ÔºõÊúÄÂ∞èÂåñÊäïÂΩ±ËØØÂ∑Æ ÊúÄÂ∞èÂåñÊäïÂΩ±ËØØÂ∑Æ ÊúÄÂ§ßÂåñÊñπÂ∑Æ Find $v_i$ ‰∏Ä‰∫õÂêçËØç ÊäïÂΩ±ËØØÂ∑ÆÔºö Ë∞±ËÅöÁ±ªÁÆóÊ≥ï(ÈóÆÈ¢ò)Ë∞±ËÅöÁ±ªÁÆóÊ≥ï ÈóÆÈ¢ò ÁâπÂæÅÂÄºÂíåÁâπÂæÅÂêëÈáèÁöÑÁâ©ÁêÜÊÑè‰πâ Ë∞±ËÅöÁ±ªÁÆóÊ≥ï‰∏≠ Reference https://blog.csdn.net/zhongkelee/article/details/44064401 „ÄäÊú∫Âô®Â≠¶‰π†ÊúÄÂêé‰∏ÄÁ´†„Äã]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Fp%2F0.html</url>
    <content type="text"><![CDATA[È¶ôËñ∞ÁÅØ ÁßãÂ§©ÁöÑÈ¶ôÊ∞¥]]></content>
  </entry>
  <entry>
    <title><![CDATA[Êï∞Â≠¶_‰ºòÂåñ]]></title>
    <url>%2Fp%2F68e3.html</url>
    <content type="text"><![CDATA[ÊÄßË¥®coerciveÔºö]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Fp%2F0.html</url>
    <content type="text"><![CDATA[Êó•Êú¨Á≠æÊ≥® https://zhuanlan.zhihu.com/p/25683802 Ë•øÂåóËßíÊîªÁï• http://f1.intocity.cn/share/dist/module/articleDetailMore.html?id=161 ÁΩë‰∏äÈ¢ÑÁ∫¶ https://www.vfsglobal.com/Japan/Hongkong/Book-an-Appointment.html Áî≥ËØ∑Ë°®Ê†º https://www.hk.emb-japan.go.jp/jp/docs/2012_visa_app_info.pdf]]></content>
  </entry>
  <entry>
    <title><![CDATA[ÊëÑÂΩ±_LightroomË∞ÉËâ≤]]></title>
    <url>%2Fp%2F5c30.html</url>
    <content type="text"><![CDATA[Ëé´ÂÖ∞Ëø™Ëâ≤ x ÂüéÂ∏ÇÈ£éÂÖâ]]></content>
  </entry>
  <entry>
    <title><![CDATA[ÊëÑÂΩ±_VSCOÊª§Èïú]]></title>
    <url>%2Fp%2Fd5da.html</url>
    <content type="text"><![CDATA[ReferenceÔºö‰∫îÊ¨æÊª§ÈïúÊé®Ëçê AV8]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Fp%2F0.html</url>
    <content type="text"><![CDATA[checkpoint = utility.checkpoint(args) self.loader_train = MSDataLoader( args, trainset, batch_size=args.batch_size, shuffle=True, pin_memory=not args.cpu ) while not t.terminate(): t.train() t.test() def terminate(self): if self.args.test_only: self.test() return True else: epoch = self.scheduler.last_epoch + 1 return epoch &gt;= self.args.epochs ËÆ≠ÁªÉÁöÑ‰æãÂ≠êÂèÇÊï∞ËÆæÁΩÆ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147cd Train/# MSRN x2 LR: 48 * 48 HR: 96 * 96python main.py --template MSRN --save MSRN_X2 --scale 2 --reset --save_results --patch_size 96 --ext sep_reset# MSRN x3 LR: 48 * 48 HR: 144 * 144python main.py --template MSRN --save MSRN_X3 --scale 3 --reset --save_results --patch_size 144 --ext sep_resetif args.template.find('MSRN') &gt;= 0: args.model = 'MSRN' args.n_blocks = 8 args.n_feats = 64 args.chop = True parser.add_argument('--debug', action='store_true', help='Enables debug mode')parser.add_argument('--template', default='.', help='You can set various templates in option.py')# Hardware specificationsparser.add_argument('--n_threads', type=int, default=8, help='number of threads for data loading')parser.add_argument('--cpu', action='store_true', help='use cpu only')parser.add_argument('--n_GPUs', type=int, default=4, help='number of GPUs')parser.add_argument('--seed', type=int, default=1, help='random seed')# Data specificationsparser.add_argument('--dir_data', type=str, default='dataset', help='dataset directory')parser.add_argument('--dir_demo', type=str, default='test', help='demo image directory')# data_train, 'DIV2K'parser.add_argument('--data_train', type=str, default='DIV2K', help='train dataset name')# data_test, parser.add_argument('--data_test', type=str, default='DIV2K', help='test dataset name')parser.add_argument('--data_range', type=str, default='1-800/896-900', help='train/test data range')parser.add_argument('--ext', type=str, default='sep', help='dataset file extension')parser.add_argument('--scale', type=str, default='4', help='super resolution scale')# patch_sizeparser.add_argument('--patch_size', type=int, default=128, help='output patch size')parser.add_argument('--rgb_range', type=int, default=255, help='maximum value of RGB')parser.add_argument('--n_colors', type=int, default=3, help='number of color channels to use')parser.add_argument('--chop', action='store_true', help='enable memory-efficient forward')parser.add_argument('--no_augment', action='store_true', help='do not use data augmentation')# Model specifications ÊÄé‰πàÊâæÂà∞Ëøô‰∏™Ê®°ÂûãÔºüparser.add_argument('--model', default='EDSR', help='model name')parser.add_argument('--act', type=str, default='relu', help='activation function')parser.add_argument('--pre_train', type=str, default='.', help='pre-trained model directory')parser.add_argument('--extend', type=str, default='.', help='pre-trained model directory')parser.add_argument('--n_resblocks', type=int, default=16, help='number of residual blocks')parser.add_argument('--n_feats', type=int, default=64, help='number of feature maps')parser.add_argument('--res_scale', type=float, default=1, help='residual scaling')parser.add_argument('--shift_mean', default=True, help='subtract pixel mean from the input')parser.add_argument('--dilation', action='store_true', help='use dilated convolution')parser.add_argument('--precision', type=str, default='single', choices=('single', 'half'), help='FP precision for test (single | half)')# Option for Residual channel attention network (RCAN)parser.add_argument('--n_resgroups', type=int, default=1, help='number of residual groups')parser.add_argument('--reduction', type=int, default=16, help='number of feature maps reduction')# Training specificationsparser.add_argument('--reset', action='store_true', help='reset the training')parser.add_argument('--test_every', type=int, default=1000, help='do test per every N batches')parser.add_argument('--epochs', type=int, default=1000, help='number of epochs to train')parser.add_argument('--batch_size', type=int, default=16, help='input batch size for training')parser.add_argument('--split_batch', type=int, default=1, help='split the batch into smaller chunks')parser.add_argument('--self_ensemble', action='store_true', help='use self-ensemble method for test')parser.add_argument('--test_only', action='store_true', help='set this option to test the model')parser.add_argument('--gan_k', type=int, default=1, help='k value for adversarial loss')# Optimization specificationsparser.add_argument('--lr', type=float, default=1e-4, help='learning rate')parser.add_argument('--lr_decay', type=int, default=200, help='learning rate decay per N epochs')parser.add_argument('--decay_type', type=str, default='step', help='learning rate decay type')parser.add_argument('--gamma', type=float, default=0.5, help='learning rate decay factor for step decay')parser.add_argument('--optimizer', default='ADAM', choices=('SGD', 'ADAM', 'RMSprop'), help='optimizer to use (SGD | ADAM | RMSprop)')parser.add_argument('--momentum', type=float, default=0.9, help='SGD momentum')parser.add_argument('--beta1', type=float, default=0.9, help='ADAM beta1')parser.add_argument('--beta2', type=float, default=0.999, help='ADAM beta2')parser.add_argument('--epsilon', type=float, default=1e-8, help='ADAM epsilon for numerical stability')parser.add_argument('--weight_decay', type=float, default=0, help='weight decay')# Loss specificationsparser.add_argument('--loss', type=str, default='1*L1', help='loss function configuration')parser.add_argument('--skip_threshold', type=float, default='1e6', help='skipping batch that has large error')# Log specificationsparser.add_argument('--save', type=str, default='test', help='file name to save')parser.add_argument('--load', type=str, default='.', help='file name to load')parser.add_argument('--resume', type=int, default=0, help='resume from specific checkpoint')parser.add_argument('--save_models', action='store_true', help='save all intermediate models')parser.add_argument('--print_every', type=int, default=100, help='how many batches to wait before logging training status')parser.add_argument('--save_results', action='store_true', help='save output results') Template.py 12 datasetdataset/DIV2K/DIV2K_train_HR; dataset/DIV2K/DIV2K_train_LR_bicubic ËÆæÂÆöÊ®°Âûã12module = import_module('model.' + args.model.lower()) # import model.msrn.pyself.model = module.make_model(args).to(self.device) # msrn.pyÁöÑmake_model: ËøîÂõûËØ•Êñá‰ª∂model]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Fp%2F0.html</url>
    <content type="text"><![CDATA[ÂêçËØçÂõΩÂÜÖAËÇ° HËÇ°ÔºöÂú®È¶ôÊ∏Ø‰∏äÂ∏ÇÁöÑÂõΩ‰ºÅËÇ°„ÄÇÂ¶ÇÔºå‰∏≠ÂõΩÈì∂Ë°å„ÄÅÂ∑•ÂïÜÈì∂Ë°å„ÄÅ‰∏≠ÂõΩ‰∫∫ÂØø„ÄÇ ËÇ°Á•®ÊòØ‰ªÄ‰πàËÇ°Á•®Èô§‰∫ÜËÇ°ÊÅØÔºåËøòÊúâÂàÜÁ∫¢ÔºåËøôÊòØÂè¶‰∏Ä‰∏™ËØùÈ¢òÔºåÊúâÁ©∫ÂÜçËÆ≤„ÄÇ ËÇ°Á•®ÂÖ∂ÂÆûÊòØ‰∏Ä‰∏™‚ÄúÂê∏ÈáëÊâãÊÆµ‚ÄùÔºåÂÖ¨Âè∏Áî®ËæÉÈ´òÁöÑËÇ°ÊÅØÔºåÊãøËÇ°Á•®Êç¢ÂèñÁé∞ÈáëÔºå‰ª•Ê±ÇÂèëÂ±ï„ÄÇ ËÇ°Á•®‰ª∑Ê†ºËÇ°Á•®‰ª∑Ê†ºÁöÑÂΩ¢Êàê: ÈõÜÂêàÁ´û‰ª∑(ÂºÄÁõò‰ª∑)+ËøûÁª≠Á´û‰ª∑ÔºöÊúÄÂ§ßÊàê‰∫§ÈáèÔºåÊù•Ëé∑ÂæóÊúÄÂ§ß‰Ω£Èáë ÈõÜÂêàÁ´û‰ª∑ÊúÄÂêéÁöÑ‰ª∑Ê†ºÔºåÁî±‚ÄúÁéãÂ≠êÁÅ∞ÂßëÂ®ò‚ÄùÁöÑ‰∫§ÊòìÊñπÊ≥ïÂÜ≥ÂÆöÔºåÂÖ∑‰Ωì‰ºöÂõ†‰∏∫‰∏çÂêåÁöÑËØÅÂà∏Â∏ÇÂú∫ËÄåÊúâ‰∏çÂêå„ÄÇ ÈõÜÂêàÁ´û‰ª∑ÁöÑ‰∫§ÊòìÊó∂Èó¥ ËÇ°Á•®ÁöÑÁßçÁ±ªhttp://www.csrc.gov.cn/pub/gansu/xxfw/tzzzsyd/200608/t20060821_92670.htm AËÇ°ÂíåHËÇ°ÁöÑÂå∫Âà´ ÈóÆÈ¢òHËÇ°ÔºöÊåáÁöÑÊòØÊåáÂ§ßÈôÜ‰∏äÂ∏ÇÂÖ¨Âè∏Âú®È¶ôÊ∏ØÂçñÁöÑËÇ°Á•®ÔºüËøòÊòØÂ§ßÈôÜÂÖ¨Âè∏ÂèàÂú®È¶ôÊ∏Ø‰∏äÂ∏ÇÔºåÂèëË°åËÇ°Á•®ÔºüÈÇ£‰πàÈ¶ôÊ∏ØÊú¨Âú∞‰∏äÂ∏ÇÁöÑÁöÑÊú¨Âú∞ÂÖ¨Âè∏ÁÆó‰ªÄ‰πàËÇ°Á•®Á±ªÂûãÔºü]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Fp%2F0.html</url>
    <content type="text"><![CDATA[ÂèÇËÄÉ ÊñáÁåÆÁªºËø∞ÂèÇËÄÉËá™ÈìæÊé•Ôºö Ê∑±Â∫¶Â≠¶‰π†Âú®ÂõæÂÉèÂéªÂô™ÊñπÈù¢ÊúÄËøëÊúâÂì™‰∫õËøõÂ±ïÔºå‰∏é‰º†ÁªüÊñπÊ≥ïÁõ∏ÊØîÊïàÊûúÂ¶Ç‰Ωï, ‰ΩúËÄÖÔºöÂæêÂêõ ÂØπdeep learningÂæàÂ•ΩÁöÑÊÄªÁªìÔºöflyywh/Image-Denoising-State-of-the-art„ÄÇËøôÈáåÂèØ‰ª•ÊâæÂà∞ÂæàÂÖ®ÁöÑÂêÑÁßçstate-of-the-artÁÆóÊ≥ïÁöÑÈìæÊé•„ÄÇ È´òÊñØÂô™Â£∞ÂéªÂô™ÊñáÁåÆÁªºËø∞ (2009 NIPS) Jain, Viren, and Sebastian Seung. ‚ÄúNatural image denoising with convolutional networks.‚Äù Advances in neural information processing systems. 2009. ÊïàÊûú‰∏ÄËà¨„ÄÇÂè™ÊòØÊØîBLS-GSM, FoEÁöÑPSNRÁ®çÂæÆÂ•Ω‰∏ÄÁÇπ„ÄÇ (2012 MLP) Burger, Harold C., Christian J. Schuler, and Stefan Harmeling. ‚ÄúImage denoising: Can plain neural networks compete with BM3D?.‚Äù 2012 IEEE conference on computer vision and pattern recognition. IEEE, 2012. ÁΩëÁªúÈÉΩ‰∏çÊòØÂæàÊ∑±ÔºåÂè™Êúâ3Â±ÇÂ∑¶Âè≥„ÄÇÊïàÊûú‰πüÂ∞±ÊòØÂíåBM3DÂ∑Æ‰∏çÂ§öÁöÑÊ∞¥Âπ≥„ÄÇ 2014-2015Âπ¥ÔºåÂá∫Áé∞‰∫Ü‰∏Ä‰∫õÂà§Âà´Â≠¶‰π†ÁöÑÊñπÊ≥ïÂá∫Áé∞ÔºåÊØîÂ¶ÇCSFÂíåTNRDÔºåËøô‰∫õÊñπÊ≥ïÁöÑPSNR/SSIMÂü∫Êú¨Ë∂ÖËøá‰∫ÜBM3DÔºåÂú®ÈÄüÂ∫¶‰∏ä‰πü‰∏çÂàÜ‰ºØ‰ª≤„ÄÇ (2014 CSF) Schmidt, Uwe, and Stefan Roth. ‚ÄúShrinkage fields for effective image restoration.‚Äù Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2014. (2015 TNRD) Chen, Yunjin, Wei Yu, and Thomas Pock. ‚ÄúOn learning optimized reaction diffusion processes for effective image restoration.‚Äù Proceedings of the IEEE conference on computer vision and pattern recognition. 2015. ÁÑ∂ÂêéShrinkage FieldÂíåTNRDËøô‰∏§ÁØáÊñáÁ´†ÊòØÂ±û‰∫éÂØπsparse codingÁöÑ‰º†Áªüiterative methodËøõË°åunfoldingÊàê‰∏∫feed forward networkÁöÑÂ∑•‰ΩúÔºåÊàëËßâÂæóÂÅöÂæóÂæàËµû„ÄÇÊàëÊúÄËøëÁöÑÂ∑•‰Ωú‰πüÂú®followËøôÈáå‰∏§‰∏™Â∑•‰Ωú„ÄÇÊàëËßâÂæóËøôÁßçapproachÂèØ‰ª•ÁªôÊõ¥Â§öÁöÑinverse problemÊèê‰æõ‰∏ÄÁßçprincipled approachÔºå‰æø‰∫éÊõ¥Â•ΩÂú∞Êõ¥ÁêÜÊô∫Âú∞ËÆæËÆ°ÁΩëÁªúÁªìÊûÑÊù•Ëß£ÂÜ≥‰∏ÄÂàáÁâπÊÆäÁöÑimagingÈóÆÈ¢ò„ÄÇÊàëËøëÊúüÁöÑÂ∑•‰ΩúÂú®Êâ©Â±ïËøô‰∏™ÊÄùË∑ØÊù•Ëß£ÂÜ≥‰∏Ä‰∫õÈ´òÁª¥Â∫¶ÈóÆÈ¢ò„ÄÇ‰ΩúËÄÖÔºöBihan Wen ÈìæÊé•Ôºöhttps://www.zhihu.com/question/66359919/answer/241936523 2016-2017 (2016 NIPS) Mao, Xiaojiao, Chunhua Shen, and Yu-Bin Yang. ‚ÄúImage restoration using very deep convolutional encoder-decoder networks with symmetric skip connections.‚Äù Advances in neural information processing systems. 2016. (2017 DnCNN) Zhang, Kai, et al. ‚ÄúBeyond a gaussian denoiser: Residual learning of deep cnn for image denoising.‚Äù IEEE Transactions on Image Processing 26.7 (2017): 3142-3155. code ResNet+BNÁÆÄÂçïÊúâÊïà„ÄÇ NTIRE 2019 Challenge on Real Image Denoising: Methods and Results ÁúüÂÆûÂô™Â£∞ÂéªÂô™ÊñáÁåÆÁªºËø∞ (2016 CVPR) Nam, Seonghyeon, et al. ‚ÄúA holistic approach to cross-channel image noise modeling and its application to image denoising.‚Äù Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016. Áî®‰πãÂâçÊèêÂà∞ÁöÑMLPËÆ≠ÁªÉÂæóÂà∞ÁúüÂÆûÂô™Â£∞ÂõæÈáåÁöÑÂô™Â£∞ÂàÜÂ∏ÉÊÉÖÂÜµ,ÁÑ∂ÂêéÁî® Bayesian Nonlocal Means FilterÁÆóÊ≥ïÂÅöÂéªÂô™ÁöÑ„ÄÇ (2017 ICCV) Xu, Jun, et al. ‚ÄúMulti-channel weighted nuclear norm minimization for real color image denoising.‚Äù Proceedings of the IEEE International Conference on Computer Vision. 2017. ËÄÉËôëÂà∞ÁúüÂÆûÂô™Â£∞ÂõæÈáåR,G,B‰∏â‰∏™ÈÄöÈÅìÁêÜÁöÑÂô™Â£∞ÂàÜÂ∏É‰∏ç‰∏ÄÊ†∑ÁöÑÊÉÖÂΩ¢,Âπ∂Âü∫‰∫é‰º†ÁªüÁöÑ‰ΩéÁß©Ê®°ÂûãÊèêÂá∫‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑÊ®°Âûã (2019 CVPR Â∑¶ËÄÅÂ∏àÁªÑÂêà)Guo, Shi, et al. ‚ÄúToward convolutional blind denoising of real photographs.‚Äù Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019. (RothËÄÅÂ∏àÁªÑÂèëË°®Âú®NeurIPS2018ÁöÑÂ∑•‰Ωúpaper+code) Tobias Pl√∂tz and Stefan Roth, Neural Nearest Neighbors Networks, Advances in Neural Information Processing Systems (NeurIPS), 2018 (2019 CVPR) Brooks, Tim, et al. ‚ÄúUnprocessing images for learned raw denoising.‚Äù Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019. ÈöæÁÇπ1: Êï∞ÊçÆÈõÜ Â§öÊ¨°ÊãçÊëÑÂèñÂπ≥Âùá‰Ωú‰∏∫ground truth (2016 A holistic approach ‚Ä¶.) Áî®ËØ•ÊñπÊ≥ïÂÅö‰∫Ü15Âº†512*512ÂõæÁâá (2018 PolyU dataset) Xu, Jun, et al. ‚ÄúReal-world noisy image denoising: A new benchmark.‚Äù arXiv preprint arXiv:1804.02603 (2018).github Áî®‰ΩéisoÂíåÈ´òisoÊù•ÊãçÊëÑÂêå‰∏ÄÂú∫ÊôØ (2017 Âæ∑ÂõΩRothÁªÑ) Plotz, Tobias, and Stefan Roth. ‚ÄúBenchmarking denoising algorithms with real photographs.‚Äù Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017. ‰∏ÄÂÖ±50Âº†Â§ßÂõæÔºåÊØèÂº†ÂàÜÂâ≤Êàê20Âº†512*512ÁöÑÂ∞èÂõæÔºåÂÖ±1000Âº† ÈöæÁÇπ2: Âô™Â£∞ÂàÜÂ∏ÉÁúüÊòØÂõæÂÉèÁöÑÂô™Â£∞Âíå‰ø°Âè∑ÊÉ≥ÂÖ≥ÔºåÈöæ‰ª•Áî®‰∏Ä‰∏™ÂàÜÂ∏ÉÊù•Ê®°Êãü„ÄÇ (2018 ECCV) Xu, Jun, Lei Zhang, and David Zhang. ‚ÄúA trilateral weighted sparse coding scheme for real-world image denoising.‚Äù Proceedings of the European Conference on Computer Vision (ECCV). 2018. ÊèêÂá∫‰∫ÜÂØπ‰∏çÂêåÁöÑÂõæÂÉèÈÄöÈÅìÂíå‰∏çÂêåÁöÑÂõæÂÉèÂø´ÈÉΩÈááÂèñ‰∏çÂêåÊñπÂ∑ÆÁöÑÈ´òÊñØÂàÜÂ∏ÉÂéªÊãüÂêàÁúüÂÆûÂô™Â£∞„ÄÇ Âô™Â£∞Á∫ßÂà´‰º∞ËÆ°ÊñáÁåÆÁªºËø∞ (2013) Liu, Xinhao, Masayuki Tanaka, and Masatoshi Okutomi. ‚ÄúSingle-image noise level estimation for blind denoising.‚Äù IEEE transactions on image processing 22.12 (2013): 5226-5237. https://arxiv.org/pdf/1712.03381.pdf Noise Level Estimation for Overcomplete Dictionary Learning Based on Tight Asymptotic Bounds https://www.itread01.com/content/1544715003.html Âü∫ÊñºpytorchÁöÑÂô™ËÅ≤‰º∞Ë®àÁ∂≤Ë∑Ø ÈóÆÈ¢ò ÊûÑÈÄ†Âô™Â£∞levelÁöÑÊó∂ÂÄôÂ¶ÇÂ¶Ç‰Ωï]]></content>
  </entry>
  <entry>
    <title><![CDATA[Ê∑±Â∫¶_Âç∑ÁßØÁ•ûÁªèÁΩëÁªú]]></title>
    <url>%2Fp%2F6a2b.html</url>
    <content type="text"><![CDATA[ÈÄöÁî®Ëøë‰ººÂÆöÁêÜÂè™ÊúâÂèÇÊï∞Ë∂≥Â§üÂ§öÔºå‰∏ÄÂ±ÇÁΩëÁªúÂèØ‰ª•Ëøë‰ºº‰ªª‰ΩïÂáΩÊï∞„ÄÇ‰ΩÜÊòØËÆ≠ÁªÉÈöæÂ∫¶Â§ßÔºåÁª¥Â∫¶ÂèØËÉΩüí•„ÄÇ Âç∑ÁßØ Âç∑ÁßØÁöÑÁâπÁÇπÔºöÂ±ÄÈÉ®ËøûÊé•„ÄÅÊùÉÂÄºÂÖ±‰∫´„ÄÅÁ©∫Èó¥ÊàñÊó∂Èó¥‰∏äÁöÑÈááÊ†∑ Âç∑ÁßØÁöÑ‰ΩúÁî®ÔºöÂáèÂ∞ëÂèÇÊï∞„ÄÅÊèêÂèñÂ±ÄÈÉ®‰∏çÂèòÊÄßÁâπÂæÅ MotivationÔºö‰∏Ä‰∏™ËßÜÁ•ûÁªèÂÖÉÁöÑÊÑüÂèóÈáéÔºåÊù•ÊøÄÊ¥ªËØ•Á•ûÁªèÂÖÉ ‰∫íÁõ∏ÂÖ≥ÊòØ‰ªÄ‰πà ÊªëÂä®Ê≠•ÈïøÂíåÂ°´ÂÖÖ ‰∏çÂêåÊªëÂä®Ê≠•ÈïøÂíåÂ°´ÂÖÖÁöÑ‰ΩúÁî® Ê†πÊçÆËæìÂá∫ÈïøÂ∫¶ÔºöÁ™ÑÂç∑ÁßØ„ÄÅÁ≠âÂÆΩÂç∑Êú∫ Âç∑ÁßØÁΩëÁªúÁöÑÁªìÊûÑÁî®Âç∑Êú∫Â±Ç‰ª£ÊõøÂÖ®ËøûÊé•ÁΩëÁªú„ÄÇ Reference: CNN‰∏≠Âç∑ÁßØÂ±ÇÁöÑËÆ°ÁÆóÁªÜËäÇ„ÄÅÂç∑ÁßØÂ±Ç‰∏éÊ±†ÂåñÂ±Ç„ÄÅÊ±†ÂåñÂ±ÇÁöÑÂÆûÁé∞„ÄÅÂèçÂêë‰º†Êí≠ Âç∑Êú∫Â±ÇÁöÑÁâπÁÇπÔºöÂ±ÄÈÉ®ÊÑüÁü•„ÄÅÂèÇÊï∞ÂÖ±‰∫´„ÄÅÊ±†Âåñ Ê±áËÅöÂ±Ç/Ê±†ÂåñÂ±Ç/poolÂ±ÇÂáèÂ∞ëÁ•ûÁªèÂÖÉ‰∏™Êï∞„ÄÇÊ±†ÂåñÂ±ÇÁöÑËæìÂÖ•‰∏ÄËà¨Êù•Ê∫ê‰∫é‰∏ä‰∏Ä‰∏™Âç∑ÁßØÂ±ÇÔºå‰∏ªË¶Å‰ΩúÁî®ÊòØÊèê‰æõ‰∫ÜÂæàÂº∫ÁöÑÈ≤ÅÊ£íÊÄßÔºà‰æãÂ¶Çmax-poolingÊòØÂèñ‰∏ÄÂ∞èÂùóÂå∫Âüü‰∏≠ÁöÑÊúÄÂ§ßÂÄºÔºåÊ≠§Êó∂Ëã•Ê≠§Âå∫Âüü‰∏≠ÁöÑÂÖ∂‰ªñÂÄºÁï•ÊúâÂèòÂåñÔºåÊàñËÄÖÂõæÂÉèÁ®çÊúâÂπ≥ÁßªÔºåpoolingÂêéÁöÑÁªìÊûú‰ªç‰∏çÂèòÔºâÔºåÂπ∂‰∏îÂáèÂ∞ë‰∫ÜÂèÇÊï∞ÁöÑÊï∞ÈáèÔºåÈò≤Ê≠¢ËøáÊãüÂêàÁé∞Ë±°ÁöÑÂèëÁîü„ÄÇÊ±†ÂåñÂ±Ç‰∏ÄËà¨Ê≤°ÊúâÂèÇÊï∞ÔºåÊâÄ‰ª•ÂèçÂêë‰º†Êí≠ÁöÑÊó∂ÂÄôÔºåÂè™ÈúÄÂØπËæìÂÖ•ÂèÇÊï∞Ê±ÇÂØºÔºå‰∏çÈúÄË¶ÅËøõË°åÊùÉÂÄºÊõ¥Êñ∞„ÄÇ bottle layer/1*1Âç∑ÁßØÔºüÈôçÁª¥ Dropout?https://zhuanlan.zhihu.com/p/38200980 https://blog.csdn.net/stdcoutzyx/article/details/49022443 ÂèçÂç∑ÁßØËΩ¨ÁΩÆÂç∑Êú∫Ôºö‰ΩéÁª¥ÁâπÂæÅÂà∞È´òÁª¥ÁâπÂæÅÔºüÂèçÂç∑ÁßØ ËæìÂá∫Áª¥Â∫¶ÁöÑÂ§ßÂ∞èÔºö ÂáΩÊï∞Ôºö 123456789101112class torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1)##in_channels(int) ‚Äì ËæìÂÖ•‰ø°Âè∑ÁöÑÈÄöÈÅìÊï∞out_channels(int) ‚Äì Âç∑ÁßØ‰∫ßÁîüÁöÑÈÄöÈÅìÊï∞kerner_size(int or tuple) - Âç∑ÁßØÊ†∏ÁöÑÂ§ßÂ∞èstride(int or tuple,optional) - Âç∑ÁßØÊ≠•ÈïøÔºåÂç≥Ë¶ÅÂ∞ÜËæìÂÖ•Êâ©Â§ßÁöÑÂÄçÊï∞„ÄÇpadding(int or tuple, optional) - ËæìÂÖ•ÁöÑÊØè‰∏ÄÊù°ËæπË°•ÂÖÖ0ÁöÑÂ±ÇÊï∞ÔºåÈ´òÂÆΩÈÉΩÂ¢ûÂä†2*paddingoutput_padding(int or tuple, optional) - ËæìÂá∫ËæπË°•ÂÖÖ0ÁöÑÂ±ÇÊï∞ÔºåÈ´òÂÆΩÈÉΩÂ¢ûÂä†paddinggroups(int, optional) ‚Äì ‰ªéËæìÂÖ•ÈÄöÈÅìÂà∞ËæìÂá∫ÈÄöÈÅìÁöÑÈòªÂ°ûËøûÊé•Êï∞bias(bool, optional) - Â¶ÇÊûúbias=TrueÔºåÊ∑ªÂä†ÂÅèÁΩÆdilation(int or tuple, optional) ‚Äì Âç∑ÁßØÊ†∏ÂÖÉÁ¥†‰πãÈó¥ÁöÑÈó¥Ë∑ù Á©∫Ê¥ûÂç∑Êú∫ÁõÆÁöÑÂ¢ûÂä†ËæìÂá∫ÂçïÂÖÉÁöÑÊÑüÂèóÈáéÔºåÈÄöËøáÂ¢ûÂä†Á©∫Ê¥ûÊù•Â¢ûÂä†Â§ßÂ∞è„ÄÇ (Â¶Ç‰ΩïÂ¢ûÂ§ßÊÑüÂèóÈáéÔºöÂ¢ûÂ§ßÂç∑Êú∫Ê†∏Â§ßÂ∞èÔºåÂ¢ûÂä†Ê∑±Â∫¶ÔºåÂÜçÂç∑Êú∫‰πãÂâçËøõË°åÊ±áËÅöÊìç‰Ωú) concat/ f= [a,b,c,d]12outputs = [branch1, branch2, branch3, branch4]return torch.cat(outputs, 1) # ÊåâÁÖßÁª¥Êï∞1ËøõË°åÊãºÊé•ÔºåÊåâÂàóÊãºÊé•„ÄÇ batch normalization?‰∏äÈááÊ†∑ Âú®Â∫îÁî®Âú®ËÆ°ÁÆóÊú∫ËßÜËßâÁöÑÊ∑±Â∫¶Â≠¶‰π†È¢ÜÂüüÔºåÁî±‰∫éËæìÂÖ•ÂõæÂÉèÈÄöËøáÂç∑ÁßØÁ•ûÁªèÁΩëÁªú(CNN)ÊèêÂèñÁâπÂæÅÂêéÔºåËæìÂá∫ÁöÑÂ∞∫ÂØ∏ÂæÄÂæÄ‰ºöÂèòÂ∞èÔºåËÄåÊúâÊó∂Êàë‰ª¨ÈúÄË¶ÅÂ∞ÜÂõæÂÉèÊÅ¢Â§çÂà∞ÂéüÊù•ÁöÑÂ∞∫ÂØ∏‰ª•‰æøËøõË°åËøõ‰∏ÄÊ≠•ÁöÑËÆ°ÁÆó(e.g.:ÂõæÂÉèÁöÑËØ≠‰πâÂàÜÂâ≤)ÔºåËøô‰∏™ÈááÁî®Êâ©Â§ßÂõæÂÉèÂ∞∫ÂØ∏ÔºåÂÆûÁé∞ÂõæÂÉèÁî±Â∞èÂàÜËæ®ÁéáÂà∞Â§ßÂàÜËæ®ÁéáÁöÑÊò†Â∞ÑÁöÑÊìç‰ΩúÔºåÂè´ÂÅö‰∏äÈááÊ†∑(Upsample)„ÄÇ ‰∏äÈááÊ†∑Êúâ3ÁßçÂ∏∏ËßÅÁöÑÊñπÊ≥ïÔºöÂèåÁ∫øÊÄßÊèíÂÄº(bilinear)ÔºåÂèçÂç∑ÁßØ(Transposed Convolution)ÔºåÂèçÊ±†Âåñ(Unpooling)ÔºåÊàë‰ª¨ËøôÈáåÂè™ËÆ®ËÆ∫ÂèçÂç∑ÁßØ„ÄÇËøôÈáåÊåáÁöÑÂèçÂç∑ÁßØÔºå‰πüÂè´ËΩ¨ÁΩÆÂç∑ÁßØÔºåÂÆÉÂπ∂‰∏çÊòØÊ≠£ÂêëÂç∑ÁßØÁöÑÂÆåÂÖ®ÈÄÜËøáÁ®ãÔºåÁî®‰∏ÄÂè•ËØùÊù•Ëß£ÈáäÔºö ÂèÇËÄÉ https://zhuanlan.zhihu.com/p/67907490 https://zhuanlan.zhihu.com/p/48501100 ÊèíÂÄºÊ≥ï ÊúÄËøëÈÇªÊèíÂÄº(Nearest neighbor interpolation) ÂèåÁ∫øÊÄßÊèíÂÄº(Bi-Linear interpolation) ÂèåÁ´ãÊñπÊèíÂÄº(Bi-Cubic interpolation) Âç∑ÁßØÁΩëÁªú‰∏≠ÁöÑÂèçÂêë‰º†Êí≠ Êõ¥Êñ∞W Êõ¥Êñ∞b ËÆ°ÁÆóÂèçÂêëËØØÂ∑Æ Ê±†ÂåñÂ±ÇÁöÑÊ±ÇÂØºÔºöÊ±†ÂåñÂ±Ç‰∏ÄËà¨Ê≤°ÊúâÂèÇÊï∞ÔºåÊâÄ‰ª•ÂèçÂêë‰º†Êí≠ÁöÑÊó∂ÂÄôÔºåÂè™ÈúÄÂØπËæìÂÖ•ÂèÇÊï∞Ê±ÇÂØºÔºå‰∏çÈúÄË¶ÅËøõË°åÊùÉÂÄºÊõ¥Êñ∞„ÄÇ max-pooling mean-pooling Âá†‰∏™ÈáçË¶ÅÁöÑÂç∑ÁßØÁ•ûÁªè CNNÂèëÂ±ïËá≥‰ªäÔºåÂ∑≤ÁªèÊúâÂæàÂ§öÂèòÁßçÔºåÂÖ∂‰∏≠ÊúâÂá†‰∏™ÁªèÂÖ∏Ê®°ÂûãÂú®CNNÂèëÂ±ïÂéÜÁ®ã‰∏≠ÊúâÁùÄÈáåÁ®ãÁ¢ëÁöÑÊÑè‰πâÔºåÂÆÉ‰ª¨ÂàÜÂà´ÊòØÔºöLeNet„ÄÅAlexnet„ÄÅGooglenet„ÄÅVGG„ÄÅDRLÁ≠â LeNet, 1998 ÂèÇËÄÉÊñáÁåÆ Ann LeCun Âú®1998Âπ¥ÂèëË°®‰∫ÜÂÖ≥‰∫éLeNetÁöÑÁªèÂÖ∏ËÆ∫Êñá„ÄäGradient-Based Learning Applied to Document Recognition „ÄãÁî®‰∫éËØÜÂà´ÊîØÁ•®‰∏äÁöÑÊâãÂÜôÂ≠ó‰Ωì Â§ßËØùCNNÁªèÂÖ∏Ê®°ÂûãÔºöLeNet ÂéüËÆ∫Êñá‰ª£Á†ÅÂ§çÁé∞: tiny-dnn/tiny-dnn„ÄÅÁÆÄÂåñÁâàÊú¨(‰∏ªË¶Å‰ΩìÁé∞Âú®ËØÑËÆ∫Âå∫ËØ¥ÁöÑs2Âà∞c3ÁöÑËøáÁ®ã‰∏ä, Âéüpaper‰πãÊâÄ‰ª•ÈÇ£Ê†∑ÂÆûÁé∞Ôºå‰πüÊòØÂèóÈôê‰∫éÂΩìÊó∂ÁöÑËÆ°ÁÆóËµÑÊ∫ê„ÄÇÁé∞ÁÆÄÂåñÁâàÊú¨‰πüÁ¨¶ÂêàpytorchÁöÑÂÆûÁé∞Ê°ÜÊû∂„ÄÇ) ÁΩëÁªúÁªìÊûÑ S2ÔºåS4: Âú®Ê±áËÅöÂ±Ç‰ΩøÁî®ÈùûÁ∫øÊÄßÊøÄÊ¥ªÂáΩÊï∞$Y^{\prime d}=f\left(w^{d} \cdot Y^{d}+b^{d}\right)$„ÄÇÂõ†Ê≠§ÔºåÂú®Ê±áËÅöÂ±Ç‰πüÊúâ‰∏§‰∏™ÂèÇÊï∞ÈúÄË¶ÅËÆ≠ÁªÉ„ÄÇ C3Â±Ç‰ΩøÁî®‰∫Ü‰∏Ä‰∏™Â±ÄÈÉ®ËøûÊé•Ôºö ‚Äã F6Â±ÇÔºö84‰∏™Á•ûÁªèÂÖÉÔºåÂèØÁªÑÊàê‰∏ÄÂº†7*12ÁöÑÁâπÂæÅÂõæÂÉèÔºåÂèØ‰ª•ÂØπ‰∏çÂêåÁöÑÂ≠ó‰ΩìËøõË°åÁºñÁ†Å ‚Äã ËæìÂá∫Â±ÇÔºö $y_{i}=\sum_{i}\left(x_{j}-w_{i j}\right)^{2}$ ÊøÄÊ¥ªÂáΩÊï∞Ôºö AlexNet, 2012 ReferenceÔºöËÆ∫ÊñáËß£ËØª„ÄÅ AlexNetËµ¢Âæó‰∫Ü2012 Âπ¥ ImageNetÂõæÂÉèÂàÜÁ±ªÁ´ûËµõÁöÑÂÜ†ÂÜõ Á™ÅÁ†¥ÁÇπÔºöBigData+GPU ËøõË°åÂπ∂Ë°åËÆ≠ÁªÉÔºåÈááÁî®‰∫Ü ReLU ‰Ωú‰∏∫ÈùûÁ∫øÊÄßÊøÄÊ¥ªÂáΩÊï∞Ôºå‰ΩøÁî® Dropout Èò≤Ê≠¢ËøáÊãüÂêàÔºå‰ΩøÁî®Êï∞ÊçÆÂ¢ûÂº∫Êù•ÊèêÈ´òÊ®°ÂûãÂáÜÁ°ÆÁéáÁ≠â„ÄÇ ÊøÄÊ¥ªÂáΩÊï∞ÔºöReLUÔºåÁ∫øÊÄßÊï¥ÊµÅÂáΩÊï∞ÔºàRectified Linear Unit, ReLUÔºâÔºåÂèàÁß∞‰øÆÊ≠£Á∫øÊÄßÂçïÂÖÉ $\max \left(0, \mathbf{w}^{T} \mathbf{x}+b\right)$ AlexNet‰∏≠ÁöÑPoolingÊòØÈáçÂè†ÁöÑÔºåÊØèÊ¨°Âèñ3 * 3ÁöÑÂÉèÁ¥†ÂÅöMax-PoolingÔºåÁÑ∂ÂêéÊØèÊ¨°Âè™Ë∂äËøá2Ê†ºÔºåËøôÊ†∑ÊØè‰∏™Pooling‰πãÈó¥ÈÉΩ‰ºöÊúâ‰∏ÄÂÆöÂæóÈáçÂè†ÔºåÊúâÂà©‰∫éÊõ¥Â•ΩÂú∞ÂÖãÊúçËøáÊãüÂêà ÂáèÂ∞ëËøáÊãüÂêà Data Augmentation Dropout Googlenet, 2014 Reference: ‰ª£Á†Å„ÄÅInceptionÁöÑÂèëÂ±ï won ImageNet 2014. InceptionÁªìÊûÑ ÁΩëÁªúÁªìÊûÑ ‰∏§‰∏™ËæÖÂä©ÁöÑsoftmaxÂàÜÊîØÔºå‰ΩúÁî®Êúâ‰∏§ÁÇπÔºå‰∏ÄÊòØ‰∏∫‰∫ÜÈÅøÂÖçÊ¢ØÂ∫¶Ê∂àÂ§±ÔºåÁî®‰∫éÂêëÂâç‰º†ÂØºÊ¢ØÂ∫¶„ÄÇÂèçÂêë‰º†Êí≠Êó∂Â¶ÇÊûúÊúâ‰∏ÄÂ±ÇÊ±ÇÂØº‰∏∫0ÔºåÈìæÂºèÊ±ÇÂØºÁªìÊûúÂàô‰∏∫0„ÄÇ‰∫åÊòØÂ∞Ü‰∏≠Èó¥Êüê‰∏ÄÂ±ÇËæìÂá∫Áî®‰ΩúÂàÜÁ±ªÔºåËµ∑Âà∞Ê®°ÂûãËûçÂêà‰ΩúÁî®„ÄÇ VGG(ÂæÖË°•ÂÖÖ)ResNet Reference He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition. InProceedings of the IEEE conference on computer vision and pattern recognition 2016 (pp. 770-778). Identity Mappings in Deep Residual Networks 1202Â±ÇÁöÑResNetÂá∫Áé∞‰∫ÜËøáÊãüÂêàÁöÑÈóÆÈ¢òÔºåÊúâÂæÖËøõ‰∏ÄÊ≠•ÊîπËøõ„ÄÇÁ¨¨‰∫åÂπ¥Ôºå‰ΩïÁöÑÂõ¢ÈòüÂàÜÊûê‰∫ÜResNetÊàêÂäüÁöÑÂÖ≥ÈîÆÂõ†Á¥†‚Äî‚Äîresidual blockËÉåÂêéÁöÑÁÆóÊ≥ïÔºåÂπ∂ÂØπresidual block‰ª•Âèäafter-addition activationËøõË°åÊîπËøõÔºåÈÄöËøá‰∏ÄÁ≥ªÂàóÁöÑablation experimentsÈ™åËØÅ‰∫ÜÔºåÂú®residual blockÂíåafter-addition activation‰∏äÈÉΩ‰ΩøÁî®identity mappingÔºàÊÅíÁ≠âÊò†Â∞ÑÔºâÊó∂ÔºåËÉΩÂØπÊ®°ÂûãËÆ≠ÁªÉ‰∫ßÁîüÂæàÂ•ΩÁöÑÊïàÊûúÔºåÈÄöËøáËøôÈ°πÊîπËøõÔºå‰πüÊàêÂäüÁöÑËÆ≠ÁªÉÂá∫‰∫ÜÂÖ∑ÊúâÂæàÂ•ΩÊïàÊûúÁöÑResNet-1001„ÄÇ ‰∏∫‰ªÄ‰πàË¶Åskip connectÔºåÊ∑±Â±ÇÁΩëÁªúÈöæ‰ª•ËÆ≠ÁªÉÁöÑÊ†πÊú¨ÂéüÂõ†‰∏çÊòØÊèêÈÄüÊ∂àÂ§± ‰∏∫‰ªÄ‰πàResidualÁΩëÁªúÊïàÊûúÂ•ΩÁöÑÂéüÂõ†ÔºåÊúâÂæàÂ§öËÆ∫ÊñáÂú®ÂàÜÊûê ‰ΩïÊÅ∫ÊòéÁöÑtutorial(https://icml.cc/2016/tutorials/icml2016_tutorial_deep_residual_networks_kaiminghe.pdf) ResNet, 2015, ÂæÆËΩØ‰∫öÊ¥≤Á†îÁ©∂Èô¢ÁöÑ‰ΩïÂáØÊòéÁ≠â‰∫∫ÊèêÂá∫ ‰∏ªË¶ÅË¥°ÁåÆÔºöÁΩëÁªúÂ±ÇÊï∞‰ªé32Â±ÇÊèêÂà∞152Â±Ç ÁâπÁÇπÔºö ÁΩëÁªúËæÉÁò¶ÔºåÊéßÂà∂‰∫ÜÂèÇÊï∞Êï∞ÈáèÔºõ Â≠òÂú®ÊòéÊòæÂ±ÇÁ∫ßÔºåÁâπÂæÅÂõæ‰∏™Êï∞ÈÄêÂ±ÇÈÄíËøõÔºå‰øùËØÅËæìÂá∫ÁâπÂæÅË°®ËææËÉΩÂäõÔºõ ‰ΩøÁî®‰∫ÜËæÉÂ∞ëÁöÑÊ±†ÂåñÂ±ÇÔºåÂ§ßÈáè‰ΩøÁî®‰∏ãÈááÊ†∑ÔºåÊèêÈ´ò‰º†Êí≠ÊïàÁéáÔºõ Ê≤°Êúâ‰ΩøÁî®DropoutÔºåÂà©Áî®BNÂíåÂÖ®Â±ÄÂπ≥ÂùáÊ±†ÂåñËøõË°åÊ≠£ÂàôÂåñÔºåÂä†Âø´‰∫ÜËÆ≠ÁªÉÈÄüÂ∫¶Ôºõ Â±ÇÊï∞ËæÉÈ´òÊó∂ÂáèÂ∞ë‰∫Ü3x3Âç∑ÁßØ‰∏™Êï∞ÔºåÂπ∂Áî®1x1Âç∑ÁßØÊéßÂà∂‰∫Ü3x3Âç∑ÁßØÁöÑËæìÂÖ•ËæìÂá∫ÁâπÂæÅÂõæÊï∞ÈáèÔºåÁß∞ËøôÁßçÁªìÊûÑ‰∏∫‚ÄúÁì∂È¢à‚Äù(bottleneck)„ÄÇ ÊÆãÂ∑ÆÂçïÂÖÉÔºö ÂÖãÊúç‰∫ÜÊ¢ØÂ∫¶Ê∂àÂ§±ÁöÑÈóÆÈ¢ò„ÄÇDRNÊÄéÊ†∑Ëß£ÂÜ≥‰∫ÜÊ¢ØÂ∫¶Ê∂àÂ§±ÈóÆÈ¢òÔºü UnetÔºå ÁΩëÁªúÁªìÊûÑ Âè≥ËæπÊúâ‰∏äÈááÊ†∑Ôºö ‰∏äÈááÊ†∑ÁöÑÊñπÊ≥ï ÈóÆÈ¢ò Âè†Âä†ÁöÑÊó∂ÂÄôconcat‰∏∫‰ªÄ‰πàÂú®Áª¥Â∫¶1 https://blog.csdn.net/u012193416/article/details/79479935 https://blog.csdn.net/qq_39709535/article/details/80803003]]></content>
  </entry>
  <entry>
    <title><![CDATA[Ê∑±Â∫¶_ÂèØËß£ÈáäÁΩëÁªú]]></title>
    <url>%2Fp%2F43c9.html</url>
    <content type="text"><![CDATA[ÂèÇËÄÉÊñáÁåÆ The Building Blocks of Interpretability https://arxiv.org/abs/1901.02413 https://arxiv.org/abs/1602.04938 https://arxiv.org/abs/1806.10574 http://www.vision.ee.ethz.ch/ntire18/ ‰ºöËÆÆÈìæÊé•]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Fp%2F0.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Fp%2F0.html</url>
    <content type="text"><![CDATA[K-means Â≠óÂÖ∏Â≠¶‰π†K-SVD Â≠óÂÖ∏Â≠¶‰π†]]></content>
  </entry>
  <entry>
    <title><![CDATA[tight frameÂéªÂô™ÂíåKSVD]]></title>
    <url>%2Fp%2F9719.html</url>
    <content type="text"><![CDATA[ReferenceCai, J. F., Ji, H., Shen, Z., &amp; Ye, G. B. (2014). Data-driven tight frame construction and image denoising. Applied and Computational Harmonic Analysis, 37(1), 89-105. ÁÆóÊ≥ïÊ°ÜÊû∂ÂíåKSVDÁöÑÂÖ≥Á≥ª Ê†∏ÂøÉÊØîËæÉ ‰∏éK-SVDÁöÑÊØîËæÉ There are images on which the K-SVD method performed better and there are some on which our approaches performed better. Overall, the performances of our proposed method and the K-SVD method are comparable in terms of PSNR value, and so is the visual quality.]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Ê∑±Â∫¶_Unet]]></title>
    <url>%2Fp%2Fc0c5.html</url>
    <content type="text"><![CDATA[ÂõæÂÉèËØ≠‰πâÂàÜÂâ≤ ÂõæÂÉèÂàÜÂâ≤ÁªºËø∞ U-net Reference Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. ‚ÄúU-net: Convolutional networks for biomedical image segmentation.‚Äù International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015. U-NetËÆ∫Êñá„ÄÅU-NetËÆ∫ÊñáÁ¨îËÆ∞„ÄÅU-NetËÆ∫ÊñáÁ¨îËÆ∞„ÄÅU-NetËÆ∫ÊñáÁ¨îËÆ∞Áü•‰πé ÁΩëÁªúÁªìÊûÑ ÂêÑÂ±Ç‰ΩúÁî® convÔºö poolÔºö up-convÔºö conv 1*1Ôºö Reference: CNN‰∏≠Âç∑ÁßØÂ±ÇÁöÑËÆ°ÁÆóÁªÜËäÇ„ÄÅÂç∑ÁßØÂ±Ç‰∏éÊ±†ÂåñÂ±Ç„ÄÅÊ±†ÂåñÂ±ÇÁöÑÂÆûÁé∞„ÄÅÂèçÂêë‰º†Êí≠ upÔºådownsampleÔºådeconvolutionÔºå batch normalization‚Ä¶ normalizationÊúâÂæàÂ§öÊñπÊ≥ïÔºåVGG-NetÔºåStride ÂèçÂç∑ÁßØÔºöhttps://blog.csdn.net/Fate_fjh/article/details/52882134 CodeÈìæÊé• ‰ª£Á†ÅÂàÜÊûê Attention U-net Key Idea: Produce foreground masks via feature maps to filter out backgournd information ÂÖ≥Ê≥®ÁÇπÂú®ÂâçÊôØÔºåÊØîUnetÂ§ö‰∫Üattention gate Unet Attention Unet Regularized UNet for Automated Pancreas Segmentation‰∏çÂêåUnetÁöÑÂØπÊØî Holistically-nested Convolutional Neural NetworksHierarchical 3D fully Convolutional Networks for Multi-organ SegmentationA Fixed-Point Model for Pancreas Segmentation in Abdominal CT ScansA 3D Coarse-to-Fine Framework for Volumetric Medical Image SegmentationFully Automated Pancreas Segmentation with Two-stage 3D Convolutional Neural NetworksËÉ∞ËÑèÂàÜÂâ≤‰ªécoarseÂà∞fine Attention U-netÔºö ÂÖ≥Ê≥®ÁÇπÂú®ÂâçÊôØÔºåÊØîUnetÂ§ö‰∫Üattention gate]]></content>
  </entry>
  <entry>
    <title><![CDATA[ÂíñÂï°]]></title>
    <url>%2Fp%2Facef.html</url>
    <content type="text"><![CDATA[ÂíñÂï°ÁöÑÈÖçÊñπÊâìÂ•∂https://www.youtube.com/watch?v=-kvY2AmbLOE ÊãøÈìÅ„ÄÅÊãâËä± https://www.youtube.com/watch?v=h3S_ClRFxX4]]></content>
      <categories>
        <category>ÁîüÊ¥ª</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ÁΩëÁªúÂèØËßÜÂåñ]]></title>
    <url>%2Fp%2Fe804.html</url>
    <content type="text"><![CDATA[tensorboardÂà©Áî®tensorboardÁîªÂõæ ÈÄöËøáloggerÊñá‰ª∂ÂèØËßÜÂåñËÆ≠ÁªÉËøáÁ®ã„ÄÅÂÆòÁΩë„ÄÅÂà´‰∫∫ÂÜôÁöÑtensorflow‰∏ãÊØîËæÉÂÖ∑‰ΩìÁöÑÂèØËßÜÂåñ Âá∫Áé∞ÁöÑÈóÆÈ¢ò Á´ØÂè£ÂÜ≤Á™ÅÈÄöËøáÊåáÂÆöÁ´ØÂè£Ëß£ÂÜ≥Ôºö 12tensorboard --logdir=/tmp --port=8008 #ÁªùÂØπË∑ØÂæÑtensorboard --logdir=./tmp --port=8008 #Áõ∏ÂØπË∑ØÂæÑ tensorbardÂëΩ‰ª§Êó†Ê≥ïÊâæÂà∞Ôºö 1python3 -m tensorboard.main --logdir=~/my/training/dir ËøõÂÖ•ÁõÆÂΩïÔºö 123pip show tensorflowcd /home/abc/xy/.local/lib/python2.7/site-packagespython main.py --logdir=/path/to/log_file/ Ë∑ØÂæÑÁöÑÂêçÁß∞Ë¶ÅÂ∞èÂøÉÔºåË∑ØÂæÑÂæóÊòØÊ†πÁõÆÂΩï, ‰∏çÈúÄË¶ÅÂºïÂè∑ 1yyfang@mai:~$ ge/ERRNet_Code/logs --port=8008 ÂèØËßÜÂåñ 1234567891011121314151617181920212223242526272829303132if iteration % 100 == 0: print("===&gt; Epoch[&#123;&#125;](&#123;&#125;/&#123;&#125;): Loss: &#123;:.6f&#125;".format(epoch, iteration, len(training_data_loader),loss.data.item())) info = &#123; 'loss': loss.data.item()&#125; itera = (epoch-1)*len(training_data_loader)+iteration for tag, value in info.items(): logger.scalar_summary(tag, value, itera) for tag, value in model.named_parameters(): # print(value.grad) logger.histo_summary(tag, to_np(value), itera) logger.histo_summary(tag+'/grad', to_np(value.grad), iteration) images = input * 255. # ?[0,1]?????[0,255]?? images[images &lt; 0] = 0 images[images &gt; 255.] = 255. a =to_np(images.view(-1, 64, 64)[:8]) # info_input = &#123;'input': to_np(images.view(-1, 64, 64)[:2])&#125; imagelabel = label * 255. # ?[0,1]?????[0,255]?? imagelabel[imagelabel &lt; 0] = 0 imagelabel[imagelabel &gt; 255.] = 255. b = to_np(imagelabel.view(-1, 64, 64)[:8]) c = np.hstack((a,b)) # print(images) info_label = &#123;'inpput/label': c&#125; for tag, images in info_label.items(): logger.image_summary(tag, images, itera) # for tag, images in info_label.items(): # logger.image_summary(tag, images, iteration) if iteration % 5000 == 0: number = opt.number save_checkpoint_iter(model, number) opt.number += 1]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Fp%2F0.html</url>
    <content type="text"><![CDATA[K-SVD K-means SVD ËÆ∫Êñá [11] M. Elad, M. Ahron, Image denoising via sparse and redundant representations over learned distionaries, IEEE Trans. on Image Processing 54 (12) (2006) 3736‚Äì3745. 2013_tight frameÊØîËæÉÁöÑËøôÁØá ÁÆóÊ≥ïÊ°ÜÊû∂ ÁÆóÊ≥ïÊ°ÜÊû∂ ÊØîËæÉ K-SVDÂíåtight frameÁöÑÂÖ≥Á≥ª psnr, ksvdÊúÄ‰Ω≥ÔºåËßÜËßâÊïàÊûúÔºåadaptive tiggt frameÊõ¥È´ò„ÄÇ‰∏§ËÄÖÊØîËæÉÁªìÊûúÂú®ÂêéËÄÖÁöÑÊñáÁ´†‰∏≠ÈòêËø∞‰∫Ü„ÄÇ Reference [11] M. Elad, M. Ahron, Image denoising via sparse and redundant representations over learned distionaries, IEEE Trans. on Image Processing 54 (12) (2006) 3736‚Äì3745. 2013_tight frameÊØîËæÉÁöÑËøôÁØá ÊúÄÂÖàÊèêÂá∫KSVD Aharon, M., Elad, M., &amp; Bruckstein, A. (2006). K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation. IEEE Transactions on signal processing, 54(11), 4311-4322. ËÆ∫ÊñáÁöÑËß£ËØª‰ª•ÂèäÂ∫îÁî® EricÁöÑ‰∏™‰∫∫ÁΩëÈ°µ https://elad.cs.technion.ac.il/software/ KSVDÁöÑÁΩëÈ°µ: http://www.cs.technion.ac.il/~ronrubin/software.html Matlab tool‰∏≠ÁöÑ‰ªãÁªç http://www.ux.uis.no/~karlsk/dle/ Code https://github.com/Deepayan137/K-svd https://github.com/jbhuang0604/SelfSimSR/tree/master/Lib/KSVD]]></content>
  </entry>
  <entry>
    <title><![CDATA[ÊúçÂä°Âô®ÂíåÊú¨Âú∞Êñá‰ª∂ÂÖ±‰∫´]]></title>
    <url>%2Fp%2Ff933.html</url>
    <content type="text"><![CDATA[ÊúçÂä°Âô®‰∏äËÆøÈóÆÊú¨Âú∞Êñá‰ª∂(Â±ÄÂüüÁΩë)Â∞öÊú™ÂÆûÁé∞ Êú¨Âú∞ÁîµËÑëËÆøÈóÆÊúçÂä°Âô® ÊñπÊ≥ï‰∏ÄÔºöÂÆâË£ÖsambaÊúçÂä° Ubuntu 16.04ÂÆâË£ÖÈÖçÁΩÆSambaÊúçÂä° Mac‰∏äÁöÑËøûÊé•ÊñπÊ≥ï ÊúçÂä°Âô®‰∏äÈÖçÁΩÆsambaÊúçÂä° ÊñπÊ≥ï‰∫å[ÊúÄÁÆÄÊòì]ÔºösshfsÂÆ¢Êà∑Á´ØÁõ¥Êé•ÂÆâË£Ö ÂÆâË£ÖFUSE for MacÂíåSSHFSÂÆ¢Êà∑Á´Ø ‰∏ãËΩΩÈìæÊé•Ôºöhttps://osxfuse.github.io/ ÊµãËØïsshfs ‰ΩøÁî®sshfsËøõË°åÊåÇËΩΩ ÂàõÂª∫Êú¨Âú∞Êñá‰ª∂Â§πServer sshfs yyfang@mai.math.cuhk.edu.hk:/home/yyfang Server ÁªàÊ≠¢ÊåÇËΩΩ umount Server ‰∏∫‰∫ÜÁÆÄÂåñÂëΩ‰ª§ÔºåÊñπ‰æøÊåÇËΩΩÔºåÊîπ‰∏Ä‰∏ã~/.ssh/config 1open ~/.ssh/config Âú®Êñá‰ª∂‰∏≠Ê∑ªÂä†Ôºö 1234Host []//ServerHostname ]mai.math.cuhk.edu.hkUser yyfangPort 22 ÁÆÄÂåñÂêéÁöÑÂëΩ‰ª§ 12ssh Serversshfs Server: Server ÊñπÊ≥ï‰∏âÔºösshfsÔºåÊåâÁÖßgithubÁöÑÊ≠•È™§ÂÆâË£Ö Reference Â¶Ç‰Ωï‰ªéMac OSËÆøÈóÆUbuntuÊúçÂä°Âô®‰∏äÁöÑÂÖ±‰∫´Êñá‰ª∂Â§πÔºü Âà©Áî® ssh ÁöÑÁî®Êà∑ÈÖçÁΩÆÊñá‰ª∂ config ÁÆ°ÁêÜ ssh ‰ºöËØù ÈóÆÈ¢ò Â¶ÇÊûúÂá∫Áé∞ÊúçÂä°Âô®Ê≤°ÂèçÂ∫îÁöÑÊÉÖÂÜµ 1.È¶ñÂÖà 123 sudo diskutil umount force ÊàñËÄÖ sudo umount Server 2.Ê£ÄÊü•ÁΩëÁªúÔºåÁúãÁúãÂÖ∂‰ªñsshÊúçÂä°ËÉΩÂê¶ÊàêÂäü 3.ÈáçÊñ∞ÊåÇËΩΩ Âá∫Áé∞Êó†Ê≥ïumountÁöÑÊÉÖÂÜµ https://github.com/osxfuse/osxfuse/issues/45 Âá∫Áé∞pn-206-40ÁöÑÊÉÖÂÜµÔºàÊú™Êü•ÊòéÔºâ 12Last login: Thu Sep 5 23:51:46 on ttys001pn-206-40:~ yyf$ c Âá∫Áé∞ Input/output error]]></content>
      <categories>
        <category>Ê∑±Â∫¶Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>ÊúçÂä°Âô®</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Graph model]]></title>
    <url>%2Fp%2F3b7a.html</url>
    <content type="text"><![CDATA[Opening‰ªäÂ§©ÊàëËÆ≤ÁöÑÂÜÖÂÆπÊòØÁ¨¨ÂçÅÂÖ≠Á´†ÔºåÂõæÊ®°Âûã„ÄÇ‰∏ªË¶ÅÂåÖÂê´‰∏â‰∏™Âü∫Êú¨ÈóÆÈ¢òÔºöÂõæÊ®°ÂûãÁöÑÁªìÊûÑ„ÄÅÊé®Êñ≠„ÄÅÂ≠¶‰π†„ÄÇË°®Á§∫ÈóÆÈ¢òÔºåÂà©Áî®ÂõæÁªìÊûÑË°®Á§∫ÂΩºÂ≤∏‰∏§‰πãÈó¥ÁöÑ‰æùËµñÂÖ≥Á≥ª Êé®Êñ≠ÈóÆÈ¢òÔºåÊé®Êñ≠È¢ÑÊµãÂèòÈáèÁöÑÂêéÈ™åÂàÜÂ∏É„ÄÇÂú®ËßÇÊµãÂà∞ÈÉ®ÂàÜÂèòÈáèeÊó∂ÂÄôÔºåËÆ°ÁÆóÂÖ∂ÂÆÉÂèòÈáèÁöÑÊüê‰∏™Â≠êÈõÜ q = {q 1 , q 2 , ¬∑ ¬∑ ¬∑ , q n } ÁöÑÂêéÈ™åÊ¶ÇÁéá p(q|e)„ÄÇ‰ª•ÂèäÂ≠¶‰π†ÈóÆÈ¢ò, ÂõæÁªìÊûÑÁöÑÂ≠¶‰π†ÂíåÂõæ‰∏≠ÂèÇÊï∞ÁöÑÂ≠¶‰π†„ÄÇ Âú®ÂâçÈù¢Âá†Âë®ÔºåÂ∑≤Áªè‰ªãÁªç‰∫Ü‰∏Ä‰∫õÊé®Êñ≠ÁöÑÊñπÊ≥ïÔºå‰ª•ÂèäÂèÇÊï∞ÁöÑÂ≠¶‰π†ÊñπÊ≥ïÔºå‰æãÂ¶ÇEMÁÆóÊ≥ï„ÄÇ‰ªäÂ§©ÔºåÊàëÂ∞ÜÈ¶ñÂÖàË°•ÂÖÖ‰∏Ä‰∏ãÂõæÁªìÊûÑÁöÑÁü•ËØÜ„ÄÇÂπ∂ÈÄöËøá‰∏æ‰æã‰∏Ä‰∫õÂÆûÈôÖÂ∫îÁî®‰æãÂ≠êÔºåÊù•ÁúãÂõæÁªìÊûÑÂ¶Ç‰ΩïÂçèÂêåÊé®Êñ≠ÂíåÂ≠¶‰π†Êù•Ëß£ÂÜ≥‰∏Ä‰∏™ÈóÆÈ¢òÔºåÂ¶ÇÂêåÂ¶ÇÊñáÊú¨ÂàÜÁ±ª„ÄÅ‰ª•ÂèäÂõæÂÉèÂéªÂô™„ÄÇ ÊúâÂêëÂõæÁªìÊûÑ ÂõæÁªìÊûÑÂàÜ‰∏∫Êó†ÂêëÂõæÂíåÊúâÂêëÂõæ ÊúâÂêëÂõæÔºöDirected Graphical modelÔºå‰πüÁß∞‰∏∫Ë¥ùÂè∂ÊñØÁΩëÁªúÔºàBayesian NetworkÔºâÔºåÊàñ‰ø°ÂøµÁΩëÁªúÔºàBelief NetworkÔºâ Êó†ÂêëÂõæÔºö ÊúâÂêëÂõæÁöÑËÅîÂêàÂàÜÂ∏É ‰ª•Âõæ(a)‰∏∫‰æãÔºåp(x1,x2,x3,x4)=p(x1)p(x2|x1)p(x3|x1,x2)p(x4|x1,x2,x3 )„ÄÇ Ê†πÊçÆÊÄßË¥®$X_{2} \perp X_{3} | X_{1}$, $p\left(x_{2} | x_{1}, x_{3}\right)=p\left(x_{2} | x_{1}\right)$, ‰ª•ÂèäÂõæÁªìÊûÑ‰∏äÁöÑÁã¨Á´ãÊÄßÔºå Êàë‰ª¨Êúâp(x2|x1)=p(x2|x1,x3) Ôºåp(x4|x3,x2)=p(x4|x3,x2,x1) Âõ†Ê≠§Âè≥ËæπÂèØ‰ª•ÁÆÄÂåñ‰∏∫p(x1)p(x2|x1 )p(x3|x1)p(x4|x2, x3) For any acyclic Bayesian network G, the joint probability distribution of X can be decomposed into a multiplicative form of the local conditional probability of each random variable X. In this graph, then the ÂØπ‰∫é‰ªªÊÑè‰∏Ä‰∏™Êó†ÁéØË¥ùÂè∂ÊñØÁΩëÁªúGÔºåX ÁöÑËÅîÂêàÊ¶ÇÁéáÂàÜÂ∏ÉÂèØ‰ª•ÂàÜËß£‰∏∫ÊØè‰∏™ÈöèÊú∫ÂèòÈáè $X_k$ ÁöÑÂ±ÄÈÉ®Êù°‰ª∂Ê¶ÇÁéáÁöÑËøû‰πòÂΩ¢Âºè p(\mathbf{x})=\prod_{k=1}^{K} p\left(x_{k} | \mathbf{x}_{\pi_{k}}\right)ÂÖ∂‰∏≠$x_{\pi k}$Ë°®Á§∫ËäÇÁÇπkÁöÑÁà∂ËäÇÁÇπ„ÄÇP(Xk|XœÄk)ÊòØÂ±ÄÈÉ®Êù°‰ª∂Ê¶ÇÁéá Ê†πÊçÆËøô‰∏™ÂÖ¨ÂºèÔºöÊàë‰ª¨ÈÅçÂéÜÂõæÔºàaÔºâ‰∏≠ÁöÑÊØè‰∏Ä‰∏™ËäÇÁÇπÔºåÂç≥ÂèØ‰ª•ÂæóÂà∞ËÅîÂêàÂàÜÂ∏É p(x)=p(x1)p(x3|x1)p(x2|x1)p(x4|x3,x2). ‚Äî‚ÄîÂíåÊàë‰ª¨‰πãÂâçÁöÑÁªìÊûú‰∏ÄÊ†∑„ÄÇ Áé∞Âú®Êàë‰ª¨Êù•ËÆ®ËÆ∫Áî®‰∏Ä‰∏™ÂõæÁªìÊûÑÊù•Ë°®Á§∫Ê¶ÇÁéáÂàÜÂ∏ÉÁöÑ‰ºòÁÇπ„ÄÇ ÂÅáËÆæX1 , X2 , X3 , X4 ÊòØ‰∫åÂÄºÂèòÈáèÔºåÂú®Ê≤°ÊúâÂõæ‰∏≠ÂèòÈáè‰æùËµñÂÖ≥Á≥ªÁöÑÊÉÖÂÜµ‰∏ãÔºåÂèØ‰ª•Áî®‰∏Ä‰∏™ËÅîÂêàÊ¶ÇÁéáË°®Êù•ÊòæÂºèÂú∞ËÆ∞ÂΩïÊØè‰∏ÄÁßçÂèñÂÄºÁöÑÊ¶ÇÁéáP(X)ÔºåÂÖ±ÈúÄË¶Å2^4 ‚àí1 = 15‰∏™ÂèÇÊï∞„ÄÇÂ¶ÇÊûúÊàë‰ª¨Áî®4 ‰∏™Ë°®Ê†ºÊù•ËÆ∞ÂΩïËøô 4 ‰∏™Â±ÄÈÉ®Êù°‰ª∂Ê¶ÇÁéáÁöÑ‰πòÁßØÔºåÂè™ÈúÄË¶Å 1 + 2 + 2 + 4 = 9 ‰∏™Áã¨Á´ãÂèÇÊï∞„ÄÇ Âõ†Ê≠§ÂΩìÊ¶ÇÁéáÊ®°Âûã‰∏≠ÁöÑÂèòÈáèÊï∞ÈáèÊØîËæÉÂ§öÊó∂ÔºåÂÖ∂Êù°‰ª∂‰æùËµñÂÖ≥Á≥ª‰πüÊØîËæÉÂ§çÊùÇ„ÄÇ‰ΩøÁî®ÂõæÁªìÊûÑÁöÑÊñπÂºèÂèØ‰ª•Â∞ÜÊ¶ÇÁéáÊ®°ÂûãÂèØËßÜÂåñÔºåÔºå‰ª•‰∏ÄÁßçÁõ¥ËßÇ„ÄÅÁÆÄÂçïÁöÑÊñπÂºèÊèèËø∞Âá∫ÈöèÊú∫ÂèòÈáè‰πãÈó¥ÁöÑÊù°‰ª∂Áã¨Á´ãÊÄßÁöÑÊÄßË¥®ÔºåÂπ∂ÂèØ‰ª•Â∞Ü‰∏Ä‰∏™Â§çÊùÇÁöÑËÅîÂêàÊ¶ÇÁéáÊ®°ÂûãÂàÜËß£‰∏∫‰∏Ä‰∫õÁÆÄÂçïÊù°‰ª∂Ê¶ÇÁéáÊ®°ÂûãÁöÑÁªÑÂêà„ÄÇ Therefore, when the number of variables in the probability model is relatively large, the conditional dependence is also complicated. The use of graph structure can visualize the probability model, describe the nature of conditional independence between random variables in an intuitive and simple way, and decompose a complex joint probability model into some simple conditional probability models. combination. Âá†ÁßçÂ∏∏ËßÅÁöÑÊúâÂêëÂõæÔºà‰∏çËÆ≤Ôºâ ÂæàÂ§öÁªèÂÖ∏ÁöÑÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÂèØ‰ª•‰ΩøÁî®ÊúâÂêëÂõæÊ®°ÂûãÊù•ÊèèËø∞ÔºåÊØîÂ¶ÇÊú¥Á¥†Ë¥ùÂè∂ÊñØÂàÜÁ±ªÂô®„ÄÅÈöêÈ©¨Â∞îÂèØÂ§´Ê®°Âûã„ÄÅÊ∑±Â∫¶‰ø°ÂøµÁΩëÁªúÁ≠â„ÄÇÂêÑËá™ÂÖ∑ÊúâÁâπÂÆöÁöÑÁªìÊûÑÔºåÈÄÇÁî®‰∫é‰∏çÂêåÁöÑ‰ªªÂä°„ÄÇ ÊúâÂêëÂõæ‚ÄîÊñáÊú¨ÂàÜÁ±ª ÂõæÁªìÊûÑÔºö‰∏Ä‰∏™Â∏∏Áî®ÁöÑÊúâÂêëÂõæÁªìÊûÑÔºåÊú¥Á¥†Ë¥ùÂè∂ÊñØÊ®°Âûã„ÄÇ ÂèÇÊï∞ÁöÑÂ≠¶‰π† ÂêéÈ™åÂàÜÂ∏ÉÂèØ‰ª•ÂàÜËß£‰∏∫ ËøôÈáåÊàëË¶ÅÂº∫Ë∞É‰∏Ä‰∏ã‰∏§‰∏™Ê¶ÇÂøµ„ÄÇÁîüÊàêÊ®°ÂûãÂíåÂà§Âà´Ê®°ÂûãÁöÑÂå∫Âà´„ÄÇ ÁîüÊàêÊ®°ÂûãÂíåÂà§Âà´Ê®°ÂûãÁöÑÂå∫Âà´Êàë‰ª¨ÁªèÂ∏∏ÊèêÂà∞ÁöÑÁîüÊàêÊ®°ÂûãÂíåÂà§Âà´Ê®°Âûã„ÄÇÊàë‰ª¨ÂèØËÉΩÈÄöÂ∏∏ÈîôËØØÁöÑ‰ª•‰∏∫ÁîüÊàêÊ®°ÂûãÂ∞±ÊòØÂõæÂÉèÂ∫îÁî®‰∏≠Êï∞ÊçÆÈáçÂª∫ÁöÑÊÑèÊÄùÔºåÂÖ∂ÂÆû‰∏çÁÑ∂„ÄÇÁîüÊàêÊ®°ÂûãÈô§‰∫ÜÈáçÂª∫‰πüÂèØ‰ª•Áî®Êù•Âà§Âà´„ÄÇ ÁÆÄÂçïÊù•ËØ¥„ÄÇÁîüÊàêÊ®°ÂûãÊòØËÆ°ÁÆó‰∏Ä‰∏™p(x,y)ÁöÑËÅîÂêàÂàÜÂ∏ÉÔºåËÄåÂà§Âà´Ê®°ÂûãÊòØÁîüÊàêp(y|x)Ôºå ‰∏§‰∏™Ê®°ÂûãÁöÑÂ∫îÁî®„ÄÇÁîüÊàêÊ®°ÂûãÂíåÂà§Âà´Ê®°ÂûãÈÉΩÂèØ‰ª•Áî®Êù•ËøõË°åÂàÜÁ±ªÈóÆÈ¢ò„ÄÇ ‰∏§‰∏™Ê®°ÂûãÁöÑÂª∫Ê®°‰ª•ÂèäÊàëÁöÑÊÄªÁªì ÊúâÂêëÂõæ‚ÄîÈ´òÊñØÊ∑∑ÂêàÊ®°ÂûãÈ´òÊñØÊ∑∑ÂêàÊ®°ÂûãÔºàGaussian Mixture ModelÔºåGMM)„ÄÇÂÅáËÆæÊ†∑Êú¨ x ÊòØ‰ªé K ‰∏™È´òÊñØÂàÜÂ∏É‰∏≠ÁîüÊàêÁöÑ„ÄÇ È´òÊñØÊ∑∑ÂêàÊ®°ÂûãÁöÑÊ¶ÇÁéáÂØÜÂ∫¶ÂáΩÊï∞‰∏∫Ôºö$p(x)=\sum_{k=1}^{K} \pi_{k} \mathcal{N}\left(x | \mu_{k}, \sigma_{k}\right)$ ÊúâÂêëÂõæÁªìÊûÑÁöÑÂÆö‰πâÔºöY-&gt;X Âú®Ëøô‰∏™Âõæ‰∏≠ÔºåÊàë‰ª¨ÂÆö‰πâ$P(X|Y=k)=\mathcal{N}\left(x | \mu_{k}, \sigma_{k}\right)$, $P(Y=k)=\pi_k, \sum_{k=1}^{K} \pi_{k}=1$. Ê†πÊçÆËøô‰∏™ÂõæÔºöÊàë‰ª¨ÂèØ‰ª•ÂæóÂà∞xÁöÑËæπÈôÖÊ¶ÇÁéáÔºö$p(x)=\sum_{k=1}^{K} \pi_{k} \mathcal{N}\left(x | \mu_{k}, \sigma_{k}\right)$ ÂèÇÊï∞‰º∞ËÆ°ÔºöÁî®ÊúÄÂ§ß‰ººÁÑ∂ÁöÑÊñπÊ≥ïÊù•ËøõË°åÂèÇÊï∞‰º∞ËÆ°ÔºåÁªôÂÆöN ‰∏™ËÆ≠ÁªÉÊ†∑Êú¨D = {x (i) }, 1 ‚â§ i ‚â§ NÔºåÂÖ∂ËÆ≠ÁªÉÈõÜÁöÑÂØπÊï∞ËæπÈôÖ‰ººÁÑ∂‰∏∫ $\mathcal{L}(\mathcal{D} | \theta)=\frac{1}{N} \sum_{i=1}^{N}\left(\log p\left(\mathbf{x}^{(i)}, \theta\right)\right.$,Âπ∂ÈÄöËøáEMÁÆóÊ≥ïÊù•Ê±ÇËß£Ëé∑ÂæóÂèÇÊï∞$u_k,\sigma_k,\pi_k$, Êé®Êñ≠ÔºöËÆ°ÁÆóÂêéÈ™åÂàÜÂ∏É p(Y=k|x)$\pi_{k} \mathcal{N}\left(x^{(n)} | \mu_{k}, \sigma_{k}\right)$ Êó†ÂêëÂõæÁªìÊûÑ Â∫îÁî®Âú∫ÊôØ Êàë‰ª¨ÂèØ‰ª•ÁúãÂà∞ÔºåÂú®ÊúâÂêëÂõæ‰∏≠ÔºåÈÄöÂ∏∏Â≠òÂú®ÊòéÁ°ÆÊñπÂêë‰∏äÁöÑÂõ†ÊûúÂÖ≥Á≥ª„ÄÇÂΩìÁõ∏‰∫íÁöÑ‰ΩúÁî®Âπ∂Ê≤° ÊúâÊú¨Ë¥®ÊÄßÁöÑÊåáÂêëÔºåÊàñËÄÖÊòØÊòéÁ°ÆÁöÑÂèåÂêëÁõ∏‰∫í‰ΩúÁî®Êó∂Ôºå‰ΩøÁî®Êó†ÂêëÊ®°ÂûãÊõ¥Âä†ÂêàÈÄÇ„ÄÇ‰Ωú‰∏∫‰∏Ä‰∏™ËøôÁßçÊÉÖÂÜµÁöÑ‰æãÂ≠êÔºåÂÅáËÆæÊàë‰ª¨Â∏åÊúõÂØπ‰∏â‰∏™‰∫åÂÄºÈöèÊú∫ÂèòÈáèÂª∫Ê®°„ÄÇX1-X2-X3„ÄÇÂÖ∂‰∏≠X1ÔºåX2ÔºåX3ÂàÜÂà´‰ª£Ë°®‰Ω†ÁöÑÂÆ§ÂèãÔºå‰Ω†Âíå‰Ω†ÁöÑÂêå‰∫ãÊòØÂê¶üò∑„ÄÇÊàë‰ª¨ÂÅáËÆæÔºå‰Ω†ÁöÑÂÆ§ÂèãÂíåÂêå‰∫ã Âπ∂‰∏çËÆ§ËØÜÔºåÊâÄ‰ª•‰ªñ‰ª¨‰∏çÂ§™ÂèØËÉΩÁõ¥Êé•Áõ∏‰∫í‰º†Êüì‰∏Ä‰∫õÁñæÁóÖÔºåÂõ†ËÄåÊàë‰ª¨ÁöÑÊ®°Âûã‰∏≠‰∏§ËÄÖ‰πãÈó¥Ê≤°ÊúâÁõ¥Êé•ÁöÑËøûÊé•„ÄÇÁÑ∂ËÄåÔºå‰Ω†‰º†ÊüìÁªô‰Ω†ÁöÑÂÆ§ÂèãÂíå‰Ω†ÁöÑÂÆ§Âèã‰º†ÊüìÁªô‰Ω†ÈÉΩÊòØÈùûÂ∏∏ÂÆπÊòìÁöÑÔºåÊâÄ‰ª•Ê®°Âûã‰∏çÂ≠òÂú®‰∏Ä‰∏™ÊòéÁ°ÆÁöÑÂçïÂêëÁÆ≠Â§¥„ÄÇÂπ∂‰∏îÔºå‰Ω†ÁöÑÂÆ§ÂèãÂíå‰Ω†ÂæàÊúâÂèØËÉΩÂÖ∂‰∏≠‰πã‰∏ÄÂ∞ÜÊÑüÂÜí‰º†ÊüìÁªô‰Ω†ÔºåÁÑ∂ÂêéÈÄöËøá‰Ω†ÂÜç‰º†ÊüìÁªô‰∫ÜÂè¶‰∏Ä‰∏™‰∫∫„ÄÇ Áé∞Âú®Êàë‰ª¨Êù•ËÄÉËôë‰∏âËÄÖÂÅ•Â∫∑Áä∂ÂÜµÁöÑËÅîÂêàÂàÜÂ∏É„ÄÇp(X1,X2,X3) Êó†ÂêëÂõæÁöÑËÅîÂêàÂàÜÂ∏ÉÁöÑÂàÜËß£ÊñπÂºè Êó†ÂêëÂõæÊ®°ÂûãÔºå‰πüÁß∞‰∏∫È©¨Â∞îÂèØÂ§´ÈöèÊú∫Âú∫ÔºàMarkov Random FieldÔºåMRFÔºâÊàñ È©¨Â∞îÂèØÂ§´ÁΩëÁªúÔºàMarkov NetworkÔºâ Êó†ÂêëÂõæÁöÑËÅîÂêàÂàÜÂ∏ÉÊñπÂºèÔºöÂØπ‰∫é‰∏Ä‰∏™È©¨Â∞îÂèØÂ§´ÈöèÊú∫Âú∫G,ÂΩìp(x)ÂèØ‰ª•Ë°®Á§∫‰∏∫,‰∏ÄÁ≥ªÂàóÂÆö‰πâÂú®ÊúÄÂ§ßÂõ¢‰∏äÁöÑÈùûË¥üÂáΩÊï∞ÁöÑ‰πòÁßØÂΩ¢Âºè,Âç≥p(\mathbf{x})=\frac{1}{Z} \prod_{c \in \mathcal{C}} \phi_{c}\left(\mathbf{x}_{c}\right)„ÄÇÂÖ∂‰∏≠ÔºöÊúÄÂ§ßÂõ¢ÔºàMaximal CliqueÔºâÂ∞±ÊòØÂÖ∂‰∏≠ÁöÑÁÇπÊòØÂÖ®ËøûÊé•ÁöÑÂ≠êÈõÜÔºåÂπ∂‰∏îÊó†Ê≥ïË¢´‰∏Ä‰∏™Êõ¥Â§ßÁöÑÂõ¢ÂåÖÂê´„ÄÇÂØπ‰∫é Âõæ‰∏≠ÁöÑÊØè‰∏Ä‰∏™Âõ¢CÔºå‰∏Ä‰∏™ Âõ†Â≠êÔºàfactorÔºâœï(C)(‰πüÁß∞‰∏∫ Âõ¢ÂäøËÉΩÔºàclique potential)ÔºåË°°Èáè‰∫ÜÂõ¢‰∏≠ÂèòÈáèÊØè‰∏ÄÁßçÂèØËÉΩÁöÑËÅîÂêàÁä∂ÊÄÅÊâÄÂØπÂ∫îÁöÑÂØÜÂàáÁ®ãÂ∫¶ÔºåÂõ†ËÄåÂøÖÈ°ª‰∏∫0„ÄÇ‰∏∫‰∫ÜÂΩí‰∏ÄÂåñ ‰æãÂ≠ê‰∏≠ÁöÑËÆ°ÁÆóÊñπÊ≥ï Âú®Êàë‰ª¨Ëøô‰∏™Ê®°Âûã‰∏≠ÔºåÊàë‰ª¨ÂèØ‰ª•‰∏∫‰Ω†Âíå‰Ω†ÁöÑÂÆ§ÂèãÂÆö‰πâËøôÊ†∑‰∏Ä‰∏™ÂäøËÉΩÂáΩÊï∞„ÄÇ Áä∂ÊÄÅ‰∏∫ 1 ‰ª£Ë°®‰∫ÜÂÅ•Â∫∑ÁöÑÁä∂ÊÄÅÔºåÁõ∏ÂØπÁöÑÁä∂ÊÄÅ‰∏∫ 0 ÂàôË°®Á§∫‰∏çÂ•ΩÁöÑÂÅ•Â∫∑Áä∂ÊÄÅÔºàÂç≥ÊÑüÊüì ‰∫ÜÊÑüÂÜíÔºâ„ÄÇ‰Ω†‰ª¨‰∏§‰∏™ÈÄöÂ∏∏ÈÉΩÊòØÂÅ•Â∫∑ÁöÑÔºåÊâÄ‰ª•ÂØπÂ∫îÁöÑÁä∂ÊÄÅÊã•ÊúâÊúÄÈ´òÁöÑÂØÜÂàáÁ®ãÂ∫¶„ÄÇ‰∏§‰∏™‰∫∫ ‰∏≠Âè™Êúâ‰∏Ä‰∏™‰∫∫ÊòØÁîüÁóÖÁöÑÂØÜÂàáÁ®ãÂ∫¶ÊòØÊúÄ‰ΩéÁöÑÔºåÂõ†‰∏∫ËøôÊòØ‰∏Ä‰∏™ÂæàÁΩïËßÅÁöÑÁä∂ÊÄÅ„ÄÇ‰∏§‰∏™‰∫∫ÈÉΩÁîüÁóÖÁöÑÁä∂ÊÄÅÔºàÈÄöËøá‰∏Ä‰∏™‰∫∫Êù•‰º†ÊüìÁªô‰∫ÜÂè¶‰∏Ä‰∏™‰∫∫ÔºâÊúâ‰∏Ä‰∏™Á®çÈ´òÁöÑÂØÜÂàáÁ®ãÂ∫¶ÔºåÂ∞ΩÁÆ°‰ªçÁÑ∂ ‰∏çÂèä‰∏§‰∏™‰∫∫ÈÉΩÂÅ•Â∫∑ÁöÑÂØÜÂàáÁ®ãÂ∫¶„ÄÇ ÂêåÊ†∑Âú∞ÔºåÊàë‰ª¨ÂèØ‰ª•‰∏∫‰Ω†Âíå‰Ω†ÁöÑÂêå‰∫ãÂÆö‰πâ‰∏Ä‰∏™„ÄÇ Áé∞Âú®Êàë‰ª¨ÂèØ‰ª•ÂæóÂà∞ÈùûÂΩí‰∏ÄÂåñÁöÑÊ¶ÇÁéáÂàÜÂ∏É„ÄÇÂ¶Çhc=0Ôºåhy=1Ôºåhx=1ÁöÑÊÉÖÂÜµ‰∏ãÔºåpÔºõhc=0Ôºåhy=1Ôºåhx=1ÁöÑÊÉÖÂÜµ‰∏ãÔºåp„ÄÇÂíåÊàë‰ª¨È¢ÑËÆæÁöÑÊÉÖÂΩ¢Áõ∏Á¨¶Âêà„ÄÇ Êó†ÂêëÂõæ‰∏≠ËÅîÂêàÂàÜÂ∏ÉÁöÑËÉΩÈáèË°®ËææÊñπÊ≥ï Áé∞Âú®Êàë‰ª¨ËøîÂõûÂà∞Ëøô‰∏™ËÅîÂêàÂàÜÂ∏ÉÁöÑÂÆö‰πâ„ÄÇÊàë‰ª¨Ê≥®ÊÑèÂà∞Ôºå‰∏∫‰∫ÜÊúâÊïàÂÆö‰πâÊØè‰∏ÄÁßçÊÉÖÂÜµÔºåÂäøËÉΩÂáΩÊï∞ÂøÖÈ°ªÂ§ß‰∫é0. Áî±‰∫éÂäøËÉΩÂáΩÊï∞ÂøÖÈ°ª‰∏∫Ê≠£ÁöÑÔºåÂõ†Ê≠§Êàë‰ª¨‰∏ÄËà¨ÂÆö‰πâ‰∏∫$\phi_{c}\left(\mathbf{x}_{c}\right)=\exp \left(-E_{c}\left(\mathbf{x}_{c}\right)\right)$ÔºåÂÖ∂‰∏≠E(xc)‰∏∫ËÉΩÈáèÂáΩÊï∞Ôºàenergy function) „ÄÇÂõ†Ê≠§ÔºåÊó†ÂêëÂõæ‰∏äÂÆö‰πâÁöÑÊ¶ÇÁéáÂàÜÂ∏ÉÂèØ‰ª•Ë°®Á§∫‰∏∫Ôºö \begin{aligned} P(\mathbf{x}) &=\frac{1}{Z} \prod_{c \in \mathcal{C}} \exp \left(-E_{c}\left(\mathbf{x}_{c}\right)\right) \\ &=\frac{1}{Z} \exp \left(\sum_{c \in \mathcal{C}}-E_{c}\left(\mathbf{x}_{c}\right)\right)\\&=\frac{1}{Z} \exp \left(-E\left(\mathbf{x}\right)\right) \end{aligned}ËøôÁßçÂΩ¢ÂºèÁöÑÂàÜÂ∏ÉÂèàÁß∞‰∏∫ÁéªÂ∞îÂÖπÊõºÂàÜÂ∏ÉÔºàBoltzmann DistributionÔºâ„ÄÇ‰ªª‰Ωï‰∏Ä‰∏™Êó†ÂêëÂõæÊ®°ÂûãÈÉΩÂèØ‰ª•Áî®ÂÖ¨Âºè(11.21) Êù•Ë°®Á§∫ÂÖ∂ËÅîÂêàÊ¶ÇÁéá„ÄÇÊúç‰ªéÂºè (16.7) ÂΩ¢ÂºèÁöÑ‰ªªÊÑèÂàÜÂ∏ÉÈÉΩÊòØ ÁéªÂ∞îÂÖπÊõºÂàÜÂ∏ÉÔºàBoltzmann distributionÔºâ ÁöÑ‰∏Ä‰∏™ÂÆû‰æã„ÄÇÊ≠£ÊòØÂü∫‰∫éËøô‰∏™ÂéüÂõ†Ôºå Êàë‰ª¨ÊääËÆ∏Â§öÂü∫‰∫éËÉΩÈáèÁöÑÊ®°ÂûãÁß∞‰∏∫ÁéªÂ∞îÂÖπÊõºÊú∫ÔºàBoltzmann MachineÔºâ„ÄÇÁé∞Âú®Êàë‰ª¨Êù•ËÆ≤‰∏Ä‰∏™Âü∫‰∫éÊó†ÂêëÂõæÁöÑÂ∫îÁî®ÔºåÂéªÂô™„ÄÇ Â∏∏ËßÅÁöÑÊó†ÂêëÂõæ(‰∏çËÆ≤) ÊÄªÁªì Âà©Áî®ÂõæÊ®°ÂûãÁöÑÂ±ÄÈÉ®È©¨Â∞îÂèØÂ§´ÊÄßÔºåÊàë‰ª¨ÂèØ‰ª•ÂØπÂ§öÂèòÈáèÁöÑËÅîÂêàÊ¶ÇÁéáËøõË°åÁÆÄÂåñÔºå‰ªéËÄåÈôç‰ΩéÂª∫Ê®°ÁöÑÂ§çÊùÇÂ∫¶„ÄÇÔºàÂèØÂä†Âà∞ÊúâÂêëÂõæÁöÑÂêéÈù¢ÔºâUsing the local Markov property of the graph model, we can simplify the joint probability of multivariates, thus reducing the complexity of modeling. (can be added to the back of the directed graph) Â±ÄÈÉ®È©¨Â∞îÂèØÂ§´ÊÄßË¥®ÔºöÂØπ‰∏Ä‰∏™Êõ¥‰∏ÄËà¨ÁöÑË¥ùÂè∂ÊñØÁΩëÁªúÔºåÂÖ∂Â±ÄÈÉ®È©¨Â∞îÂèØÂ§´ÊÄßË¥®‰∏∫ÔºöÊØè‰∏™ÈöèÊú∫ÂèòÈáèÂú®ÁªôÂÆöÁà∂ËäÇÁÇπÁöÑÊÉÖÂÜµ‰∏ãÔºåÊù°‰ª∂Áã¨Á´ã‰∫éÂÆÉÁöÑÈùûÂêé‰ª£ËäÇÁÇπ„ÄÇÂØπ‰∏é‰∏Ä‰∏™Êó†ÂêëÂõæËÄåË®ÄÔºåÂç≥‰∏Ä‰∏™ÂèòÈáè Xk Âú®ÁªôÂÆöÂÆÉÁöÑÈÇªÂ±ÖÁöÑÊÉÖÂÜµ‰∏ãÁã¨Á´ã‰∫éÊâÄÊúâÂÖ∂ÂÆÉÂèòÈáè„ÄÇ Êó†ÂêëÂõæ‚ÄîÂõæÂÉèÂéªÂô™Êó†ÂêëÂõæÔºöÂõæÂÉèÂéªÂô™„ÄÇ Âü∫‰∫éÈ©¨Â∞îÁßëÂ§´ÈöèÊú∫Âú∫ÁöÑÂõæÂÉèÂéªÂô™ÊñπÊ≥ï+python‰ª£Á†Å È©¨Â∞îÂèØÂ§´ÂéªÂô™+matlabÔºöËÉΩÈáèÂáΩÊï∞ÊúâÁÇπ‰∏çÂêå GMNN: Graph Markov Neural Networks ÂèóÈôêÁéªËÄ≥ÂÖπÊõºÊú∫A widely used model of Undirected graph is Boltzman‚Äôs machine„ÄÇ ‰∏ãÈù¢Êàë‰ª¨ÊúâËØ∑Ms TangÔºåÊù•‰ªãÁªçsome details about the Boltzman‚Äôs machine and its extentions in deep learning models. ÁéªËÄ≥ÂÖπÊõºÊú∫ÊòØ‰∏Ä‰∏™Êó†ÂêëÂõæ ÂèëÂ±ïÔºö1986HintonÂèëÊòé‰∫ÜÁéªËÄ≥ÂÖπÊõºÊú∫-&gt;2002HintonÂèëÊòé‰∫ÜCD(ÂØπÊØîÊï£Â∫¶)Êù•ËÆ°ÁÆóÊ¢ØÂ∫¶-&gt;2006HintonÊèêÂá∫‰∫ÜÂèóÈôêÁéªËÄ≥ÂÖπÊõºÊú∫ Ê®°ÂûãÊûÑÂª∫ÔºöIntroduction to Restricted Boltzmann Machines Using PyTorch„ÄÅËã±ÊñáÂéüÊñá ËÆ°ÁÆóÂéüÁêÜÔºöÈ¢ÑÂ§áÁü•ËØÜ„ÄÅÊ¢ØÂ∫¶‰∏äÂçáÊ≥ï„ÄÅËØÑ‰ª∑ÊïàÊûúÁöÑÊñπÊ≥ï ‰ª£Á†ÅÔºöÂèóÈôêÁéªËÄ≥ÂÖπÊõºÂß¨ÈáçÊûÑÔºötfÁâàÊú¨„ÄÅÂèóÈôêÁéªËÄ≥ÂÖπÊõºÂß¨ÈáçÊûÑÔºöpytorchÁâàÊú¨„ÄÅIntroduction to Restricted Boltzmann Machines Using PyTorch„ÄÅpytorch-rbm„ÄÅ ÂèóÈôêÁéªËÄ≥ÂÖπÊõºÂß¨ÂíåÊ∑±Â∫¶Â≠¶‰π†ÁöÑÂÖ≥Á≥ªÊú™ÂÆåÂæÖÁª≠ GMNN: Graph Markov Neural Networks]]></content>
      <categories>
        <category>Ê∑±Â∫¶Â≠¶‰π†</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ÂõæÂÉèÂ§ÑÁêÜÁõ∏ÂÖ≥ÈóÆÈ¢òÁªºËø∞]]></title>
    <url>%2Fp%2F23e4.html</url>
    <content type="text"><![CDATA[deblur Learning a Discriminative Prior for Blind Image Deblurring \min _{I, k}\|I \otimes k-B\|_{2}^{2}+\gamma\|k\|_{2}^{2}+p(I) The key to the success of this framework lies on the latentimage prior p(I), which favors clear images over blurredimages when minimizing (2). Therefore, the image priorp(I) should have lower responses for clear images andhigher responses for blurred images. test $a+b=\beta$ super-resolution Deep Plug-and-Play Super-Resolution for Arbitrary Blur Kernels ReferenceÂú®ÂõæÂÉèÂ§ÑÁêÜÈ¢ÜÂüüÁöÑ‰∏çÂêåÁöÑÁ†îÁ©∂ÈóÆÈ¢ò]]></content>
  </entry>
  <entry>
    <title><![CDATA[hexoÂçöÂÆ¢Êê≠Âª∫]]></title>
    <url>%2Fp%2F7ab7.html</url>
    <content type="text"><![CDATA[ÂÆâË£Önode.js https://nodejs.org/en/ sudo npm install ‚Äîunsafe-perm ‚Äîverbose -g hexoÔºõhexo version ÊµãËØï Ëá™Â∏¶‰∫ÜgitÔºåÂê¶ÂàôÈúÄË¶ÅÂÆâË£Ö ÂàùÂßãÂåñÂçöÂÆ¢Êñá‰ª∂Â§π 123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install ÊµãËØïÁîüÊàêÁΩëÈ°µ 123hexo s ÈáçÊñ∞ÁºñËØëÔºåÂπ∂Âú®Êú¨Âú∞ÊòæÁ§∫hdxo g ÈáçÊñ∞ÁºñËØëhexo d ‰∏ä‰º†Ëá≥github ÈÄâ‰∏ªÈ¢òhttps://hexo.io/themes/ ‰∏ãËΩΩ git clone https://github.com/theme-next/hexo-theme-next Â∞ÜÂÆÉÊîæÂà∞theme‰∏ãÔºåÂπ∂ÈáçÂëΩÂêç ‰øÆÊîπ Á´ôÁÇπÈÖçÁΩÆÊñá‰ª∂_config.yml‰∏≠ÁöÑ‰∏ªÈ¢ò 12345# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/# theme: landscapetheme: next ÈáçÊñ∞ÁºñËØë ‰øÆÊîπ‰∏ªÈ¢òÈ£éÊ†º ÁîüÊàêÁöÑgithubÊñá‰ª∂ÊàëÁöÑgithubÈìæÊé•Ôºöhttps://github.com/ysix7/ysix7.github.io/tree/master/2019 ÂèÇËÄÉblogÔºö https://hellozhaozheng.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/ Êú¨Âú∞Êõ¥Êñ∞Êñá‰ª∂ Hero s Êú¨Âú∞Áúã Êñ∞Â¢ûÁöÑÂäüËÉΩÂàÜÁ∫ßÁõÆÂΩïÔºöhttps://blog.csdn.net/wugenqiang/article/details/88609066 Êñ∞Â¢ûÂàÜÁ±ªÔºöhttp://www.iooeo.com/2017/07/20/Hexo-%E6%96%B0%E5%BB%BA%E8%8F%9C%E5%8D%95-menu-%E5%AD%98%E6%94%BE%E5%BD%92%E6%A1%A3/ ÂàÜÁ±ª‰ª•ÂèäÊ†áÁ≠æÊ∑±Â∫¶Â≠¶‰π†ÔºöpytorchÔºåpython, Êú∫Âô®Â≠¶‰π†ÔºåÊúçÂä°Âô® ÁæéÈ£üÁ±ªÔºöË•øÂÆâ,È¶ôÊ∏Ø.. ËΩØ‰ª∂Ôºölatex ÂõæÂΩ¢Â§ÑÁêÜÔºödenoising,segmentation ‰∏ªÈ°µËá™ÂÆö‰πâ12345678npm install --save hexo-generator-searchnpm install hexo-generator-searchdb --save Ê∑ªÂä†Êú¨Âú∞ÊêúÁ¥¢npm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --save ÁîüÊàêsitemapÔºåÁî®Êù•Ë¢´ÁôæÂ∫¶Ë∞∑Ê≠åÊî∂ÂΩïnpm install --save hexo-symbols-count-time Ê∑ªÂä†ÁªüËÆ°Â≠óÊï∞npm install hexo-generator-index --savenpm install hexo-generator-index-pin-top --save ÂçöÂÆ¢ÁΩÆÈ°∂npm install hexo-abbrlink --save ‰ºòÂåñÈìæÊé• ‰∏ªÈ¢òÈÖçÁΩÆÊñá‰ª∂ Â§¥ÂÉè Ôºötheme-source-imgs È°µÈù¢Â∑¶‰∏äËßíÂõæÊ†á ÈìæÊé•Ôºöhttps://www.iconfont.cn/home/index?spm=a313x.7781069.1998910419.2 Êñá‰ª∂‰øùÂ≠ò‰ΩçÁΩÆÔºö ÂàÜÁ±ªÂõæÊ†á ÈìæÊé•Ôºöhttp://fontawesome.dashgame.com/ ÂºÄÂêØÁ´ôÂÜÖÊêúÁ¥¢ ‰øÆÊîπÈ°µËæπË∑ùÂÖ¨ÂºèÊ∏≤ÊüìÈóÆÈ¢ò ÂºÄÂêØÂÖ¨ÂºèÔºöscaffolds-post.md‰∏≠‰øÆÊîπÈªòËÆ§Ê®°Áâà Ê®°ÊùøÈáåÈù¢Âè™ÂÜômathjax: ÔºåÂè™Âú®ÈúÄË¶ÅÂÖ¨ÂºèÁöÑÂú∞ÊñπÂÜôtrue„ÄÇÊ®°Áâà‰∏≠ÂÜôtrueÔºå‰ºöÂØºËá¥ÁΩëÈ°µÊòæÁ§∫ÂèòÊÖ¢„ÄÇ Ëß£ÂÜ≥mathjaxÈªòËÆ§Ê∏≤ÊüìÂ∞Ü‰∏Ä‰∫õÁ¨¶Âè∑ËΩ¨‰πâÁöÑÈóÆÈ¢ò Êñ∞Âª∫ËçâÁ®øÂçöÂÆ¢hexo n titleÔºö ÈªòËÆ§Áî®ÁöÑÊòØpostÂ∏ÉÂ±Ä hexo n draft titleÔºö ‰ºöÂú®postÂêåÁ∫ßÂª∫‰∏Ä‰∏™draftÊñá‰ª∂Â§πÊîæËçâÁ®øsource/_drafts ËçâÁ®øÁöÑÈªòËÆ§ÁªìÊûÑÂú®scaffoldsÈáåÁöÑdraft.mdÈáåÈù¢Êîπ Âá∫Áé∞ËøáÁöÑÈóÆÈ¢ò ÊñáÁ´†‰∏çÊòæÁ§∫Âú®ÂàóË°®Ôºötags‰ª•ÂèäcatogoriesÁöÑÂ°´ÂÜôÊ†ºÂºèÊúâÈóÆÈ¢ò ÂÖ®Â±ÄÊêúÁ¥¢‰∏çÂá∫Áé∞ÁöÑÈóÆÈ¢ò]]></content>
      <categories>
        <category>ÂÖ∂‰ªñ</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ÁîüÊàêÊ®°ÂûãvsÂà§Âà´Ê®°Âûã]]></title>
    <url>%2Fp%2F44f5.html</url>
    <content type="text"><![CDATA[‰∏çÂêåÁöÑÂ∫îÁî®Âà§Âà´ÂºèÊ®°ÂûãÔºåËøôÁßçÊ®°ÂûãÁöÑÂΩ¢Âºè‰∏ªË¶ÅÊòØÊ†πÊçÆÂéüÂßãÂõæÂÉèÊé®ÊµãÂõæÂÉèÂÖ∑Â§áÁöÑ‰∏Ä‰∫õÊÄßË¥®Ôºå‰æãÂ¶ÇÊ†πÊçÆÊï∞Â≠óÂõæÂÉèÊé®ÊµãÊï∞Â≠óÁöÑÂêçÁß∞ÔºåÊ†πÊçÆËá™ÁÑ∂Âú∫ÊôØÂõæÂÉèÊé®ÊµãÁâ©‰ΩìÁöÑËæπÁïåÔºõËÄåÁîüÊàêÊ®°ÂûãÊÅ∞ÊÅ∞Áõ∏ÂèçÔºåÈÄöÂ∏∏ÁªôÂá∫ÁöÑËæìÂÖ•ÊòØÂõæÂÉèÂÖ∑Â§áÁöÑÊÄßË¥®ÔºåËÄåËæìÂá∫ÊòØÊÄßË¥®ÂØπÂ∫îÁöÑÂõæÂÉè„ÄÇËøôÁßçÁîüÊàêÊ®°ÂûãÁõ∏ÂΩì‰∫éÊûÑÂª∫‰∫ÜÂõæÂÉèÁöÑÂàÜÂ∏ÉÔºåÂõ†Ê≠§Âà©Áî®ËøôÁ±ªÊ®°ÂûãÔºåÊàë‰ª¨ÂèØ‰ª•ÂÆåÊàêÂõæÂÉèËá™Âä®ÁîüÊàêÔºàÈááÊ†∑Ôºâ„ÄÅÂõæÂÉè‰ø°ÊÅØË°•ÂÖ®Á≠âÂ∑•‰Ωú„ÄÇ ÁîüÊàêÊ®°ÂûãÂèØ‰ª•Áî®Êù•ÈáçÊûÑ„ÄÅ‰πüÂèØ‰ª•Áî®Êù•Âà§Âà´„ÄÇÂΩìÁî®‰∫éÂà§Âà´Êó∂ ÁîüÊàêÊ®°ÂûãÂèØ‰ª•ÊòØÁõëÁù£ÁöÑÔºå‰πüÂèØ‰ª•ÊòØÊó†ÁõëÁù£ÁöÑÔºü Â∏∏Áî®ÁöÑÁîüÊàêÁΩëÁªúÔºöVAE„ÄÅGAN„ÄÅGAN ÈóÆÈ¢òÁîüÊàêÊ®°ÂûãÁöÑËæìÂÖ•ÊòØ‰ªÄ‰πàÔºü ÂèÇËÄÉ ÂçÅ‰∏™ÁîüÊàêÊ®°Âûã(GANs)ÁöÑÊúÄ‰Ω≥Ê°à‰æãÂíåÂéüÁêÜ | ‰ª£Á†Å+ËÆ∫Êñá GNNËÆ∫ÊñáÂàÜÈó®Âà´Á±ªÔºå16Â§ßÂ∫îÁî®200+ÁØáËÆ∫ÊñáÊúÄÊñ∞Êé®Ëçê]]></content>
      <categories>
        <category>Ê∑±Â∫¶Â≠¶‰π†</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ÂõæÂΩ¢ËæπÁºòÊèêÂèñ]]></title>
    <url>%2Fp%2Fbe62.html</url>
    <content type="text"><![CDATA[ÂèÇËÄÉËµÑÊñô Edge detection ppt Edge detection blog Edge detection matlab ÂõæÂÉèÁöÑ‰∫åÈò∂‰ø°ÊÅØ ‰º†ÁªüÊï∞Â≠¶ÊñπÊ≥ïÂèëÂ±ïËøáÁ®ã ‰∏ÄÈò∂„ÄÅ‰∫åÈò∂„ÄÅ‰ºòÁÇπ„ÄÅÁº∫ÁÇπ„ÄÅÈ≤ÅÊ£íÊÄß canny Sobel code++ I. Sobel. Camera models and machine perception. Technical report, DTIC Document, 1970. thresholding the gradient map. CannyÔºöan extension of Sobel, more robust to noise. code++ J. Canny. A computational approach to edge detection. IEEE TPAMI, 8(6):679‚Äì698, 1986. Gaussian smoothing as a preprocessing step Laplacian: Áî®‰∏Ä‰∏™Á∫øÊÄßÁÆóÂ≠êÂç≥ÂèØ Ansitropic nabla^2 = uxx+uyy. (Âè≥ËæπÂèñÁªùÂØπÂÄº) Ê∑±Â∫¶Â≠¶‰π†ÊñπÊ≥ï Xie, S., Tu, Z.: Holistically-nested edge detection. In: Proceedings of the IEEE international conference on computer vision, pp. 1395‚Äì1403 (2015) Liu, Y., Cheng, M.M., Hu, X., Wang, K., Bai, X.: Richer convolutional features for edge detection. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 3000‚Äì3009 (2017) LaplacianÊñπÊ≥ïËæπÁºòÂä†Âº∫ÂéªÂô™‰∫åÈò∂ÁÆóÂ≠êÊàñËÄÖ‰∏ÄÈò∂ÁÆóÂ≠ê ËæπÁºò ‰∫åÈò∂ÁÆóÂ≠êÂØπÂ∫îÂÖ∂‰ªñËæπÁºò Â¶ÇcannyËæπÁºòÊàñËÄÖsobelËæπÁºò ËÉΩÂê¶ÊúâËøô‰∏™ÁªìÊûú ÂÆûÈ™åËÆ∞ÂΩï08.30 ÂéüÊù•ÁöÑÁΩëÁªúÔºåÊõ¥Êñ∞‰∫ÜinputÂíålabelÁöÑÂª∫Á´ãÊñπÊ≥ï„ÄÇ ÂçïÁã¨ËÆ≠ÁªÉgxÂíågyÔºåÂõ†‰∏∫divergenceÂèØ‰ª•ÈÄöËøágxÂíågyÂæóÂà∞„ÄÇ label: gx 1234image = im2double(uint8(image));image = double(image);[gx, gy] = gradient(image);edge = gy+0.5; Label:gx_YY ËÆ≠ÁªÉÊ†∑Êú¨Ôºödetail_gradient15_gx.h5„ÄÅdetail_gradient15_gy.h5 Â∞ÜimageÂΩí‰∏ÄÂåñÂêéÊ±ÇÊ¢ØÂ∫¶ÔºåÂú®DIV2Êï∞ÊçÆ‰∏≠ËåÉÂõ¥Âú®[-0.4,+0.4] Â∞ÜÂΩí‰∏ÄÂåñÂêéÁöÑg_15Âíågx‰Ωú‰∏∫ËæìÂÖ•Âíålabel ÁõÆÂâçËÆ≠ÁªÉËé∑Âæó‰∏Ä‰∏™‰æùÁÑ∂Êê∫Â∏¶Âô™Â£∞ÁöÑÁÅ∞Â∫¶Âõæ ‰∏ã‰∏ÄÊ≠•ÂÆûÈ™åËÆ°Âàí ÁõÆÂâçÈóÆÈ¢ò ËÆ≠ÁªÉlossÂõûÂçáÁöÑÂéüÂõ† 09.01 È™åËØÅÊòØÂê¶gxÁöÑ‰ø°ÊÅØ‰πüÂèØ‰ª•ËæÖÂä©ÂéªÂô™Ôºå‰∏ç‰∏ÄÂÆöË¶Å‰∫åÈò∂‰ø°ÊÅØ„ÄÇ matlabËá™Â∏¶ÁöÑgradientÊìç‰Ωú ÁªìËÆ∫ÔºöÂéüÂõæÁöÑgx‰πüËÉΩÂ∏ÆÂä©ÂõæÂÉèÂ§çÂéüÔºåÊØîgxgyÁöÑ‰ø°ÊÅØÁöÑÊïàÊûúÁ®çÂ∑Æ‰∏ÄÁÇπ„ÄÇ ‰ΩÜÊòØÂØπgxÁöÑÂÅèÁßªÊàñËÄÖÁº©ÊîæÈÉΩ‰ºö‰∏•ÈáçÂΩ±ÂìçËæÖÂä©ÊïàÊûúÔºåÈÄöÂ∏∏ÊòØÊ≤°ÊúâÊïàÊûú„ÄÇ ËÆ°ÁÆóÊòØ‰∏ÄÂêåÁº©ÊîæÊàñËÄÖÂπ≥ÁßªÁöÑÂΩ±Âìç ‰∏ÄÈò∂ËæπÁºòÂíå‰∫åÈò∂ËæπÁºòÁöÑÂå∫Âà´ ‰∏ÄÈò∂ËæπÁºòÊõ¥ÂÉèÊòØ‰∏Ä‰∏™ÊµÆÈõïÂõæ„ÄÇ 09/04‰∏çÂêåÁöÑÁΩëÁªúÔºå‰∏çÂêåÁöÑlabelÔºåËÆ≠ÁªÉÁÅ∞Â∫¶ÂõæÁöÑÁªìÊûú 1.Â§©ËìùËâ≤ÔºöUnet, label-&gt;gradientXÁî®ÁöÑÊòØËá™Â∑±ÂÜôÁöÑgradient_x 2.Ê∑±Á∫¢: LjcÁöÑNetÔºålabel-&gt;gradientXÁî®ÁöÑÊòØËá™Â∑±ÂÜôÁöÑgradient_xÔºåÁΩëÁªúÁöÑÂΩ±Âìç‰∏çÂ§ß 3.Ê∑±ËìùËâ≤ÔºöUnet, label-&gt;gradientYÁî®ÁöÑÊòØÁ≥ªÁªü 4.ÈªÑËâ≤Ôºö Unet, label-&gt;gradientXÁî®ÁöÑÊòØÁ≥ªÁªü 12345678910111213141516171819202122232425262728% ‰∏ÄÈò∂ËæπÁºò%% 1.label: gradient matlabËá™Â∏¶Ê¢ØÂ∫¶image = im2double(uint8(image));image = double(image);[gx, gy] = gradient(image); %[-0.3, 0.3]edge1 = gx+0.5;%% 2.label: gradient_x Áõ∏ÈÇª‰∏§‰∏™ÂÉèÁ¥†ÁÇπÁöÑÂ∑ÆÂÄºedge = gradient_x(image) % [-0.6, 0.6]edge2 = edge/2.0+0.5 % [0.2, 0.8];% ‰∫åÈò∂ËæπÁºò%% zengÁöÑedgegx = gx./sqrt(gx.^2+gy.^2+1);gy = gy./sqrt(gx.^2+gy.^2+1);edge = divergence(gx,gy); [-0.6, 0.6]%% 3.label ÂΩí‰∏ÄÂåñÁöÑ‰∫åÈò∂ËæπÁºòÔºöËÆ≠ÁªÉÂá∫Êù•ÁöÑÁªìÊûúÊØîshiftÂ•Ω„ÄÇ‰ΩÜÊòØÁΩëÁªúÂπ∂Ê≤°ÊúâÊî∂ÊïõÁöÑË∂ãÂäøÔºüMaxValue = max(max(edge));MinValue = min(min(edge));edge2=(edge-MinValue)/(MaxValue-MinValue);%% 4.divgradientÔºöÁÆóÂ≠êÁöÑËøêÁÆóÊõ¥Áõ¥Êé•, ÂØπÂ∫îdivgradient_TËΩ¨ÁΩÆedge3 = divgradient(ftrue); # [-0.6, 0.6]% label_divgradient: edge3 = edge3/2.0;% label_divgradient: edge3 = edge3/2.0+0.5;% ÈÉΩÈááÁî®DenoiseNetÔºåÂÜçÂ∞ùËØïUnet Ê≠£ÂàôÈ°πÁöÑÊîπËøõ ÁÆóÂ≠êÂíåÁΩëÁªúedgeÂåπÈÖç Áº©Êîæ Âπ≥Áßª ‰∏ÄÈò∂gx‰∏ãÔºågradient_xÂíålabelÔºö‰∏ÄÈò∂ËæπÁºòÁ≥ªÁªügradientÁöÑpsnrÊúÄÈ´ò„ÄÇËßÜËßâÊïàÊûúÊúÄÂ•Ω„ÄÇ Ê≠£ÂàôÈ°πÁöÑÂèòÂΩ¢ $|x-edge_x|_{1}+|y-edge_y|_{2}$ ÁªìÊûú ËßÜËßâÊñπÈù¢ÔºåÂô™Â£∞Â§ßÁöÑÊó∂ÂÄôÔºåÊñ∞ÁöÑedgeËÉΩ‰∏çËÉΩÂáèÂ∞ëartifactsÔºü Âô™Â£∞‰ΩéÁöÑÊó∂ÂÄôÔºåpsnrËÉΩ‰∏çËÉΩÂçáÈ´ò ÈáçÂ§çÁöÑÁ∫πÁêÜËÉΩ‰∏çËÉΩÊèêÂá∫Êù• ‰ΩøÁî®divgradient+DenoiseNetÔºåSet12Ôºånoise=15ÔºåpsnrÊØîËøábm3d, sum(bm3d)=388.4312 alpha=0.1Ôºåbeta=0.3, sum(psnr)= 390.5050 alpha=0.1Ôºåbeta=0.4, sum(psnr)= 390.0549 alpha=0.1Ôºåbeta=0.2, sum(psnr)=390.2907 alpha=0.07Ôºåbeta=0.3, sum(psnr)=391.5980 09.09 ÈóÆÈ¢ò‰∏ÄÔºöÂô™Â£∞50‰∏ãÔºåÂéüÂõæÁöÑedgeÔºå‰πüÊó†Ê≥ïÂ∞ÜÂõæÂÉèÂ§çÂéü„ÄÇÊúâÊñëÈ©≥„ÄÇ Ëß£ÂÜ≥ÂäûÊ≥ïÔºö Ê£ÄÊü•ÊúâÊ≤°ÊúâËß£ÈîôÔºåbetaÂæàÂ∞èÁöÑÊÉÖÂÜµ‰∏ãÔºå‰∏∫‰ªÄ‰πà‰ºöÊúâÊñëÈ©≥ÔºåÁêÜÂ∫îÂíåÊ≤°ÊúâbetaÊòØ‰∏ÄËá¥ÁöÑ Â∞ùËØï‰∏§Ê≠•Ëß£Ê≥ïÔºåÂÖàtvÔºåÂÜçedge ‰∏çÂ§™Ë°åÔºöÂä†‰∏äÂéªÁöÑÁ∫πÁêÜÂÉèÂô™Â£∞ ÈóÆÈ¢ò‰∫åÔºöÊó†Ê≥ïÊèêÂèñÈ´òÂô™Â£∞‰∏ãÁöÑedge Ëß£ÂÜ≥ÂäûÊ≥ïÔºöÁî®Êñ∞ÁöÑËÆ≠ÁªÉ‰ª£Á†ÅÔºåÊàñËÄÖÊâæÂè¶‰∏Ä‰∏™‰∫∫‰∏ÄËµ∑ËÆ≠ÁªÉÔºåÂÖàÈ™åËØÅ15‰∏ãÁöÑlossÂíåÊ®°ÂûãÊòØÂ∑Æ‰∏çÂ§öÁöÑÊïàÊûú„ÄÇ ÂÖàÂ∞ùËØïÂô™Â£∞20 25 30 ËÆ∫ÊñáË¶Å‰øÆÊîπÁöÑÂú∞Êñπ Âô™Â£∞Á≠âÁ∫ßÂíåÂô™Â£∞ÊñπÂ∑Æ‰πãÈó¥ÁöÑÂÖ≥Á≥ª $\sigma=15,35,50$ Ê†áÂøóÁùÄÂô™Â£∞Á≠âÁ∫ß„ÄÇ ÂØπÂ∫îÂùáÂÄº‰∏∫0ÔºåÊñπÂ∑Æ‰∏∫$(\sigma/255)^2$ÁöÑÈ´òÊñØÁôΩÂô™Â£∞„ÄÇ Âô™Â£∞ÁöÑÂêàÊàêÁî±matlabÁöÑimnoiseÂÆåÊàê„ÄÇ ÂÆûÈ™åËØÑ‰ª∑ ÊØîËæÉÁöÑÊñπÊ≥ï NLM, BM3D, tight frame \cite{cai2014data} ÂèÇÊï∞ÁöÑÈÄâÊã© the code of BM3D and Tight frame are downloaded from thier official website. and run directly.? we choose the parameters for the best performance. TV: 15, alpha=0.01, 35, alpha=0.28, 07_tv28.bmp 50, alpha=0.38, 07_tv38.bmp Edge TV: 15, alpha=0.08, beta=0.3 35, alpha=0.25, beta=0.9 50, alpha=0.30, beta=0.8 ÊëòÂΩï g, the introduction of the second order term leads to a signiÔ¨Åcant reduction of the staircasing effect resulting in piecewise smooth images rather than piecewise constant images when using the ROF model. The superiority of an approach that combines Ô¨Årst and second order regularisation rather than Ô¨Årst order regularisation only, is conÔ¨Årmed quantitatively by the SSIM index. ÂõæÁâáË°®Ê†ºÁöÑÊîπËøõÔºö Ë°•ÂÖÖÂô™Â£∞Á∫ßÂà´ÂíåÂô™Â£∞variance‰πãÈó¥ÁöÑÂÖ≥Á≥ª Ôºàsigma/255Ôºâ^2; therefore 15 corresponds to the 50 corresponds to Ë°•ÂÖÖÂèÇÊï∞Ë°®Ê†º Â∞ÜÊâÄÊúâpsnrÂèÇÊï∞Áî®Á∫¢Ëâ≤Ê†áÂá∫ÔºåÊääË°®Ê†ºËΩ¨ÁΩÆ The results are illustrated in Fig. 15 . And all the numerical mesurements of the results of Set 12 is listed in Table 7. the psnr and ssim of the proposed methods which outperform the BM3Dis marked red in ÂõæÂêéÈù¢ÂèØ‰ª•Âä†Ëß£Èáä tight frameÂíåBM3DÁöÑÂèÇÊï∞‰∏çÈúÄË¶Å for BM3D and tight frameÔºåwe use their code published on their and the parameters are tuned to the best performance Ë∞ÉÂèÇÁöÑÂèØËßÜÂåñ ËØÑ‰ª∑ ÊïàÁéáÔºö For tight frame based methods, a sparse basis for transforming the noisy images to a sparser representation is the crucial step.a over-complete dictionary is calculated for each noisy image, where it can get a sparse representation. BM3DÔºåblock searching, time costÔºåPatch-based methods, searching the pixels in a similar block, and therefore cosume a lot of time p needs to be trained for different level of noise rather than different images. for images of diÔ¨Äerent types, ÊïàÊûú these methods all work quite well in the case of noise 15. Therefore,we have to show you the the enlaegement to see the tiny difference. Compared to BM3D, EdgeTV is more sharp in the edge, as in the Êµ∑Êòü„ÄÇ It is much smoother in the smooth district, sometimes even smoother and smoothed but not at the loss of the detail. Actually, BM3D is still oversmoothed as in the mouth of parrot. Actually, the sharp the edg Comparisons of denoising results with other methods on Set12 ËÆ∫ÊñáÂÆûÈ™åÈÉ®ÂàÜÂèÇËÄÉ Êû∂ÊûÑÂèÇËÄÉ 3.3 Inpainting 3.4 Zooming 3.5 Denoising ÈòêÊòéÊØîËæÉÁöÑÊñπÊ≥ïÔºõÈòêËø∞ÂêÑÁßçÊñπÊ≥ï‰∏≠ÁöÑË∂ÖÂèÇÔºåÂàùÂßãÊù°‰ª∂Ôºõ 3.5.1 Synthetic Image Âô™Â£∞ÁöÑÁ∫ßÂà´ÔºõÁÆóÊ≥ïÁöÑËø≠‰ª£Ê¨°Êï∞ÔºõÈòêËø∞ÁªìÊûúÁöÑËßÜËßâÊïàÊûú„ÄÇ 3.5.2 Natural Image Âô™Â£∞ÁöÑÁ∫ßÂà´ÔºõÂèÇÊï∞ÁöÑËÆæÁΩÆ,Ëø≠‰ª£Ê¨°Êï∞ÔºõËØÑ‰ª∑ÁªìÊûúÔºàÂÖàÊääË°®Ê†ºÂíåÂõæÊ†áËØ¥ÊòéÂÖ∑‰ΩìÂåñÔºöÂÖ∑‰ΩìÊüêÂàóÊüê‰∏™ÁªÜËäÇÁöÑÊèèËø∞ÊñπÊ≥ïÔºâ In all the experiments displayed in Fig. 15, we observe a similar phenomenon. The TV regularization contains staircasing effects and reduces the contrast or erases thin features,see the ropes in Boat. Some gray stripes on the NLTV denoising result become less notable, see the second row, fourth column in Fig. 16. NLTVG denoising results have similar problems because of an excessive blur. BM3D puts distracting artifact around ropes, see the Ô¨Årst row, sixth column in Fig. 16, and smooths out some of the textures on the scarf ÂõæÁâáÁöÑÁªÑÊàê ÂçïÂº†ÂõæÁöÑÊâÄÊúâÂô™Â£∞‰∏çÂêåÊñπÊ≥ïÁöÑÁªìÊûúÔºõÂèÇÊï∞ÁöÑËÆæÁΩÆÔºõÂ§öÂº†ÂõæÁöÑÂ§öÁßçÂô™Â£∞ÁªìÊûúÔºõË°®Ê†ºÊï∞ÂÄºÔºõÊîæÂ§ßÂå∫ÂüüÊØîËæÉ ÈòêÊòéÂ§ÑÁêÜÁöÑÈóÆÈ¢òÔºödenoising, images corrupted with Gaussian noise, thus L2 norm in the fidelity term is the most suitable. ÊØîËæÉÊñπÊ≥ï: We compare our method with‚Ä¶ ÂèÇÊï∞ÈÄâÊã©: We present examples of (5.2) for alpha=, beta=. ÊúâÈ¢ùÂ§ñËØ¥ÊòéÁöÑÁî®Note that ÊµãËØïÁöÑÂõæÂÉèÔºöthe basic synthetic test image is shown in Fig. 3. ËØÑ‰ª∑ÊñπÊ≥ïÔºöOur main assessment for the quality of the reconstruction is the structural similarity index SSIM. The SSIM index also assesses the conservation of the structural information of the reconstructed image. N ÂÆûÈ™åÁöÑÁªàÊ≠¢Êù°‰ª∂:Âõ∫ÂÆöËø≠‰ª£Ê¨°Êï∞ ËØÑ‰ª∑Ôºö ËØçÁªÑÊëòÂΩï visual quality, visual inspection, Âô™Â£∞ We consider additive Gaussian white noise with standard deviation œÉ = 0.04, 0.06 and 0.08 The noise has been produced with MATLAB‚Äôs built in function imnoise. ÂèÇÊï∞ÈÄâÊã© The setting of the parameters in RNLTV and NLTV is presented in Tables 5 and 6, respectively. The number of iterations 8 is both 600. BM3D does not have any input parameters (except the polluted image). The parameter of the TV model is tuned to Ô¨Ånd the best restoration quality. The highest SSIM value for TV denoising is achieved for Œ± = 0.12 (SSIM =0.8979) while the highest one for TV-TV 2 is achieved for Œ± = 0.06, Œ≤ = 0.03 (SSIM = 0.9081). Note, however, that this optimal combination of Œ± and Œ≤ in terms of SSIM does not always correspond to best visual result. In general, the latter corresponds to a slightly bigger Œ≤ than the one chosen by SSIM, see Fig. 5(h). ÁúãÂõæËØ¥ËØù See Fig. 4 for an visual inspection of the results for the image ‚ÄúBarbara‚Äù by diÔ¨Äerent methods. Figure 5 depicts one denoising example, where the original image is corrupted with Gaussian noise of variance 0.005. For better visualisation, we include the middle row slices of all the reconstructions in Fig. 6. ÂØπTVÁöÑËØÑ‰ª∑ The TV regularization contains staircasing effects and reduces the contrast or erases thin features, see the ropes in Boat. ‚Äîwhile being simple and efÔ¨Åciently numerically solvable. ‰∏çÂêåÊñπÊ≥ïÁöÑÊØîËæÉ the performances of the K-SVD method with patch size 8√ó8 and our approaches with Ô¨Ålter 8√ó8, 16√ó16 are nearly the same with similar PSNR values. Overall, the performances of our proposed method and the K-SVD method are comparable in terms of PSNR value, and so is the visual quality. There are images on which the K-SVD method performed better and there are some on which our approaches performed better. Êó∂Èó¥ÊØîËæÉ Moreover, the computational effort needed for its numerical solution is not much more than the one needed for solving the standard ROF model [61]. For comparison the numerical solution for TGV regularisation is in general about ten times slower than this, see Table 1 at the end of the paper. ÊñπÊ≥ïÁöÑÂª∂‰º∏ Let us note that the algorithm (5.19)‚Äì(5.23) can be easily generalised to colour images, again see [57, 76].]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Proof_Ëß£ÁöÑÂ≠òÂú®ÊÄß]]></title>
    <url>%2Fp%2Fe1d.html</url>
    <content type="text"><![CDATA[ÁõÆÂΩï Â≠òÂú®ÊÄßÔºöÂ≠òÂú®Êî∂ÊïõÁöÑÂ∫èÂàó ÂîØ‰∏ÄÊÄßÔºåÂá∏ÊÄß Ëß£Â≠òÂú®ÊÄßËØÅÊòé‰æãÂ≠ê1 ËØÅÊòé $\inf _{\Omega} f \leq u^{*} \leq \sup _{\Omega} f$ ÈÄöËøáÊúâÁïåÊÄßËØ¥Êòé ËØÅÊòéÊúâÁïåÊÄß BVÁöÑÊúâÁïåÊÄß Ëß£Â≠òÂú®ÊÄßËØÅÊòé‰æãÂ≠ê2ÈóÆÈ¢òÁöÑËΩ¨Âåñ1.ÂéüÈóÆÈ¢òÔºöThe natural space for the functional H to be deÔ¨Åned in, is $W^{2,1}(\Omega)$ \begin{aligned} H(u)=& \frac{1}{2} \int_{\Omega}\left(u_{0}-T u\right)^{2} d x+\alpha \int_{\Omega} f(\nabla u) d x +\beta \int_{\Omega} g\left(\nabla^{2} u\right) d x \end{aligned}Áº∫ÁÇπÔºöthis space is not reÔ¨Çexive(Ëá™ÂèçÁ©∫Èó¥), and thus existence of minimisers cannot be guaranteed. ÊØè‰∏™ÊúâÈôêÁª¥ËµãËåÉÂêëÈáèÁ©∫Èó¥ÈÉΩÊòØËá™ÂèçÁ©∫Èó¥„ÄÇ ÊâÄÊúâÁöÑÂ∏åÂ∞î‰ºØÁâπÁ©∫Èó¥ÈÉΩÊòØËá™ÂèçÁ©∫Èó¥„ÄÇÊØîÂ¶ÇËØ¥Ôºå$\mathrm{L}^2$Á©∫Èó¥ÊòØËá™ÂèçÁ©∫Èó¥„ÄÇ 2.Á©∫Èó¥ÊãìÂ±ï‰∏äÔºöextend the functional H in (3.5) to $\mathrm{BH}(\Omega)$ H_{e x}(u)=\left\{\begin{array}{l}{\frac{1}{2} \int_{\Omega}\left(u_{0}-T u\right)^{2} d x+\alpha \int_{\Omega} f(\nabla u) d x} \\ {+\beta \int_{\Omega} g\left(\nabla^{2} u\right) d x \quad \text { if } u \in W^{2,1}(\Omega)} \\ {+\infty \text { if } f \in \mathrm{BH}(\Omega) \backslash W^{2,1}(\Omega)}\end{array}\right.Áº∫ÁÇπÔºö$H_{ex}$ is not sequentially lower semicontinuous with respect to the strict topology in BH(Œ©) and hence it is neither with respect to the $weak^‚àó$ topology in $[\mathrm{BH}(\Omega)]^{n}$ ‰∏∫‰ªÄ‰πàÈúÄË¶Ålower semicontinuous? $BH$Á©∫Èó¥, $\mathrm{BH}(\Omega)=\left\{u \in W^{1,1}(\Omega) : \nabla u \in[\mathrm{BV}(\Omega)]^{2}\right\}$ the $weak^‚àó$ topology in BH(Œ©) provides a good compactness property which is inherited from the weak ‚àó topology in $[\mathrm{BV}(\Omega)]^{n}$ 3.ÂáΩÊï∞‰∏äÊãìÂ±ïÔºöRelaxed functional Â∞Ü$\nabla$ÊîπÊàêÂèØ$D$, ÂÜçÂ∞Ü$D$ÂàÜËß£ \begin{aligned} \overline{H_{e x}}(u) :=& \frac{1}{2} \int_{\Omega}\left(u_{0}-T u\right)^{2} d x+\alpha \int_{\Omega} f(\nabla u) d x \\ &+\beta g\left(D^{2} u\right)(\Omega) \\=& \frac{1}{2} \int_{\Omega}\left(u_{0}-T u\right)^{2} d x+\alpha \int_{\Omega} f(\nabla u) d x \\ &+\beta \int_{\Omega} g\left(\nabla^{2} u\right) d x \\ &+\beta \int_{\Omega} g_{\infty}\left(\frac{D^{s} \nabla u}{\left|D^{s} \nabla u\right|}\right) d\left|D^{s} \nabla u\right| \end{aligned} Relaxed functionÔºö ‰ºòÁÇπÔºö lower semicontinuous„ÄÇ Theorem 3.6 The functional $\overline{H_{e x}}(u)$ is lower semicontinuous with respect to the strict topology in $\mathrm{BH}(\Omega)$. which means, $\overline{H_{e x}}(u)\le\lim_{k\to\infty}\inf\overline{H_{e x}}(u_k)$, when $u_k\to u$, in $\mathrm{BH}{(\Omega)}$ Also, $\overline{H_{e x}}(u)\le\lim_{k\to\infty}\inf\overline{H_{e x}}(u_k)$, when $u_k\rightarrow^{w^*} u$, in $\mathrm{BH}{(\Omega)}$ ËØÅÊòéÊ≠•È™§ÁõÆÊ†áÊñπÁ®ãÔºö$\inf _{u \in \mathrm{BH}(\Omega)} \overline{H_{e x}}(u)$ Âèñ‰∏Ä‰∏™minimizing sequence $\{u_k\}$ ËØÅÊòé$\{u_k\}$ is bounded in BH(Œ©). Âà©Áî®BHÁöÑcompactness, ÂæóÂà∞$u_k\rightarrow u$ weakly Âú®BHÁ©∫Èó¥ Âà©Áî®${H_{ex}}$ÁöÑ‰∏ãÂçäËøûÁª≠ÊÄßÔºåÂæóÂà∞ $\overline{H_{e x}}(u)\le\lim_{k\to\infty}\inf\overline{H_{e x}}(u_k)$ which implies that(Âõ†‰∏∫$u_k$minimizing): $u=\min _{u \in \mathrm{BH}(\Omega)} \overline{H_{e x}}(u)$ Âà©Áî® property of the relaxed functionalÔºö$\min _{x \in X} F(x)=\inf _{x \in X} F(x)$ ÈóÆÈ¢òÔºöÔºüÈÇ£‰∏çÊòØÂè™ËÉΩËØ¥ÊòéFÂ≠òÂú®‰∏ãÁïåÔºü inf F(x) = min F(x) BregmanÁÆóÊ≥ïÁöÑÊî∂ÊïõÊÄßËØÅÊòé ÂèÇËÄÉ ‚ÄúTHE SPLIT BREGMAN METHOD FOR L1 REGULARIZED PROBLEMS‚Äù ÂèÇËÄÉ ‚ÄúA Combined First and Second Order Variational Approach for Image Reconstruction‚Äù Á∫ßÊï∞ÁöÑÊî∂ÊïõÁ∫ßÊï∞Ôºö‰∏Ä‰∏™ÊúâÁ©∑ÊàñÊó†Á©∑ÁöÑÂ∫èÂàóÁöÑÂíåÁß∞‰∏∫Á∫ßÊï∞„ÄÇÊ†πÊçÆÈ°πÊï∞ÂàÜ‰∏∫ÔºöÊúâÁ©∑Á∫ßÊï∞ÂíåÊó†Á©∑Á∫ßÊï∞ Êó†Á©∑Á∫ßÊï∞ÁöÑÊî∂ÊïõÊÄßÔºöÂ¶ÇÊûúÂΩì$n$Ë∂ã‰∫éÊ≠£Êó†Á©∑Â§ßÊó∂ÔºåË∂ãÂêë‰∏Ä‰∏™ÊúâÈôêÁöÑÊûÅÈôê„ÄÇÂ¶ÇÊûúÂΩìË∂ã‰∫éÊ≠£Êó†Á©∑Â§ßÊó∂ÔºåË∂ãÂêë‰∏Ä‰∏™ÊúâÈôêÁöÑÊûÅÈôê)Ôºö Êù°‰ª∂Êî∂ÊïõÔºöÂ¶ÇÊûú‰ªªÊÑèÈ°πÁ∫ßÊï∞Êî∂ÊïõÔºåËÄåÁ∫ßÊï∞ÂèëÊï£ÔºåÂàôÁß∞Á∫ßÊï∞Êù°‰ª∂Êî∂Êïõ„ÄÇ ÁªùÂØπÊî∂ÊïõÔºöÂ¶ÇÊûúÁ∫ßÊï∞Êî∂ÊïõÔºåÂàôÁß∞Á∫ßÊï∞ÁªùÂØπÊî∂Êïõ„ÄÇÁªùÂØπÊî∂Êïõ-&gt;Êù°‰ª∂Êî∂Êïõ Êî∂ÊïõÁ∫ßÊï∞ÁöÑÊÄßË¥®ÔºöÂΩìË∂ãÂêëÊó†ÈôêÂ§ßÊó∂Ôºå‰ªª‰Ωï‰∏Ä‰∏™Êî∂ÊïõÁ∫ßÊï∞ÁöÑÈÄöÈ°πÈÉΩË∂ã‰∫é0Ôºö Â∫èÂàóÁöÑÊî∂ÊïõÊÄßÊúâÁïå ÂÆö‰πâ Thus a sequence f = (a0, a1, a2, ‚Ä¶) is bounded if there exists a real number M such that ÂÆûÊï∞‰∏≠ÁöÑÂÆö‰πâ Â¶ÇÊûúÂ≠òÂú®‰∏Ä‰∏™ÂÆûÊï∞ kÔºå‰ΩøÂæóÂØπ‰∫éÊâÄÊúâ S ‰∏≠ÁöÑ s Êúâ k ‚â• sÔºåÂÆûÊï∞ÈõÜÂêà S Ë¢´Áß∞‰∏∫‚Äú‰∏äÊúâÁïå‚ÄùÁöÑÔºåËøô‰∏™Êï∞ k Ë¢´Áß∞‰∏∫ S ÁöÑ‰∏äÁïå„ÄÇÂèØÁî®Á±ª‰ººÁöÑÂÆö‰πâÊúØËØ≠‚Äú‰∏ãÊúâÁïå‚ÄùÂíå‰∏ãÁïå„ÄÇ Â∫¶ÈáèÁ©∫Èó¥‰∏≠ÁöÑÂÆö‰πâ Â∫¶ÈáèÁ©∫Èñì (M, d) ÁöÑÂ≠êÈõÜS ÊòØÊúâÁïåÁöÑÔºåÂ¶ÇÊûúÂÆÉÂåÖÂê´Âú®ÊúâÈôêÂçäÂæëÁöÑÁêÉÂÖßÔºåÂ∞±ÊòØË™™Â¶ÇÊûúÂ∞çÊñºÊâÄÊúâ S ‰∏≠ÁöÑ sÔºåÂ≠òÂú® M ‰∏≠ÁöÑ x ‰∏¶‰∏î r &gt; 0Ôºå‰ΩøÂæó d(x, s) &lt; r„ÄÇM ÊòØÊúâÁïåÂ∫¶ÈáèÁ©∫ÈñìÔºàÊàñ d ÊòØÊúâÁïåÂ∫¶ÈáèÔºâÔºåÂ¶ÇÊûú M ‰ΩúÁÇ∫Ëá™Ë∫´ÁöÑÂ≠êÈõÜÊòØÊúâÁïåÁöÑ„ÄÇ Á©∫Èó¥ ÂêëÈáèÁ©∫Èó¥„ÄÅÂáΩÊï∞Á©∫Èó¥ LpÁ©∫Èó¥ LpÁ©∫Èó¥ÊòØÁî±pÊ¨°ÂèØÁßØÂáΩÊï∞ÁªÑÊàêÁöÑÁ©∫Èó¥ÔºõÂØπÂ∫îÁöÑ‚ÑìpÁ©∫Èó¥ÊòØÁî±pÊ¨°ÂèØÂíåÂ∫èÂàóÁªÑÊàêÁöÑÁ©∫Èó¥ÔºåÊúâÊó∂Âè´ÂÅöÂãíË¥ùÊ†ºÁ©∫Èó¥„ÄÇ Sobolev spaces: $W^{1,1}$, $W^{2,1}$ Equipped with the norm becomes a Banach space. BanachÁ©∫Èó¥ÔºöÂÆåÂ§á(ÊüØË•øÊî∂ÊïõÂç≥Êî∂Êïõ)+ËµãËåÉ, Â±û‰∫éHilbertÁ©∫Èó¥ A Banach space is a vector space X over any scalar field K, which is equipped with a norm) and which is complete with respect to the distance function induced by the norm, that is to say, for every Cauchy sequence ${x_n}$ in X, there exists an element x in X such that $\lim _{n \rightarrow \infty} x_{n}=x$ BVÁ©∫Èó¥ One variable Functions of bounded variation, BV functions), are functions whose distributional derivative is a finite[5] Radon measure. $|u|_{\mathrm{BV}(\Omega)} :=\int_{\Omega}|u| d x+|D u|(\Omega)$ $BV^2$Á©∫Èó¥ $|u|_{\mathrm{BV}(\Omega)} :=\int_{\Omega}|u| d x+|D u|(\Omega)$ BHÁ©∫Èó¥, Â±û‰∫éBanachÁ©∫Èó¥ $\mathrm{BH}(\Omega)=\left\{u \in W^{1,1}(\Omega) : \nabla u \in[\mathrm{BV}(\Omega)]^{2}\right\}$ $\mathrm{BH}(\Omega)$ is a Banach space equipped with the norm $|u|_{B H(\Omega)}=|u|_{B V(\Omega)}+\left|D^{2} u\right|(\Omega)$. DeÔ¨Ånition 3.1 ($Weak^‚àó$ Convergence in BH(Œ©)) We say that $(u_k ),k\in N$ converges to $u$ $weakly^‚àó$ in $\mathrm{BH}(\Omega)$ if $u_{k} \rightarrow u, \quad \text {in} L^{1}(\Omega)$ and $\nabla u_{k} \rightarrow \nabla u \quad \text {weakly }^{*} \text { in }[\mathrm{BV}(\Omega)]^{2},\text{as } k \rightarrow \infty$ or in other words: \begin{array}{l}{\left\|u_{k}-u\right\|_{L^{1}(\Omega)} \rightarrow 0} \\ {\left\|\nabla u_{k}-\nabla u\right\|_{\left[L^{1}(\Omega)\right]^{2}} \rightarrow 0} \\ {\int_{\Omega} \phi d D^{2} u_{k} \rightarrow \int_{\Omega} \phi d D^{2} u, \quad \forall \phi \in C_{0}(\Omega)}\end{array} Theorem 3.2 (Compactness in $\mathrm{BH}(\Omega)$): ÂèØÊ†πÊçÆboundedÂæóÂà∞Êî∂ÊïõÁöÑÂ∫èÂàó Suppose that the sequence $\left(u_{k}\right)_{k \in \mathbb{N}}$ is bounded in $\mathrm{BH}(\Omega)$. Then there exists a subsequence $\left(u_{k_{\ell}}\right)_{\ell \in \mathbb{N}}$ and a function $u \in \mathrm{BH}(\Omega)$ such that $\left(u_{k_{\ell}}\right)_{\ell \in \mathbb{N}}$ converges to u $weakly^‚àó$ in $\mathrm{BH}(\Omega)$. DeÔ¨Ånition 3.3 (Strict Convergence in BH(Œ©)) We say that $(u_k ),k\in N$ converges to $u$ $strictly$ in $\mathrm{BH}(\Omega)$ if $u_{k} \rightarrow u, \quad \text {in } L^{1}(\Omega)$ and the weak ‚àó topology in BH(Œ©) provides a good compactness property which is inherited from the weak ‚àó topology in [BV(Œ©)] n. CompactnessÔºöÂèØÊ†πÊçÆboundedÂæóÂà∞Êî∂ÊïõÁöÑÂ∫èÂàó Lebesgue space Â∞±ÊòØLpÁ©∫Èó¥Ôºü ÂêÑÁ±ªÁ©∫Èó¥ Â∫èÂàó ÊüØË•øÂ∫èÂàó ÂÆö‰πâÔºö ÂíåÊî∂ÊïõÂ∫èÂàóÁöÑÂÖ≥Á≥ªÔºö‰ªª‰ΩïÊî∂ÊïõÊï∞ÂàóÂøÖÁÑ∂ÊòØÊüØË•øÂàóÔºå‰ªª‰ΩïÊüØË•øÂàóÂøÖÁÑ∂ÊòØÊúâÁïåÂ∫èÂàó„ÄÇ Êó†ÈôêÁª¥Â∫¶‰∏≠ÁöÑÊúâÁïåÂ∫èÂàóÂÖ∑‰ΩìÂê´‰πâÔºöËßÅ‚ÄúÊúâÁïå‚Äù ÊüØË•øÂàóÊòØÂê¶‰∏ÄÂÆöÊòØÊî∂ÊïõÁöÑÔºü Â∫èÂàóÊî∂ÊïõÁöÑÂÆö‰πâ Êî∂Êïõ(Âº∫)ÔºöÂÆö‰πâÂú®norm Âº±(weak)Êî∂ÊïõÔºöÂÆö‰πâÂú®ÂÜÖÁßØ weak*Êî∂ÊïõÔºö ÂÆûÊï∞Â∫èÂàóÊî∂ÊïõÁöÑÂà§Âà´ÊñπÊ≥ï Bolzano-Weierstrass: ‰ªª‰∏ÄÊúâÈôêÁª¥ÂÆûÂêëÈáèÁ©∫Èó¥$\mathbb {R} ^{n}$‰∏≠ÁöÑÊúâÁïåÂ∫èÂàóÈÉΩËá≥Â∞ëÂåÖÂê´‰∏Ä‰∏™Êî∂ÊïõÁöÑÂ≠êÂàó„ÄÇ ÊúâÁïå‰∏ç‰∏ÄÂÆöÊî∂Êïõ ÊúâÁïåÂ∫èÂàóÊòØ‰ªÄ‰πàÊÑèÊÄùÔºü ÊúâÁïåÂ∫èÂàó Theorem 3.2 (Compactness in $\mathrm{BH}(\Omega)$) Suppose that the sequence $(u_k)_{k \in N}$ is bounded in $\mathrm{BH}(\Omega)$. Then there exists a subsequence $\left(u_{k_{\ell}}\right)_{\ell \in \mathbb{N}}$ and a function $u \in \mathrm{BH}(\Omega)$ such that $\left(u_{k_{\ell}}\right)_{\ell \in \mathbb{N}}$ converges to $u$ weakly‚àó in $\mathrm{BH}(\Omega)$. ‰∏çÂêåÁöÑÊî∂ÊïõÈÄüÂ∫¶ converge sublinearly $\lim _{k \rightarrow \infty} \frac{\left|x_{k+1}-L\right|}{\left|x_{k}-L\right|}=1$ converge linearly $\lim _{k \rightarrow \infty} \frac{\left|x_{k+1}-L\right|}{\left|x_{k}-L\right|}=\mu, \mu \in(0,1)$ converge superlinearly $\lim _{k \rightarrow \infty} \frac{\left|x_{k+1}-L\right|}{\left|x_{k}-L\right|}=0$ Q-linear convergence: distinguish superlinear rates of convergence. $\lim _{k \rightarrow \infty} \frac{\left|x_{k+1}-L\right|}{\left|x_{k}-L\right|^{q}}&lt;M$ Monotone operator ‰∏çÂêåÁöÑÊî∂ÊïõÊ®°Âºè Âº∫Êî∂Êïõ Âº±Êî∂Êïõ Ë°•ÂÖÖFatous lemma Lower semi-continuous A lower semi-continuous function. $f(x)=\lceil x \rceil$ is lower semi-continuous. An upper semi-continuous function. Distributional derivative weak derivative Reference Distributions and distributional derivatives Distributional Derivative ÈóÆÈ¢ò ËØÅÊòé‰∏≠ÁöÑÈóÆÈ¢ò minimizing sequenceÂ∞±‰∏çÊòØbounded in BHÔºü ÂàÜËß£ÁöÑÂâçÊèêÂè™ÈúÄË¶ÅgÊòØËøûÁª≠ÁöÑÔºåconvexÔºå‰∏çÈúÄË¶Åcoercivity condition ËØÅÊòébounded in BHÁöÑÂÖÖÂàÜÊù°‰ª∂ÊòØ‰ªÄ‰πà BHÁ©∫Èó¥ÁöÑÊâ©Â±ï‰∏≠Ôºå‰ªénablaÂà∞DÁöÑËøáÁ®ãËΩ¨Âèò K-SVD code Á∫øÊÄßÂ¢ûÈïøÊòØÂê¶‰∏ÄÂÆöÁ≠â‰ª∑‰∫é‰∏ãËø∞‰∏çÁ≠âÂºèÔºü‰ΩúÁî®ÊòØ‰ªÄ‰πàÔºü‰ª•ÂèäÂàÜËß£ÁöÑ‰ΩúÁî®Ôºü coercivity condition ÊòØ‰ªÄ‰πàÔºü‰∏ÄÂÆöÁ≠â‰ª∑‰∫éÔºüÂú®Ê≠§Â§ÑÁöÑ‰ΩúÁî®ÊòØ‰ªÄ‰πàÔºü ÈóÆÈ¢ò Linear growth ‰∏∫‰ªÄ‰πàÈúÄË¶Å$1+|x|$ $Du=\nabla u$ ÂΩì‰∏î‰ªÖÂΩì$u \in W^{1,1}$ $\nabla$ÊõøÊç¢ÊàêDÔºå‰∏∫‰ªÄ‰πàÂèØ‰ª•Â∞ÜÊñπÁ®ãrelaxed, ÁªßËÄåÂØπgÁöÑÂàÜËß£ gÂàÜËß£ÁöÑÂâçÊèêÂíå‰æùÊçÆÔºü minimizing sequenceÊòØ‰ªªÊÑèÂèñÁöÑÊú™ÂøÖÂú®${W^{1,1}}$‰∏≠ÔºåÈÇ£‰πà‰∏∫‰ªÄ‰πàm Du bounded, L1 bounded-&gt; bounded in BH? relaxed $\overline H$ÊúâËß£Ôºå‰∏∫‰ªÄ‰πà‰ª£Ë°®ÂéüÈóÆÈ¢òÊúâËß£ÔºüÈúÄË¶Å $\min \overline{H}=\inf H$ Á¶ªÊï£ÂåñSplitting bregmanÁöÑÊî∂ÊïõÊÄß]]></content>
      <categories>
        <category>Êï∞Â≠¶</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Ê¶ÇÁéáÂõæÊ®°Âûã]]></title>
    <url>%2Fp%2Fd0e9.html</url>
    <content type="text"><![CDATA[ÁªüËÆ°Â≠¶Áü•ËØÜ ÊûÅÂ§ß‰ººÁÑ∂‰º∞ËÆ°‰∏éÊúÄÂ§ßÂêéÈ™åÊ¶ÇÁéá‰º∞ËÆ° ÊûÅÂ§ß‰ººÁÑ∂‰º∞ËÆ°Ôºöp(X=Â§¥Áóõ|Y=‰∏≠È£é)=0.8 P(X=Â§¥Áóõ|Y=ÊÑüÂÜí)=0.5 P(X=Â§¥Áóõ|Y=) X=Â§¥Áóõ Y=argmaxP(X=Â§¥Áóõ|Y) Y=‰∏≠È£é ÊúÄÂ§ßÂêéÈ™åÊ¶ÇÁéáÔºöY = argmax p(Y|X=Â§¥Áóõ)=P(X|Y)P(Y) ÁîüÊàêÊ®°ÂûãÂíåÂà§Âà´Ê®°ÂûãÁöÑÂå∫Âà´ Âà§Âà´Ê®°Âûã p(y|x), Áªô‰∏Ä‰∏™XÔºåÂà§Êñ≠y=1ÁöÑÂÄº„ÄÇ Áîü‰∫ßÊ®°Âûã p(y|x)Á≠â‰ª∑‰∫ép(x|y)p(y)=p(x,y)„ÄÇÈúÄË¶ÅÊûÑÈÄ†‰∏Ä‰∏™p(x|y=1)p(y=1)ÁöÑÊ†πÊçÆÈªÑÁâõÁâπÂæÅÂæóÂà∞ÁöÑÈªÑÁâõÊ®°ÂûãÔºåp(x|y=0)p(y=0)ÁöÑÊ∞¥ÁâõÊ®°ÂûãÔºåÊØîËæÉËÅîÂêàÊ¶ÇÁéáÂØÜÂ∫¶„ÄÇ Ê∑±Â∫¶Â≠¶‰π†‰∏≠ÁöÑÁîüÊàêÊ®°ÂûãÔºöÊ∑±Â∫¶Â≠¶‰π†ÁöÑ‰∏âÂ§ßÁîüÊàêÊ®°ÂûãÔºöVAE„ÄÅGAN„ÄÅGAN„ÄÅÂçÅ‰∏™ÁîüÊàêÊ®°Âûã(GANs)ÁöÑÊúÄ‰Ω≥Ê°à‰æãÂíåÂéüÁêÜ„ÄÅ Ê¶ÇÁéáÂõæÊ®°Âûã structured probabilistic models.Ê¶ÇÁéáÂõæÊ®°ÂûãÔºöÁî®ÂõæËÆ∫Ë°®Áé∞ÈöèÊú∫ÂèòÈáè‰πãÈó¥ÁöÑÊù°‰ª∂‰æùËµñÂÖ≥Á≥ªÁöÑÂª∫Ê®°ÊñπÊ≥ï„ÄÇÂÖ∏ÂûãÁöÑÊ¶ÇÁéáÂõæÊ®°ÂûãÂåÖÊã¨Ë¥ùÂè∂ÊñØÁΩëÁªúÂíåÈ©¨Â∞îÂèØÂ§´ÈöèÊú∫Âú∫ÔºåÂàÜÂà´ÂØπÂ∫îÁùÄÊúâÂêëÂõæÊ®°ÂûãÂíåÊó†ÂêëÂõæÊ®°Âûã„ÄÇ ÂÆÉ‰ª¨Êèê‰æõ‰∫ÜÂ∞ÜÊ¶ÇÁéáÊ®°ÂûãÁöÑÁªìÊûÑÂèØËßÜÂåñÁöÑÁÆÄÂçïÊñπÂºèÔºåËÄåÂØπÂõæÂΩ¢ÁöÑËßÇÂØüÂèØ‰ª•Âä†Ê∑±ÂØπÊ®°ÂûãÊÄßË¥®ÁöÑËÆ§ËØÜÔºåÂÖ∂‰∏≠ÊúÄ‰∏ªË¶ÅÁöÑÊÄßË¥®Â∞±ÊòØÂèòÈáè‰πãÈó¥ÁöÑÊù°‰ª∂Áã¨Á´ãÊÄß„ÄÇÊ≠§Â§ñÔºåÊ¶ÇÁéáÂõæÊ®°ÂûãËøòÂèØ‰ª•Ë°®Á§∫Â≠¶‰π†ÂíåÊé®Êñ≠ËøáÁ®ã‰∏≠ÁöÑÂ§çÊùÇËÆ°ÁÆóÔºåÈöêÂºèÂú∞ÊâøËΩΩ‰∫ÜÂõæÂΩ¢ËÉåÂêéÁöÑÊï∞Â≠¶Ë°®Ëææ„ÄÇ ‰ºòÁÇπÔºöÂõæÊ®°ÂûãÂª∫Ê®°ÊñπÂºèÁöÑ‰ºòÁÇπÊòØÔºöÂ§öÂèòÈáèÂàÜÂ∏ÉÈÄöÂ∏∏ÂèØ‰ª•Ë°®Á§∫‰∏∫‰∏Ä‰∫õÂ±ÄÈÉ®ÂáΩÊï∞Ôºàlocal functionsÔºâÁöÑ‰πòÁßØÔºåËÄåÊØè‰∏™Â±ÄÈÉ®ÂáΩÊï∞‰æùËµñ‰∫éÊõ¥Â∞èÁöÑÂèòÈáèÂ≠êÈõÜ„ÄÇÈÄöËøáÂõ†Â≠êÂåñÔºàfactorizationÔºâÂíåÊù°‰ª∂Áã¨Á´ãÊÄßÔºàconditional independenceÔºâÔºå‰ΩøÂæóÂ§çÊùÇÁöÑÂ§öÂèòÈáèÂàÜÂ∏ÉÂèØ‰ª•Áî®Â∞ëÂæóÂ§öÁöÑÂèÇÊï∞ËøõË°åÂàªÁîª„ÄÇ 1„ÄÅÊ¶ÇÁéáÊ®°ÂûãÊòØÂà©Áî®ËÆ≠ÁªÉÊ†∑Êú¨Êï∞ÊçÆÔºåÈÄöËøáÂ≠¶‰π†Êù°‰ª∂Ê¶ÇÁéáÂàÜÂ∏ÉP(X|Y)Êù•ËøõË°åÊé®Êñ≠ÂÜ≥Á≠ñÔºåËÄåÈùûÊ¶ÇÁéáÊ®°ÂûãÊòØÈÄöËøáÂ≠¶‰π†ÂæóÂà∞ÂÜ≥Á≠ñÂáΩÊï∞Y=f(X)Êù•ËøõË°åÂÜ≥Á≠ñ„ÄÇ 2„ÄÅÁîüÊàêÊ®°ÂûãÁöÑÁõÆÊ†áÊòØÊ±ÇËÅîÂêàÊ¶ÇÁéáÂàÜÂ∏ÉP(X,Y)ÔºåÁÑ∂ÂêéÁî±Êù°‰ª∂ÂÖ¨ÂºèÊ±ÇÂèñÊù°‰ª∂Ê¶ÇÁéáÂàÜÂ∏ÉP(X|Y)„ÄÇÂç≥P(X|Y) = P(X,Y) / P(X)„ÄÇ 3„ÄÅÂà§Âà´Ê®°ÂûãÊòØÁî±ËÆ≠ÁªÉÊï∞ÊçÆÁõ¥Êé•Ê±ÇÂèñÂÜ≥Á≠ñÂáΩÊï∞Y=f(x)ÊàñËÄÖÊù°‰ª∂ÂàÜÂ∏ÉP(X|Y)„ÄÇÂÆÉÂπ∂‰∏çÈúÄË¶ÅÂÖ≥ÂøÉX‰∏éY‰πãÈó¥ÁöÑÁîüÊàêÂÖ≥Á≥ªÔºåÂÆÉÂÖ≥ÂøÉÁöÑÊòØÂØπ‰∫éÁªôÂÆöËæìÂÖ•XÂ∫îËØ•ÂæóÂà∞ÊÄé‰πàÊ†∑ÁöÑËæìÂá∫Y„ÄÇ 4„ÄÅÊú∫Âô®Â≠¶‰π†Â§ßÈÉ®ÂàÜÊ®°ÂûãÈÉΩÊòØÂà§Âà´Ê®°ÂûãÔºåÂà§Âà´Ê®°ÂûãÂæóÂà∞Êù°‰ª∂Ê¶ÇÁéáÊàñËÄÖÂÜ≥Á≠ñÂáΩÊï∞Áõ¥Êé•Áî®‰∫éÈ¢ÑÊµãÔºåÂáÜÁ°ÆÁéá‰ºöÊõ¥È´òÔºõËÄåÁîüÊàêÊ®°ÂûãÁî®‰∫éÊï∞ÊçÆÈ¢ÑÊµãÔºåÊâÄ‰ª•ÂÆÉÁöÑÂ∫îÁî®È¢ÜÂüü‰ºöÊõ¥Âä†ÂπøÊ≥õ„ÄÇ 5„ÄÅÂ∏∏ËßÅÁöÑÂà§Âà´Ê®°ÂûãÊúâÔºöKËøëÈÇª„ÄÅSVM„ÄÅÂÜ≥Á≠ñÊ†ë„ÄÅÊÑüÁü•Êú∫„ÄÅÁ∫øÊÄßÂà§Âà´ÂàÜÊûêÔºàLDAÔºâ„ÄÅÁ∫øÊÄßÂõûÂΩí„ÄÅ‰º†ÁªüÁöÑÁ•ûÁªèÁΩëÁªú„ÄÅÈÄªËæëÊñØËíÇÂõûÂΩí„ÄÅboosting„ÄÅÊù°‰ª∂ÈöèÊú∫Âú∫ Â∏∏ËßÅÁöÑÁîüÊàêÊ®°ÂûãÊúâÔºöÊú¥Á¥†Ë¥ùÂè∂ÊñØ„ÄÅÈöêÈ©¨Â∞îÂèØÂ§´Ê®°Âûã„ÄÅÈ´òÊñØÊ∑∑ÂêàÊ®°Âûã„ÄÅÊñáÊ°£‰∏ªÈ¢òÁîüÊàêÊ®°ÂûãÔºàLDAÔºâ„ÄÅÈôêÂà∂ÁéªÂ∞îÂÖπÊõºÊú∫ ‰ΩúËÄÖÔºödecan5958Êù•Ê∫êÔºöCSDNÂéüÊñáÔºöhttps://blog.csdn.net/decan5958/article/details/76607082 Ê∑±Â∫¶Â≠¶‰π†ÂíåÊ¶ÇÁéáÂõæÊ®°ÂûãÁöÑÂÖ≥Á≥ª ÂèÇËÄÉ Ê∑±Â∫¶Â≠¶‰π†‰πãÂ§ñÁöÑ‰∫∫Â∑•Êô∫ËÉΩ‚Äî‚ÄîÊ¶ÇÁéáÂõæÊ®°Âûã ‰∏éÊ∑±Â∫¶Â≠¶‰π†ÁöÑÂÖ≥Á≥ª ‰∏§ËÄÖËÄÖ‰ΩøÁî® ÂêåÁöÑÂü∫Êú¨ËÆ°ÁÆóÂ∑•ÂÖ∑ÔºöËøë‰ººÊé®Êñ≠ÔºüÊçüÂ§±ÂáΩÊï∞ÔºüÂ≠¶‰π†ËøáÁ®ãÔºü Ê∑±Â∫¶Â≠¶‰π†ÊΩúÂèòÈáèÔºöÊØîÂèØËßÇÂØüÂèòÈáèÊõ¥Â§öÔºõ‰∏çÂåÖÂê´ÁâπÂÆöÂê´‰πâÔºõ Ê¶ÇÁéáÂõæÊ®°ÂûãÊΩúÂèòÈáèÔºöÊï∞ÈáèÈÄöÂ∏∏ÂæàÂ∞ëÔºõÈÄöÂ∏∏Ë¢´Ëµã‰∫à‰∏Ä‰∫õÁâπÂÆöÂê´‰πâÔºõ Ê∑±Â∫¶Â≠¶‰π†ÁöÑËøûÊé•ÊñπÂºèÔºöÂÖ∂‰ªñÂçïÂÖÉÁªÑÂÖ®ËøûÊé• Ê¶ÇÁéáÂõæÁöÑËøûÊé•ÊñπÂºèÔºöÂÖ∑ÊúâÈùûÂ∏∏Â∞ëÁöÑËøûÊé•Ôºå Âπ∂‰∏îÊØè‰∏™ÂèòÈáèÁöÑËøûÊé•ÈÄâÊã©ÂèØ‰ª•ÂçïÁã¨ËÆæËÆ°„ÄÇ Ê®°ÂûãÁªìÊûÑÁöÑËÆæËÆ°‰∏éÊé®Êñ≠ÁÆóÊ≥ïÁöÑÈÄâÊã©Á¥ßÂØÜÁõ∏ÂÖ≥„ÄÇÂõæÊ®°ÂûãÁöÑ‰º†ÁªüÊñπÊ≥ïÈÄöÂ∏∏Êó®Âú®‰øùÊåÅÁ≤æÁ°Æ Êé®Êñ≠ÁöÑÂèØËß£ÊÄß„ÄÇ Êé®Êñ≠ÊñπÂºèÔºö‰ªÄ‰πàÊòØÊé®Êñ≠Ôºü‰ΩúÁî®Ôºü ÂõæÊ®°ÂûãÁöÑ‰º†ÁªüÊñπÊ≥ïÈÄöÂ∏∏Êó®Âú®‰øùÊåÅÁ≤æÁ°ÆÊé®Êñ≠ÁöÑÂèØËß£ÊÄß„ÄÇ Â§ßËßÑÊ®°ÂõæÊ®°ÂûãÂíåÊ∑±Â∫¶ÂõæÊ®°ÂûãÊúÄÂ§ßÁöÑÂå∫Âà´‰πã‰∏ÄÂ∞±ÊòØÊ∑±Â∫¶Â≠¶‰π†‰∏≠Âá†‰πé‰ªéÊù•‰∏ç‰ºö‰ΩøÁî®ÁéØÁä∂‰ø°Âøµ‰º†Êí≠„ÄÇÁõ∏ÂèçÁöÑÔºåËÆ∏Â§öÊ∑±Â∫¶Â≠¶‰π†Ê®°ÂûãÂèØ‰ª•ËÆæËÆ°Êù•Âä†ÈÄü Gibbs ÈááÊ†∑ÊàñËÄÖÂèòÂàÜÊé®Êñ≠„ÄÇ ÂõæÊ®°ÂûãÂ¶Ç‰ΩïÁî®‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑÂÖ∏Âûã‰æãÂ≠êÔºöÂèóÈôêÁéªÂ∞îÂÖπÊõºÊú∫ÔºàRestricted Boltzmann Machine, RBMÔºâ ÁâπÁÇπÔºöÂÆÉÁöÑÂçïÂÖÉË¢´ÂàÜÊàêÂæàÂ§ßÁöÑÁªÑÔºåËøôÁßçÁªÑÁß∞‰ΩúÂ±ÇÔºåÂ±Ç‰πãÈó¥ ÁöÑËøûÊé•Áî±Áü©ÈòµÊèèËø∞ÔºåËøûÈÄöÊÄßÁõ∏ÂØπÂØÜÈõÜ„ÄÇËØ•Ê®°ÂûãË¢´ËÆæËÆ°‰∏∫ËÉΩÂ§üËøõË°åÈ´òÊïàÁöÑ Gibbs ÈááÊ†∑Ôºå Âπ∂‰∏îÊ®°ÂûãËÆæËÆ°ÁöÑÈáçÁÇπÂú®‰∫é‰ª•ÂæàÈ´òÁöÑËá™Áî±Â∫¶Êù•Â≠¶‰π†ÊΩúÂèòÈáè„ÄÇ Ê†áÂáÜÁöÑ RBM ÊòØÂÖ∑Êúâ‰∫åÂÄºÁöÑÂèØËßÅÂíåÈöêËóèÂçïÂÖÉÁöÑÂü∫‰∫éËÉΩÈáèÁöÑÊ®°Âûã„ÄÇÂÖ∂ËÉΩÈáèÂáΩÊï∞‰∏∫$E(\boldsymbol{v}, \boldsymbol{h})=-\boldsymbol{b}^{\top} \boldsymbol{v}-\boldsymbol{c}^{\top} \boldsymbol{h}-\boldsymbol{v}^{\top} \boldsymbol{W h}$ Ê¶ÇÁéáÂõæ(ÁªìÊûÑÂåñ)Ê®°ÂûãÁöÑ‰ºòÁÇπ ÊòæËëóÈôç‰ΩéË°®Á§∫Ê¶ÇÁéáÂàÜÂ∏É„ÄÅÂ≠¶‰π†ÂíåÊé®Êñ≠ÁöÑÊàêÊú¨„ÄÇÂ¶ÇÊúâÂêëÂõæ‰∏≠ÁöÑÂèÇÊï∞Ë°®Á§∫„ÄÇ1+4+4+9ÁöÑ‰æãÂ≠ê ÊúâÂêëÊ®°Âûã‰∏≠ÈááÊ†∑ËøòÂèØ‰ª•Ë¢´Âä†ÈÄüÔºå‰ΩÜÊòØÂØπ‰∫éÊó†ÂêëÊ®°ÂûãÊÉÖÂÜµÂàôËæÉ‰∏∫Â§çÊùÇ„ÄÇÔºü Ê¶ÇÁéáÂõæÊ®°ÂûãÁöÑÂ∫îÁî® MRFÂéªÂô™ÔºöÊó†ÂêëÂõæ‰∏≠ÁöÑÈ©¨Â∞îÂèØÂ§´Ê®°ÂûãÔºü ËÉΩÂê¶ÁúãÂà∞‰∏Ä‰∏™ÂÖ∑‰ΩìÁöÑÂ≠¶‰π†„ÄÅÂª∫Ê®°ËøáÁ®ã„ÄÇ ÊúâÂêëÂõæÊ®°Âûã/Ë¥ùÂè∂ÊñØÁΩëÁªú/‰ø°ÂøµÁΩëÁªú ÊúâÂêëÂõæÊ®°Âûã‰ª•ÂèäËÅîÂêàÂàÜÂ∏É Â∏∏ËßÅÁöÑÊúâÂêëÂõæÔºösigmoid ‰ø°ÂøµÁΩëÁªú„ÄÅÊú¥Á¥†Ë¥ùÂè∂ÊñØÂàÜÁ±ªÂô®„ÄÅÈöêÈ©¨Â∞îÂèØÂ§´Ê®°Âûã(HMM) ‰∏Ä‰∏™ËÉΩÁúãÊáÇÁöÑHMM‰æãÂ≠êÔºöÊØèÂ§©ËßÇÂØü‰∏Ä‰∏™ÁóÖ‰∫∫ÁöÑÁä∂ÊÄÅ Êó†ÂêëÂõæ/È©¨Â∞îÂèØÂ§´ÈöèÊú∫Âú∫/È©¨Â∞îÂèØÂ§´ÁΩë Â∏∏ËßÅÁöÑÊó†ÂêëÂõæÔºöÂØπÊï∞Á∫øÊÄßÊ®°Âûã„ÄÅÊù°‰ª∂ÈöèÊú∫Âú∫(CRFÔºâ Êó†ÂêëÂõæÊ®°Âûã Êó†ÂêëÂõæÁöÑËÅîÂêàÊ¶ÇÁéáÂèØ‰ª•ÂàÜËß£‰∏∫‰∏ÄÁ≥ªÂàóÂÆö‰πâÂú®ÊúÄÂ§ßÂõ¢‰∏äÁöÑÈùûË¥üÂáΩÊï∞ÁöÑ‰πòÁßØÂΩ¢Âºè„ÄÇ ÁªÑÊàêÔºöÈÖçÂàÜÂáΩÊï∞$Z=\int \tilde{p}(\mathbf{x}) d \mathbf{x}$„ÄÇ Â∏∏ËßÅÁöÑÊó†ÂêëÂõæÔºöÊù°‰ª∂ÈöèÊú∫Âú∫, ËØçÊÄßÂàÜÁ±ª Êù°‰ª∂ÈöèÊú∫Âú∫ËøõË°åËØçÊÄßÂàÜÁ±ª Á∫øÊÄßÈìæÊù°‰ª∂ÈöèÊú∫Âú∫-tutorialÔºà‰∏ÄÔºâ Á∫øÊÄßÈìæÊù°‰ª∂ÈöèÊú∫Âú∫-tutorialÔºà‰∫åÔºâ Â∏∏ËßÅÁöÑÊó†ÂêëÂõæÔºöÂéªÂô™ Âü∫‰∫éÈ©¨Â∞îÁßëÂ§´ÈöèÊú∫Âú∫ÁöÑÂõæÂÉèÂéªÂô™ÊñπÊ≥ï+python‰ª£Á†Å È©¨Â∞îÂèØÂ§´ÈöèÊú∫Âú∫ÂΩ©Ëâ≤ÂõæÂéªÂô™ È©¨Â∞îÂèØÂ§´ÂéªÂô™+matlabÔºöËÉΩÈáèÂáΩÊï∞ÊúâÁÇπ‰∏çÂêå ÈááÊ†∑ÂéªËé∑ÂèñÊª°Ë∂≥‰∏Ä‰∏™ÂàÜÂ∏ÉÁöÑÊ†∑Êú¨„ÄÇ ‰æãÂ¶ÇÔºöÈúÄË¶ÅËé∑Âæó‰∏Ä‰∏™Ê≥äÊùæÂàÜÂ∏ÉÔºåÁü•ÈÅìÊüê‰∫ã‰ª∂Á¨¶ÂêàÊ≠§ÂàÜÂ∏ÉÁöÑËØùÔºåÂèØ‰ª•ÈÄöËøáÈááÈõÜËøô‰∏™‰∫ã‰ª∂ÁöÑ‰ø°ÊÅØÔºåÊù•Ëé∑ÂæóÊ†∑Êú¨„ÄÇ ÊãíÁªùÈááÊ†∑ÔºöÂà©Áî®‰∏Ä‰∏™ÂÆπÊòìËé∑ÂèñÊ†∑Êú¨ÁöÑÂàÜÂ∏ÉqÔºåÂÖàËé∑Âæó‰∏Ä‰∏™Ê†∑Êú¨ÔºåÂÜçÈÄöËøáÂà§Êñ≠$\alpha(\hat{x})=\frac{\hat{p}(\hat{x})}{k q(\hat{x})}$ÔºåÊù•ÂÜ≥ÂÆöÊòØÂê¶Áïô‰∏ãËøô‰∏™Ê†∑Êú¨x GibbsÈááÊ†∑Ôºö‰∏ÄÁßçÊª°Ë∂≥Á®≥ÊÄÅËΩ¨ÁßªÁöÑÈ©¨Â∞îÂèØÂ§´ÈááÊ†∑Ê≥ï„ÄÇ ÂèÇËÄÉÔºö Áõ¥ËßÇÁêÜËß£Ê¶ÇÁéáÂõæÊ®°Âûã‰∏≠ÁöÑÈááÊ†∑(sampling)ÊäÄÊúØ ÊµÖË∞àGibbs ‰∏ÄÁØáMCMCËß£ÈáäÁöÑ‰∏çÈîôÁöÑÊñáÁ´† ÈóÆÈ¢òÔºöÂíåÊé®Êñ≠ÁöÑÂÖ≥Á≥ªÔºü ËíôÁâπÂç°Ê¥õÈááÊ†∑„ÄÅÈùûÊï∞Â≠¶ËØùÁöÑËß£ÈáäËíôÁâπÂç°Ê¥õÈááÊ†∑„ÄÅ Êé®Êñ≠Âà©Áî®ÂõæÁöÑÁªìÊûÑÔºåÊù•ËÆ°ÁÆóÂá∫‰∏Ä‰∫õÂèòÈáèÁöÑÂêéÈ™å‰ø°ÊÅØ Êé®Êñ≠ÂíåÊúÄÂ§ß‰ººÁÑ∂‰ªªÂä°ÁöÑÂÖ≥Á≥ªÔºöÂú®ËÆ°ÁÆóÊúÄÂ§ßÂØπÊï∞‰ººÁÑ∂ÂáΩÊï∞ÁöÑÊó∂ÂÄôÔºå‰∏≠Èó¥Ê≠•È™§ÈúÄË¶Å‰∏Ä‰∫õÂèòÈáèÁöÑÂêéÈ™å‰ø°ÊÅØ„ÄÇ ‰æãÂ≠êÔºöEMÁÆóÊ≥ï Êú¨Ë¥®ÊòØÊúÄÂ§ßÂåñ‰ººÁÑ∂ÂáΩÊï∞Ôºö$p(\mathbf{x|\theta})$ ÈÄöËøáÈöêÂê´ÁªìÁÇπzÔºåÊù•Ë°®Á§∫xÁöÑÁºñËæëÊ¶ÇÁéáÔºö$p(\mathbf{x} | \theta)=\sum_{\mathbf{Z}} p(\mathbf{x}, \mathbf{z} | \theta)$ ÈÄöËøáÂèòÂàÜÂáΩÊï∞q(z)(zÁöÑÂÖàÈ™å‰ø°ÊÅØ)ÔºåÊù•Ëé∑Âæó‰∏Ä‰∏™‰∏ãÁïå„ÄÇ EMËø≠‰ª£qÂíå$\theta$, ‰ΩøÂæó$p(x|\theta)$Ë∂äÊù•Ë∂äÂ∞è. ÂÖ∂‰∏≠ÊØè‰∏ÄÊ¨°Ëø≠‰ª£Êó∂ÁöÑ$ q(\mathbf{z})=p(\mathbf{z} | \mathbf{x}, \theta)$ÔºåÂõ†Ê≠§ÈúÄË¶ÅËÆ°ÁÆó$p(z|x)$„ÄÇÊ≠§Êó∂Áî®Âà∞ÁöÑÂ∞±ÊòØÊé®Êñ≠„ÄÇÊ†πÊçÆÂõæÁöÑÂÆö‰πâÔºå$p(x|z)Âíåp(x),p(z)$ÊòØÂ∑≤Áü•ÁöÑ„ÄÇ Â≠¶‰π†Â¶Ç‰∏äËø∞ÁöÑEMÁÆóÊ≥ïÔºåÂ≠¶‰π†ÂèÇÊï∞ÁöÑ‰ºòÂåñÁÆóÊ≥ï„ÄÇ ÁéªËÄ≥ÂÖπÊõºÊú∫(RBM)ÂèÇËÄÉ‰∏Ä‰∏™ÂÜôÁöÑ‰∏çÈîôÁöÑÂèóÈôêÁéªÂ∞îÂÖπÊõºÊú∫ÔºàRBMÔºâÂ≠¶‰π†Á¨îËÆ∞ ÂçöÂÆ¢ÔºöÁÆóÊ≥ïÊèèËø∞ ÂØπ‰∏ä‰∏Ä‰∏™ÂçöÂÆ¢ÁöÑÁ¨îËÆ∞ÔºöÂØπÊØîÊï£Â∫¶(CD)ÁÆóÊ≥ï code: RBM-for-MNIST ÂÖ∂‰ªñÔºö Â¶Ç‰Ωï‰ΩøÁî®TensorFlowÂíåVAEÊ®°ÂûãÁîüÊàêÊâãÂÜôÊï∞Â≠ó free energyÁöÑÊé®ÁÆó ÁâπÁÇπÔºöÂÆÉÁöÑÂçïÂÖÉË¢´ÂàÜÊàêÂæàÂ§ßÁöÑÁªÑÔºåËøôÁßçÁªÑÁß∞‰ΩúÂ±ÇÔºåÂ±Ç‰πãÈó¥ ÁöÑËøûÊé•Áî±Áü©ÈòµÊèèËø∞ÔºåËøûÈÄöÊÄßÁõ∏ÂØπÂØÜÈõÜ„ÄÇËØ•Ê®°ÂûãË¢´ËÆæËÆ°‰∏∫ËÉΩÂ§üËøõË°åÈ´òÊïàÁöÑ Gibbs ÈááÊ†∑Ôºå Âπ∂‰∏îÊ®°ÂûãËÆæËÆ°ÁöÑÈáçÁÇπÂú®‰∫é‰ª•ÂæàÈ´òÁöÑËá™Áî±Â∫¶Êù•Â≠¶‰π†ÊΩúÂèòÈáè„ÄÇ È©¨Â∞îÂèØÂ§´ÂéªÂô™+matlabÔºöËÉΩÈáèÂáΩÊï∞ÊúâÁÇπ‰∏çÂêå ÊàëÂØπÁéªËÄ≥ÂÖπÊõºÂß¨ÁöÑÁêÜËß£ÔºöÊ±ÇÂá∫ËΩ¨ÁßªÁöÑÊù°‰ª∂Ê¶ÇÁéá‰ª•ÂêéÔºåGIbbsÈááÊ†∑ÔºåÈÄöËøá‰∏ÄÁ≥ªÂàóÁöÑÂæÄËøîÊìç‰ΩúÔºåÂèØ‰ª•ÈááÂá∫Êª°Ë∂≥pÔºàVÔºâÂàÜÂ∏ÉÁöÑÊ†∑Êú¨„ÄÇÂÜçÈÄöËøágibbsÈááÊ†∑ÔºåËé∑ÂæóÊª°Ë∂≥p(v)ÁöÑÊ†∑Êú¨„ÄÇ ÈááÊ†∑Ôºö Êé®Êñ≠ÂíåÈááÊ†∑ÁöÑÂÖ≥Á≥ª ‰ªÄ‰πàÊó∂ÂÄôÈúÄË¶ÅÈááÊ†∑ ÂÖ∂‰ªñÂèÇËÄÉËÅîÂêàÊ¶ÇÁéá„ÄÅËæπÈôÖÊ¶ÇÁéá„ÄÅÊù°‰ª∂Ê¶ÇÁéá ‰∏Ä‰∏™ÂÆåÊï¥ÁöÑÊ¶ÇÁéáÂõæÊ®°ÂûãÁ¨îËÆ∞„ÄÅËøôÁ≥ªÂàóÁõ∏ÂÖ≥ÁöÑ‰∏Ä‰∏™ÂçöÂÆ¢ Ê¶ÇÁéáÂõæÊ®°ÂûãÁöÑËÆ≤Ëß£ ÈöêÈ©¨Â∞îÂèØÂ§´(HMM)Ê®°Âûã CPD(conditional probability distribution)Ê¶ÇÁéáÂõæÊ®°Âûã]]></content>
      <categories>
        <category>Ê∑±Â∫¶Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ëá™ÁºñÁ†ÅÂô®]]></title>
    <url>%2Fp%2F221.html</url>
    <content type="text"><![CDATA[ÂèÇËÄÉ Ëá™ÁºñÁ†ÅÂô®ÊòØ‰ªÄ‰πàÔºüÊúâ‰ªÄ‰πàÁî®ÔºüËøôÈáåÊúâ‰∏Ä‰ªΩÂÖ•Èó®ÊåáÂçóÔºàÈôÑ‰ª£Á†ÅÔºâ ÂèëÂ±ï Ëá™ÁºñÁ†ÅÂô® Êï¥‰∏™Ëá™ÁºñÁ†ÅÂô®ÂèØ‰ª•Áî®ÂáΩÊï∞g(f(x)) = rÊù•ÊèèËø∞ÔºåÂÖ∂‰∏≠ËæìÂá∫r‰∏éÂéüÂßãÁõ∏Ëøë„ÄÇ ‰ΩúÁî® Â¶ÇÊûúËá™ÁºñÁ†ÅÂô®ÁöÑÂîØ‰∏ÄÁõÆÁöÑÊòØËÆ©ËæìÂá∫ÂÄºÁ≠â‰∫éËæìÂÖ•ÂÄºÔºåÈÇ£Ëøô‰∏™ÁÆóÊ≥ïÂ∞ÜÊØ´Êó†Áî®Â§Ñ„ÄÇ‰∫ãÂÆû‰∏äÔºåÊàë‰ª¨Â∏åÊúõÈÄöËøáËÆ≠ÁªÉËæìÂá∫ÂÄºÁ≠â‰∫éËæìÂÖ•ÂÄºÁöÑËá™ÁºñÁ†ÅÂô®ÔºåËÆ©ÊΩúÂú®Ë°®ÂæÅhÂ∞ÜÂÖ∑Êúâ‰ª∑ÂÄºÂ±ûÊÄß„ÄÇËá™ÁºñÁ†ÅÂô®ËÉΩ‰ªéÊï∞ÊçÆÊ†∑Êú¨‰∏≠ËøõË°åÊó†ÁõëÁù£Â≠¶‰π†ÔºåËøôÊÑèÂë≥ÁùÄÂèØÂ∞ÜËøô‰∏™ÁÆóÊ≥ïÂ∫îÁî®Âà∞Êüê‰∏™Êï∞ÊçÆÈõÜ‰∏≠ÔºåÊù•ÂèñÂæóËâØÂ•ΩÁöÑÊÄßËÉΩÔºå‰∏î‰∏çÈúÄË¶Å‰ªª‰ΩïÊñ∞ÁöÑÁâπÂæÅÂ∑•Á®ãÔºåÂè™ÈúÄË¶ÅÈÄÇÂΩìÂú∞ËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇ ÂÆûÁé∞ ÈôêÂà∂hÁöÑÁª¥Â∫¶‰ΩøÂÖ∂Â∞è‰∫éËæìÂÖ•xÔºåËøôÁßçÊÉÖÂÜµ‰∏ãÁß∞‰ΩúÊúâÊçüËá™ÁºñÁ†ÅÂô®„ÄÇÈÄöËøáËÆ≠ÁªÉÊúâÊçüË°®ÂæÅÔºå‰ΩøÂæóËá™ÁºñÁ†ÅÂô®ËÉΩÂ≠¶‰π†Âà∞Êï∞ÊçÆ‰∏≠ÊúÄÈáçË¶ÅÁöÑÁâπÂæÅ„ÄÇ Ê≠£Âàô Â∫îÁî® Á¨¨‰∏ÄÊòØÊï∞ÊçÆÂéªÂô™ÔºåÁ¨¨‰∫åÊòØ‰∏∫ËøõË°åÂèØËßÜÂåñËÄåÈôçÁª¥„ÄÇËÆæÁΩÆÂêàÈÄÇÁöÑÁª¥Â∫¶ÂíåÁ®ÄÁñèÁ∫¶ÊùüÔºåËá™ÁºñÁ†ÅÂô®ÂèØ‰ª•Â≠¶‰π†Âà∞ÊØîPCAÁ≠âÊäÄÊúØÊõ¥ÊúâÊÑèÊÄùÁöÑÊï∞ÊçÆÊäïÂΩ±„ÄÇ ÁßçÁ±ª È¶ôËçâËá™ÁºñÁ†ÅÂô® Â§öÂ±ÇËá™ÁºñÁ†ÅÂô® Âç∑ÁßØËá™ÁºñÁ†ÅÂô® Ê≠£ÂàôËá™ÁºñÁ†ÅÂô®Ôºö‰ΩøÁî®ÊçüÂ§±ÂáΩÊï∞Êù•ÈºìÂä±Ê®°ÂûãÂ≠¶‰π†ÂÖ∂‰ªñÁâπÊÄß Â∏∏Áî®‰∏§ÁßçÊ≠£ÂàôËá™ÁºñÁ†ÅÂô® Á®ÄÁñèËá™ÁºñÁ†ÅÂô®ÔºöÈÄöËøáÂØπÊçüÂ§±ÂáΩÊï∞ÊñΩÂä†ÊÉ©ÁΩöÈ°π ÈôçÂô™Ëá™ÁºñÁ†ÅÂô®ÔºöÊòØÈÄöËøáÊîπÂèòÊçüÂ§±ÂáΩÊï∞ÁöÑÈáçÊûÑËØØÂ∑ÆÈ°πÊù•Â≠¶‰π†‰∏Ä‰∫õÊúâÁî®‰ø°ÊÅØ„ÄÇ ÂéªÂô™Ëá™ÁºñÁ†ÅÂô®DAE]]></content>
      <categories>
        <category>Ê∑±Â∫¶Â≠¶‰π†</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Ê∑òÂÆùÊî∂Ëóè]]></title>
    <url>%2Fp%2F4dde.html</url>
    <content type="text"><![CDATA[Ë£§Ë£§ Áü≠Ë£§ Ë°£Êúç ‰∏ÄÂÆ∂Á∫¢Ë£ôÂ≠êÂ∫ó]]></content>
      <categories>
        <category>ÁîüÊ¥ª</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Á≤§ËØ≠Âè£ËØ≠]]></title>
    <url>%2Fp%2F39a8.html</url>
    <content type="text"><![CDATA[Á≤§ËØ≠Â≠¶‰π†Á¨îËÆ∞ Âπø‰∏úËØùÂíåÊôÆÈÄöËØùÁöÑÂå∫Âà´https://wenku.baidu.com/view/33face69011ca300a6c390cf.htmlÁ≤§ËØ≠Âè£ËØ≠https://hal.archives-ouvertes.fr/hal-00271141/document Â≠¶Á≤§ËØ≠ÁöÑ‰∏Ä‰∏™‰∏çÈîôÁöÑÁΩëÈ°µÔºå‰∏≠ÊñáÂ§ßÂ≠¶ÈìæÊé• https://www.ilc.cuhk.edu.hk/chinese/canton_express/others/download.html jÂ∏¶Â§¥ÁöÑÂ≠ó ‰ªä jin-&gt;gen Â∞ΩÈáè jin-&gt;zen Âè´jiao-&gt;gao ÈùôÂÄô jing-&gt;zeng Ëá™Áî±Ôºözi-&gt;zei you ÂùöÊåÅÔºöjian-&gt;gin ci ÊûØÊûù-&gt;fuzi Êî∂ÊàêÔºösou seng Ëøô‰∏ÄÊ¨°Ôºözeiyici ‰Ω†Ë¶ÅÔºönei you Â§±ÂÆà sei sou ÂßãÁªà si zhong Êàê-&gt;seng ËÆ∞ËΩΩ-&gt;gei zai]]></content>
      <categories>
        <category>ËØ≠Ë®Ä</category>
      </categories>
      <tags>
        <tag>Á≤§ËØ≠</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[presentationÂ∏∏Áî®Ëã±ÊñáÂè£ËØ≠]]></title>
    <url>%2Fp%2F9de6.html</url>
    <content type="text"><![CDATA[Ëã±ËØ≠preÊëòÂΩï It‚Äôs been a while ÊúâÈòµÂ≠ê‰∫Ü It all boils down to realizing that it is natural (and interesting!) to consider different topologies on the same set ùëã, each of which comes with a notion of convergence.Ëøô‰∏ÄÂàáÂΩíÁªì‰∏∫ ÊàëÁöÑÂ£∞Èü≥Â§üÂ§ßÂêó ‰Ω†ÂèØ‰ª•ÈáçÂ§ç‰∏Ä‰∏ãËøô‰∏™ÈóÆÈ¢òÂêó ÊàëÊ≤°ÊúâÊÉ≥ËøáËøô‰∏™ÈóÆÈ¢òÔºå‰ΩÜÊòØÊàëËßâÂæó ‰ªãÁªç‰∏ã‰∏Ä‰ΩçÊºîËÆ≤ÂòâÂÆæ ÂØπËøôÈÉ®‰∏ÄÈÉ®ÂàÜ‰Ω†‰ª¨Â∫îËØ•ÊúâÊõ¥Ê∑±ÁöÑÂç∞Ë±° ÊúØËØ≠Maximum a posteriori estimation MAP posteriori probability ÂêéÈ™åÊ¶ÇÁéá ReferencePresentation English(Ëã±ËØ≠ ÊºîËÆ≤Áî®Âà∞ÁöÑÂêÑÁßçË°®Ëææ) PresentationÂÆûÁî®Ë°®ËææÊÄªÁªì]]></content>
      <categories>
        <category>ËØ≠Ë®Ä</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÁîüÊ¥ª‰∏≠ÁöÑËã±ÊñáÂè£ËØ≠]]></title>
    <url>%2Fp%2Fef9c.html</url>
    <content type="text"><![CDATA[ÈáçËØªÈü≥Âä®ËØç+‰ªãËØçÔºö ËΩªËΩªÂ∏¶Ëøá‰ªãËØçÔºåÂ¶Çlook at ÈáçËØª‰ªãËØçÂ¶ÇÔºötake off Âä®ËØç+ÂêçËØç: Êó•Â∏∏ÊëòÂΩïÂÖ≥‰∫éÂêÉÈ•≠„ÄÅÁÇπÈ§ê„ÄÅÁªìË¥¶6/13 Áª≠ÊùØ„ÄÅÁÇπÈ§ê split the fare I have a god feeling I could tell]]></content>
      <categories>
        <category>ËØ≠Ë®Ä</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac/ipad/iphoneËΩØ‰ª∂Ê∏ÖÂçï]]></title>
    <url>%2Fp%2F44bc.html</url>
    <content type="text"><![CDATA[MacËΩØ‰ª∂Â∑•ÂÖ∑IpadËΩØ‰ª∂Â∑•ÂÖ∑ÂÅöÁ¨îËÆ∞ÂäüËÉΩ notabilityÂäüËÉΩ‰ªãÁªç]]></content>
      <categories>
        <category>ËΩØ‰ª∂</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[iosËΩØ‰ª∂Ê∏ÖÂçï]]></title>
    <url>%2Fp%2F44bc.html</url>
    <content type="text"><![CDATA[MacËΩØ‰ª∂Â∑•ÂÖ∑IpadËΩØ‰ª∂Â∑•ÂÖ∑ÂÅöÁ¨îËÆ∞ÂäüËÉΩ notabilityÂäüËÉΩ‰ªãÁªç]]></content>
      <categories>
        <category>ËΩØ‰ª∂</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[L1ÁÆóÊ≥ïÁªºËø∞]]></title>
    <url>%2Fp%2F65b3.html</url>
    <content type="text"><![CDATA[lowercontinuity ‰∏ÄÈò∂ÁÆóÊ≥ï Proximal point algorithm Gradient projection method. Dual-projection An Algorithm for Total Variation Minimization and Applications ALMÂíåPPA ReferenceADMMÔºà1975Ôºå1976Ôºå2011Ôºâ Gabay, D., and Mercier, B., A dual algorithm for the solution of nonlinear variational problems via finite-element approximations, Comp. Math. Appl., 2 (1976), pp. 17-40. Glowinski, R., and Marrocco, A., Sur lapproximation par elements finis dordre un, et la resolution par penalisation-dualite dune classe de problemes de Dirichlet nonlineaires, Rev. Francaise dAut. Inf. Rech. Oper., R-2 (1975), pp. 41-76. Existing convergence theory for ADMM Eckstein, J., and Bertsekas, D., On the Douglas-Rachford splitting method and the proximal point algorithm for maximal monotone operators, Mathematical Programming 55, NorthHolland, 1992. Boyd, S., Parikh, N., Chu, E., Peleato, B., &amp; Eckstein, J. (2011). Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends¬Æ in Machine learning, 3(1), 1-122. Split Bregman Bregman distanceÂõæÂÉèÂ§çÂéü. Osher, S., Burger, M., Goldfarb, D., Xu, J., &amp; Yin, W. (2005). An iterative regularization method for total variation-based image restoration. Multiscale Modeling &amp; Simulation, 4(2), 460-489. ‰πüÊòØÂà©Áî®‰∫ÜBregman distance Â§ÑÁêÜdenoising (È¶ñÊ¨°ÊèêÂá∫) Goldstein, T., &amp; Osher, S. (2009). The split Bregman method for L1-regularized problems. SIAM journal on imaging sciences, 2(2), 323-343. (‰∏éADMMÁöÑÁ≠â‰ª∑ÊÄß) Esser, E. (2009). Applications of Lagrangian-based alternating direction methods and connections to split Bregman. CAM report, 9, 31. Split BregmanÔºà1967Ôºå2009Ôºâ ÂèÇËÄÉÊñáÁåÆÔºö Goldstein, T., &amp; Osher, S. (2009). The split Bregman method for L1-regularized problems. SIAM journal on imaging sciences, 2(2), 323-343. (‰∏ãËø∞ÊñáÁåÆÁºñÂè∑ÁöÑÂá∫Â§Ñ) BregmanËØÅÊòéÔºàÂÖ∑‰ΩìÈíàÂØπ‰ªÄ‰πàÁöÑËØÅÊòéÔºâ ÁªÑÊàêÈÉ®ÂàÜ Bregman Iteration to unconstrained problem Bregman Iteration to constrained problem Split Bregman to two variable problem Bregman distance Bregman Iteration for unconstrained problem ÁõÆÊ†áÊñπÁ®ã(2.1)Ôºö$\min_u E(u)+\lambda H(u)$, with $H$ is differentiable and $\min_u H(u)=0$. Bregman Iteration: Áî±[4]ÊèêÂá∫ \begin{aligned} u^{k+1} &=\min _{u} D_{E}^{p}\left(u, u^{k}\right)+\lambda H(u) \\ &=\min _{u} E(u)-\left\langle p^{k}, u-u^{k}\right\rangle+\lambda H(u) \\ p^{k+1} &=p^{k}-\nabla H(u^{k+1}) \end{aligned}ÂæóÂà∞ÁöÑËß£ÊòØÔºà2.4ÔºâÁöÑÊúÄÂ∞èÂÄºÔºå‰∏îÊª°Ë∂≥$H(u)=0$? Â∫îËØ•Âè™ÊòØÊî∂ÊïõÂà∞H(u)=0 $H\left(u^{k}\right) \rightarrow 0$ as $k\rightarrow\infty$. and $H(u^{k+1})\le H(u^k)$. Bregman IterationÁöÑÊî∂ÊïõÊÄß $u^*$: $H\left(u^{k}\right) \rightarrow 0$ as $k\rightarrow\infty$. | Theorem 2.1 || ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî || 1) Monotonic decrease in $H$: $H(u^{k+1})\leq H(u^k)$2) Convergence to a minimizer of $H$ :$H(u^{k})\leq H(u^)+J(u^)/k$ | ProofÔºöÂèÇËÄÉÊñáÁåÆ[21] Bregman iteration for constrained problem ÁõÆÊ†áÊñπÁ®ã(2.4) \min _{u} E(u) \text { such that } \mathrm{Au}=\mathrm{b}Á≠â‰ª∑‰∫éÊó†Á∫¶ÊùüÈóÆÈ¢ò(2.5)ÂΩì$\lambda\rightarrow\infty$ÔºåÂ¶ÇPPAÁÆóÊ≥ïÔºå‰ΩÜÊòØ$\lambda$ÂæàÂ§ßÊó∂‰∏çÂ•ΩÊ±ÇËß£ \min _{u} E(u)+\frac{\lambda}{2}\|A u-b\|_{2}^{2} ÂØπ(2.5)‰ΩøÁî®Bregman iteration [30][21] \begin{aligned} u^{k+1} &=\min _{u} D_{E}^{p}\left(u, u^{k}\right)+\frac{\lambda}{2}\|A u-b\|_{2}^{2} \\ &=\min _{u} E(u)-\left\langle p^{k}, u-u^{k}\right\rangle+\frac{\lambda}{2}\|A u-b\|_{2}^{2} \\ p^{k+1} &=p^{k}-\lambda A^{T}\left(A u^{k+1}-b\right) \end{aligned}ÂΩì$A$ÊòØÁ∫øÊÄßÁöÑÊó∂ÂÄôÔºåÂèØÁÆÄÂåñ‰∏∫ \begin{aligned} u^{k+1} &=\min _{u} E(u)+\frac{\lambda}{2}\left\|A u-b^{k}\right\|_{2}^{2} \\ b^{k+1} &=b^{k}+b-A u^{k} \end{aligned} ËØÅÊòé(2.5)ÁöÑBregmanËø≠‰ª£ÂèØ‰ª•Ëé∑Âæó(2.4)ÁöÑËß£„ÄÇÔºàËß£ÁöÑÁ≠â‰ª∑ÊÄßËØÅÊòéÔºâ | Theorem 2.2 || ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî || Let $H:R^n \rightarrow R$ be convex. Let $A: R^n \rightarrow R^m$ be linear. Consider the algorithm (2.9-2.10). Suppose that some iterate, $u^‚àó$ , satisÔ¨Åes $Au^‚àó = b$(Âà©Áî®theorem2.1). Then $u^‚àó$ is a solution to the original constrained problem (2.4). | Proof1: ÂèÇËÄÉtheorem 2.2 Assumption: $Au_{k+1}=b$, Proof2: ‚ÄúA Combined First and Second Order Variational Approach for Image Reconstruction‚Äù ÈóÆÈ¢òÔºöÊÑèÂë≥ÁùÄ‰ªª‰Ωï‰∏Ä‰∏™lambda‰∏ãÁöÑ2.5ÁöÑËø≠‰ª£Ëß£ÔºåÈÉΩÁ≠â‰ª∑‰∫é(2.4)ÁöÑËß£ÔºüËø≠‰ª£ÊâÄÂæóÁöÑËß£Êú™ÂøÖÊòØ(2.5)ÁöÑËß£ BregmanÁöÑ‰ºòÁÇπÔºöÊî∂ÊïõÂø´(ÂéüÂõ†ËßÅappendix); ÂèØ‰ª•‰øùÊåÅ$\lambda$ÊòØÂ∏∏Êï∞Ôºå‰∏çÈúÄË¶ÅÂèòÂ§ßÔºåÂõ†Ê≠§Á®≥ÂÆö„ÄÇ Âú®ÂÖ∂‰ªñ$\lambda_k$Â¢ûÂ§ßÁöÑÊÉÖÂÜµ‰∏ãÔºåÈúÄË¶Å‰ª•‰∏ÄÁßçÊûÅÊÖ¢ÁöÑÊ≠•Â≠êÂ¢ûÂ§ßÔºå‰ΩøÂæóÁÆóÊ≥ïÁöÑÊïàÁéáÂèò‰Ωé„ÄÇ Split Bregman for l1-regularized optimization problem (1.1) ÁõÆÊ†áÊñπÁ®ã \min _{u}|\Phi(u)|+H(u)where |¬∑| denotes the l1-norm, and both |Œ¶(u)| and H(u) are convex functions, Œ¶(¬∑) to be diÔ¨Äerentiable. ÂºïÂÖ•‰∏Ä‰∏™ÂèòÈáèd, ËΩ¨ÂåñÊàê‰∏Ä‰∏™Á∫¶ÊùüÈóÆÈ¢ò (3.1) $\min \limits_{u, d}|d|+H(u) \text { such that } d=\Phi(u)$ËΩ¨ÂåñÊàê‰∏Ä‰∏™Êó†Á∫¶ÊùüÈóÆÈ¢ò (3.2) $\min\limits_{u, d}|d|+H(u)+\frac{\lambda}{2}|d-\Phi(u)|_{2}^{2}$Ëøõ‰∏ÄÊ≠•ËΩ¨ÂåñÊàêÊó†Á∫¶ÊùüÈóÆÈ¢ò Bregman iteration \begin{aligned}\left(u^{k+1}, d^{k+1}\right) &=\min _{u, d}|d|+H(u)+\frac{\lambda}{2}\left\|d-\Phi(u)-b^{k}\right\|_{2}^{2} (3.7)\\ b^{k+1} &=b^{k}+\left(\Phi\left(u^{k+1}\right)-d^{k+1}\right) (3.8)\end{aligned} Splitting technique to solve (3.7) \begin{array}{l}{\text { Step } 1 : u^{k+1}=\min _{u} H(u)+\frac{\lambda}{2}\left\|d^{k}-\Phi(u)-b^{k}\right\|_{2}^{2}} \\ {\text { Step } 2 : d^{k+1}=\min _{d}|d|+\frac{\lambda}{2}\left\|d-\Phi\left(u^{k+1}\right)-b^{k}\right\|_{2}^{2}}\end{array} Generalized Split Bregman Iteration ÂÜÖÂæ™ÁéØN=1Âç≥ÂèØÔºåÁõ¥ËßÇÁêÜËß£ Application ADMM Dual Ascent ADMM ADMMÂíåSplit bregmanÁöÑÂÖ≥Á≥ª ÂíåSplit BregmanÁöÑÁ≠â‰ª∑ÊÄßproof Applications of Lagrangian-Based Alternating Direction Methods and Connections to Split Bregman [2009] ADMM ÊúÄÊó©ÂàÜÂà´Áî± Glowinski &amp; Marrocco Âèä Gabay &amp; Mercier ‰∫é 1975 Âπ¥Âíå 1976 Âπ¥ÊèêÂá∫ÔºåÂπ∂Ë¢´ Boyd Á≠â‰∫∫‰∫é 2011 Âπ¥ÈáçÊñ∞ÁªºËø∞Âπ∂ËØÅÊòéÂÖ∂ÈÄÇÁî®‰∫éÂ§ßËßÑÊ®°ÂàÜÂ∏ÉÂºè‰ºòÂåñÈóÆÈ¢ò„ÄÇÁî±‰∫é ADMM ÁöÑÊèêÂá∫Êó©‰∫éÂ§ßËßÑÊ®°ÂàÜÂ∏ÉÂºèËÆ°ÁÆóÁ≥ªÁªüÂíåÂ§ßËßÑÊ®°‰ºòÂåñÈóÆÈ¢òÁöÑÂá∫Áé∞ÔºåÊâÄ‰ª•Âú® 2011 Âπ¥‰ª•ÂâçÔºåËøôÁßçÊñπÊ≥ïÂπ∂‰∏çÂπø‰∏∫‰∫∫Áü•„ÄÇ ADMMÊòØ‰∏ÄÁßçALMÁöÑÊñπÊ≥ï„ÄÇPPA‰πüÊòØ„ÄÇ Related Algorithm Êù•Ëá™Dual ascent+approximate Primal ascentÔºåÂõ†‰∏∫ÂáΩÊï∞‰∏çÂÖ∑ÊúâËøûÁª≠ÊÄßÔºåÊúâÂæàÂ§öÊñ≠ÊéâÁöÑÊûÅÂ§ßÂÄºÁÇπ„ÄÇ PPAÔºà1976ÔºâPrimal-dualÔºà2011Ôºâ A First-Order Primal-Dual Algorithm for Convex Problems with Applications to Imaging ‰∫åÈò∂ÁÆóÊ≥ïInexact Lagrangian + ÁâõÈ°øÊ≥ï A highly eÔ¨Écient semismooth Newton augmented Lagrangian method for solving Lasso problems code++„ÄÅSuiteLasso Êó†Á∫¶ÊùüÈóÆÈ¢òËΩ¨ÂåñÊàêÁ∫¶ÊùüÈóÆÈ¢ò \text { (P) } \max -\{f(x)=h(\mathcal{A} x)-\langle c, x\rangle+ p(x)\} \text { (P) } \max -\{f(x)=h(\mathcal{A} x)-\langle c, x\rangle+ p(x)\} \text { (P) } \min \{f(x)=h(\mathcal{A} x)-\langle c, x\rangle+p(x)\} \text { (P) } \max -\{f(x)=h(\mathcal{A} x)-\langle c, x\rangle+ p(x)\} \text { (D) } \min \left\{h^{*}(y)+p^{*}(z) | \mathcal{A}^{*} y+z=c\right\} ‰ªé(P)Âà∞(D)ÁöÑËΩ¨ÂåñËøáÁ®ãÔºö‰∏éÂ¢ûÂπøÊãâÊ†ºÊúóÊó•ÁöÑÂÖ≥Á≥ªÔºü Assumption: ÁÆóÊ≥ïÂü∫Á°ÄÔºöAn inexact augmented Lagrangian method for (D)[42]: $\lambda$ÊòØË∂äÊù•Ë∂äÂ§ßÁöÑ l(y, z, x)=h^{*}(y)+p^{*}(z)-\left\langle x, \mathcal{A}^{*} y+z-c\right\rangle, \quad \forall(y, z, x) \in \mathcal{Y} \times \mathcal{X} \times \mathcal{X} \mathcal{L}_{\sigma}(y, z ; x) :=l(y, z, x)+\frac{\sigma}{2}\left\|\mathcal{A}^{*} y+z-c\right\|^{2}, \quad \forall(y, z, x) \in \mathcal{Y} \times \mathcal{X} \times \mathcal{X} ÁÆóÊ≥ïÊ†∏ÂøÉ Â∞Ü(18) ËΩ¨ÂåñÊàê (22) Ëß£ÂÜ≥Ôºà22ÔºâÔºöAx = 0 ÁöÑÊñπÊ≥ï ÁâõÈ°øÊ≥ïÊ≥ï Êî∂ÊïõÊÄßÂàÜÊûê Â∫îÁî®ÔºöYuan, Y., Sun, D., &amp; Toh, K. C. (2018). An efficient semismooth Newton based algorithm for convex clustering. arXiv preprint arXiv:1802.07091. Nonconvex + ÁâõÈ°øÊ≥ï ÁõÆÊ†áÈóÆÈ¢òÔºösquare-root regression problem \min _{\beta \in \mathbb{R}^{n}}\{g(\beta) :=\|X \beta-b\|+\lambda p(\beta)-q(\beta)\} Êî∂ÊïõÊÄßËØÅÊòé‰∏ÄËà¨ÊµÅÁ®ãÔºöËß£ÁöÑÂ≠òÂú®ÊÄß„ÄÅÂîØ‰∏ÄÊÄßÂà∞ÁÆóÊ≥ïÁöÑÊî∂ÊïõÊÄß ÂÖàËØÅÊòéËß£ÁöÑÂ≠òÂú®ÊÄß„ÄÅÈÄöËøá‰∏•Ê†ºÂá∏ÈóÆÈ¢òÂæóÂà∞Ëß£ÁöÑÂîØ‰∏ÄÊÄß„ÄÅÂÅáËÆæÂ≠òÂú®ÂîØ‰∏ÄËß£ÔºåÁÑ∂ÂêéÊî∂ÊïõÂà∞ÊúÄÂ∞èËß£ ‰æãÂ≠êÔºö Â≠òÂú®ÊÄßËØÅÊòéÔºöA CONVEX VARIATIONAL MODEL FOR RESTORING BLURRED IMAGES WITH MULTIPLICATIVE NOISE; On the convex model of speckle reduction ÂîØ‰∏ÄÊÄßÔºöA CONVEX VARIATIONAL MODEL FOR RESTORING BLURRED IMAGES WITH MULTIPLICATIVE NOISE; On the convex model of speckle reduction Êî∂ÊïõÊÄßÔºö ÈóÆÈ¢ò ÁâõÈ°øÊ≥ï‰∏≠ÔºåPÂíåD‰πãÈó¥‰∏éÊãâÊ†ºÊúóÊó•ÁöÑÂÖ≥Á≥ª semismoothÂà∞Â∫ï‰ªÄ‰πàÊÑèÊÄù Âú®Split Bregman‰∏≠ÔºåSplit Bregman‰∏ãÁöÑ‰ªª‰ΩïlambdaÈÉΩÊòØÂéüÁ∫¶ÊùüÈóÆÈ¢òÁöÑËß£Ôºü]]></content>
      <categories>
        <category>ÁÆóÊ≥ï</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ÂèòÂàÜ‰∏çÁ≠âÂºèÁöÑÊî∂ÊïõÊÄßËØÅÊòé]]></title>
    <url>%2Fp%2Ff8c4.html</url>
    <content type="text"><![CDATA[ÂèòÂàÜ‰∏çÁ≠âÂºèÂèòÂàÜ‰∏çÁ≠âÂºè(VI)ÁöÑÂÆö‰πâÔºö ÊúÄ‰ºòÂåñÈóÆÈ¢òÁöÑËΩ¨ÂåñÔºö ‚Äã $x^{*}=\arg \min _{x \in X} f(x)‚Äã$ ‚Äã Á≠â‰ª∑‰∫éÊª°Ë∂≥$\operatorname{VI}(\nabla f, X)‚Äã$Âç≥ ‚Äã $\nabla f\left(x^{}\right)^{T}\left(x^{\prime}-x^{}\right) \geq 0, \forall x^{\prime} \in X$ ‰ºòÂåñÈóÆÈ¢ò x^{*} \in \arg \min \{\theta(x)+f(x) | x \in \mathcal{X}\}‚Äã ÂÖ∂‰∏≠$f(x),\theta(x)$ÊòØconvex function, $\theta$‰∏ç‰∏ÄÂÆöÂèØÂæÆ, Á≠â‰ª∑‰∫éÔºö x^{*} \in \mathcal{X}, \quad \theta(x)-\theta\left(x^{*}\right)+\left(x-x^{*}\right)^{T} \nabla f\left(x^{*}\right) \geq 0, \quad \forall x \in \mathcal{X} ‚Äã ‚Äã ‚Äã ‰ºòÂåñÈóÆÈ¢òËΩ¨ÂåñVI‰∏çÁ≠âÂºèÈóÆÈ¢òÂ∞Ü‰∏çÂêåÁöÑ‰ºòÂåñÈóÆÈ¢òËΩ¨ÂåñÊàêÁ≠â‰ª∑ÁöÑVIÈóÆÈ¢òÔºö ‰∏ÄÂÖÉÁ∫¶ÊùüÈóÆÈ¢ò$\min \{\theta(x) | A x=b, x \in \mathcal{X}\}$ Á≠â‰ª∑‰∫éÊãâÊ†ºÊúóÊó•Ôºö$L(x, \lambda)=\theta(x)-\lambda^{T}(A x-b), \quad(x, \lambda) \in \mathcal{X} \times \Re^{m}$ ËΩ¨ÂåñÂêéÁ≠â‰∫éVI inequalityÔºö$w^{} \in \Omega, \quad \theta(x)-\theta\left(x^{}\right)+\left(w-w^{}\right)^{T} F\left(w^{}\right) \geq 0, \quad \forall w \in \Omega$ ‰∫åÂÖÉ‰∏âÂÖÉ„ÄÇ„ÄÇ min-maxÈóÆÈ¢ò: $\min _{x \in \mathcal{X}} \max _{y \in \mathcal{Y}}\left\{\mathcal{L}(x, y)=\theta_{1}(x)-y^{T} A x-\theta_{2}(y)\right\}$ PPAÁöÑÊî∂ÊïõÊÄßÁî®PI‰∏çÁ≠âÂºèËØÅÊòéÊñπÁ®ãÔºö \min \{\theta(x)+f(x) | x \in \mathcal{X}\}where Œ∏(x) and f(x) are convex but Œ∏(x) is not necessary smooth, X is a closed convex set. ÂÆö‰πâ Monotone operator ÂçïË∞ÉÂáΩÊï∞Ôºàx-yÔºâÔºàFÔºàxÔºâ-F(y)Ôºâ&gt;0Ôºå ÂàôFÊòØÂçïË∞ÉÂáΩÊï∞ Âá∏ÂáΩÊï∞Êª°Ë∂≥ÁöÑÊÄßË¥® (x-y)^{T}(\nabla f(x)-\nabla f(y)) \geq 0We say the gradient rf of the convex function f is a monotone operator. min max Lagrangian Âíå max min LagrangianÁöÑÂÖ≥Á≥ª]]></content>
      <categories>
        <category>ÁÆóÊ≥ï</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SemismoothÁâõÈ°øÊ≥ï]]></title>
    <url>%2Fp%2F157d.html</url>
    <content type="text"><![CDATA[ÂèÇËÄÉÊñáÁåÆ A highly efficient semismooth Newton augmented Lagrangianmethod for solving Lasso problemsÔºåËÆ∫Êñá‰ª£Á†Å A sparse semismooth Newton based proximalmajorization-minimization algorithm for nonconvexsquare-root-loss regression problems, h(Ax)+p(x) ËÆ∫Êñá‰∏≠ÁöÑÊ®°ÂûãÔºöPrimal/Dual \text { (P) } \max -\{f(x)=h(\mathcal{A} x)-\langle c, x\rangle+ p(x)\} \text { (P) } \min \{f(x)=h(\mathcal{A} x)-\langle c, x\rangle+p(x)\} \text { (D) } \min \left\{h^{*}(y)+p^{*}(z) | \mathcal{A}^{*} y+z=c\right\}where, $\mathcal{A} \in R^{MN}‚Äã$, $p, h : \mathcal{Y} \rightarrow \Re \text { and } p : \mathcal{X} \rightarrow(-\infty,+\infty]‚Äã$ are two closed proper convex functions. ÂØπ‰∫éDualÈóÆÈ¢òÔºö $h^$ is essentially smooth with $\nabla h^{}$ is locally Lipschitz continuous and directionally diÔ¨Äerentiable on int $\operatorname{int}\left(\operatorname{dom} h^{*}\right)$. ÂØπÂÅ∂ÈóÆÈ¢òÁöÑÊãâÊ†ºÊúóÊó•$l‚Äã$ÂíåÂ¢ûÂπøÊãâÊ†ºÊúóÊó•$\mathcal{L}‚Äã$ l(y, z, x)=h^{*}(y)+p^{*}(z)-\left\langle x, \mathcal{A}^{*} y+z-c\right\rangle, \quad \forall(y, z, x) \in \mathcal{Y} \times \mathcal{X} \times \mathcal{X} \begin{aligned} \mathcal{L}_{\sigma}(y, z ; x) &=l(y, z, x)+\frac{\sigma}{2}\left\|\mathcal{A}^{*} y+z-c\right\|^{2}, \quad \forall(y, z, x) \in \mathcal{Y} \times \mathcal{X} \times \mathcal{X}\\ &=h^{*}(y)+p^{*}(z) +\frac{\sigma}{2}\left\|\mathcal{A}^{*} y+z-c-\frac{x}{\sigma}\right\|^{2}-\frac{1}{2 \sigma}\|x\|^{2} \end{aligned} ÁÆóÊ≥ïÊ°ÜÊû∂ÔºàÁ¨¨‰∏ÄÂ±ÇÂæ™ÁéØÔºâ Â∞Ü(18)‰∏≠ÁöÑÊãâÊ†ºÊúóÊó•ÊñπÁ®ãËΩ¨ÂåñÊàêÂçïÂèòÈáèÊãâÊ†ºÊúóÊó•ÊñπÁ®ã Define $\min _{y, z} \Psi(y, z) :=\mathcal{L}_{\sigma}(y, z ; \tilde{x})‚Äã$ Define $\psi(y) :=\inf _{z} \Psi(y, z)‚Äã$ Ôºà18Ôºâ‰∏≠ÁöÑÊãâÊ†ºÊúóÊó•ËΩ¨ÂåñÊàêÂçïÂèòÈáèÂÖâÊªëÊñπÁ®ã \begin{aligned} \Psi(y) &=\inf _{z}\{ h^{*}(y)+p^{*}(z) +\frac{\sigma}{2}\left\|\mathcal{A}^{*} y+z-c-\frac{x}{\sigma}\right\|^{2}-\frac{1}{2 \sigma}\|x\|^{2}\} \\ &=h^*(y)+\sigma \inf _{z}\left\{\frac{1}{\sigma} p^*(z)+\frac{1}{2}\left\|z-(c-A^*y+\frac{x}{\sigma})\right\|^{2}\right\}-\frac{1}{2 \sigma}\|x\|^{2} \\ &=h^*(y)+\sigma M_{\frac{1}{\sigma}}p^*(c-A^*y+\frac{x}{\sigma})-\frac{1}{2 \sigma}\|x\|^{2} \end{aligned})with $z = \arg\min_z p^(z)/\sigma+\frac{1}{2}\left|z-(c-A^y+\frac{x}{\sigma})\right|^{2}=\operatorname{Prox}_{p^{} / \sigma}\left(x / \sigma-\mathcal{A}^{} \overline{y}+c\right)$ . $\psi(y)$ is a smooth function whose gradient is derived as: \begin{aligned} \nabla\Psi(y) &= \nabla h^{*}(y)-\mathcal{A} \operatorname{Prox}_{\sigma p}\left(\tilde{x}-\sigma\left(\mathcal{A}^{*} y-c\right)\right) \end{aligned} Â∞Ü $z =\operatorname{Prox}_{p^{} / \sigma}\left(x / \sigma-\mathcal{A}^{} \overline{y}+c\right)‚Äã$ ‰ª£ÂÖ• (18) ÂæóÂà∞ \psi(y)=h^{*}(y)+p^{*}\left(\operatorname{Prox}_{p^{*} / \sigma}\left(x / \sigma-\mathcal{A}^{*} y+c\right)\right)+\frac{1}{2 \sigma}\left\|\operatorname{Prox}_{\sigma p}\left(x-\sigma\left(\mathcal{A}^{*} y-c\right)\right)\right\|^{2}-\frac{1}{2 \sigma}\|x\|^{2} Moreau-Yosida regularization and proximal mapping M_{\lambda} f(x) :=\min _{u} f(u)+\frac{1}{2 \lambda}\|u-x\|_{2}^{2} \nabla M_{\lambda} f(x)=\frac{1}{\lambda}\left(x-\operatorname{Prox}_{\lambda f}(x)\right) \operatorname{Prox}_{\lambda f}(x) :=\arg \min _{u \in \mathcal{X}} f(x)+\frac{1}{2 \lambda}\|u-x\|^{2} \operatorname{Prox}_{\lambda p}(x)+\lambda \operatorname{Prox}_{p^{*}(x) / \lambda}(x / \lambda)=x\operatorname{Prox}_{\lambda p}(x)+\lambda \operatorname{Prox}_{p^{*}(x) / \lambda}(x / \lambda)=x $\min _{y, z} \Psi(y, z) $Á≠â‰ª∑‰∫é‰ª•‰∏ãÂçïÂèòÈáèÈùûÁ∫øÂΩ¢ÊñπÁ®ã (22) \nabla\Psi(y)=0whose the generalized Hessian of $\Psi$ at y is defined as \hat{\partial}^{2} \psi(y) :=\partial\left(\nabla h^{*}\right)(y)+\sigma \mathcal{A} \partial \operatorname{Prox}_{\sigma p}\left(\tilde{x}-\sigma\left(\mathcal{A}^{*} y-c\right)\right) \mathcal{A}^{*}Defining the $H \in \partial^{2} h^{}(y)$ and $U \in \partial \operatorname{Prox}_{\sigma p}\left(\tilde{x}-\sigma\left(\mathcal{A}^{} y-c\right)\right)$, then, we have V :=H+\sigma \mathcal{A} U \mathcal{A}^{*} Âà©Áî®ÁâõÈ°øÊ≥ïÂíåHessian Áü©ÈòµÊ±ÇËß£ÈùûÁ∫øÂΩ¢Á≠âÂºè(22) (Á¨¨‰∫åÂ±ÇÂæ™ÁéØ) ÂØªÊâæÊñπÂêë$d$Ôºö$V_{j} d+\nabla \psi\left(y^{j}\right)=0$Ôºà24Ôºâ $V \in \hat{\partial}^{2} \psi(y)$, $\hat{\partial}^{2} \psi(y) :=\partial\left(\nabla h^{}\right)(y)+\sigma \mathcal{A} \partial \operatorname{Prox}_{\sigma p}\left(\tilde{x}-\sigma\left(\mathcal{A}^{} y-c\right)\right) \mathcal{A}^{*}$ $V :=H+\sigma \mathcal{A} U \mathcal{A}^{*}‚Äã$ Ê≠•ÈïøÔºöset $\alpha_{j}=\delta^{m_{j}}‚Äã$ $y^{j}+\delta^{m} d^{j} \in \operatorname{int}\left(\operatorname{dom} h^{*}\right) \quad \text { and } \quad \psi\left(y^{j}+\delta^{m} d^{j}\right) \leq \psi\left(y^{j}\right)+\mu \delta^{m}\left\langle\nabla \psi\left(y^{j}\right), d^{j}\right\rangle‚Äã$ Êõ¥Êñ∞Ôºö$y^{j+1}=y^{j}+\alpha_{j} d^{j}$ Ëø≠‰ª£ÁªàÊ≠¢Êù°‰ª∂Ôºö$\nabla \psi\left(y^{j}\right)$ is sufficiently small Ê±ÇËß£Á∫øÊÄßÈóÆÈ¢òÔºà24Ôºâ$V_{j} d=-\nabla \psi\left(y^{j}\right)‚Äã$ ÊñπÊ≥ï‰∏ÄÔºöÂà©Áî®$V_j‚Äã$ÁöÑÁ®ÄÁñèÊÄßÊ±ÇÂá∫Ëß£ÊûêËß£ \left(H+\sigma A U A^{T}\right) d=-\nabla \psi(y), H = LL^T \left(I_{m}+\sigma\left(L^{-1} A\right) U\left(L^{-1} A\right)^{T}\right)\left(L^{T} d\right)=-L^{-1} \nabla \psi(y)ËÄÉËôëÁÆÄÂåñÂêéÁöÑÊÉÖÂÜµÔºö \left(I_{m}+\sigma A U A^{T}\right) d=-\nabla \psi(y) \mbox{with } A U A^{T}=(A U)(A U)^{T}=A_{\mathcal{J}} A_{\mathcal{J}}^{T} \left(I_{m}+\sigma A U A^{T}\right)^{-1}=\left(I_{m}+\sigma A_{\mathcal{J}} A_{\mathcal{J}}^{T}\right)^{-1}=I_{m}-A_{\mathcal{J}}\left(\sigma^{-1} I_{r}+A_{\mathcal{J}}^{T} A_{\mathcal{J}}\right)^{-1} A_{\mathcal{J}}^{T}Áª¥Â∫¶Èôç‰ΩéÔºöÂà©Áî®UÊòØ‰∏Ä‰∏™ÂØπËßíÁî±0Âíå1ÁªÑÊàêÁöÑÂØπËßíÁü©ÈòµÔºå$\mathcal{O}\left(m^{2} n\right)$-&gt;$\mathcal{O}\left(m^{2} r\right)$-&gt;$\mathcal{O}\left(r^{2} m\right)$ ÊñπÊ≥ï‰∫åÔºöPcg Âæ™ÁéØÔºàÁ¨¨‰∏âÂ±ÇÂæ™ÁéØÔºâ Do $V_jd^j‚Äã$ Until $\left|V_{j} d^{j}+\nabla \psi\left(y^{j}\right)\right| \leq \min \left(\overline{\eta},\left|\nabla \psi\left(y^{j}\right)\right|^{1+\tau}\right)‚Äã$ Â∞ùËØïËøáÁöÑÂä†ÈÄüÂäûÊ≥ïÔºö ‰∏é$\tau$ÁöÑÂ§ßÂ∞èÊúâÂÖ≥ Â∞ÜËØ•Âæ™ÁéØÂÜôÊàêcËØ≠Ë®Ä ÊØèÊ¨°ÁâõÈ°øËø≠‰ª£‰ªé‰∏ä‰∏ÄÊ¨°dÁöÑÁªìÊûúÂºÄÂßã„ÄÇÂú®ÁÆóÊ≥ïÂø´Êî∂ÊïõÁöÑÊó∂ÂÄôÂèØ‰ª•Âä†ÈÄü„ÄÇ ÈÄüÂ∫¶ÂàÜÊûê Âæ™ÁéØ‰∏ÄÔºölnexact Lagrangian methd Âæ™ÁéØ‰∫åÔºöÁâõÈ°øÊ≥ïËø≠‰ª£Ê±ÇËß£ÈóÆÈ¢òÔºà22Ôºâ ÂΩ±ÂìçÂæ™ÁéØ‰∫åËø≠‰ª£Ê¨°Êï∞ÁöÑÂõ†Á¥†Ôºö 1.ËØ•Âæ™ÁéØÁöÑ‰∏≠Ê≠¢Êù°‰ª∂: $\left|\nabla \psi_{k}\left(y^{k+1}\right)\right|$ Ë∂≥Â§üÂ∞è 2.Âæ™ÁéØ‰∏â‰∏≠ÁöÑÁ≤æÂ∫¶$\tau$ÔºöËØ•Âæ™ÁéØÁöÑÊî∂ÊïõÈÄüÂ∫¶‰∏éÂæ™ÁéØ‰∏â‰∏≠pcgÁöÑÁ≤æÂ∫¶ÊúâÂÖ≥ \left\|y^{j+1}-\overline{y}\right\|=O\left(\left\|y^{j}-\overline{y}\right\|^{1+\tau}\right) Âæ™ÁéØ‰∏â(Ëã•‰ΩøÁî®pcgÁöÑÊñπÊ≥ïÊ±ÇËß£(24))Ôºö ÂΩ±ÂìçÂæ™ÁéØ‰∏âËø≠‰ª£Ê¨°Êï∞ÁöÑÂõ†Á¥†: $\tau$ÁöÑÂ§ßÂ∞è 1.ËØ•Âæ™ÁéØÁªàÊ≠¢Êù°‰ª∂Ôºö$\left|V_{j} d^{j}+\nabla \psi\left(y^{j}\right)\right| \leq \min \left(\overline{\eta},\left|\nabla \psi\left(y^{j}\right)\right|^{1+\tau}\right),\tau=(0,1]$ h(x)+p(Bx) ÁõÆÊ†áÊñπÁ®ãÔºö $\min|y-g|+\lambda|\nabla y|_1$ Êó†Ê≥ïÂ•óÁî®ËÆ∫Êñá‰∏≠$h(Ay)+p(y)‚Äã$ÁöÑDualÊñπÊ≥ïÁöÑÂéüÂõ†Ôºö Â¶ÇÊûú$p(y)=\lambda|\nabla y|_1‚Äã$ÔºåÈÇ£‰πàp*ÁöÑÊòæÂºèÊó†Ê≥ïË°®Ëææ„ÄÇ Â¶ÇÊûú$h(Ay)=\lambda|\nabla y|_1, A=\nabla$, ÈÇ£‰πà‰æùÁÑ∂Êó†Ê≥ïÂ∞ÜÈóÆÈ¢òËΩ¨ÂåñÊàêÂçïÂèòÈáèÁöÑsmoothÈóÆÈ¢òÔºåÂõ†‰∏∫hÈ°π‰ºöË¢´‰øùÁïô $\nabla$ÁöÑÁü©ÈòµÂΩ¢Âºè (Ë°•ÂÖÖ) ÊèêÂá∫Ê®°Âûã $h(y)+p(By), h(y)=|Ay-g|, p(Bx)=|\nabla y|_1‚Äã$Ôºå$B=\nabla‚Äã$ ÔºàPÔºâ$\min h(y)+p(By)‚Äã$, $h(y)=|Ay-g|‚Äã$, $p(Bx)=|\nabla y|_1‚Äã$ ÔºàDÔºâ$\min \left\{h^{}(y)+p^{}(z) | \mathcal{B}^{} z+y=c\right\}$, $h^{}(y)=\frac{1}{2}|b+y|^{2}-\frac{1}{2}|b|^{2}$, $p^{*}(z)=I\left\{|z|_{\infty} \leq \lambda\right\}$ ÂØπ‰∫éDÈóÆÈ¢òÔºåÊó†Ê≥ïËΩ¨ÂåñÊàêÂçïÂèòÈáèÁöÑsmoothÊñπÁ®ãÔºåÊé®ÂØºËßÅÈôÑÂΩï(ÂæÖË°•ÂÖÖ)„ÄÇÂõ†Ê≠§ÈÄâÊã©ËØ•Ê®°ÂûãÁöÑ‰∏ªÈóÆÈ¢ò„ÄÇ ÂØπ‰∫é(P) $h(y)+p(By)‚Äã$ÔºåËΩ¨ÂåñÊàêÂçïÂèòÈáèÁöÑsmoothÊñπÁ®ã Â¢ûÂπøÊãâÊ†ºÊúóÊó•Ôºö$\mathcal{L}_{\sigma}(y, z ; x) :=h(y)+p(z)++\frac{\sigma}{2}|\mathcal{B} y-z|^{2}‚Äã$ ‚Äã $=h(y)+p(z)+\frac{\sigma}{2}\left|\mathcal{B} y+\frac{x}{\sigma}-z\right|^{2}-\frac{1}{2 \sigma}|x|^{2}‚Äã$ ËΩ¨ÂåñÂêéÁöÑÂçïÂèòÈáèÊñπÂÖâÊªëÊñπÁ®ãÔºö $\mathcal{L}_{\sigma}(y ; x) :=h(y)+p\left(\operatorname{Prox} \frac{p}{\sigma}\left(\mathcal{B} y+\frac{x}{\sigma}\right)\right)+\frac{1}{2 \sigma}\left|\operatorname{Prox}_{\sigma p^{*}}\left(\sigma\left(\mathcal{B} y+\frac{x}{\sigma}\right)\right)\right|^{2}-\frac{1}{2 \sigma}|x|^{2}, \overline{z}=\operatorname{Prox}_{\frac{p}{\sigma}}\left(\mathcal{B} y+\frac{x}{\sigma}\right)$ $\nabla \mathcal{L}_{\sigma}(y) :=\nabla h(y)+\mathcal{B}^{} \operatorname{Prox}_{\sigma p^{}}(\sigma(\mathcal{B} y+\frac{x}{\sigma})$ $\partial\left(\nabla \mathcal{L}_{\sigma}(y)\right) :=\partial(\nabla h(y))+\sigma \mathcal{B}^{} \partial \operatorname{Prox}_{\sigma p^{}}\left(\sigma\left(\mathcal{B} y+\frac{x}{\sigma}\right)\right) \mathcal{B}\\=\partial(\nabla h(y))+\sigma \mathcal{B}^{*}\left(I-\partial \operatorname{Prox}_{\frac{p}{\sigma}}\left(\mathcal{B} y+\frac{x}{\sigma}\right)\right) \mathcal{B}‚Äã$ Ê±ÇËß£$V_{j} d=-\nabla \psi\left(y^{j}\right)‚Äã$ ÊñπÊ≥ï‰∏ÄÔºöÊ±ÇÈÄÜ ÂÖ∂‰∏≠, $\partial \operatorname{Prox}_{\sigma p^{}}\left(\sigma\left(\mathcal{B} y+\frac{x}{\sigma}\right)\right)‚Äã$ÁöÑÁ®ÄÁñèÊÄßÈöèÁùÄÂõæÂÉèÁöÑÂπ≥ÊªëÂáèÂº±ÔºåÂõ†Ê≠§Áõ¥Êé•Âà©Áî®ËØ•Á®ÄÁñèÁü©ÈòµÊ±ÇÈÄÜÔºå*ËÆ°ÁÆóÁ´ãÈ©¨ÈöèÁùÄÂô™Â£∞ÁöÑÂáèÂº±ËÄåÂèòÊÖ¢„ÄÇÁõ∏ÂèçÔºå$\partial \operatorname{Prox}_{\frac{p}{\sigma}}\left(\mathcal{B} y+\frac{x}{\sigma}\right)‚Äã$ÁöÑÁ®ÄÁñèÊÄßÈöèÁùÄÂõæÂÉèÁöÑÂπ≥ÊªëÂèòÁ®ÄÁñè„ÄÇ $\left(A^TA+\sigma \mathcal{B}^\mathcal{B}-\sigma \mathcal{B}^{}\partial \operatorname{Prox}_{\frac{p}{\sigma}}\left(\mathcal{B} y+\frac{x}{\sigma}\right)\mathcal{B}\right)d=-\nabla \psi\left(y^{j}\right) ‚Äã$ Denote $U =\partial \operatorname{Prox}_{\frac{p}{\sigma}}\left(\mathcal{B} y+\frac{x}{\sigma}\right)‚Äã$ , $b =-\nabla \psi\left(y^{j}\right) ‚Äã$ we have $\left(A^TA+\sigma \mathcal{B}^\mathcal{B}-\sigma \mathcal{B}^{}U\mathcal{B}\right)d=-\nabla \psi\left(y^{j}\right) ‚Äã$ Â¶ÇÊûúÊ≤°ÊúâUÔºåÂ∞±ÂèØ‰ª•‰ΩøÁî®FFTÂø´ÈÄüÂèòÂåñÔºåÂõ†‰∏∫BÂèØ‰ª•ÂΩì‰Ωú[-1 1]ÊûÑÊàêÁöÑÂç∑ÁßØ Â¶ÇÊûúÂØπÂèØ‰ª•ÂØπ$A^TA+\sigma \mathcal{B}^*\mathcal{B}$ËøõË°å$LL^T$ÁöÑÂàÜËß£„ÄÇÂèØÂ∞ÜÂéüÈóÆÈ¢òËΩ¨ÂåñÊàê‰ª•‰∏ãÂΩ¢ÂºèÂêéÊ±ÇÈÄÜ \left(I_{m}+\sigma\left(L^{-1} A\right) U\left(L^{-1} A\right)^{T}\right)\left(L^{T} d\right)=-L^{-1} \nabla \psi(y)‰æãÂ¶ÇÂú®TV denoisingÁöÑÊÉÖÂÜµ‰∏ãÔºö$A=I$Ôºå$B=[B1, B2]$, ÂàôÈúÄÂØπ$I+\sigma B^*B$ËøõË°åÂàÜËß£ (ÁõÆÂâçÊ≤°ÊúâÂÆûÁé∞Ëøô‰∏™ÂàÜËß£, ÊâÄ‰ª•‰ΩøÁî®pcgÊ±ÇËß£ËØ•Á∫øÊÄßÁ≠âÂºè) ÊñπÊ≥ï‰∫åÔºöPcg Âæ™ÁéØÔºàÁ¨¨‰∏âÂ±ÇÂæ™ÁéØÔºâ Do $V_jd^j‚Äã$ Until $\left|V_{j} d^{j}+\nabla \psi\left(y^{j}\right)\right| \leq \min \left(\overline{\eta},\left|\nabla \psi\left(y^{j}\right)\right|^{1+\tau}\right)‚Äã$ Â∞ùËØïËøáÁöÑÂä†ÈÄüÂäûÊ≥ïÔºö Â∞ÜËØ•Âæ™ÁéØÂÜôÊàêcËØ≠Ë®Ä Âä†ÈÄüÁöÑÂäûÊ≥ïÔºåÊØèÊ¨°ÁâõÈ°øËø≠‰ª£‰ªé‰∏ä‰∏ÄÊ¨°dÁöÑÁªìÊûúÂºÄÂßã„ÄÇÂú®ÁÆóÊ≥ïÂø´Êî∂ÊïõÁöÑÊó∂ÂÄôÂèØ‰ª•Âä†ÈÄü ÂÆûÈ™åÁªìÊûú‰∏éÂÆûÈ™åËÆæÁΩÆ Âæ™ÁéØ‰∏ÄÔºölnexact Lagrangian methd Âæ™ÁéØ‰∫åÔºöÁâõÈ°øÊ≥ïËø≠‰ª£Ê±ÇËß£ÈóÆÈ¢òÔºà22Ôºâ ËÆæÁΩÆÂæ™ÁéØ‰∫åÁöÑ‰∏≠Ê≠¢Êù°‰ª∂‰∏∫: $\left|\nabla \psi_{k}\left(y^{k+1}\right)\right|$ &lt;{0.005} psÔºöÂ¶ÇÊûúÂú®Â∞è‰∫é0.005ÂâçËææÂà∞Êî∂ÊïõÔºåÂàôÁªàÊ≠¢Âæ™ÁéØ‰∫åÔºåËøõÂÖ•Âæ™ÁéØ‰∏ÄÁöÑ‰∏ã‰∏ÄËΩÆËø≠‰ª£ ËØ•Âæ™ÁéØÁöÑÊî∂ÊïõÈÄüÂ∫¶‰∏éÂæ™ÁéØ‰∏â‰∏≠pcgÁöÑÁ≤æÂ∫¶ÊúâÂÖ≥: \left\|y^{j+1}-\overline{y}\right\|=O\left(\left\|y^{j}-\overline{y}\right\|^{1+\tau}\right) Âæ™ÁéØ‰∏â(pcg)Ôºö ÂΩ±ÂìçÂæ™ÁéØ‰∏âËø≠‰ª£Ê¨°Êï∞ÁöÑÂõ†Á¥†: $\tau‚Äã$ÁöÑÂ§ßÂ∞è ËØ•Âæ™ÁéØÁªàÊ≠¢Êù°‰ª∂Ôºö$\left|V_{j} d^{j}+\nabla \psi\left(y^{j}\right)\right| \leq \min \left(\overline{\eta},\left|\nabla \psi\left(y^{j}\right)\right|^{1+\tau}\right),\tau=(0,1]$ $\tau=1$:Âæ™ÁéØ‰∏âÂæ™ÁéØ(Â§ßÊ¶Ç20)Ê¨°ÔºåÂæ™ÁéØ‰∫åÊî∂ÊïõÈúÄË¶Å*Ê¨°ÔºåÂæ™ÁéØ‰∏ÄÈúÄË¶Å*Ê¨° $\tau=2$:Âæ™ÁéØ‰∏âÂæ™ÁéØ*Ê¨°ÔºåÂæ™ÁéØ‰∫åÊî∂ÊïõÈúÄË¶Å*Ê¨°ÔºåÂæ™ÁéØ‰∏ÄÈúÄË¶Å*Ê¨° (ÂÆûÈ™åÁªìÊûúÈúÄË¶ÅË°•ÂÖÖ) ÂÆûÈ™å‰∏≠Â≠òÂú®ÁöÑÈóÆÈ¢ò Âæ™ÁéØ‰∫åÂíåÂæ™ÁéØ‰∏â‰πãÈó¥ÁöÑÊî∂ÊïõÈÄüÂ∫¶Ê≤°ÊúâÊª°Ë∂≥ÁêÜËÆ∫ÂÄºÔºö \left\|y^{j+1}-\overline{y}\right\|=O\left(\left\|y^{j}-\overline{y}\right\|^{1+\tau}\right) ‚Äã ÂÖ∑‰ΩìÁöÑËØ¥ÔºåÂæ™ÁéØ1‰∏≠ÁöÑ‰∏≠Èó¥Âá†Ê¨°Ëø≠‰ª£‰∏≠ÔºåÂæ™ÁéØ‰∫åÁöÑÊî∂ÊïõÈÄüÂ∫¶ÂæàÊÖ¢ÔºåÊ≤°ÊúâËææÂà∞ÁêÜËÆ∫ÂÄºÔºåÁîöËá≥ÊØîÁ∫øÊÄßÊî∂ÊïõËøòË¶ÅÊÖ¢„ÄÇ ‚Äã ÔºàÂæ™ÁéØ‰∫åÁöÑÊî∂ÊïõÂõæÈúÄË¶ÅË°•ÂÖÖÔºâ‚Äã Non-convex model1. General Model A nonconvex problem (square-root regression problem) (3) \min _{\beta \in \Re^{n}}\{g(\beta) :=\underbrace{h(X \beta)}_{f(\beta)}+\underbrace{p(\beta)-q(\beta)}_{r(\beta)}\}‚Äã $p : \Re^{n} \rightarrow(-\infty,+\infty] \text { is a proper closed convex function }‚Äã$ ‚Äã $q : \Re^{n} \rightarrow \Re \text { is a finite-valued (smooth, not essential) convex function. }$ ‚Äã $ \text {The proximal functions of h and p to be (strongly) semismooth.}$ Examples ÔºàÁ≠âÂæÖË°•ÂÖÖÔºâ Âõ†‰∏∫Âéügeneral model (3) ËΩ¨ÂåñÊàêÊ®°Âûã (10)/(P): $\text { Given } \sigma&gt;0, \tau&gt;0, \tilde{\beta} \in \mathbb{R}^{n}, \tilde{v} \in \mathbb{R}^{n}, \text { and }\tilde{b} \in \mathbb{R}^{m}$ \begin{aligned} \min _{\beta \in \mathbb{R}^{n}}\{h(\beta ; \sigma, \tau, \tilde{\beta}, \tilde{v}, \tilde{b}) :=&\|X \beta-b\|+\lambda p(\beta)-q(\tilde{\beta})-\langle\tilde{v}, \beta-\tilde{\beta}\rangle \\ &+\frac{\sigma}{2}\|\beta-\tilde{\beta}\|^{2}+\frac{\tau}{2}\|X \beta-\tilde{b}\|^{2} \} \end{aligned}(1) Linearize the concave term: $-q(\beta)$. Âõ†‰∏∫Ê≠§È°πnonconvex (2) Add the proximal termÔºö$\frac{\tau}{2}|X \beta-X \tilde{\beta}|^{2}$. Âõ†‰∏∫$h(\cdot)$Âíå$p(\beta)$ÊòØnonsmooth $\beta^{k+1}=\operatorname{Prox}_{\lambda p / \sigma^{2, k}}\left(\beta^{k}+\left(\nabla q\left(\beta^{k}\right)-X^{T} u^{k+1}\right) / \sigma^{2, k}\right)‚Äã$ ÈóÆÈ¢ò [x] $\frac{\sigma}{2}|\beta-\tilde{\beta}|$ÁöÑ‰ΩúÁî®ÔºöÂõ†‰∏∫ÊòØPPAÁÆóÊ≥ï [ ] $\frac{\tau}{2}|X \beta-\tilde{b}|^{2}$Ëøô‰∏™ProximalÈ°πÁöÑÁî±Êù• [ ] ÈíàÂØπËØ•ÈùûÂá∏Ê®°ÂûãÁöÑÁÆóÊ≥ïÔºåËß£ÁöÑÂîØ‰∏ÄÊÄßÂíåÁÆóÊ≥ïÁöÑÊî∂ÊïõÊÄßËÉΩÂê¶Ë¢´ËØÅÊòéÔºüÂè™Ë¶ÅÊòØÈùûÂá∏ÈóÆÈ¢òÔºåÈÉΩÊó†Ê≥ï‰øùÈöúËß£ÁöÑÂîØ‰∏ÄÊÄßÔºüÈÇ£‰πàËØ•ÁÆóÊ≥ïÁöÑ‰ºòÁÇπÔºü [ ] ËØ•Á±ªÈóÆÈ¢òÊú¨Êù•ÁöÑËß£Ê≥ï 2. SSN-based PPM Algorithm PPM algorithmÔºö Proximal majorization-minimization Initialize: $\beta^{0} \approx \underset{\beta \in \mathbb{R}^{n}}{\operatorname{argmin}}\left\{h\left(\beta ; \sigma^{1}, \tau^{1}, 0,0, b\right)\right\}‚Äã$ Iteration: step 1 $\beta^{k+1}=\underset{\beta \in \mathbb{R}^{n}}{\operatorname{argmin}}\left\{h\left(\beta ; \sigma^{2, k}, \tau^{2, k}, \beta^{k}, \nabla q\left(\beta^{k}\right), X \beta^{k}\right)+\left\langle\delta^{k}, \beta-\beta^{k}\right\rangle\right\}$ ‚Äã step 2 $\sigma^{2, k+1}=\rho_{k} \sigma^{2, k}, \tau^{2, k+1}=\rho_{k} \tau^{2, k}\text { with } \rho_{k} \in(0,1)‚Äã$ Until: If $Œ≤_{k+1}‚Äã$ satisÔ¨Åes a prescribed stopping criterion, terminate; Step 1: solve the dual of the (10) which isÔºà12Ôºâ \begin{aligned} \min _{u \in \mathbb{R}^{m}} &\left\{\varphi(u) :=\langle u, b\rangle+\frac{\tau}{2}\left\|\tau^{-1} u+\tilde{b}-b\right\|^{2}-\left\|\operatorname{Prox}_{\tau^{-1}\|\cdot\|}\left(\tau^{-1} u+\tilde{b}-b\right)\right\|\right.\\ &-\frac{1}{2 \tau}\left\|\operatorname{Prox}_{\tau \delta_{B}}(u+\tau(\tilde{b}-b))\right\|^{2}+\frac{\sigma}{2}\left\|\tilde{\beta}+\sigma^{-1}\left(\tilde{v}-X^{T} u\right)\right\|^{2} \\ &-\lambda p\left(\operatorname{Prox}_{\sigma^{-1} \lambda p}\left(\tilde{\beta}+\sigma^{-1}\left(\tilde{v}-X^{T} u\right)\right)\right)-\frac{1}{2 \sigma}\left\|\operatorname{Prox}_{\sigma(\lambda p) *}\left(\sigma \tilde{\beta}+\tilde{v}-X^{T} u\right)\right\|^{2} \} \end{aligned} (12)with $\overline{y}=\operatorname{Prox}_{\tau^{-1}| |}\left(\tau^{-1} \overline{u}+\tilde{b}-b\right), \quad \overline{\beta}=\operatorname{Prox}_{\sigma^{-1} \lambda p}\left(\tilde{\beta}+\sigma^{-1}\left(\tilde{v}-X^{T} \overline{u}\right)\right)‚Äã$. and $\beta^{k+1}=\operatorname{Prox}_{\lambda p / \sigma^{2, k}}\left(\beta^{k}+\left(\nabla q\left(\beta^{k}\right)-X^{T} u^{k+1}\right) / \sigma^{2, k}\right)‚Äã$ (12) ÁöÑÊé®ÂØºËøáÁ®ã ‰ª§$y=X \beta-b$Â∞Ü(10)ËΩ¨ÂåñÊàêÁ∫¶ÊùüÈóÆÈ¢ò(11) \min _{\beta \in \mathbb{R}^{n}, y \in \mathbb{R}^{m}}\left\{\|X\beta-b\|+\lambda p(\beta)-\langle\tilde{v}, \beta-\tilde{\beta}\rangle+\frac{\sigma}{2}\|\beta-\tilde{\beta}\|^{2}+\frac{\tau}{2}\|y+b-\tilde{b}\|^{2} \right\}\\ \text{subject to }X \beta-b=y\\ Â∞ÜÁ∫¶ÊùüÈóÆÈ¢òËΩ¨ÂåñÊàêLagrangianÔºö $L(y,\beta; u) = \left\{|y|+\lambda p(\beta)-\langle\tilde{v}, \beta-\tilde{\beta}\rangle+\frac{\sigma}{2}|\beta-\tilde{\beta}|^{2}+\frac{\tau}{2}|y+b-\tilde{b}|^{2} - \right\}‚Äã$ (11) Dual function of (11) g(u):=\inf _{y,\beta} L(y, \beta;u) ÂØπ$L(y,\beta; u) ‚Äã$ËøõË°åÈÖçÊñπ \begin{aligned} L(y,\beta; u) &= \|y\|+\lambda p(\beta)-\langle\tilde{v}, \beta-\tilde{\beta}\rangle+\frac{\sigma}{2}\|\beta-\tilde{\beta}\|^{2}+\frac{\tau}{2}\|y+b-\tilde{b}\|^{2} - \langle u, y-X \beta+b\rangle\\ &=\{\|y\|+\frac{\tau}{2}\|y+b-\tilde{b}\|^{2}-\langle u,y\rangle\}+\{\lambda p(\beta)-\langle\tilde{v}, \beta-\tilde{\beta}\rangle+\frac{\sigma}{2}\|\beta-\tilde{\beta}\|^{2}+\langle X^T u,\beta\rangle\}-\langle u,b\rangle\\ &=\{\|y\|+\frac{\tau}{2}\|y+b-\tilde{b}-\frac{u}{\tau}\|^{2}\}-\frac{u^2}{2\tau}+\langle \tilde b,u\rangle+\{\lambda p(\beta)+\frac{\sigma}{2}\|\beta-\tilde{\beta}\|^{2}+\langle X^Tu-\tilde{v}, \beta-\tilde{\beta}\rangle+\langle \tilde{\beta},X^Tu\rangle\}\\ &=\{\|y\|+\frac{\tau}{2}\|y+b-\tilde{b}+\frac{u}{\tau}\|^{2}\}+\{\lambda p(\beta) + \frac{\sigma}{2}\|\beta-\tilde{\beta}+\frac{X^Tu-\tilde{v}}{\sigma}\|^{2}\}...\\ &-\frac{u^2}{2\tau}+\langle \tilde b,u\rangle+\langle\tilde{\beta},X^Tu\rangle-\|\frac{X^Tu-\tilde{v}}{\sigma}\|^2 \\ \end{aligned} (12) ÁöÑÊ±ÇËß£ÔºöA semismooth Newton‚Äòs method ÊúÄÂ∞èÂåñÔºà12ÔºâÁ≠â‰ª∑‰∫éÔºà12ÔºâÁöÑ‰∏ÄÈò∂Êù°‰ª∂ \nabla \varphi(u)=\operatorname{Prox}_{\tau^{-1} \|}\left(\tau^{-1} u+\tilde{b}-b\right)-X \operatorname{Prox}_{\sigma^{-1} \lambda p}\left(\tilde{\beta}+\sigma^{-1}\left(\tilde{v}-X^{T} u\right)\right)+b\\ \nabla \varphi(u)=0\qquad(13)\\ Solve nonlinear equationÔºà13Ôºâby pcg $\hat{\partial}^{2} \varphi(u) :=\sigma^{-1} X \partial \operatorname{Prox}_{\sigma^{-1} \lambda p}\left(\tilde{\beta}+\sigma^{-1}\left(\tilde{v}-X^{T} u\right)\right) X^{T}+\tau^{-1} \partial \operatorname{Prox}_{\tau^{-1} |}\left(\tau^{-1} u+\tilde{b}-b\right)$ $H:=\sigma^{-1} X U X^{T}+\tau^{-1} V \in \hat{\partial}^{2} \varphi(u)‚Äã$ 3. Problem4. Our case For the ROF model: $h(X\beta)=|\nabla \beta|_1$ $p(\beta)=|\beta-b|_2^2,q(\beta)=0‚Äã$ ÈôÑÂΩï ËΩ¨ÂåñÊàêsmoothÂçïÂèòÈáèÊñπÁ®ãÁöÑÊé®ÂØºËøáÁ®ã \begin{aligned} \Psi(\hat{y}, \hat{z}) &=\inf _{z} \Psi(\hat{u}, z) \\ &=G(\hat{y})+\sigma \inf _{z}\left\{\frac{1}{\sigma} F(z)+\frac{1}{2}\left\|z-K \hat{y}-\frac{x}{\sigma}\right\|^{2}\right\}-\frac{1}{2 \sigma}\|x\|^{2} \\ &=G(\hat{y})+\sigma M(F / \sigma)(K \hat{y}+x)-\frac{1}{2 \sigma}\|x\|^{2} \end{aligned}Using the Moreau-Yosida regularization: M_{\lambda} f(x) :=\min _{u} f(u)+\frac{1}{2 \lambda}\|u-x\|_{2}^{2} \nabla M_{\lambda} f(x)=\frac{1}{\lambda}\left(x-\operatorname{Prox}_{\lambda f}(x)\right) $h(y)+p(By)$ÂØπÂÅ∂ÈóÆÈ¢òÊó†Ê≥ïËΩ¨ÂåñÊàêÂçïÂèòÈáèsmoothÁöÑÂéüÂõ† \begin{array}{c}{\partial \psi(z)=\partial p^{*}(z)-\underline{A x}+\sigma\left(\mathcal{A}^{*} z+y-c\right)} \\ {0 \in \partial \psi(\overline{z})} \\ {0 \in \partial p^{*}(\overline{z})-\mathcal{A} x+\sigma\left(\mathcal{A}^{*} \overline{z}+y-c\right)} \\ {0 \in \sigma\left(\frac{\partial p^{*}(\overline{z})}{\sigma}+\mathcal{A}^{*} z-\left(c-y+\frac{1}{\sigma} \mathcal{A} x\right)\right)}\end{array}$z$Êó†Ê≥ïÁî®proximalË°®Á§∫]]></content>
      <categories>
        <category>ÁÆóÊ≥ï</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[È¶ôÊ∏ØÂú∞Âõæ]]></title>
    <url>%2Fp%2Facef.html</url>
    <content type="text"><![CDATA[Â∞ñÊ≤ôÂíÄ Êµ∑Ê∏ØÂüéÊóÅËæπÔºö DFSÔºåAqua spiritÔºå ÊääÂú∞ÈìÅÂè£‰πüÊ†á‰∏ä ‰π∞Â∞èÁÜäÈ•ºÂπ≤ÔºöÂú®Áæé‰∏ΩÂçéÂïÜÂé¶ÔºåÊòØ‰∏™Á±ª‰ººÈáçÂ∫ÜÂ§ßÊ•ºÁöÑÂºÄÊîæÁöÑÊ•º Êó∫ËÆ∞ÂÜ∞ÂÆ§/‰∏ÄÂÖ∞ÊãâÈù¢Ôºö Â¶àÂí™È∏°Ëõã‰ªîÂíåËñØÊù°/Ôºõ ÂÜ∞Ê∑áÊ∑ãÔºõÈÄÅ‰ªñ‰ª¨‰∏äËàπÔºõ ÁÇπÂøÉÔºöÂ•ΩËøêÊ∑ªÔºåÂîêÂÆ´Â∞èËÅöÔºàÊñ∞ÂºèÔºâ ÁÅ´ÈîÖÔºöÁÅ´Ê∞¥ÁàêÂÜ∞ÂÆ§ÁÅ´Èçã Êó∫Ëßí https://www.openrice.com/zh/hongkong/r-%E7%81%AB%E6%B0%B4%E7%88%90%E5%86%B0%E5%AE%A4%E7%81%AB%E9%8D%8B-%E6%97%BA%E8%A7%92-%E6%B8%AF%E5%BC%8F-%E7%81%AB%E9%8D%8B-r544211/reviews Â≤õ‰∏äÊãçÁÖß Ë¥≠Áâ© Áúã‰π¶ÂñùÂíñÂï°È¶ôÊ∏ØÂ∞è‰ºóÊúâË∂£ÁöÑÊ∂àÂ§èÂ•ΩÂéªÂ§Ñ Ê∏ÖÂçïÂéª‰∏Ä‰∏™Â≤õÂæíÊ≠•/ÈïøÊ¥≤Â≤õ/Ë•øË¥°ÔºåÊôö‰∏äÂùêËàπÂêÉÂÜ∞Ê∑áÊ∑ãÔºöÂ§èÂ§©Â∞èÊ∏ÖÊñ∞È£é ÂéªÂêÉËå∂È§êÂéÖ ÂéªÂùêÂÇçÊôöÁöÑÂèÆÂèÆËΩ¶ÔºåÂêÉshakeshack ÂéªÈÄõÈ¶ôÊ∏ØÁöÑË∂ÖÂ∏ÇÔºå‰π∞ÂØøÂè∏ÂΩìÊôöÈ§êÔºåÂí∏ËõãÈªÑÈ∏°Ëõã‰ªî ÂêÉÂ§ßÊéíÊ°£ÔºöÊôö‰∏ä Êê¨ÂÆ∂+ÁúãÊºîÂî±‰ºö ÁÇπÂøÉÔºöÂë®ËÆ∞ÁÇπÁÇπÂøÉÔºå Ë•øÂÆâ Ë•øÂÆâÂèäÂë®Ëæπ100ÂÖ¨ÈáåÂÜÖÊúâÂì™‰∫õÂÜ∑Èó®‰ΩÜÈùûÂ∏∏ÂÄºÂæó‰∏ÄÂéªÁöÑÂú∞ÊñπÔºü Ë•øÂÆâÂÄºÂæóÂêÉÁöÑÂú∞Êñπ Ë•øÂÆâÊúâÂì™‰∫õÂèØ‰ª•ÂÆâÈùôÂú∞ÂæÖ‰∏Ä‰∏ãÂçàÁöÑÂú∞ÊñπÔºü Ë∏©ËøáÁöÑÈõ∑Ôºötop1ÁöÑÂÖ≠üà¥Ô∏èÊ±§ÂåÖ Â∏ÇÂå∫Ôºö Â§ßÈõÅÂ°îÔºöÁæéÊúØÈ¶Ü„ÄÅÂõûÊ∞ëË°ó„ÄÅÊ¥íÈáëÊ°•„ÄÅÈíüÈºìÊ•º Ë•øÂÆâÊòéÂüéÂ¢ôÔºö Êé®ËçêÁéØÂ¢ô‰∏ÄÂë®ÁöÑËá™Ë°åËΩ¶„ÄÇË•øÂÆâÂüéÂ¢ôÊòØ‰∏≠ÂõΩÁé∞Â≠òËßÑÊ®°ÊúÄÂ§ß„ÄÅ‰øùÂ≠òÊúÄÂÆåÊï¥ÁöÑÂè§‰ª£ÂüéÂû£„ÄÇÁé∞Â≠òÂüéÂ¢ô‰∏∫ÁúÄ‰ª£Âª∫Á≠ë,ÂÖ®Èïø13.7ÂçÉÁ±≥,‰Ωç‰∫éË•øÂÆâÂ∏Ç‰∏≠ÂøÉ,ÈÄÅÊàë‰ª¨ËøáÂéªÁöÑÂè∏Êú∫Â∏àÂÇÖËØ¥Ëµ∑ÂüéÂ¢ôÈÇ£ÁßçÊ≤πÁÑ∂ËÄåÁîüÂèëËá™ÂÖßÂøÉÁöÑËá™Ë±™ÊÑüÊª°Êª°ÈÉΩÊòØ Â§ßÊòéÂÆ´ÈÅóÂùÄÂÖ¨Âõ≠ÔºöËøô‰∏™ÊòØÁÉ≠Èó®Ôºå‰ΩÜÂÜ∑Èó®Áé©Ê≥ïÊòØÂÇçÊôöÂéª ÂÖ´‰ªôÂÆ´Âè§Áé©Â∏ÇÂú∫ÔºåÂÖ´‰ªôÂ∫µÔºåÔºåÁ¶ªÊ∞∏ÂÖ¥Âùä‰∏çËøú È°∫ÂüéÂ∑∑Ôºö‰∏Ä‰æßÊòØÂ∑çÂ∑çÂè§ÂüéÂ¢ôÔºå‰∏Ä‰æßÊòØÁßÄ‰∏ΩÁ´ØÂ∫ÑÁöÑÊòéÊ∏ÖÂè§Âª∫„ÄÇ„ÄÅÈ£üÂ∫ó„ÄÅÈÖíÂêß„ÄÅÂíñÂï°Â±ãÔºåÊõ¥Êúâ‰∏Ä‰∫õÁß¶ËÖîÊàñÁõ∏Â£∞Êõ≤Ëâ∫Á§æÔºåÈô¢Èó®ÂçäÊé©ÈùôÂæÖÂê¨ÂÆ¢Âà∞ËÆø„ÄÇ ÁéØÂüéÂÖ¨Âõ≠Ôºö‰ª•Êä§ÂüéÊ≤≥‰∏∫Á∫øÔºåÂú®ÂüéÂ¢ôÊ†π‰∏ãÂõ¥ÁªïÁùÄÊòéÂüéÂ¢ô‰øÆÂª∫ÁöÑÁéØÂüéÂÖ¨Âõ≠ÔºåÊòØË•øÂÆâÊú¨Âú∞‰∫∫ËøêÂä®„ÄÅÊï£Ê≠•„ÄÅ‰ºëÈó≤ÁöÑÂ•ΩÂéªÂ§Ñ ËæÉËøúÔºö Áß¶Â≤≠Ôºö‰∏úÊ¢ÅÂ±±(ÂÜ∑Èó®)ÔºõÈªëÊ≤≥ÔºõÊ•ºËßÇÂè∞ÔºõÈªéÂÖÉÂù™„ÄÇ Ë•øÂ≤≥Â∫ô„ÄÇ‰∏ÄËà¨Ê∏∏ÂÆ¢ÈÉΩ‰ºöÂéªÂçéÂ±±,ÂæàÂ∞ë‰ºöÂéªË•øÂ≤≥Â∫ô„ÄÇ‰ΩÜÊòØË•øÂ≤≥Â∫ôÊúâÁùÄÈùûÂ∏∏Á≤æÁæéÁöÑÊòéÊ∏ÖÂª∫Á≠ë,ËÄå‰∏îÈù¢ÁßØ Â∑®Â§ß,ÊñáÈù©ÊúüÈó¥Áî®‰ΩúÂÜõËê•ÊâÄ‰ª•‰øùÂ≠òÁöÑ‰∏çÈîô,‰∏çËøáËøôÈáåÂíåÂçéÂ±±ÊòØËÅîÁ•®,Â¶ÇÊûúÂéªÂçéÂ±±ÁöÑËØù‰∏ÄÂÆöË¶ÅÊäΩÊó∂Èó¥ ÂéªË•øÂ≤≥Â∫ô„ÄÇ Á¢ëÊûóÂçöÁâ©È¶Ü„ÄÇËøô‰∏™Ê†πÊú¨Â∞±‰∏çÁÆóÂÜ∑Èó®,‰∏çËøáËøòÊòØÂ∞è‰ºó‰∏Ä‰∫õ,‰π¶Ê≥ïÁà±Â•ΩËÄÖÁöÑÂú£Âú∞„ÄÇËÄå‰∏îËøôÈáåÈù¢ËøòÊúâÊò≠Èôµ È™èÂíåÊôØ‰∫ëÈíü„ÄÇÈáåÈù¢ÁöÑ‰ΩõÂÉèÁü≥ÂàªÊõ¥ÊòØÁ≤æÁæéÁªù‰º¶„ÄÇÂè¶Â§ñÁ¢ëÊûóÊóÅËæπÊúâ‰∏Ä‰∏™ÂçßÈæôÂØ∫,ÊòØÈôïË•øÁ¨¨‰∏ÄÊâÄÂØ∫Â∫ô, ‰πüÂèØ‰ª•ÁúãÁúã„ÄÇ ÂÖ≥‰∏≠Ê∞ë‰øóËâ∫ÊúØÂçöÁâ©Èô¢„ÄÇÂùêÊ†áÂçó‰∫îÂè∞ ÂùêÊ†áÂçó‰∫îÂè∞„ÄÇÊòØ‰∏ÄÂÆ∂ÁßÅ‰∫∫ÂÖ≥‰∏≠Ê∞ë‰øóÂçöÁâ©Èô¢,Âª∫Á≠ëÁ≤æÁæé,ËóèÂìÅ‰∏∞ÂØå„ÄÇ ÂæàÊÑüÊøÄÊúâËøôÊ†∑ÁöÑÊî∂ËóèÂÆ∂ËÉΩÂ§üÂ∞ÜÂÖ≥‰∏≠Ê∞ë‰øóÊúâÊù°ÁêÜÁöÑÊî∂Ëóè‰øùÂ≠ò,ÂØπÂ§ñÂºÄÊîæ, Èó®Á•®Áï•Ë¥µ,120ÂÖÉ,‰ΩÜËøòÊòØÈùûÂ∏∏ÂÄºÂæóÂéªÊÑüÂèó‰∏Ä‰∏ã,Â∞§ÂÖ∂ÊòØÂ¶ÇÊûúË∫´ËæπÊúâÂ§ñÂõΩÂèã‰∫∫,ÈùûÂ∏∏Êé®ËçêÂ∏¶‰ªñ‰ª¨Êù• ËøôÈáå,ÁªùÂØπ‰ºöÂØπË•øÂÆâ„ÄÅÂØπ‰∏≠ÂõΩ‰ºöÊúâÊõ¥Ê∑±‰∏ÄÂ±ÇÁöÑËÆ§ËØÜ„ÄÇ Ë•øÂÆâÂêÉÁöÑÈ©¨Â≥∞Â∞èÁÇíÔºàÂ•ΩÂêÉÔºÅÔºÅ‰ΩÜÊãçÂæó‰∏çÂ•ΩÁúãÔºåËßÅË∞ÖÔºâÔºö ÂÆöÂÆ∂Â∞èÈÖ•ËÇâ Âú∞ÂùÄÔºöÈÖøÁöÆÈöîÂ£Å ‰∏úÂçó‰∫öÁîëÁ≥ï Ë•øÁæäÂ∏Ç Èù¢ÔºöÈ©¨ËôéÈù¢È¶Ü ËøûÈîÅÂ∫óÔºåÈ©¨ËôéÈù¢È¶Ü ËøûÈîÅÂ∫óÔºåËã±Â≠êÁâõËÇâÈù¢ ÊôØËßÇË∑Ø Â§úÂÆµÔºöÂ∞è‰ΩêÁÉ§ËÇâ(ÂºÄÂÖÉË∑ØÊÄªÂ∫ó) ÂíñÂï°È¶Ü„ÄÅÂ∞èÊÉÖË∞É ÊõºËíÇÂπøÂú∫ ‰∫∫‰∏çÂ§öÁöÑ‰∏Ä‰∏™ÂïÜÂú∫,Â∫óÂÖ∂ÂÆû‰πü‰∏çÂ§ö„ÄÇ‰ΩÜÊòØËâ∫ÊúØÊÑüÂæàÂº∫,ÁªèÂ∏∏Êúâ‰∏Ä‰∫õÁîªÊàñÈõïÂ°ëÁöÑÂ∞èÂ±ïËßà„ÄÇÈáåÈù¢ÁöÑËô´ÂÑø ÂíñÂï°„ÄÅÂùáËÆ∞ÂíñÂï°ÁöÑË£Ö‰øÆÈ£éÊ†ºÊàëÈÉΩÂæàÂñúÊ¨¢„ÄÇÂ∞±ËøûËøôÈáåÁöÑÁ±≥ÂÆ∂Â§ßÈõ®Ê≥°È¶çÈÉΩÊòØÂíñÂï°È¶ÜÂºèÁöÑÊú®Ë¥®Ê∑±Ëâ≤Ë£Ö‰øÆÈ£é Ê†º,ÂæàÊòØÈõÖËá¥,Â¶ÇÊûúËØ∑‰∫∫ÂêÉÊ≥°È¶çËøò‰∏çÊÉ≥ÁéØÂ¢ÉËÑè‰π±Â∑ÆÁöÑËØùÂèØ‰ª•ËÄÉËôëËøôÈáå„ÄÇ ÈôïË•øÁúÅÂõæ‰π¶È¶Ü„ÄÇ Êõ≤Ê±ü‰π¶Âüé ‰π¶ÂüéÊèê‰æõÂæàÂ§öÂ∫ß‰Ωç„ÄÅÂ∞èÊ≤ôÂèëÔºåÁúã‰π¶ÂæàÊÉ¨ÊÑè„ÄÇ]]></content>
      <categories>
        <category>ÁîüÊ¥ª</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Ê®°‰ªøËÉ∂ÁâáËâ≤Ë∞É]]></title>
    <url>%2Fp%2F3acf.html</url>
    <content type="text"><![CDATA[06-14 ËØæÁ®ãÈìæÊé•Ôºöhttps://m.lizhiweike.com/classroom/12544288 https://pan.baidu.com/s/1QCXJhicXgzQgHirQioIPSw ÂØÜÁ†ÅÔºö4yqr Âø´ÈÄüÊ®°‰ªøËÉ∂ÁâáËâ≤Ë∞É @‰øÆÂõæÂ∏àÊùéÊñ∞È¢ñ Êó∂Â∞öÂçö‰∏ªÔºöÂ∞èË±°ÁéãÂõΩ„ÄÅfashionmodels ÊëÑÂΩ±Â∏àÔºöÂº†ÂÆ∂ËØö ÂêåÂ≠¶‰ª¨Ôºå‰Ω†‰ª¨Â∑≤ÁªèÁúãÂÆå‰∫ÜËøô5‰∏™ÊëÑÂΩ±Â∏àÁöÑ‰ΩúÂìÅ‰∫ÜÂêßÔºåÂÖ∂ÂÆûÂë¢ÔºåÊàë‰ª¨Èô§‰∫Ü‰∏Ä‰∫õÊäÄÊ≥ï‰∏äËøòÊúâÊÄùË∑Ø‰∏äÁöÑÊèêÂçáÔºåÂÖ∂ÂÆûÊàë‰ª¨ÂÆ°Áæé‰∏äÁöÑ‰∏Ä‰∏™ÊèêÂçá‰πüÊòØÈùûÂ∏∏ÈáçË¶ÅÁöÑÔºåÈÇ£‰πàÊàë‰ª¨Â¶Ç‰ΩïÂéªÊèêÂçáÂÆ°ÁæéÂë¢Ôºü‰∏ãÈù¢Êàë‰ªãÁªçÁªôÂ§ßÂÆ∂‰∏Ä‰∫õÊèêÂçáËá™Â∑±ÁöÑÊñπÊ≥ï„ÄÇ ËØÜ‰∏Ä‰∫õÂõΩÂ§ñÁöÑÂ∞±ÊòØÂõΩÈôÖÁöÑÔºåÂóØÊØîËæÉÂéâÂÆ≥ÁöÑÊëÑÂΩ±Â∏àÁöÑÂêçÂ≠ó‰ªéËÆ§ËØÜÊëÑÂΩ±Â∏àÁöÑÂêçÂ≠óÂºÄÂßãÔºåÁÑ∂ÂêéÂë¢ÔºåÂóØÔºåÂ¶ÇÊûúËØ¥‰Ω†‰ª¨‰∏ÄÂºÄÂßã‰∏çÁü•ÈÅì‰∏Ä‰∫õÂõΩÈôÖÊëÑÂΩ±Â∏àÁöÑÂêçÂ≠óÔºåÈÇ£‰πàÊàë‰ª¨ÂèØ‰ª•Âú®ÂõΩÂÜÖÁöÑ‰∏Ä‰∫õÂæÆÂçöÂïäÔºåÊØîÂ¶ÇËØ¥ÂæÆÂçöÂçö‰∏ªÂàÜ‰∫´‰∏Ä‰∫õÊó∂Â∞öÂ§ßÁâáÁöÑÂæÆÂçöÔºåÂçö‰∏ªÊØîÂ¶ÇËØ¥Â∞èË±°ÁéãÂõΩÂïäÔºåËøòÊúâ‰∏Ä‰∏™fashion modelsÔºåÁÑ∂ÂêéÂë¢ÔºåËøô‰∏§‰∏™Êó∂Â∞öÂçö‰∏ª‰ªñ‰πüÊòØ‰ºöÁªèÂ∏∏ÁöÑÂàÜ‰∫´‰∏Ä‰∫õÂõΩÂ§ñÁöÑÂ§ßÁâá„ÄÇ ‰ªñÂàÜ‰∫´ÁöÑ‰∏Ä‰∫õÊó∂Â∞öÂ§ßÁâáÁöÑÔºå‰ªñ‰ºöËâæÁâπÂá∫Êù•ÊëÑÂΩ±Â∏àÔºåÁÑ∂ÂêéÊàë‰ª¨ÊâæÂà∞Êàë‰ª¨ÂñúÊ¨¢ÁöÑÊëÑÂΩ±Â∏àÁöÑÂêçÂ≠óÂéªËøõË°å‰∏Ä‰∏™Ê†áËÆ∞ÔºåÁÑ∂ÂêéÂéªÁªôÊëÑÂΩ±Â∏àÁöÑ‰ΩúÂìÅËøõË°å‰∏Ä‰∏™ÂàÜÁ±ªÔºåÊØîÂ¶ÇËØ¥ÂóØÔºåÊàë‰ª¨È¶ñÂÖàÂ∞±ÊòØËøô‰∏™ÊëÑÂΩ±Â∏àÁöÑÂêçÂ≠óËøõË°å‰∏Ä‰∏™Ê†áËÆ∞ÔºåÁÑ∂ÂêéÂë¢ÔºåÊàë‰ª¨ÂÜçÂéªÊää‰ªñÁöÑ‰ΩúÂìÅËøõË°å‰∏Ä‰∏™ÊêúÈõÜÔºåÊØîÂ¶ÇËØ¥ÈÇ£‰∏™Êµ∑ËæπÁöÑÂú∫ÊôØÊàë‰ª¨ÁªôÂÆÉÂΩíÁ±ª‰∏Ä‰∏™Êñá‰ª∂Â§πÊµ∑ËæπÔºåÁÑ∂ÂêéÂë¢ÔºåÊàë‰ª¨ÂÆ§ÂÜÖÁöÑÊñá‰ª∂Â§πÂ∞±ÁªôÂÆÉÂΩíÁ±ª‰∏∫ÂÆ§ÂÜÖÔºåÁÑ∂ÂêéÂë¢ÔºåÊàë‰ª¨ÈÇ£‰∏™ËçâÂú∞ÁöÑÔºåÁÑ∂ÂêéÂ∞±Êää‰ΩúÂìÅÂàÜÁ±ª‰∏∫ËçâÂú∞ÔºåËøôÊ†∑Â≠êÂë¢ÔºåÂèØ‰ª•ÊúâÊïàÁöÑÂéªÊèêÂçáÊàë‰ª¨ÊâæÁâáÂ≠êÁöÑÊïàÁéá„ÄÇ ‰∏§‰∏™Êó∂Â∞öÂçö‰∏ªÊòØÊàëÊØîËæÉÁªèÂ∏∏ÁúãÁöÑÔºå‰ªñ‰∏çÊ≠¢‰ºöÂàÜ‰∫´‰∏Ä‰∫õÊó∂Â∞öÁöÑÂ§ßÁâáÔºåËøò‰ºöÂàÜ‰∫´‰∏Ä‰∫õÊó∂Â∞öÁöÑËµÑËÆØÔºå‰ºöËÆ©ÊàëÂú®‰∏Ä‰∏™ËßÜËßâÂïäÔºåÁÑ∂ÂêéÂë¢ÔºåËøòÊúâÊàëÁöÑÈÇ£‰∏™ÂÆ°Áæé‰∏äÈù¢‰ºöÂ∏¶ÁªôÊàë‰∏Ä‰∫õÊñ∞ÁöÑÁÅµÊÑü Êî∂ÈõÜÊëÑÂΩ±Â∏àÁöÑÂêçÂ≠ó„ÄÇÂ§öÁúãÂõΩÈôÖÊ†áÂáÜÁöÑÊëÑÂΩ±‰ΩúÂìÅ„ÄÇÂ¶Ç‰ΩïÊèêÈ´òÂÆ°ÁæéÔºåÊØèÊó•‰∏çÊñ≠ÁöÑÈòÖËØªÔºå‰∏çÊñ≠ÁöÑÂéªÊèêÂçáËá™Â∑±ÁöÑÁúºÁïåÔºåÂºÄÊãìËá™Â∑±ÁöÑËßÜÈáé„ÄÇÈòÖËØªÊñπÂºè‰πüÂæàÈáçË¶ÅÔºåË¶ÅÊâæÂà∞Ëá™Â∑±ÂñúÊ¨¢ÁöÑÁÖßÁâáÔºåÊúâÁõÆÁöÑÁöÑÂéªÊ¨£ËµèÔºåËøôÂæàÈáçË¶Å„ÄÇ‰ªé‰ª•‰∏ãÂá†ÁÇπËøõË°åÊ¨£Ëµè„ÄÇÁúãÁâáÁöÑËØù‰∏çÊòØÁõ≤ÁõÆÁöÑÂéªÁúãÁâáÂ≠êÔºåÁúãÁâáÂ≠êÁöÑËØùË¶ÅÂ∞±ÊòØÊúâÁõÆÁöÑÁöÑÂéªÊ¨£ËµèÂéªÂàÜÊûê ËàíÊúçÁöÑË∞ÉÂ≠ê„ÄÅÂÖâÂΩ±Â±ÇÊ¨°„ÄÅÊÉÖÁª™„ÄÅÊûÑÂõæ „ÄÅËÇ¢‰ΩìËØ≠Ë®Ä„ÄÅÊúâË∂£ÁöÑËâ≤ÂΩ©ÂØπÊØî„ÄÅÊúâÂàõÊÑèÊúâË∂£Âë≥ÊÄßÁöÑÁîªÈù¢ÊàñËÄÖÂπ≤ÂáÄ„ÄÅÁÆÄÊ¥Å„ÄÅÁªü‰∏ÄÁöÑÁîªÈù¢ ÁéãÂÆ∂Âç´ÁöÑÈ£éÊ†ºÈÉΩÊòØËâ≤ÂΩ©ÊØîËæÉÊµìÈÉÅÁöÑÔºåÊàë‰ª¨Ê®°ÊãüÁöÑÊó∂ÂÄôË¶ÅÂóØÔºåË¶ÅÂä†‰∏Ä‰∫õÂ§ßÈáèÁöÑËâ≤Ê∏©ÔºåÊàñËÄÖÊòØÂú®Êõ≤Á∫øÁªô‰ªñÂ§öÂä†Á∫¢ÂïäÔºåÁÑ∂ÂêéÂä†ÈªÑÂ∞±ÂèØ‰ª•Ê®°ÊãüÂá∫Êù•ÁéãÂÆ∂Âç´ÈÇ£ÁßçÂóØÁâπÂà´ÊµìÈÉÅÁöÑËâ≤ÂΩ©ÔºåÁÑ∂ÂêéËÆ∞ÂæóÊåâ‰∏çÁªô‰ªñÔºåÂóØÔºåÊöóÈÉ®ÁöÑËØùÂä†Ê∞¢ÔºåÁÑ∂ÂêéÂë¢Âä†ÈÇ£‰∏™ÈªÑ„ÄÇ ÊèêÁÅ∞ÔºöËâ≤Èò∂„ÄÅÂèØÈÄâÈ¢úËâ≤„ÄÅÊõ≤Á∫øÈÉΩÂèØ‰ª•ÊèêÁÅ∞ ËßÜÈ¢ë‰∏≠ÊèêÂèäÁöÑÈ´òÂÖâ„ÄÅ‰∏≠Èó¥Ë∞É„ÄÅÊöóÈÉ®Á≠âÂ∞èÁü•ËØÜÔºåÂ§ßÂÆ∂ÂèØ‰ª•Áúã‰∏ã‰∏ãÊñπËøôÂº†Âõæ~ ËÉ∂ÁâáÁÖßÁâáÁöÑÁâπÁÇπÔºöÈ´òÂÖâÊØîËæÉÊüîÔºåÈ´òÂÖâÊØîËæÉÊöóÔºåÊöóÈÉ®ÊØîËæÉÊâéÂÆûÔºåÂíå‰∏≠Èó¥Ë∞ÉÊØîËæÉÈ´ò‰∫ÆÊúâÂØπÊØîÔºåÁ∫øÊù°ÊòéÊòæÔºåËâ≤ÂΩ©Â§ö‰π±ÔºõËÉ∂Áâá‰ºöËâ≤ÂÅèÔºàÁ∫¢Ëâ≤ÂæÄÈªÑËâ≤ÂÅèÔºâ Êï∞Á†ÅÁÖßÁâáÁöÑÁâπÁÇπÔºöËøáÊ∏°ÊØîËæÉÂπ≥ÁºìÔºåÂØπÊØîÂ∫¶‰ΩéÔºåÂÉèÁ¥†È´òÔºåÁªÜËäÇÂ§öÔºå‰∏¢Â§±ÂÖâÊÑüÂíåÁ´ã‰ΩìÊÑüÔºõË¥®ÊÑüÈÄÄÂåñ Êï∞Á†ÅÁõ∏Êú∫Âà∞ËÉ∂ÁâáÁÖßÁâáÔºöË¥®ÊÑüÈÄÄÂåñÔºåÈ´òÂÖâË∞ÉÊöóÔºå‰∏≠Èó¥Ë∞ÉÊèê‰∫ÆÔºåÊöóÈÉ®ÂéãÂÆûÔºõÊõùÂÖâÊãâÈ´ò ‰∏≠Èó¥Ë∞ÉÊèê‰∫Æ ÂéöÈáçÔºåÂ∞±ÊòØÊòéÊöóÂ∑ÆÂà´Â§ßÔºåÂ∞±ÂÉè‰∏äÂ¶ÜÈáçÔºåÈ´òÂÖâÁâπÂà´‰∫ÆÔºå‰∏≠Èó¥Ë∞ÉÁâπÂà´Êöó 1.ÂÖàË∞ÉÂÖâÂΩ± ÂáèÂ∞ëÂØπÊØîÂ∫¶ Â¢ûÂä†ÊõùÂÖâ Ëâ≤ÂΩ©Êõ≤Á∫øÔºöÂä†Ê∑±ÊöóÈÉ®ÔºàÂ∞ÜÊõ≤Á∫øÂ∫ïÈÉ®ÂæÄÂè≥Âπ≥ÁßªÔºâÔºåÊèêÈ´ò‰∏≠Èó¥Ë∞ÉÔºàÊää‰∏≠Èó¥ÁÇπÂõ∫ÂÆöÂú®ÂéüÊù•ÁöÑ‰ΩçÁΩÆÔºâÔºåÈôç‰ΩéÈ´òÂÖâ(Èôç‰Ωé) Ë∞ÉËâ≤ÂΩ©ÔºåËâ≤ÂÅè ÂâçÊúü Ê®°‰ªøËÉ∂ÁâáÁöÑÁÖßÁâáÔºåÂâçÊúüÊãçÊëÑÁöÑËØùÂ∞ΩÈáèÈ°∫ÂÖâÈ°∫ÂÖâÊãçÊëÑÔºåÁÑ∂ÂêéÂë¢ÔºåÂ∞ΩÈáèÊõùÂÖâÁ®çÂæÆ‰∫Æ‰∏ÄÁÇπÔºå‰∏çË¶ÅÂ∞±ÊòØÊõùÂÖâÁ®çÂæÆË¶ÅÈ´ò‰∏ÄÊ°£Ôºå‰∏çË¶ÅËØ¥Â§™‰Ωé‰∫Ü„ÄÇ]]></content>
      <categories>
        <category>ÊëÑÂΩ±</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Â∞èÊ≥¢ÂüüÂõæÂÉèÂéªÂô™]]></title>
    <url>%2Fp%2F2812.html</url>
    <content type="text"><![CDATA[ÂèòÊç¢ÂèòÊç¢ÁöÑ‰ΩúÁî®ÔºöÊñπ‰æøÂéãÁº©„ÄÅËÆ°ÁÆóÁ≠â Â¶ÇÔºöÊñπ‰æøËÆ°ÁÆóÁöÑÁâπÂæÅÂêëÈáèÂü∫Á°ÄÔºåTv=cv„ÄÇeigenvector basisÂ∞±ÊòØÁªÑÊàêTÁöÑÂêëÈáèÔºåTÂ∞±ÊòØËΩ¨Êç¢„ÄÇ ÂèòÊç¢ÊúâÔºöÂÇÖÁ´ãÂè∂ÂèòÊç¢„ÄÅÂ∞èÊ≥¢ÂèòÊç¢ÔºàÂÇÖÁ´ãÂè∂ÂèòÂåñ‰∏çÂ±û‰∫éÂ∞èÊ≥¢ÂèòÂåñ„ÄÇÂÇÖÁ´ãÂè∂ÂèòÊç¢ÂíåÂ∞èÊ≥¢ÂèòÊç¢ÂêåÂ±û‰∫éÂèòÊç¢Ôºâ ÂÇÖÁ´ãÂè∂ÂèòÊç¢ ÁâπÁÇπÔºöÊòØÊ≠£‰∫§Âü∫„ÄÇÊ≠£‰∫§Âü∫Êñπ‰æøÊ±ÇÂá∫Âü∫ÁöÑÁ≥ªÊï∞„ÄÇ Â±ÄÈôêÊÄß ÊúÄÊìÖÈïøÁöÑÊòØÊää‰∏ÄÁª¥ÁöÑÔºåÁ±ª‰∏âËßíÊ≥¢ËøûÁª≠ÂèòÈáèÂáΩÊï∞‰ø°Âè∑Êò†Â∞ÑÂà∞‰∏ÄÁª¥Á≥ªÊï∞Â∫èÂàó‰∏äÔºå‰ΩÜÂØπ‰∫éÁ™ÅÂèò‰ø°Âè∑Êàñ‰ªª‰ΩïÈ´òÁª¥ÁöÑÈùû‰∏âËßíÊ≥¢‰ø°Âè∑ÂàôÂá†‰πéÊó†ËÉΩ‰∏∫Âäõ„ÄÇ Â¶ÇÔºö Â∞èÊ≥¢ÂèòÊç¢ ÂèÇËÄÉ Â∞èÊ≥¢ÂèòÊç¢ÂÆåÁæéÈÄö‰øóËÆ≤Ëß£Á≥ªÂàó‰πã Ôºà‰∏ÄÔºâ Â∞èÊ≥¢ÂèòÊç¢ÂÆåÁæéÈÄö‰øóËÆ≤Ëß£Á≥ªÂàó‰πã Ôºà‰∫åÔºâ Ê≥¢ÁöÑÂÆö‰πâ Ê≥¢ÔºöÂú®Êó∂Èó¥ÂüüÊàñËÄÖÁ©∫Èó¥ÂüüÁöÑÈúáËç°ÊñπÁ®ã Â∞èÊ≥¢ÔºöÈõÜ‰∏≠Âú®Êó∂ÂüüÊüê‰∏ÄÁÇπÁöÑÊ≥¢Ôºõ‰ºòÁÇπÔºåËÉΩÂ§üÂàÜÊûêÁû¨Êó∂Êó∂Âèò‰ø°Âè∑ÔºõÂÆûÁé∞ÔºåÈÄöËøáÂØπÂ∞èÊ≥¢ÁöÑ‰º∏Áº©Âπ≥ÁßªÂØπÂáΩÊï∞‰ø°Âè∑ËøõË°åÂ§öÂ∞∫Â∫¶ÁªÜÂàÜ„ÄÇ Â∞èÊ≥¢ÁöÑÁâπÁÇπ ‰∏§‰∏§Ê≠£‰∫§ÔºåÂΩí‰∏ÄÂåñ„ÄÇ Â∞èÊ≥¢Á∫ßÊï∞ÁöÑÂ±ïÂºÄÂêåÊó∂Âú®Êó∂ÂüüÂíåÈ¢ëÁéá‰∏äËøõË°åÔºå‰πüÂ∞±ÊòØÂØπÂ∫î‰º∏Áº©(È¢ëÂüü)ÂíåÂπ≥Áßª(Ë¶ÜÁõñÊó∂Âüü)ÔºåÂÇÖÁ´ãÂè∂ÂèòÊç¢Âè™Âú®È¢ëÂüü„ÄÇ Â∞èÊ≥¢ÁöÑÊûÑÊàêÔºöÁà∂Â∞èÊ≥¢ÂíåÊØçÂ∞èÊ≥¢ÁöÑÂπ≥Áßª‰º∏Áº©Ôºõscaling function+wavelet function(mother) mother waveletÔºöÊØçÂ∞èÊ≥¢ father waveletÔºöscaling function/Áà∂Â∞èÊ≥¢/Â∞∫Â∫¶ÂáΩÊï∞ ÂØπ‰ªªÊÑèV_jÁöÑfunctionÂèØ‰ª•ÂàÜËß£‰∏∫Ôºö Ôºà1Ôºâscaling fucntionÁöÑÂΩ¢ÂºèÔºö \begin{array}{c}{\varphi_{j, k}} \end{array}Ôºà2ÔºâÁ¨¨‰∫åÁßçÂ∞±ÊòØÂÆÉ‰∏ä‰∏Ä‰∏™Â≠êÁ©∫Èó¥ÁöÑbasis‰ª•Âèä‰∏ä‰∏ÄÁ∫ßÂ≠êÁ©∫Èó¥ÁöÑwavelet function \begin{array}{c}{\varphi_{j-1, k}} \\ {\psi_{j-1, k}}\end{array}Ôºà3Ôºâ‰∏ÄÁõ¥Âà©Áî®‰∏ä‰∏ä..Á∫ßÁöÑscaling functionÔºåÂàôÂæóÂà∞Â∞èÊ≥¢Â±ïÂºÄÂΩ¢ÂºèÔºö f(t)=\sum_{k=-\infty}^{\infty} c_{k} \varphi(t-k)+\sum_{k=-\infty}^{\infty} \sum_{j=0}^{\infty} d_{j, k} \psi\left(2^{j} t-k\right)ÂÖ∂‰∏≠Ôºå$\varphi(t)$ÊòØÁà∂Â∞èÊ≥¢Ôºå$\psi_{j, k}(t)$ÊòØÊØçÂ∞èÊ≥¢„ÄÇscaling function‰∏çÊòØÂá≠Á©∫ÊèíËøõÂéªÁöÑÔºåËÄåÊòØÈÄöËøá‰∏çÊñ≠ÁöÑÂµåÂ•óËø≠‰ª£Âá∫Êù•ÁöÑ ‰∏∫‰ªÄ‰πà‰ΩøÁî®Á¨¨3ÁßçÊñπÂºèÔºàÂ∞èÊ≥¢ÂèòÊç¢ÔºâÊù•Ë°®Ëææ‰ø°Âè∑ ËÆ°ÁÆó ÈÇ£‰∏∫‰ªÄ‰πàÊàë‰ª¨ÊúÄÂêéÈÄâÂÆöÁöÑÊòØËøôÁßçÈÄâÂèñÊñπÂºèÂë¢?ÂÆûÈôÖ‰∏äÔºåÂàöÊâç‰ªãÁªçÁöÑËøô‰∏™ÊÄßË¥®Â∑≤ÁªèÂëäËØâÊàë‰ª¨ÔºåÂØπ‰∫é‰ªª‰ΩïÁöÑscale j0ÔºåÊàë‰ª¨ÈÉΩÂèØ‰ª•ÁªôÊàë‰ª¨ÁöÑsignal spaceÊâæÂà∞‰∏ÄÁªÑorthonormal basisÔºåËøô‰∏™basisÊòØÈÄöËøáÁªÑÂêàscale j0‰∏äÁöÑscaling function‰ª•ÂèäÊâÄÊúâÂú®scale jÔºåj&gt;j0‰∏äÁöÑwaveletsÂæóÂà∞ÁöÑ„ÄÇËøôÊ†∑ÔºåÂü∫‰∫éËøô‰∏™orthonormal basisÔºåÊâÄÊúâ‰ø°Âè∑Á©∫Èó¥‰∏≠ÁöÑ‰ø°Âè∑ÈÉΩÂèØ‰ª•ÂÜôÊàêÁªÑÊàêËøô‰∏™basisÁöÑfunctionsÁöÑÁ∫øÊÄßÁªÑÂêàÔºö \begin{array}{l}{c_{j_{0}, k}=\left\langle s(n), \varphi_{j_{0}, k}(n)\right\rangle} \\ { d_{j, k}=\left\langle s(n), \psi_{j, k}(n)\right\rangle}\end{array} ‰∏§ÁßçÂáΩÊï∞Áõ∏ÂΩì‰∫éÈ´òÈÄöÊª§Ê≥¢Âíå‰ΩéÈÄöÊª§Ê≥¢ÁöÑ‰ΩúÁî® wavelet functionÂíåscaling functionËÉåÂêéÁöÑÁâ©ÁêÜÊÑè‰πâ‰∫ÜÔºöwavelet functionÁ≠âÂêå‰∫éÂØπ‰ø°Âè∑ÂÅöÈ´òÈÄöÊª§Ê≥¢‰øùÁïôÂèòÂåñÁªÜËäÇÔºåËÄåscaling functionÁ≠âÂêå‰∫éÂØπ‰ø°Âè∑ÂÅö‰ΩéÈÄöÊª§Ê≥¢‰øùÁïôÂπ≥ÊªëÁöÑshape! scaling function Âíå MRAÁöÑÂÖ≥Á≥ª(scaling functionÂú®Â∞èÊ≥¢ÂèòÊç¢‰∏≠ÁöÑ‰ΩúÁî®ÂíåÊÑè‰πâÔºâ Âú®‰∏çÂêåÁöÑÂ≠êÁ©∫Èó¥ÔºåÂØπ‰∫éÂêå‰∏Ä‰∏™‰ø°Âè∑Â∞±Êúâ‰∏çÂêåÁöÑËØ†Èáä„ÄÇËØ†ÈáäÊúÄÂ•ΩÁöÑÂΩìÁÑ∂ÊòØV3ÔºåÂÆåÂÖ®‰∏çÊçüÂ§±ÁªÜËäÇ„ÄÇËøôÂ∞±ÊòØÂ§öËß£ÊûêÂ∫¶ÁöÑÊÑè‰πâ„ÄÇÊàë‰ª¨ÂèØ‰ª•ÊúâÂµåÂ•óÁöÑÔºåÁî±scaling functionÊºîÂèòÁöÑbasis functionÈõÜÂêàÔºåÊØè‰∏Ä‰∏™ÈõÜÂêàÈÉΩÊèê‰æõÂØπÂéüÂßã‰ø°Âè∑ÁöÑÊüêÁßçËøë‰ººÔºåËß£ÊûêÂ∫¶Ë∂äÈ´òÔºåËøë‰ººË∂äÁ≤æÁ°Æ„ÄÇ Áâ©ÁêÜÊÑè‰πâÔºöÂÅö‰ΩéÈÄöÊª§Ê≥¢ Â∞èÊ≥¢ÂèòÊç¢ÁöÑËÆ°ÁÆóÂ§çÊùÇÂ∫¶(ËøòÊ≤°ÁêÜËß£) ‰ªé‰ø°Âè∑ÁÆóÂá∫Â±ïÂºÄÁ≥ªÊï∞aÈúÄË¶ÅÂæàÊñπ‰æø„ÄÇÊôÆÈÅçÊÉÖÂÜµ‰∏ãÔºåÂ∞èÊ≥¢ÂèòÊç¢ÁöÑÂ§çÊùÇÂ∫¶ÊòØO(Nlog(N))ÔºåÂíåFFTÁõ∏ÂΩì„ÄÇÊúâ‰∏çÂ∞ëÂæàÂø´ÁöÑÂèòÊç¢ÁîöËá≥ÂèØ‰ª•ËææÂà∞O(N)Ôºå‰πüÂ∞±ÊòØËØ¥ÔºåËÆ°ÁÆóÂ§çÊùÇÂ∫¶Âíå‰ø°Âè∑ÈïøÂ∫¶ÊòØÁ∫øÊÄßÁöÑÂÖ≥Á≥ª„ÄÇÂ∞èÊ≥¢ÂèòÊç¢ÁöÑÁ≠âÂºèÂÆö‰πâÔºåÂèØ‰ª•Ê≤°ÊúâÁßØÂàÜÔºåÊ≤°ÊúâÂæÆÂàÜÔºå‰ªÖ‰ªÖÊòØ‰πòÊ≥ïÂíåÂä†Ê≥ïÂç≥ÂèØ‰ª•ÂÅöÂà∞ÔºåÂíåÁé∞‰ª£ËÆ°ÁÆóÊú∫ÁöÑËÆ°ÁÆóÊåá‰ª§ÂÆåÂÖ®match„ÄÇ ÂìàÂ∞îÂ∞èÊ≥¢ÊòØÂ∞èÊ≥¢ÂèòÊç¢ÁöÑ‰∏ÄÁßç„ÄÇ‰ª•ÂìàÂ∞îÂ∞èÊ≥¢‰∏∫‰æã Â¶ÇÔºö[9 7 3 5 ]-&gt;[8 4 1 -1]-&gt;[6 2 1 -1] Â∞èÊ≥¢ÂèòÊç¢ÁöÑÂü∫Êú¨ÊµÅÁ®ã ÈÄâÂèñÂêàÈÄÇÁöÑwavelet functionÂíåscaling functionÔºå‰ªéÂ∑≤ÊúâÁöÑ‰ø°Âè∑‰∏≠ÔºåÂèçÁÆóÂá∫Á≥ªÊï∞cÂíåd„ÄÇ ÂØπÁ≥ªÊï∞ÂÅöÂØπÂ∫îÂ§ÑÁêÜ ‰ªéÂ§ÑÁêÜÂêéÁöÑÁ≥ªÊï∞‰∏≠ÈáçÊñ∞ÊûÑÂª∫‰ø°Âè∑„ÄÇ Â∞èÊ≥¢ÂèòÊç¢ÁöÑÂ∫îÁî®ÔºöÁ≥ªÊï∞Â§ÑÁêÜ Â∫îÁî®ÊúâÂéãÁº©„ÄÅÂéªÂô™„ÄÅÊ∞¥Âç∞„ÄÅÂõæÂÉèËûçÂêàÁ≠âÁ≠â ‰æãÂ¶ÇÔºöÊØîÂ¶ÇÂõæÂÉèÊàñËÄÖËßÜÈ¢ëÂéãÁº©ÔºåÂ∞±Â∏åÊúõÈÄâÂèñËÉΩÂ∞ÜËÉΩÈáèËÅöÈõÜÂà∞ÂæàÂ∞è‰∏ÄÈÉ®ÂàÜÁ≥ªÊï∞‰∏≠ÁöÑÂ∞èÊ≥¢ÔºåÁÑ∂ÂêéÊäõÂºÉÈÇ£‰∫õËÉΩÈáèÂæàÂ∞èÁöÑÂ∞èÊ≥¢Á≥ªÊï∞ÔºåÂè™‰øùÁïôÂ∞ëÊï∞ÁöÑËøô‰∫õÂ§ßÂ§¥Á≥ªÊï∞ÔºåÂÜçÂèçÂèòÊç¢ÂõûÂéª„ÄÇËøôÊ†∑ÁöÑËØùÔºåÂõæÂÉè‰ø°Âè∑ÁöÑËÉΩÈáèÂπ∂Ê≤°ÊúâÊÄé‰πà‰∏¢Â§±ÔºåÂõæÂÉè‰ΩìÁßØÂç¥Â§ßÂ§ßÂáèÂ∞è‰∫Ü„ÄÇ Â∞èÊ≥¢ÂéªÂô™ÁöÑÂéüÁêÜ Â∞èÊ≥¢ÂàÜËß£Ê†ë(‰ª•HaarÂ∞èÊ≥¢‰∏∫‰æã) Áî±È´òÈ¢ëÂíå‰ΩéÈ¢ëÁªÑÊàê MatlabÁöÑÂÆûÁé∞ÔºàÊú™ÂÆåÊàêÔºåÂèÇËÄÉ„ÄäÂõæÂÉèÂ§ÑÁêÜ‰∏≠ÁöÑÊï∞Â≠¶„ÄãÔºâ wavedec2 Â∞èÊ≥¢ÂüüÂéªÂô™ÁªºËø∞ ÈóÆÈ¢òÔºöÊòØÂê¶ÊâÄÊúâÂ∞èÊ≥¢Âüü‰∏ãÁöÑÂéªÂô™ÊñπÊ≥ïÈÉΩÂà©Áî®‰∫ÜÁ®ÄÁñèÊÄßÔºåÊâÄÊúâÂ∞èÊ≥¢ËΩ¨ÂåñÈÉΩÊòØ‰∏∫‰∫ÜÂæóÂà∞Á®ÄÁñèÊÄßÔºü Â∞èÊ≥¢ÂüüÁöÑÂõæÂÉèÈôçÂô™ Âü∫‰∫éfilter,ÔºàÂà©Áî®sparsityÔºâ H. Zhang, Aria Nosratinia, and R. O. Wells, Jr., ‚ÄúImage denoising via wavelet-domain spatially adaptive FIR Wiener filtering‚Äù, in IEEE Proc. Int. Conf. Acoust., Speech, Signal Processing, Istanbul, Turkey, June 2000. Âà©Áî®Â∞èÊ≥¢Â•áÂºÇÊ£ÄÊµãÁâπÊÄßÂ∞Ü‰ø°Âè∑‰∏éÂô™Â£∞ÂàÜÂºÄ„ÄÇMallat, 1992„ÄÇËÆ°ÁÆóÈáèÂ§ßÔºåÊî∂ÊïõÁºìÊÖ¢Ôºå‰∫ßÁîüÊåØËç°Âíå‰∏çÁ®≥ÂÆö Mallat, S., &amp; Hwang, W. L. (1992). Singularity detection and processing with wavelets. IEEE transactions on information theory, 38(2), 617-643. Âà©Áî®Â∞èÊ≥¢Á≥ªÊï∞ÈòàÂÄºÊî∂Áº©Ê≥ïÊù•ÂàÜÂºÄ‰ø°Âè∑ÂíåÂô™Â£∞„ÄÇDonohoÔºå1992„ÄÇGibbs phenomena in the neighborhood of discontinuities ‚Äì Âç≥‰∏çËøûÁª≠ÁÇπÂë®Âõ¥ÁöÑ‰ø°Âè∑ËÉΩÈáè‰ºöÂú®‰∏ÄÂÆöÂ∞∫Â∫¶ÁöÑËåÉÂõ¥‰∏äÊù•ÂõûÊ≥¢Âä®-to the lack of translation invariance of the wavelet basis„ÄÇ (ÈÉΩ‰∏çÊòØMRA-based tight frameÔºåÈÇ£‰πàÊòØMRA-based tight frame‰ªÄ‰πàÂèàÊòØÂÖ∂‰ªñtight frame) ÊîπËøõGibbsÔºöR.R. Coifman and D.L. DonohoÊèêÂá∫‰∫ÜÂπ≥Áßª‰∏çÂèòÈáèÁÆóÊ≥ïÂèØÊúâÊïàÂú∞ÈÅøÂÖçËøôÁßçÁé∞Ë±°ÁöÑÂèëÁîü È¶ñÂÖàËÆ©Âê´ÊúâÂô™Â£∞ÁöÑÂéüÂßã‰ø°Âè∑ËøõË°åÂ§öÊ¨°Âæ™ÁéØÂπ≥ÁßªÔºàÊØîÂ¶ÇËøõË°å n Ê¨°Ôºâ,ÂÖ∂Ê¨°ËøêÁî®ÈòàÂÄºÁÆóÊ≥ïÂØπÂπ≥ÁßªÂêéÁöÑ‰ø°Âè∑ËøõË°åÂéªÂô™Â§ÑÁêÜ,ÁÑ∂ÂêéÂÜçÂπ≥ÂùáÂéªÂô™ÁöÑ‰ø°Âè∑,Ê≠§Áß∞‰∏∫‚ÄúÂπ≥Áßª-ÂéªÂô™-Âπ≥Âùá‚ÄùÁöÑÂπ≥Áßª‰∏çÂèòÈáèÁÆóÊ≥ïÁöÑÂéüÁêÜ„ÄÇ \overline{T}\left(x,\left(S_{h}\right)_{h \in H_{n}}\right)=A v e_{h \in H_{k}} S_{-h}\left(T\left(S_{h}(x)\right)\right)[57] R.R. Coifman and D.L. Donoho, Translation-invariant de-noising, Lecture Notes in Statistics-New York-Springer Verlag (1995), 125‚Äì125. Ë¥ùÂè∂ÊñØÊñπÊ≥ïÂéªÂô™(Âà©Áî®sparsity‰∫ÜÊ≤°ÊúâÔºü)ÔºåÈúÄË¶ÅÂà©Áî®ÂÖàÈ™åËØÅÊ®°Âûã ÂÖàÈ™åÊ®°ÂûãÊòØÂ∞èÊ≥¢Á≥ªÊï∞ÂÖàÈ™åÊ®°ÂûãÔºöÂà©Áî®ËÅîÂêàÂàÜÂ∏ÉÔºåGGD ÂÖàÈ™åÊ®°ÂûãÊòØÂ∞èÊ≥¢Á≥ªÊï∞ÁöÑÁ©∫Èó¥Â±ÄÈÉ®‰ΩúÁî®ÂÖ≥Á≥ªÔºàÈ©¨Â∞îÂèØÂ§´Ê®°ÂûãÔºâÔºöHMM ÔºàÂü∫‰∫éÊ°ÜÊû∂ÁöÑwavelet frameÂú®ÂõæÂÉèËøòÂéü‰∏≠ÊúâÂæàÂ§ßÁöÑÂ∫îÁî®ÔºåË∞ÅÊúÄÂÖàÂÖàÊèêÂá∫ÁöÑÔºâ: wavelet frame. ÔºàËøòÊúâ‰∏ÄÁßçËØ¥Ê≥ïÔºâÂºïËá™Âü∫‰∫éÁ®ÄÁñèË°®Á§∫ÁöÑÂ∞èÊ≥¢ÂéªÂô™_Êú±Êù∞.pdf Âü∫‰∫éÂ§öÂ∞∫Â∫¶ÂàÜÊûêÁöÑÁ¥ßÊ°ÜÊû∂ÁªìÊûÑ (MRA-based tight frame method): The community‚Äôs effort to develop redundant wavelet systems that have sparse approximations for various classes of functions has led to the development of the MRA-based wavelet frames.Ôºàthose tight wavelet frames generated via a multiresolution analysisÔºâÔºàËØ¶ËßÅÂü∫‰∫éÂ∞èÊ≥¢Ê°ÜÊû∂ÁöÑÂèòÂàÜÊ®°ÂûãÔºâ tight wavelet frame: ÊòØ‰∏ÄÁßçÂèòÂàÜÊ≥ïÔºåÂõ†‰∏∫u = Wt (Wu). uÂú®W‰∏ã‰∏çÂîØ‰∏Ä„ÄÇÊâÄ‰ª•Êúâ‰∏âÁßçÊñπÊ≥ïÊù•Ëé∑ÂèñÁõÆÊ†áÂõæÂÉèÁöÑÁ®ÄÁñèËøë‰ººÂÄº„ÄÇ Therefore, there are three formulations for the sparse approximation of the underlying images; namely, the analysis based approach, the synthesis based approach and the balanced approach. Analysis basedÔºöThe analysis based approach was Ô¨Årst proposed in [84, 170]. \min _{u \in \mathbb{R}^{n}} \frac{1}{2}\|A u-f\|_{D}^{2}+\|\mbox{diag}(\lambda) W u\|_{1}[170] J.L. Starck, M. Elad, and D.L. Donoho, Image decomposition via the combination of sparse representations and a variational approach, IEEE transactions on image processing 14 (2005), no. 10, 1570‚Äì1582. [84] M. Elad, J.L. Starck, P. Querre, and D.L. Donoho, Simultaneous cartoon and texture image inpainting using morphological component analysis (MCA), Applied and Computational Harmonic Analysis 19 (2005), no. 3, 340‚Äì358. synthesis based: The synthesis based approach was first introduced in [66, 86, 87, 90, 91]. \min _{\alpha \in \mathbb{R}^{m}} \frac{1}{2}\left\|A W^{\top} \alpha-f\right\|_{D}^{2}+\|\mbox{diag}(\lambda) \alpha\|_{1}[90]M.A.T. Figueiredo and R.D. Nowak, An EM algorithm for wavelet-based image restoration, IEEE Transactions on Image Processing 12 (2003), no. 8, 906‚Äì916. [91]A bound optimization approach to wavelet-based image deconvolution, Image Processing, 2005. ICIP 2005. IEEE International Conference on, vol. 2, IEEE, 2005, pp. II‚Äì782. [86] M.J. Fadili and J.L. Starck, Sparse representations and bayesian image inpainting, Proc. SPARS 5 (2005). [66] I. Daubechies, G. Teschke, and L. Vese, Iteratively solving linear inverse problems under general convex constraints, Inverse Problems and Imaging 1 (2007), no. 1, 29. [87]MJ Fadili, J.L. Starck, and F. Murtagh, Inpainting and zooming using sparse representations, The Computer Journal 52 (2009), no. 1, 64. balanced methodÔºöThe balanced approach was Ô¨Årst used in [34, 36] for high resolution image reconstruction. \min _{\alpha \in \mathbb{R}^{m}} \frac{1}{2}\left\|A W^{\top} \alpha-f\right\|_{D}^{2}+\frac{\kappa}{2}\left\|\left(I-W W^{\top}\right) \alpha\right\|_{2}^{2}+\|\mbox{diag}(\lambda) \alpha\|_{1}Ê±ÇËß£ÁÆóÊ≥ïÔºöthe proximal forward and backward splitting algorithm [34]R.H. Chan, T.F. Chan, L. Shen, and Z. Shen, Wavelet algorithms for high-resolution image reconstruction, SIAM Journal on ScientiÔ¨Åc Computing 24 (2003), no. 4, 1408‚Äì1432. [36]Tight frame: an eÔ¨Écient way for high-resolution image reconstruction, Applied and Computational Harmonic Analysis 17 (2004), no. 1, 91‚Äì115. Â∞èÊ≥¢ÂüüÂéªÂô™ÁªºËø∞ Â∞èÊ≥¢ÂüüÂéªÂô™ÊòØÂà©Áî®‰ø°Âè∑Á®ÄÁñèË°®ËææÁöÑ‰∏Ä‰∏™‰ª£Ë°®ÊÄßÁöÑÊñπÊ≥ï„ÄÇÊ≠§Á±ªÊñπÊ≥ï‰∏ªË¶ÅÂ∞±ÊòØÂØπÂõæÂÉèËΩ¨ÂåñÂà∞Â∞èÊ≥¢ÂüüÂêéÁöÑÁ≥ªÊï∞ËøõË°åÂ§ÑÁêÜÔºåÂÜçÂ∞ÜÂ§ÑÁêÜÂêéÁöÑÂ∞èÁ≥ªÊï∞ËøòÂéüÂà∞Á©∫Èó¥ÂüüÔºå‰ªéËÄåÂæóÂà∞Â§çÂéüÂêéÁöÑÂõæÂÉè„ÄÇÂ∞èÊ≥¢ÂüüÁöÑÂéªÂô™ÊñπÊ≥ïÂ§ßËá¥ÂèØ‰ª•ÂàÜ‰∏∫‰∏âÁ±ªÔºöÂ•áÂºÇÂÄºÊ£ÄÊµã„ÄÅÈòàÂÄºÊî∂Áº©‰ª•ÂèäÂü∫‰∫éË¥ùÂè∂ÊñØÁöÑÊ®°Âûã„ÄÇÂÖ∂‰∏≠Â∞èÊ≥¢ÈòàÂÄºÂéªÂô™Áî±DoÂú®Âú®1992ÊèêÂá∫Êù•Ôºå ÊòØÊúÄË¢´Âπø‰∏∫Â≠¶‰π†ÁöÑ‰∏ÄÁßçÊñπÊ≥ï„ÄÇÂÆÉÁöÑÂ∑•‰ΩúÂéüÁêÜÊòØÊ†πÊçÆÂô™Â£∞ÂíåËá™ÁÑ∂ÂõæÂÉèÂú®È¢ëÁéáÊÆµ‰∏çÂêåÁöÑË°®Áé∞ÂΩ¢Âºè(Âô™Â£∞ÂëàÁé∞Âá∫È´òÈ¢ëÂ∞èÂπÖÂÄº)ÔºåÈÄöËøáËÆæÂÆöÈòàÂÄºÂ∞ÜÂô™Â£∞‰ªéÂô™Â£∞ÂõæÂÉè‰∏≠Âå∫ÂàÜÂá∫Êù•ÔºåÂπ∂Â∞ÜÂô™Â£∞Á≥ªÊï∞ËøòÂéü‰∏∫0Ôºå‰ªéËÄåÊ∂àÈô§Âô™Â£∞„ÄÇÂ§ßÈáèËÆ∫ÊñáÈíàÂØπÈòàÂÄºÁöÑÈÄâÊã©ËøõË°å‰∫ÜÁ†îÁ©∂„ÄÇÁÑ∂ËÄåÔºåÈÄöËøáÈòàÂÄºÊî∂Áº©ÁöÑÊñπÊ≥ïÔºåÂú®ÂéªÂô™ÁöÑÂêåÊó∂ÂÆπÊòìÊäπÂéª‰∏Ä‰∫õÂõæÂÉèÁöÑÈ´òÈ¢ë‰ø°ÊÅØÔºåÂõ†Ê≠§Âú®ÂõæÂÉè‰∏çËøûÁª≠ÁöÑÂå∫ÂüüÂÆπÊòì‰∫ßÁîüÊåØÈìÉ(Gibbs)ÁöÑÁº∫Èô∑„ÄÇR.R. Coifman and D.L. DonohoÊèêÂá∫‰∏ÄÁßçÂπ≥Áßª‰∏çÂèòÈáèÁÆóÊ≥ïÔºåÂèØÊúâÊïàÂáèÂ∞ëÊ≠§Á±ªÁº∫Èô∑„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÈöèÁùÄÊ°ÜÊû∂ÁêÜËÆ∫ÁöÑÂèëÂ±ïÔºåÂ∞èÊ≥¢Á¥ßÊ°ÜÊû∂Á≥ªÁªüË¢´ËØÅÊòé‰∫ÜÊòØ‰∏ÄÁßçÊúâÊïàÁöÑÁ®ÄÁñèÈÄºËøëÂàÜÊÆµÂÖâÊªëÂõæÂÉèÁöÑÁ≥ªÁªü„ÄÇÂõ†Ê≠§ÔºåÂ∞èÊ≥¢Á¥ßÊ°ÜÊû∂ÂèòÊç¢Âú®ÂõæÂÉèÊÅ¢Â§çÈóÆÈ¢ò‰∏≠Â∫îÁî®ÂçÅÂàÜÂπøÊ≥õ [] „ÄÇ( Âü∫‰∫éÂ§öÂ∞∫Â∫¶ÂàÜÊûêÁöÑÂ∞èÊ≥¢Á¥ßÊ°ÜÊû∂ÂºÄÂßãË¢´ÊàêÂäüÂú∞Áî®‰∫éËß£ÂÜ≥ÂõæÂÉèÂ§çÂéüÈóÆÈ¢ò„ÄÇÂü∫‰∫éÂ∞èÊ≥¢Ê°ÜÊû∂ÁöÑÂèòÂàÜÊ®°Âûã[14-19]Ë¢´ÊàêÂäüÂ∫îÁî®‰∫éÂõæÂÉèÂéªÂô™‰∏≠ÔºåÂÖ∂‰∏≠Á®ÄÁñèÊÄßÁöÑÁâπÁÇπ‰Ωú‰∏∫Á∫¶ÊùüÈ°π„ÄÇ)ÁÑ∂ËÄåÔºåÈúÄË¶ÅÂ§ÑÁêÜÁöÑÂõæÂÉèÊòØÂ§öÁßçÂ§öÊ†∑ÁöÑÔºåÂπ∂Ê≤°Êúâ‰∏Ä‰∏™ÈùôÊÄÅÁöÑÂ∞èÊ≥¢Á¥ßÂ∏ßÁ≥ªÁªüËÉΩÂ§üÂæàÂ•ΩÂú∞Â§ÑÁêÜÊÅ¢Â§çÂÆÉ‰ª¨„ÄÇÂõ†Ê≠§CaiÂú®[1]‰∏≠ÊèêÂá∫‰∫Ü‰∏ÄÁßçÁî±ÂõæÁâáÊï∞ÊçÆÈ©±Âä®ÁöÑËÆæËÆ°tight frame waveletÁöÑÊñπÊ≥ïÔºåÊù•Ëß£ÂÜ≥‰∏ÄÁ±ªtight frameÂè™ËÉΩËß£ÂÜ≥‰∏ÄÁ±ªÂõæÁâáÁöÑÈóÆÈ¢ò„ÄÇ [1] Cai, J. F., Ji, H., Shen, Z., &amp; Ye, G. B. (2014). Data-driven tight frame construction and image denoising. one of the most studied coefficients with small magnitude can be considered as pure noise and should be set to zero. redundant wavelet systems that have sparse approximations for various classes of functions has led to the development of the MRA-based wavelet frames A number of papers were proposed to select the threshold.a number of methods differs in the selection of the threshold parameter. As for the coeÔ¨Écients with small magnitude can be considered as pure noise and should be set to zero The sparsity is later incorporated in the variational method. The most investigated domain in denoising using Wavelet Transform is the non-linear coefficient thresholding based methods. Most of the wavelet shrinkage literature is based on methods for choosing the optimal threshold which can be adaptive or non-adaptive to the image. generates spurious blips, better known as artifacts wavelet thresholdingÊòØÁî±DonohoÈ¶ñÂÖàÂú®1992ÊèêÂá∫Êù•ÁöÑÔºåÂú®Ëøô‰πãÂâçÂú®wavelet domainÁöÑÂéªÂô™‰πüÊòØÊúâÁöÑ„ÄÇÂ¶ÇH. Zhang, Aria Nosratinia, and R. O. Wells, Jr., ‚ÄúImage denoising via wavelet-domain spatially adaptive FIR Wiener filtering‚Äù, in IEEE Proc. Int. Conf. Acoust., Speech, Signal Processing, Istanbul, Turkey, June 2000. Wavelet-based denoising aims to decompose the signal into the by high-frequency filter and low-frequency filter. {As for the coeÔ¨Écients with small magnitude can be considered as pure noise and should be set to zero.} As for the detail coeÔ¨Écients of the noise presented as high frequency with small magnitude while a clean image tend to be many zeros. Thus stronger sparse expression: wavelet tight frame (limitation: not adaptive, a class of ) Â∞èÊ≥¢ÈòàÂÄºÂéªÂô™ ÈóÆÈ¢ò Â∞èÊ≥¢ÈòàÂÄºÂéªÂô™ÔºåÈÄâÊã©ÁöÑÊòØÂì™ÁßçÂ∞èÊ≥¢ÂèòÊç¢ÔºåÂ±û‰∫étight frameÂêóÔºåÈÇ£‰πàÂ±û‰∫éMRA-based tight frameÂêó„ÄÇ ÂéüÁêÜ The coefficients of the wavelet transform are usually sparse. That is, most of the coefficients in a noiseless wavelet transform are effectively zero. Therefore, we may reformulate the problem of recovering f as one of recovering the coefficients of f which are relatively ‚Äùstronger‚Äù than the Gaussian white noise background. That is, coefficients with small magnitude can be considered as pure noise and should be set to zero. The approach in which each coefficient is compared with a threshold in order to decide whether it constitute a desirable part of the original signal or not, is called waveletthresholding. ËøáÁ®ã transform-based thresholding working in three steps: Transform the noisy data into an orthogonal domain. Apply soft or hard thresholding to the resulting coefficients, thereby suppressingthose coefficients smaller than a certain amplitude. Transform back into the original domain. ‰∏§ÁßçÂàÜÁ±ªÊñπÊ≥ï ÂÖ®Â±ÄÈòàÂÄºÂíåËá™ÈÄÇÂ∫îÈòàÂÄº ËΩØÈòàÂÄºÂíåÁ°¨ÈòàÂÄº soft-thresholdingÂá†‰πéÁî®‰∫éÊâÄÊúâÁöÑÁÆóÊ≥ï„ÄÇHard-thresholding‰ºö‰∫ßÁîü‰∏ÄÁßçspurious blipsÁöÑÁº∫Èô∑Ôºåas a result of unsuccessful attempts of removing moderately large noise coefficients„ÄÇ ÈòàÂÄºÁöÑÈÄâÊã©ÂΩ±ÂìçÂæàÂ§ß Large threshold lead to the details lost. Small threshold lead to the noise unclean. Reviews of literatureÔºö(1990s) Wavelet thresholding and wavelet shrinkageÔºöVisuShrinkÔºåSureShrinkÔºåBayesShrink, NeighBlock [VisuShrink 1994] David L. Donoho and Jain M. Johnstone. Ideal spatial adaptation by wavelet shrinkage. Biometrika, 81(3):425‚Äì455, 1994. 3 ÂÖ®Â±ÄÈòàÂÄº [SureShrink 1995] David L. Donoho and Iain M. Johnstone. Adapting to unknown smoothness via wavelet shrinkage. Journal of the American Statistical Association, pages 1200‚Äì1224, 1995. Á¨¨‰∏Ä‰∏™adaptive [BayesShrink 2000] Martin Vetterli S Grace Chang, Bin Yu. Adaptive wavelet thresholding for image denoising and compression. IEEE Transactions on Image Processing, 9(9):1532‚Äì1546, Sep 2000 [NeighBlock 2001] T.T. Cai and B.W. Silverman. Incorporating information on neighbouring coefficients into wavelet estimation. Sankhya, Series A, 63, 2001 Â∞èÊ≥¢ÂèòÂàÜÊ®°ÂûãÂü∫‰∫éÂ∞èÊ≥¢Ê°ÜÊû∂ÁöÑÂèòÂàÜÊ®°Âûã[14-19]Ë¢´ÊàêÂäüÂ∫îÁî®‰∫éÂõæÂÉèÂéªÂô™‰∏≠„ÄÇ Á†îÁ©∂Ë°®ÊòéÔºåÂü∫‰∫éÂ∞èÊ≥¢Ê°ÜÊû∂ÁöÑÂèòÂàÜÊ®°ÂûãÊØîÂÖ∂‰ªñÂèòÂàÜÊ®°Âûã ‰æãÂ¶Ç ROF Ê®°ÂûãÊõ¥Â•ΩÔºåËøôÊòØÂõ†‰∏∫Â∞èÊ≥¢Ê°ÜÊû∂ÁöÑÂ§öÂàÜËæ®ÁéáÁªìÊûÑÂíåÂÜó‰Ωô„ÄÇ Chan, R. H., Chan, T. F., Shen, L., &amp; Shen, Z. (2003). Wavelet algorithms for high-resolution image reconstruction. SIAM Journal on Scientific Computing, 24(4), 1408-1432. Cai, J. F., Osher, S., &amp; Shen, Z. (2009). Split Bregman methods and frame based image restoration. Multiscale modeling &amp; simulation, 8(2), 337-369. Dong, B., &amp; Shen, Z. (2010). MRA based wavelet frames and applications. IAS Lecture Notes Series, Summer Program on ‚ÄúThe Mathematics of Image Processing‚Äù, Park City Mathematics Institute, 19Ôºé Chan, R., Shen, L., &amp; Shen, Z. (2005). A framelet-based approach for image inpainting. Res. Rep, 4, 325. tight-frame Cai, J. F., Osher, S., &amp; Shen, Z. (2009). Linearized Bregman iterations for frame-based image deblurring. SIAM Journal on Imaging Sciences, 2(1), 226-252. J.-F. Cai, S. Osher, and Z. Shen, ‚ÄúSplit Bregman methods and frame based image restoration,‚Äù Multiscale Model. Simul., vol. 8, no. 2, pp. 337‚Äì369, Dec. 2010. Cai, J. F., Dong, B., Osher, S., &amp; Shen, Z. (2012). Image restoration: total variation, wavelet frames, and beyond. Journal of the American Mathematical Society, 25(4), 1033-1089. Cai, J. F., Ji, H., Shen, Z., &amp; Ye, G. B. (2014). Data-driven tight frame construction and image denoising. Applied and Computational Harmonic Analysis, 37(1), 89-105. ÊúÄËøëÂª∫Á´ã‰∫ÜÂ∞èÊ≥¢Ê°ÜÊû∂ÂíåÂèòÂàÜÊ®°Âûã‰πãÈó¥ÁöÑËÅîÁ≥ªÔºåÂπ∂ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊï∞ÊçÆÈ©±Âä®Á¥ßÊ°ÜÊû∂Ôºå ËØ•Ê°ÜÊû∂ÊØî‰ª•ÂæÄÁöÑÊ®°ÂûãÊõ¥ËÉΩÁ≤æÁ°ÆÂú∞ÈáçÊûÑÂõæÂÉè„ÄÇcode++ ÊèêÂá∫‰∫Ü‰∏ÄÁßç‰ªéÂõæÁâáÊú¨Ë∫´ËÆæËÆ°tight frame waveletÁöÑÊñπÊ≥ï„ÄÇÊù•Ëß£ÂÜ≥‰∏ÄÁ±ªtight frameÂè™ËÉΩËß£ÂÜ≥‰∏ÄÁ±ªÂõæÁâáÁöÑÈóÆÈ¢ò„ÄÇ ‰ª£Á†ÅÂÆûÁé∞ Â∞èÊ≥¢ÂéªÂô™ÁöÑÂü∫Êú¨ÂéüÁêÜ ÂΩ±ÂìçÂéªÂô™ÁöÑÂõ†Á¥† ÂüüÂÄºÁöÑÈÄâÊã©ÔºåÂ∞èÊ≥¢ÁöÑÈÄâÊã©ÔºåÂàÜËß£Â±ÇÊ¨°ÁöÑÈÄâÊã© [2014 Cai] „ÄäMRA-Based Wavelet Frames and Applications„Äã[cam11-22] on wavelet frame based image restoration [35, 36, 37, 38, 39, 40, 41, 42, 43, 21]. Split Bregman methods and frame based image restoration. Therefore, there are mainly three formulations utilizing the sparseness of the wavelet frame coeÔ¨Écients, namely analysis based approach, synthesis based approach, and balanced approach. Detailed and integrated descriptions of the three approaches can be found in [34]. [34] ‰∏ÄÊú¨‰π¶ B. Dong and Z. Shen, ‚ÄúMRA Based Wavelet Frames and Applications,‚Äù IAS Lecture Notes Series, Summer Program on ‚ÄúThe Mathematics of Image Processing‚Äù, Park City Mathematics Institute, 2010 The analysis based approach was Ô¨Årst proposed in [84, 170]. [84] M. Elad, J.L. Starck, P. Querre, and D.L. Donoho, Simultaneous cartoon and texture image inpainting using morphological component analysis (MCA), Applied and Computational Harmonic Analysis 19 (2005), no. 3, 340‚Äì358. [170] J.L. Starck, M. Elad, and D.L. Donoho, Image decomposition via the combination of sparse representations and a variational approach, IEEE transactions on image processing 14 (2005), no. 10, 1570‚Äì1582. ËÆ≤Ëø∞‰∫Ü‰∏ÄÁßçÁªìÂêàÂèòÂàÜÂíåËΩ¨Êç¢‰∏é ÂéªÂô™ÁªºËø∞ ÂèÇËÄÉÊñáÁåÆÔºö Survey of Image Denoising Techniques Â∞èÊ≥¢ÂüüÂõæÂÉèÈôçÂô™Ê¶ÇËø∞ B. Dong and Z. Shen, ‚ÄúMRA Based Wavelet Frames and Applications,‚Äù IAS Lecture Notes Series, Summer Program on ‚ÄúThe Mathematics of Image Processing‚Äù, Park City Mathematics Institute, 2010 Ê®°ÊûÅÂ§ßÔºåÂüüÂÄºÔºåÂπ≥Áßª‰∏çÂèò NLMÔºåBM3DÂéªÂô™ÂéüÁêÜ Áª¥Á∫≥Êª§Ê≥¢Âô®ÁöÑÊó∂ÂüüËß£ Áª¥Á∫≥Êª§Ê≥¢ÁöÑÈ¢ëÂüüËß£(Â∞öÊú™ÊâæÂà∞) ‰ΩéÈÄöÊª§Ê≥¢ Â∞èÊ≥¢ÂèòÊç¢ÂéªÂô™Âü∫Á°ÄÁü•ËØÜÊï¥ÁêÜ ÁªºËø∞ Ê†πÊçÆ‰∏çÂêåÂéªÂô™ÊñπÊ≥ïÁöÑÂÆûÁé∞ÂéüÁêÜÔºåÊàë‰ª¨Â∞ÜÂéªÂô™ÊñπÊ≥ïÂ§ßËá¥ÂàÜ‰∏∫‰ª•‰∏ã‰∫îÁ±ªÔºö‰º†ÁªüÊª§Ê≥¢Ê≥ïÔºåÂü∫‰∫éÁ®ÄÁñèË°®ËææÁ∫¶ÊùüÊ≥ïÔºåÂü∫‰∫éÂõæÂÉèËá™Áõ∏‰ººÁöÑÊñπÊ≥ïÔºåÂèòÂàÜÊ≥ïÔºåÂü∫‰∫éÈ©¨Â∞îÂèØÂ§´Ê®°ÂûãÁöÑÊ≥ïÔºå‰ª•ÂèäÁõÆÂâçÁöÑÊ∑±Â∫¶Â≠¶‰π†ÊñπÊ≥ï„ÄÇÊØè‰∏ÄÁ±ªÊñπÊ≥ïÈÉΩÂèØ‰ª•Âú®Á©∫Èó¥Âüü‰ª•ÂèäËΩ¨ÂåñÂüüÊù•ÂÆûÁé∞„ÄÇ ‰º†ÁªüÊª§Ê≥¢Ê≥ïÂåÖÊã¨ÂùáÂÄºÊª§Ê≥¢Ôºå‰∏≠ÂÄºÊª§Ê≥¢ [3] ÔºåÂç°Â∞îÊõºÊª§Ê≥¢ [4] ÔºåÁª¥Á∫≥Êª§Ê≥¢[5]Á≠â„ÄÇ ÂùáÂÄºÊª§Ê≥¢(Mean)ÊòØ‰∏ÄÁßçÊúÄÁÆÄÂçïÁöÑÊª§Ê≥¢Âô®ÔºåÂÖ∂Âà©Áî®ÈÇªÂüüÂÜÖÂÉèÁ¥†ÁöÑÂπ≥ÂùáÂÄº‰Ωú‰∏∫ÊõøÊç¢ÂÄºÊù•Ê∂àÈô§ÂõæÂÉèÁöÑÂ≠§Á´ãÁÇπÂô™Â£∞„ÄÇÈÄöÂ∏∏‰º¥ÊúâËøáÊ®°Á≥äÁöÑÈóÆÈ¢ò„ÄÇÂè¶‰∏ÄÁßçÂùáÂÄºÊª§Ê≥¢ÈÄöËøáÔºåÈÄöËøáÂØπÊ†∑Êú¨Â§öÊ¨°ËßÇÂØüÂèñÂπ≥ÂùáÊù•ÈôçÂô™„ÄÇ Áª¥Á∫≥Êª§Ê≥¢(Weiner)ÊòØÁî±WeinarÂú®‰∫åÂçÅ‰∏ñÁ∫™ÂõõÂçÅÂπ¥‰ª£ÊèêÂá∫Êù•ÔºåÈÄöËøáÊúÄÂ∞èÂùáÊñπÂ∑ÆÂØªÊâæÂáÜÂàôÔºå‰ªéÂô™Â£∞ÂõæÂÉè‰∏≠ÊèêÂèñÊúÄ‰Ω≥Á∫øÊÄßÊª§Ê≥¢ÁöÑÊñπÊ≥ïÔºåÂõ†Ê≠§‰πüÂè´ÊúÄÂ∞èÂùáÊñπÊª§Ê≥¢/ÊúÄ‰Ω≥Á∫øÊÄßÊª§Ê≥¢Âô®„ÄÇ \begin{array}{c}{ y(n)=\hat{s}(n)=\sum_{m=0}^{+\infty} h(m) x(n-m)} \\ \min_{x}{E\left[e^{2}(n)\right]=E\left[\left(s(n)-\sum_{m=0}^{+\infty} h(m) x(n-m)\right)^{2}\right]}\end{array}ÂÖ∂‰∏≠h(m)ÊòØÊó†Ê±°Êüì‰ø°Âè∑Ôºåx(n)ÊòØÁ∫øÊÄßÊª§Ê≥¢„ÄÇ Wiener, Norbert (1949), Extrapolation, Interpolation, and Smoothing of Stationary Time Series. New York: Wiley. ÊØîÂùáÂÄºÊª§Ê≥¢ÁöÑÊïàÊûúÂ•ΩÔºåÂú®È´òÊñØÂô™Â£∞‰∏≠ÁöÑÊïàÊûúÊúÄÂ•ΩÔºåËÆ°ÁÆóÈáèÂ§ß„ÄÇ‰πü‰∏çËÉΩÁî®‰∫éÂô™Â£∞‰∏∫ÈùûÂπ≥Á®≥ÁöÑÈöèÊú∫ËøáÁ®ã ‰∏≠ÂÄºÊª§Ê≥¢Âô®(Median)ÊòØ‰∏ÄÁßçÈùûÁ∫øÊÄßÊª§Ê≥¢ÔºåÊúÄÊó©Áî±TukeyÂíå PrattÂú®1974Âíå1978Âπ¥ÊèêÂá∫ [1] [2]ÔºåÂπ∂Ë¢´ÂπøÊ≥õÁî®‰∫éÂéªÂô™ÈóÆÈ¢ò[3]„ÄÇËøô‰∏™ÊñπÊ≥ïÔºåÁî®È¢ÜÂüüÂÜÖÂÉèÁ¥†ÁöÑ‰∏≠ÂÄº‰Ωú‰∏∫ÂÉèÁ¥†ÂÄº„ÄÇÊúÄÊòæËëóÁöÑ‰ºòÁÇπÊòØÂú®‰∏¥ËøëÂÉèÁ¥†ÊòæËëó‰∏çÂêåÂå∫ÂüüÂÜÖÔºåËÆ©ÂÉèÁ¥†ÁöÑÁÅ∞Â∫¶ÂÄº‰∏éÂÖ∂ÈÇªËøëÂÉèÁ¥†Êõ¥Âä†Êé•Ëøë„ÄÇÁº∫ÁÇπÔºåÂú®Á∫πÁêÜÂ§çÊùÇÁöÑÂõæÂÉè‰∏≠‰æùÁÑ∂ÊúâÊ®°Á≥äÁöÑÈóÆÈ¢ò„ÄÇÂú®ÁÇπÁ∫øÂ∞ñÁöÑÁ∫πÁêÜËæÉÂ§öÁöÑÂú∞ÊñπË°®Áé∞‰∏çÂ•Ω„ÄÇ The one-dimensional median filter was devised by Tukey [1]. Some discussion of it, and an extension to two dimensions, is given by Pratt [2]. [1] Tukey. J.W. Exploratory Data Analysis. Addison-Wesley, Reading, Mass., 1974. [2] William K. Pratt, Digital image processing, John Wiley &amp; Sons, Inc., New York, NY, 1978 [3] Brownrigg D R K, ‚ÄúThe Weighted Median Filter,‚Äù Communications of the Acm,1984, 27(8):807-818. ÂÖ∂‰ªñÁöÑÊª§Ê≥¢ËøòÊúâÂú®ËΩ¨ÂåñÂüüÁöÑ‰ΩéÈÄöÊª§Ê≥¢Ê≥ïÔºåÈÄöËøáÂéªÊéâÂÇÖÁ´ãÂè∂ÂèòÊç¢Âêé‰∏≠ÁöÑÈ´òÈ¢ëÊàêÂàÜÔºåÈÄÜËΩ¨ÂåñÂêéÂæóÂà∞Â§çÂéüÂõæÂÉè„ÄÇ Adel Sedra &amp; Peter BrackettÔºå Filter Theory and Design, Active and Passive,Matrix Publisher, Oregon 1978 Â∞èÊ≥¢ÂüüÂéªÂô™ËßÅÂ∞èÊ≥¢ÂüüÂéªÂô™ÁªºËø∞ ÂèòÂàÜÊ≥ïÊòØÂè¶Â§ñ‰∏ÄÂ§ßÁ±ªÈáçË¶ÅÁöÑÂàÜÊîØ„ÄÇÂÆÉÂ∞ÜÁóÖ‰ΩìÈóÆÈ¢òËΩ¨ÂåñÊàê‰∏Ä‰∏™ÊúÄÂ∞èÂåñÊñπÁ®ãÈóÆÈ¢ò„ÄÇÁõÆÊ†áÊñπÁ®ãÁî±‰∏Ä‰∏™ÂåÖÁúüÈ°πÂíåÊ≠£ÂàôÈ°πÁªÑÊàêÔºå‰øùÁúüÈ°πÊòØ ÔºåÊ≠£ÂàôÈ°πÔºåÂéªÂô™ÁöÑÁªìÊûúÂ∞±ÊòØÈÄöËøá‰ºòÂåñÁÆóÊ≥ïËé∑ÂæóÁöÑÊñπÁ®ãËß£„ÄÇÂú®‰∏çÂêåÁöÑÊ≠£ÂàôÈ°π‰∏≠ÔºåÂÖ®ÂèòÂàÜÊúÄÂèóÊ¨¢Ëøé„ÄÇ Á©∫Èó¥ÂüüÔºöÂÖ®ÂèòÂàÜ Âü∫‰∫éÂ∞èÊ≥¢Ê°ÜÊû∂ÁöÑÂèòÂàÜÊ®°Âûã(ÊòØ‰∏çÊòØÈÉΩÂ±û‰∫éwavelet frame) NLMÊòØÁ¨¨‰∏Ä‰∏™Âü∫‰∫éÁõ∏‰ººÂùóÁöÑËæÉ‰∏∫Áé∞‰ª£ÁöÑÊñπÊ≥ï„ÄÇÊòØÂú®2005Âπ¥Áî±BaudesÈ¶ñÂÖàÊèêÂá∫Áî®Êù•ÂéªÂô™ÁöÑÊñπÊ≥ï[1]„ÄÇ‰ªñÈÄöËøáÊêúÂØª‰∏éÁõÆÊ†áÂÉèÁ¥†ÂÖ∑ÊúâÁõ∏‰ººÂùóÁöÑÁõ∏‰ººÁÇπ‰Ωú‰∏∫ÂèÇËÄÉÂÄºÔºåÂØπËøô‰∫õÈÄâÊã©ÁöÑÂÉèÁ¥†ÁÇπÂùáÂÄºÔºåÊùÉÈáçÁî±Áõ∏‰ººÂ∫¶ÂÜ≥ÂÆöÔºåÂØπÁõÆÊ†áÂÉèÁ¥†ËøõË°åÂéªÂô™„ÄÇ‰∏é‰º†ÁªüÁöÑÊª§Ê≥¢Ê≥ï‰∏çÂêåÔºåËØ•ÊñπÊ≥ïÂà©Áî®‰∫ÜÊï¥ÂπÖÂõæÂÉèÁöÑÂÜó‰ΩôÊÄßÔºåÊØîËæÉÂ•ΩÂú∞ÂéªÊéâÂõæÂÉè‰∏≠Â≠òÂú®ÁöÑÈ´òÊñØÂô™Â£∞„ÄÇ [1] Buades, A., Coll, B., &amp; Morel, J. M. (2005, June). A non-local algorithm for image denoising. In 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR‚Äô05) (Vol. 2, pp. 60-65). IEEE.ÔºàBM3DÔºâ [2] Dabov, K., Foi, A., Katkovnik, V., &amp; Egiazarian, K. (2007). Image denoising by sparse 3-D transform-domain collaborative filtering. Image Processing, IEEE Transactions on 16 (8), pp. 2080-2095. patch-based methods ‰∏∫‰∫ÜÂÆåÂ§áÊÄßÔºåÂÖ∂‰ªñÂéªÂô™ÊñπÊ≥ïËøòÊúâÂü∫‰∫éÈ©¨Â∞îÂèØÂ§´Ê®°ÂûãÁöÑÁ≠â„ÄÇÁé∞Âú®ÁöÑÊñπÊ≥ïÂ§ßÂ§öÊòØÂ∞ÜËøôÂá†Á±ªÊñπÊ≥ïËøõË°åÁªìÂêà‰ΩøÁî®ÔºåÊù•Ëé∑ÂæóÊõ¥Â•ΩÁöÑÊïàÊûú„ÄÇ‰æãÂ¶ÇÔºåÊúÄÂÖàËøõÁöÑBM3D‰∏ªË¶ÅÂ∞±ÊòØNLMÔºåÂ∞èÊ≥¢Êª§Ê≥¢ÂíåÁª¥Â∞ºÊª§Ê≥¢ÁöÑÁªÑÂêà„ÄÇÊï¥‰∏™ËøáÁ®ãÊúâ‰∏§Ê≠•ÁªÑÊàêÔºåÁ¨¨‰∏Ä‰∏™ÊµÅÁ®ãÈ¶ñÂÖàÈÄöËøáNLMÁõ∏‰ººÂùóÂàÜÁªÑÔºåÁ¨¨ÂØπÊØè‰∏Ä‰∏™Áõ∏‰ººÂùóÁªÑËøõË°åÂ∞èÊ≥¢Á°¨ÈòàÂÄºÂ§ÑÁêÜÂêéÈÄÜËΩ¨Êç¢ÂõûÂõæÂÉèÂùóÔºåÂ∞ÜËøô‰∫õÂùóËøõË°åÂä†ÊùÉÂêéËûçÂêàÂà∞ÂéüÊù•ÁöÑ‰ΩçÁΩÆÔºåÂæóÂà∞ÂàùÊ≠•ÂéªÂô™ÁªìÊûú„ÄÇÁ¨¨‰∫å‰∏™ÊµÅÁ®ãÂØπÂô™Â£∞ÂõæÂíåÂàùÊ≠•ÂéªÂô™ÁªìÊûúÂàÜÂà´ËøõË°åÁõ∏ÊÄùÁöÑÂàÜÁªÑ, ‰ªéÁ¶ªÊï£‰ΩôÂº¶ÂèòÊç¢ÂêéÁöÑÂô™Â£∞Âùó‰∏≠ÊèêÂèñÁª¥Á∫≥Êª§Ê≥¢Á≥ªÊï∞ÂØπÂàùÊ≠•ÂéªÂô™ÂùóËøõË°åÊª§Ê≥¢Â§ÑÁêÜÂêéÔºåÈÄÜËΩ¨ÂåñÂêéËûçÂêàÊàêÊúÄÂêéÁöÑÂéªÂô™ÁªìÊûú„ÄÇ Ë°•ÂÖÖ Âü∫‰∫éÁ®ÄÁñèË°®ËææÔºàsparsity approximationÔºâÁöÑÂéªÂô™ÊñπÊ≥ïhttps://wenku.baidu.com/view/ed8fc817c5da50e2524d7fe6.html Âü∫‰∫éÂÖ®Â±ÄÂõæÂÉèÁ®ÄÁñèÂéªÂô™ Âü∫‰∫éÁ®ÄÁñèÂ≠óÂÖ∏ÁöÑÂõæÂÉèÂéªÂô™ÊñπÊ≥ï ËßÅÂ∞èÊ≥¢ÂüüÁöÑÂéªÂô™ÁªºËø∞ MGA ÂéªÂô™ÊñπÊ≥ï‰∏≠ÁöÑÁ®ÄÁñèÊÄßÂ∫îÁî® ICA ÂéªÂô™ÊñπÊ≥ï‰∏≠ÁöÑÁ®ÄÁñèÊÄßÂ∫îÁî® 2010 Âπ¥Ôºå Anjali Á≠â‰∫∫ÂØπ ICA ÊäÄÊúØÂéªÂô™ËøõË°å‰∫ÜÁªºËø∞ÔºåÊåáÂá∫ Fourier ÊñπÊ≥ïÂ±ÄÈôê‰∫éÈ¢ëÁéáÔºåÂ∞èÊ≥¢ÂèòÊç¢ËôΩËÉΩÂêåÊó∂Âú®Á©∫Èó¥Âüü‰∏éÈ¢ëÁéá ÂüüÔºå‰ΩÜÈÉΩ‰∏çÂÖ∑ÊúâÊï∞ÊçÆÁöÑËá™ÈÄÇÂ∫îÊÄßÔºõ ËÄå ICA ÊñπÊ≥ïËÉΩ‰ªéÈ´òÈò∂ÂéªÂàÜÊûê Â§öÊñπÂêëÊï∞ÊçÆÂÜÖÂú®ÁöÑÈÄÇÂ∫îÊÄßÔºåÂô™Â£∞Ë¢´ËÆ§‰∏∫ÊòØÈ´òÊñØÈöèÊú∫ÂèòÈáèÔºåËÄåÂõæ Ôºª61ÔºΩ ÂÉèÊï∞ÊçÆÂàôÊòØÈùûÈ´òÊñØÈöèÊú∫ÂèòÈáè È©¨Â∞îÂèØÂ§´Ê®°Âûã MRAÔºåWavelet frame, MRA-based wavelet frameÔºåMRA-based tight wavelet frame(generalization) ÁöÑÂèëÂ±ïËøáÁ®ã Â∞èÊ≥¢ÂàÜÊûêÂ∑≤Áî®‰∫éÂ§ö‰∏™È¢ÜÂüüÔºåÂ¶Ç‰ø°Âè∑Â§ÑÁêÜÔºåÂõæÂÉèÂàÜÊûêÁ≠âÊñπÈù¢ÔºåËÄåÊ°ÜÊû∂ÁêÜËÆ∫ÊòØÂ∞èÊ≥¢ÂàÜÊûêÁöÑ‰∏Ä‰∏™ÈáçË¶ÅÂ∑•ÂÖ∑„ÄÇÊ°ÜÊû∂ÁêÜËÆ∫ÊúÄÂàùÊòØÁî± Duffin Âíå Schaffcf Âú® 1952 Âπ¥Á†îÁ©∂ÈùûË∞ÉÂíå Fourier Á∫ßÊï∞Êó∂ÊèêÂá∫Êù•ÁöÑÔºåÂú®ÊúÄÂºÄÂßãÊèêÂá∫ÁöÑÊó∂ ÂÄôÔºåÊ°ÜÊû∂Âπ∂Ê≤°ÊúâÂπøÊ≥õÂú∞ÂºïËµ∑ÂÖ∂‰ªñÂ≠¶ËÄÖÁöÑÁ†îÁ©∂ÂÖ¥Ë∂£„ÄÇÁõ¥Âà∞ 1986 Âπ¥ÔºåDaubechies„ÄÅGrossmann Âíå Meyer ÂØπÊ°ÜÊû∂ÁêÜËÆ∫Êúâ‰∫ÜÁ™ÅÁ†¥ÊÄßÁöÑÁ†îÁ©∂ÔºåËá≥Ê≠§Ê°ÜÊû∂ÁêÜËÆ∫ÊâçÂºÄÂßãÂê∏Âºï‰∫ÜÂ§ßÊâπÂ≠¶ËÄÖÁöÑÂÖ≥Ê≥®„ÄÇËøë‰∫õÂπ¥Êù•ÔºåÂú®Ê°ÜÊû∂ÁêÜËÆ∫ÁöÑÁ†îÁ©∂ ËøáÁ®ã‰∏≠ÔºåÁî®Âà∞‰∫ÜÁÆóÂ≠êÁêÜËÆ∫‰ª•Âèä Banach Á©∫Èó¥ÁêÜËÆ∫„ÄÇÁõ¥Âà∞ D. R. I. Arson„ÄÅDeguang Han Âíå Xingde Dai Á≠â‰∫∫Êää ÁÆóÂ≠ê‰ª£Êï∞ÁêÜËÆ∫ËøêÁî®Âà∞Ê°ÜÊû∂ÁöÑÁ†îÁ©∂‰∏≠ÔºåÊ°ÜÊû∂ÁêÜËÆ∫Á†îÁ©∂ÊâçÊõ¥‰∏ä‰∫Ü‰∏Ä‰∏™Â±ÇÊ¨°ÔºåÂπ∂‰ªéÊï¥‰Ωì‰∏äÊääÊè°ÂíåÁ†îÁ©∂‰∫ÜÊ°ÜÊû∂Âíå Âü∫ÁöÑÊÄßË¥® „ÄÇËá≥Ê≠§ÔºåÁªìÂêà‰∫ÜÁÆóÂ≠êÁêÜËÆ∫ÁöÑÊ°ÜÊû∂ÁêÜËÆ∫Âø´ÈÄüÂèëÂ±ïÔºåÂÖ∂ÊÄßË¥®‰ª•ÂèäÂ∫îÁî®ÂæóÂà∞Êõ¥Âä†ÂπøÊ≥õÂú∞Á†îÁ©∂‰∏éÊé®Âπø„ÄÇ Tight frame,1952, Duffin [80] R.J. DuÔ¨Én and A.C. SchaeÔ¨Äer, A class of nonharmonic Fourier series, Transactions of the American Mathematical Society 72 (1952), no. 2, 341‚Äì366. Wavelet frames (without a multiresolution structure) (see e.g. [61, 132]), [61]Ten lectures on wavelets, vol. CBMS-NSF Lecture Notes, SIAM, nr. 61, Society for Industrial Mathematics, 1992. [132] A wavelet tour of signal processing, vol. 2nd ed. New York: Academic, Academic press, 1999 and Applications: eg. Tight wavelet frames derived from over sampled orthonormal wavelet basis are already used in noise removal by [57, 77]. [57] R.R. Coifman and D.L. Donoho, Translation-invariant de-noising, Lecture Notes in Statistics-New York-Springer Verlag (1995), 125‚Äì125. [77] De-noising by soft-thresholding, IEEE transactions on information theory 41 (1995), no. 3, 613‚Äì627. De-Noising using the traditional orthogonal wavelet transform. MRAËøô‰∏™Ê¶ÇÂøµÁî±MallatÂú®1989ÊèêÂá∫„ÄÇÊúÄÂ∏∏Áî®‰æÜÂàÜÊûêÈõ¢Êï£Â∞èÊ≥¢ËÆäÊèõ„ÄàDWT„ÄâÊàñÊòØÈ©óË≠âÂø´ÈÄüÂ∞èÊ≥¢ËΩâÊèõ„ÄàFWT„ÄâÁêÜË´ñÁöÑÊñπÊ≥ï [131] S.G. Mallat, Multiresolution approximations and wavelet orthonormal bases of L 2 (R), Transactions of the American Mathematical Society 315 (1989), no. 1, 69‚Äì87. MRA-based compactly supported orthonormal wavelet systems, Daubechies [60]. MRA-based compactly supported orthonormal wavelets of [60]. [60] Daubechies, Orthonormal bases of compactly supported wavelets, Commun. Pure Appl. Math. 41 (1988), no. 7, 909‚Äì996. MRA-based tight wavelet frames.(a generalization) , ÊâÄ‰ª•‰πüÊúâ‰∏çÊòØMRA-based [158] AÔ¨Éne Systems in L 2 (R d ): The Analysis of the Analysis Operator, Journal of Functional Analysis 148 (1997), no. 2, 408‚Äì447. MRA-based wavelet ËÆ∫Êñá‰∏≠Âú®Á¨¨‰∫îÁ´†‰ªãÁªç‰∫Ü‰∏çÂêåÂ∫îÁî®‰∏≠ÁöÑÂÖ∑‰ΩìÊ®°Âûã We discuss the model proposed in [18] on blind deblurring (motion deblurring to be speciÔ¨Åc) problems. we present a frame based image segmentation model with a fast algorithm for the general image segmentation problems of [71]. we discuss the model proposed by [112] on reconstruction of scenes (visible surfaces) from scattered, noisy and possibly sparse range data (point clouds). ÈóÆÈ¢ò [ ] Âú®ÂÅöwavelet domain denoisingÁöÑÁªºËø∞‰∏≠Ôºå‰ªéÊù•Ê≤°ÊúâÊèêÂà∞ÂèòÂàÜÊ®°ÂûãÔºõwavelet frameÁöÑÁªºËø∞‰∏≠Ôºå‰ªéÊù•Ê≤°ÊúâÊèêÂà∞ËøáthresholdingÁöÑÊñπÊ≥ï„ÄÇ Ê°ÜÊû∂ÁêÜËÆ∫ÊúÄÂàùÊòØÁî± Duffin Âíå Schaffcf Âú® 1952 Âπ¥Á†îÁ©∂ÈùûË∞ÉÂíå Fourier Á∫ßÊï∞Êó∂ÊèêÂá∫Êù•ÁöÑÔºåÂú®ÊúÄÂºÄÂßãÊèêÂá∫ÁöÑÊó∂ ÂÄôÔºåÊ°ÜÊû∂Âπ∂Ê≤°ÊúâÂπøÊ≥õÂú∞ÂºïËµ∑ÂÖ∂‰ªñÂ≠¶ËÄÖÁöÑÁ†îÁ©∂ÂÖ¥Ë∂£„ÄÇÁõ¥Âà∞ 1986 Âπ¥ÔºåDaubechies„ÄÅGrossmann Âíå Meyer ÂØπÊ°Ü Êû∂ÁêÜËÆ∫Êúâ‰∫ÜÁ™ÅÁ†¥ÊÄßÁöÑÁ†îÁ©∂ÔºåËá≥Ê≠§Ê°ÜÊû∂ÁêÜËÆ∫ÊâçÂºÄÂßãÂê∏Âºï‰∫ÜÂ§ßÊâπÂ≠¶ËÄÖÁöÑÂÖ≥Ê≥®„ÄÇËøë‰∫õÂπ¥Êù•ÔºåÂú®Ê°ÜÊû∂ÁêÜËÆ∫ÁöÑÁ†îÁ©∂ ËøáÁ®ã‰∏≠ÔºåÁî®Âà∞‰∫ÜÁÆóÂ≠êÁêÜËÆ∫‰ª•Âèä Banach Á©∫Èó¥ÁêÜËÆ∫„ÄÇÁõ¥Âà∞ D. R. I. Arson„ÄÅDeguang Han Âíå Xingde Dai Á≠â‰∫∫Êää ÁÆóÂ≠ê‰ª£Êï∞ÁêÜËÆ∫ËøêÁî®Âà∞Ê°ÜÊû∂ÁöÑÁ†îÁ©∂‰∏≠ÔºåÊ°ÜÊû∂ÁêÜËÆ∫Á†îÁ©∂ÊâçÊõ¥‰∏ä‰∫Ü‰∏Ä‰∏™Â±ÇÊ¨°ÔºåÂπ∂‰ªéÊï¥‰Ωì‰∏äÊääÊè°ÂíåÁ†îÁ©∂‰∫ÜÊ°ÜÊû∂Âíå Âü∫ÁöÑÊÄßË¥® „ÄÇËá≥Ê≠§ÔºåÁªìÂêà‰∫ÜÁÆóÂ≠êÁêÜËÆ∫ÁöÑÊ°ÜÊû∂ÁêÜËÆ∫Âø´ÈÄüÂèëÂ±ïÔºåÂÖ∂ÊÄßË¥®‰ª•ÂèäÂ∫îÁî®ÂæóÂà∞Êõ¥Âä†ÂπøÊ≥õÂú∞Á†îÁ©∂‰∏éÊé®Âπø„ÄÇ [ ] Âü∫‰∫éÁ®ÄÁñèË°®Á§∫ÁöÑÂ∞èÊ≥¢ÂéªÂô™ÔºåÊòØÂê¶Êúâ‰∏çÂü∫‰∫éÁ®ÄÁñèÁöÑÂ∞èÊ≥¢ÂéªÂô™ÔºåÊàëÊÑüËßâÂ∞èÊ≥¢Â∞±ÊòØÂà©Áî®‰∫ÜÁ®ÄÁñè „ÄÇÈÇ£‰πàÁ®ÄÁñèÈô§‰∫ÜÂ∞èÊ≥¢ÂüüÔºåËøòÊúâÊ≤°ÊúâÂÖ∂‰ªñÊñπÊ≥ï [ ] ÂÇÖÁ´ãÂè∂ÂèòÂåñ,‰ΩôÂº¶ÂèòÂåñ,Â∞èÊ≥¢ÂèòÂåñÂêåÂ±û‰∫éËΩ¨ÂåñÔºåÈÉΩÊòØÂú®ÊêûÂü∫„ÄÇÂÖ∂‰∏≠Â∞èÊ≥¢ÁöÑÁâπÁÇπÊòØÁ®ÄÁñè„ÄÇ Á¥ßÊ°ÜÊû∂‰πüÊòØ‰∏ÄÁßçËΩ¨ÂåñÔºåÁâπÁÇπÊòØÂÜó‰ΩôÂü∫ÔºåÁ≥ªÂ±ûÊÄßÊõ¥Â•Ω„ÄÇÊ°ÜÊû∂ÁêÜËÆ∫ÔºöÂåÖÊã¨ÂÇÖÁ´ãÂè∂ÂèòÂåñÔºåÂ∞èÊ≥¢ÂèòÂåñ„ÄÇ Âü∫‰∫éÂ§öËß£ÊûêÂ∫¶ÁöÑÁ¥ßÊ°ÜÊû∂ÔºöÂÖ∑ÊúâÂø´ÈÄüÈáçÊûÑÂíåÂàÜËß£ÁöÑ‰ºòÁÇπ„ÄÇ [ ] MRAÔºåWavelet frame, MRA-based wavelet frameÔºåMRA-based tight wavelet frame(generalization) ÁöÑÂèëÂ±ïËøáÁ®ã [ ] ÂõæÂÉèÊúâÂì™‰∫õwavelet transformationÊúâÂì™‰∫õÔºåtight frameÊúâÂì™‰∫õÔºåÊÄé‰πàÊ†∑ÁÆóÂ±û‰∫éMRA(Multi-resolution Analysis) [ ] Â¶Ç‰ΩïÈÄâÊã©Ëøô‰∫õ‰∏çÂêåÁöÑÂèòÊç¢ [ ] (2D)DT-CWTÊòØ‰ªÄ‰πà„ÄÅ(1D)DT-WT Ëøô‰∏§‰∏™ÊòØ‰ªÄ‰πàÔºåÂ¶Ç‰ΩïÁî®matlabÂÆûÁé∞ÔºåÂ∫îËØ•ÊòØMRA-based tight frameÁöÑ‰∏ÄÁßç [ ] Âü∫‰∫éÂ∞èÊ≥¢Ê°ÜÊû∂ÁöÑÂèòÂàÜÊ®°ÂûãÂì™ÁØáËÆ∫Êñá‰∏≠ÊúÄÂÖàÊèêÂá∫„ÄÇÂèÇÁÖßMRA-Based Wavelet Frames and ApplicationsÁöÑÊñáÁåÆÂõûÈ°æÂç≥ÂèØ \left(\mathrm{P}_{1}\right) \quad \min _{x \in \mathbb{R}^{n}}\|x\|_{\ell_{1}} \quad \text { subject to } \quad y=\Phi x [x] Êú™ÈÄâ‰∏≠‰ªÄ‰πàÊòØÊåØÈìÉÁé∞Ë±°Ôºå‰ªÄ‰πàÊòØGibbsÁé∞Ë±°ÔºåÂõæÂÉè‰∏≠Â¶Ç‰ΩïË°®Áé∞ ‰∏§ËÄÖÂΩ¢ÂÆπÁöÑÊòØÂêå‰∏ÄÁßçÁé∞Ë±°„ÄÇÊåØÈìÉÊïàÂ∫îÔºàRingingeffectÔºâÊòØÂΩ±ÂìçÂ§çÂéüÂõæÂÉèË¥®ÈáèÁöÑ‰ºóÂ§öÂõ†Á¥†‰πã‰∏ÄÔºåÂÖ∂ÂÖ∏ÂûãË°®Áé∞ÊòØÂú®ÂõæÂÉèÁÅ∞Â∫¶ÂâßÁÉàÂèòÂåñÁöÑÈÇªÂüüÂá∫Áé∞Á±ªÂêâÂ∏ÉÊñØÔºàGibbsÔºâÂàÜÂ∏É ÊâÄË∞ì‚ÄúÊåØÈìÉ‚ÄùÔºåÂ∞±ÊòØÊåáËæìÂá∫ÂõæÂÉèÁöÑÁÅ∞Â∫¶ÂâßÁÉàÂèòÂåñÂ§Ñ‰∫ßÁîüÁöÑÈúáËç°ÔºåÂ∞±Â•ΩÂÉèÈíüË¢´Êï≤ÂáªÂêé‰∫ßÁîüÁöÑÁ©∫Ê∞îÈúáËç°„ÄÇÂ¶Ç‰∏ãÂõæÔºö [ ] CWTÊòØ‰ªÄ‰πàÔºöcontinuous wavelet transform [ ] ÂõæÂÉèÊúâÂì™‰∫õwavelet transformationÔºåÂéªÂô™Â∫îËØ•ÈÄâÊã©Âì™ÁßçËΩ¨ÂèòÔºàHaarÊòØ‰∏ÄÁßçÔºâ [ ] ÊòØÂê¶ÊâÄÊúâÂ∞èÊ≥¢Âüü‰∏ãÁöÑÂéªÂô™ÊñπÊ≥ïÈÉΩÂà©Áî®‰∫ÜÁ®ÄÁñèÊÄßÔºåÊâÄÊúâÂ∞èÊ≥¢ËΩ¨ÂåñÈÉΩÊòØ‰∏∫‰∫ÜÂæóÂà∞Á®ÄÁñèÊÄßÔºü ÂÆûÈ™åËÆ∞ÂΩïÂà©Áî®non-convex tight frameÂéªÂô™ËÆ∞ÂΩï ÂèÇËÄÉÊñáÁåÆÔºöPlease cite as: A. Parekh and I. W. Selesnick. Convex Denoising Using Non-convex Tight Frame Regularization, IEEE Signal Processing Letters, 22(10): 1786-1790, Oct. 2015. ÂèÇËÄÉ‰ª£Á†ÅÔºöhttps://github.com/aparek/cncTightFrame/blob/master/Documentation/demo2D.pdf ÁªìËÆ∫1: tfÂú®Âô™Â£∞50ÁöÑÊÉÖÂÜµ‰∏ãÔºå‰∏çËÉΩÂøÖËøáTVÔºå‰ºöÊúâÊ®°Á≥äÁöÑÊïàÊûú„ÄÇ L1-tightframe 0.8/0.9/1.0 nonconvex tightframe 1.0/1.1/1.2 ÁªìËÆ∫2: Âú®Âô™Â£∞‰Ωé15ÁöÑÊÉÖÂÜµ‰∏ã nonconvexÁöÑÊ≠£ÂàôÈ°πÂèØ‰ª•Ë∂ÖËøáTV ÁªìËÆ∫3: Âú®Âô™Â£∞35ÁöÑÊÉÖÂÜµ‰∏ãÔºåÂ§çÊùÇÁöÑÂõæÂÉèÂæàÊ®°Á≥äÔºå‰ΩÜÊòØpsnr‰æùÊóßÂèØ‰ª•Ë∂ÖËøáTVÔºå PSNR_x = 25.9576 26.2444 26.1463 25.9175 25.6507 25.3786 Êç¢‰∏™W‰∏™‰ºöÂ•Ω‰∫õÂêó ÂèÇËÄÉÊñáÁåÆ Â∞èÊ≥¢„ÄÅÊ°ÜÊû∂ A short introduction to frames, Gabor systems, and wavelet systems ‰∏Ä‰∏™ËæÉÂ•ΩÁêÜËß£Â∞èÊ≥¢ÁöÑppt]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
      </categories>
      <tags>
        <tag>denoising</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂÅ•Ë∫´Ê∏ÖÂçï]]></title>
    <url>%2Fp%2F4221.html</url>
    <content type="text"><![CDATA[ÂÅ•Ë∫´list ËáÄÈÉ® Â§©ÈπÖÈ¢à Âèå‰∏ãÂ∑¥ ËÑñÂ≠ê]]></content>
      <categories>
        <category>ÁîüÊ¥ª</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ÁîµÂΩ±Ê∏ÖÂçï]]></title>
    <url>%2Fp%2Fab3e.html</url>
    <content type="text"><![CDATA[32ÈÉ®Êó†ËÆ∫ÊòØËâ≤ÂΩ©„ÄÅÊûÑÂõæËøòÊòØÂú∫ÊôØÈÉΩË∂ÖÊ£íÁöÑÂ•ΩÁîµÂΩ±]]></content>
      <categories>
        <category>ÁîüÊ¥ª</category>
      </categories>
      <tags>
        <tag>ÁîµÂΩ±</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÁæéÂ¶ÜÁ¨îËÆ∞]]></title>
    <url>%2Fp%2F13be.html</url>
    <content type="text"><![CDATA[Âà∑Â§¥ Âü∫Á°ÄÂà∑Â§¥ ÁúºÂΩ±Âà∑ÂåÖÊã¨ÔºöÂ§ßÂè∑ÊâìÂ∫ïÈì∫Ëâ≤(ÂÅèÁ°¨, ÊØîËæÉÂÆΩ)ÔºåÊôïÊüì(ÂÅèËΩØ‰∏ÄÁÇπ)ÔºåÁúºÁ∫øÂà∑(ÂÅèÁ°¨)„ÄÇ ÁúºÂ¶Ü ÁúºÂ¶ÜÁöÑÊ≠•È™§ ÁúºÂΩ±-ÁúºÁ∫ø-ÂÅáÁù´ÊØõ-Â§πÁù´ÊØõ-Áù´ÊØõÊ∂≤ Èò≤Êôí-ÈöîÁ¶ª(‰øÆÊ≠£ËÇ§Ëâ≤„ÄÅ‰øùÊπøÁ≠â‰∏çÂêå‰ΩúÁî®)-ÈÅÆÁëï-Á≤âÂ∫ïÊ∂≤-ÁúºÂ¶Ü-ÈºªÂΩ±-‰øÆÂÆπ-ÂÆöÂ¶Ü (ÁúâÊØõÂú®Âì™‰∏ÄÊ≠•) ÁúºÁ∫øÁöÑÁîªÊ≥ï ÂÅáÁù´ÊØõÁöÑÁ≤òË¥¥ Áù´ÊØõÂ§π ÈÅÆÊ≥™Ê≤ü Â∑•ÂÖ∑ÔºåinnisfreeÈÅÆÁëïÂà∑ÔºåÊ©òËâ≤Â•óË£Ö‰πüÂåÖÂê´ ‰∏ÄÊîØÈÅÆÁëïËÜèÂ±ÇÂ±ÇÂè†Âä†Ê≥ï Ê≠åÂâßÈ≠ÖÂΩ±6Ëâ≤ÈÅÆÁëïÔºåÊ©òËâ≤Âà∑Â≠ê ÈÅÆÁëïËØÑÊµã ÂèëËâ≤2019ÊµÅË°å‚Äú‰∏çÈ•±ÂíåÂèëËâ≤‚Äù 2019Âπ¥ÊúÄÂ§ØÊúÄÊòæÁôΩÁöÑTOP10ÂèëËâ≤ÔºÅ Èù¢ËÜúÊé®ËçêCNPÈªÑËâ≤ÂíåËìùËâ≤ Â¢®ÈïúÈÄâÊã©‰∏çÂêåËÑ∏ÂûãÈÄâÊã©Â¢®Èïú]]></content>
      <categories>
        <category>ÁîüÊ¥ª</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ÁêÜË¥¢Áü•ËØÜ]]></title>
    <url>%2Fp%2Fe897.html</url>
    <content type="text"><![CDATA[‰ø°Áî®Âç° ‰ø°Áî®Âç°Âë®Êúü statement balanceÊòØ‰∏ä‰∏™Âë®ÊúüÁöÑÊ¨†Ê¨æ account balanceÊòØÁõÆÂâçÊÄªÊ¨†Ê¨æ = ‰∏ä‰∏™Âë®ÊúüÁöÑÊ¨†Ê¨æ+‰∏ä‰∏™Âë®Êúü-Âà∞ÂΩìÊó•ÁöÑÊ¨†Ê¨æ ÊàëÁöÑËøòÊ¨æÊñπÂºè„ÄÇÊúàÂ∞æ‰ªòaccount balance ‰ªòÂÆå‰πãÂêéaccount balance‰ΩïÊó∂Êõ¥Êñ∞„ÄÇÂÅáËÆæ6.3Âè∑‰ªò‰∫Üaccount balanceÔºå6.3Âè∑‰πãÂâç‰ø°Áî®Âç°ËøòÊúâ‰∏ÄÁ¨îÊîØÂá∫ÔºåËøòÊú™ÊòæÁ§∫Âú®account balance‰∏≠„ÄÇÈÉΩÊòØÊåâÁÖßÂá∫Â∏êÊó•ÊúüÁÆóÁöÑ„ÄÇ current balanceÊòØÊåâÁÖßÂá∫Â∏êÊó•ÊúüÁÆóÁöÑÔºåÂπ∂‰∏çÊòØÊåâÁÖßÊ∂àË¥πÂΩìÂ§©ÁöÑÊó•ÊúüÁÆóÁöÑ„ÄÇÂ¶ÇÊûúÊ∂àË¥πÂΩìÊó•Âú®‰∏ä‰∏Ä‰∏™Âë®ÊúüÔºåËÄåÂá∫Â∏êÊó•ÊòØÂú®‰∏ã‰∏™Âë®ÊúüÔºåÂàôÂ±û‰∫é‰∏ã‰∏™Âë®Êúü„ÄÇ‰∏ÄËà¨Âá∫Â∏êÊó∂Èó¥ÈúÄË¶Å‰∏§Â§©„ÄÇ ‰øùÈô©Áü•ËØÜ some links ÂØπ‰øùÈô©ÁöÑÂàùÊ≠•ËÆ§ËØÜ ÂåªÁñóÈô©0ÂÖçËµîÈ¢ùÊØî1wÂÖçËµîÈ¢ùÂ•ΩÂêó Á§æ‰øùÂíåÂÖ∂‰ªñ‰øùÈô© È¶ôÊ∏Ø‰øùÈô©ÂíåÂÜÖÂú∞‰øùÈô© Êàë‰ª¨ÂÆ∂ÁöÑ‰øùÈô© ËÄÅÁà∏ÁöÑ‰øùÈô© ÂÖ¨Âè∏ÁöÑÁ§æ‰ºöÂÖªËÄÅ‰øùÈô©Ôºö‰∫îÈô©‰∏ÄÈáë Êñ∞Âçé‰øùÈô©ÔºöÂØøÈô©Ôºà ‰∫§ÂÆå‰∫ÜÔºâ ËÄÅÂ¶àÁöÑ‰øùÈô© ÁîüÊó•Ôºö Á§æ‰ºöÂÖªËÄÅ‰øùÈô©ÔºöÂåÖÊã¨ÂÖªËÄÅ‰øùÈô©+ÂåªÁñó‰øùÈô© Êàë ÊàëÁöÑ‰∏≠ÂõΩÂπ≥ÂÆâÁöÑ‰∫∫Ë∫´‰øùÈô© ÊàëÂ¶àËÄÉËôëÊÉ≥‰π∞ÁöÑ Êñ∞ÂçéÂ∫∑ÂÅ•ÂçéË¥µBÔºöËøôÊ¨æÁôæ‰∏áÂåªÁñóÂæàÂπ≥Â∏∏ Êñ∞ÂçéÂ∫∑ÂÅ•ÂçéË¥µB‰øùÈöúËåÉÂõ¥ÂíåÊäï‰øùÈ°ªÁü•(Ê°à‰æã)]]></content>
      <categories>
        <category>ÁîüÊ¥ª</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Â∞ëÂ•≥ÁßÅÊàøÁÖß]]></title>
    <url>%2Fp%2F7d48.html</url>
    <content type="text"><![CDATA[ÊãçÊëÑ‰∏ªÈ¢òÊ∏ØÈ£éÈò¥Â§© È¶ôÊ∏ØÈõ®Â§©ÔºöÊñáÁ§ºÈòÅÁöÑÈõ®ÔºåÂú∞‰∏äÁöÑÊ∞¥Âúà ÂØùÂÆ§‰ªôÂ•≥ÁöÑÁßÅÊàøÁÖßOne year ending Project 1: ÁïôÂ≠¶Â∞ëÂ•≥ÁßÅÊàøÁÖß ÁÆÄ‰ªã Ê∏ØÈ£éÁïôÂ≠¶Â∞ëÂ•≥Áõ∏ÔºàÁßÅÊàøÁÖßÔºâÔºå‰ΩìÁé∞ÂíåÂ±ãÂ≠êÁöÑËøô‰∏™‰∫íÂä®Ôºå‰Ωú‰∏∫Êàë‰ª¨Ëøô‰∏ÄÂπ¥ÁîüÊ¥ªÊù•ÁöÑËÆ∞ÂΩïÂíåÁïôÂøµÔºå‰ΩìÁé∞Ê∏ØÈ£éÁîüÊ¥ª„ÄÇ Ë¶ÅÊ±Ç ÂäõÊ±ÇÊãçÂá∫ÊÄßÊÑü‰∏çËâ≤ÊÉÖÁöÑÊÑüËßâ„ÄÇÂπ∂‰∏îÂåÖÂê´ÁîüÊ¥ª‰∏≠ÊúÄÂÖ∏ÂûãÁöÑÂú∫ÊôØ„ÄÇÊúâÊ∏ØÈ£éÂë≥„ÄÇ‰∏çÂÅö‰Ωú Âú∫ÊôØËÆæËÆ° Ëè≤ÔºöÂÅöÁâõÊéíÔºàÂé®ÊàøÔºâÔºåÂØùÂÆ§ÂáÜÂ§¥ÊêûÊÄ™ÈÇ£‰∏Ä‰∏ãÔºàÁúãÂâßÂ∞ëÂ•≥Ôºâ ÂúàÔºöÊôæË°£ÊúçÔºåÂõûÂÆ∂ÁöÑÊó∂ÂÄô Áé•ÔºöÂ∫ä‰∏äËµ∑Ë∫´ÊàñÊ¢≥Â¶ÜÂè∞Ââç„ÄÇ Â§ßÁéãÔºöÂé®ÊàøÔºåËíúËìâÔºåÂíåÂ•πÁöÑÊ≥°Èù¢ÈîÖ„ÄÇÔºàÊãçÊëÑÁöÑÊó∂ÂÄôË¶ÅÊ≥®ÊÑèÔºå‰∏çË¶ÅÊòæÂæóÁîüÊ¥ªÂ§™ËøáÂøÉÈÖ∏ÂíåË¥´Áò†ÔºåË¶ÅÊúâÈ´òÂ§ß‰∏äÁöÑÈÉ®ÂàÜÔºåÂ¶ÇÁª¥Â∞ºÈ•ºÂπ≤Ôºâ Idea ‰∏ÄÂº†ÁîüÊ¥ªÁÖßÔºå‰∏ÄÂº†Âá∫Èó®ÂâçÁöÑÁÖßÔºåÂΩ¢ÊàêÂØπÊØî„ÄÇÂÜÖÂÆπÊØîËæÉÊúâË∂£„ÄÇ Ââç‰∏ÄÁßíÊôæË°£ÁöÑÈÇãÈÅ¢Â•≥Â≠©ÔºåÂá∫Èó®ÁöÑÁ≤æËá¥Â•≥Â≠©ÔºåÂèçÂ∑ÆËêå„ÄÇ Ê≠•È™§Ôºà1ÔºâÊâæÊëÑÂΩ±Â∏à‰ΩúÂìÅÔºåÁúãÂà´‰∫∫ÊãçÊëÑÁöÑ‰ΩúÂìÅÔºåÊâæÂà∞‰∏éËá™Â∑±Á¨¶ÂêàÊàñËÄÖÁõ∏ËøëÁöÑÁÖßÁâá„ÄÇÂâçÊúüÂèØ‰ª•Áî®Êù•Ê®°‰ªø„ÄÇ Ôºà2Ôºâ‰∫ÜËß£ÁßÅÊàøÁÖß‰ª•ÂèäÊ∏ØÈ£éÁÖßÁöÑÊãçÊëÑÊäÄÂ∑ßÔºåÈúÄË¶Å‰∏éÂêéÊúüË∞ÉËâ≤Á¨¶Âêà„ÄÇ Ôºà3ÔºâËß£ÂÜ≥Â±ãÂ≠êÈáåÂÖâÁ∫ø‰∏çË∂≥ÁöÑÊÉÖÂÜµ Ôºà4ÔºâËÆæËÆ°ÊñπÊ°àÔºöÂú∫ÊôØ„ÄÅÊúçÈ•∞„ÄÅÂ¶ÜÂÆπ Ôºà5ÔºâÁ∫¶Êãç ‰ΩúÂìÅÊó•Á≥ªÁîüÊ¥ªÁÖß ÊúÄÁæéÁßÅÊàøÁÖß ‰∫∫Áâ©ÂíåÊÉÖÁª™ ÊãçÊëÑË∞ÉËâ≤vscoÊìç‰ΩúÊîªÁï• vscoË∞ÉËâ≤ÊãçÊëÑÂ≠¶‰π† vscoÊª§ÈïúÊé®Ëçê ÊëÑÂΩ±‰π¶Á±ç10 Êú¨Â•ΩÁúãÂèàÂÆûÁî®ÁöÑÊëÑÂΩ±‰π¶]]></content>
      <categories>
        <category>ÊëÑÂΩ±</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Êï∞Â≠¶Âü∫Á°ÄÁü•ËØÜ]]></title>
    <url>%2Fp%2Fccc1.html</url>
    <content type="text"><![CDATA[Ê≠£Âàô TikhonovÊ≠£Âàô ÈóÆÈ¢ò lower semicontinuousËøô‰∏™ÊÄßË¥®ÁöÑ‰ΩúÁî®Âú®Âì™Èáå„ÄÇÂ•ΩÂÉèÈÄöÂ∏∏Áî®Âú®ËØÅÊòéÊî∂ÊïõÊÄß„ÄÇ PCAÊòØ‰ªÄ‰πàÔºåÊúâ‰ªÄ‰πàÂ∫îÁî® ‰∏çÂêåÁöÑÁ©∫Èó¥„ÄÇÊääÂõæÂÉèÂáΩÊï∞fÂÆö‰πâÂú®Êüê‰∏™Á©∫Èó¥‰∏äÊòØ‰∏∫‰∫ÜmeasureÔºå‰∏∫‰ªÄ‰πàË¶ÅmeasureÔºåÊúâÂì™‰∫õtypical space SVDÂéªÂô™ Ê¨ßÊãâÊñπÁ®ãÔºöÊ¨ßÊãâÊñπÁ®ãÊòØÊ≥õÂáΩÊûÅÂÄºÊù°‰ª∂ÁöÑÂæÆÂàÜË°®ËææÂºè tensor Norm‰∏çÂêåÁöÑnorm [semi-normÂíånorm] ËØÅÊòéËß£ÁöÑÂ≠òÂú®ÊÄß ‰∏Ä‰∏™ÂáΩÊï∞Âú®Êüê‰∏™Á©∫Èó¥ÂÜÖÊúâÁïåÁöÑÊÑèÊÄù $0&lt;c_{1} \leq u_{n} \leq c_{2}, \text{which implies that u n is bounded in} L^{1}(\Omega)$ $\left\{u_{n}\right\} \text { is bounded in } B V(\Omega)$ Ê≥õÂáΩÔºå is bounded below, we can choose a minimizing sequence $\left\{u_{n} : n=1,2, \cdots\right\} \in \overline{S}(\Omega)$ Â∫èÂàóÁöÑÂº∫Êî∂ÊïõÂíåÂº±Êî∂Êïõ Fatous‚Äô lemma ÂêÑÁ±ªÂáΩÊï∞Á©∫Èó¥$l_p$Á©∫Èó¥ $W^{1, 1}(\Omega)$usually defined as all functions $v \in L^{1}(\Omega)$, with weak derivatives of first order and these derivatives shall belong to $L^{1}(\Omega)$. The space $W^{1, \infty}(\Omega)$ is usually defined as all functions $v \in L^{\infty}(\Omega)$with weak derivatives of first orderand these derivatives shall belong to $L^{\infty}(\Omega) .$ BVÁ©∫Èó¥The space $[\mathrm{BV}(\Omega)]^{m}$ with $|u|_{\mathrm{BV}(\Omega)} :=\int_{\Omega}|u| d x+|D u|(\Omega)$ is a Banach space. BHÁ©∫Èó¥ËØÅÊòéÊî∂ÊïõÈÄüÂ∫¶ converge sublinearly $\lim _{k \rightarrow \infty} \frac{\left|x_{k+1}-L\right|}{\left|x_{k}-L\right|}=1$ converge linearly $\lim _{k \rightarrow \infty} \frac{\left|x_{k+1}-L\right|}{\left|x_{k}-L\right|}=\mu, \mu \in(0,1)$ converge superlinearly $\lim _{k \rightarrow \infty} \frac{\left|x_{k+1}-L\right|}{\left|x_{k}-L\right|}=0$ Q-linear convergence: distinguish superlinear rates of convergence. $\lim _{k \rightarrow \infty} \frac{\left|x_{k+1}-L\right|}{\left|x_{k}-L\right|^{q}}&lt;M$ Monotone operator ÂÇÖÁ´ãÂè∂ÂèòÊç¢ÂÇÖÁ´ãÂè∂ÁöÑÂπ≥Áßª‰∏çÂèòÊÄß Sup/Inf ‰∏äÁ°ÆÁïåÂíå‰∏ãÁ°ÆÁïåA lower bound a of S is called an infimum (or greatest lower bound, or meet) of S if lim sup/lim inf ‰∏äÊûÅÈôêÂíå‰∏ãÊûÅÈôê ÂÆö‰πâ ‰æãÂ≠ê lim inf Semi-continuous Upper continuous Lower continuous Minimizing sequence Âü∫Êú¨ÊãìÊâë]]></content>
      <categories>
        <category>Êï∞Â≠¶</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[pythonËØ≠Ê≥ïÂ≠¶‰π†]]></title>
    <url>%2Fp%2Fe35e.html</url>
    <content type="text"><![CDATA[ÊâßË°åÂèÇÊï∞ store_true ÊòØÊåáÂ∏¶Ëß¶ÂèëactionÊó∂‰∏∫ÁúüÔºå‰∏çËß¶ÂèëÂàô‰∏∫ÂÅáÔºå2LËØ¥ÁöÑ‰ª£Á†ÅÂéªÊéâdefaultÂàùÂßãÂåñÔºåÂÖ∂ÂäüËÉΩ‰πü‰∏ç‰ºöÂèòÂåñ parser.add_argument(‚Äò-c‚Äô, action=‚Äôstore_true‚Äô) #python test.py -c =&gt; cÊòØtrueÔºàËß¶ÂèëÔºâ #python test.py =&gt; cÊòØfalseÔºàÊó†Ëß¶ÂèëÔºâ ÈìæÊé•Ôºöhttps://www.zhihu.com/question/56692630/answer/358222352 Êï∞ÊçÆÁªìÊûÑÁ±ªÁöÑÂÆö‰πâÁ±ªÁöÑÂÆö‰πâ„ÄÅÁ±ªÁöÑÁªßÊâø ‰∏ãÂàíÁ∫øÁöÑÂê´‰πâ ÂèòÈáè ÂâçÂ∏¶_ÁöÑÂèòÈáè: Ê†áÊòéÊòØ‰∏Ä‰∏™ÁßÅÊúâÂèòÈáè, Âè™Áî®‰∫éÊ†áÊòé, Â§ñÈÉ®Á±ªËøòÊòØÂèØ‰ª•ËÆøÈóÆÂà∞Ëøô‰∏™ÂèòÈáè _ _ ÂâçÂ∏¶‰∏§‰∏™_ ,ÂêéÂ∏¶‰∏§‰∏™_ ÁöÑÂèòÈáè: Ê†áÊòéÊòØÂÜÖÁΩÆÂèòÈáè, Â§ßÂÜôÂä†‰∏ãÂàíÁ∫øÁöÑÂèòÈáè: Ê†áÊòéÊòØ ‰∏ç‰ºöÂèëÁîüÊîπÂèòÁöÑÂÖ®Â±ÄÂèòÈáè ÂáΩÊï∞: ÂâçÂ∏¶_ÁöÑÂèòÈáè: Ê†áÊòéÊòØ‰∏Ä‰∏™ÁßÅÊúâÂáΩÊï∞, Âè™Áî®‰∫éÊ†áÊòé,_ _ ÂâçÂ∏¶‰∏§‰∏™_ ,ÂêéÂ∏¶‰∏§‰∏™_ ÁöÑÂáΩÊï∞: Ê†áÊòéÊòØÁâπÊÆäÂáΩÊï∞ ÂèÇÊï∞ÁöÑÂÆö‰πâPositional argument v.s. keyword argument In other words, keyword arguments are only ‚Äúoptional‚Äù because they will be set to their default value if not specifically supplied. Â§öÂèÇÊï∞ÁöÑËæìÂÖ• list ÂàóË°®ÂàõÂª∫ÂàóË°®Ôºö 12files = []files.append(os.path.splitext(i)) ÁêÜËß£Python‰∏≠ÂàóË°®ÔºåÂÖÉÁªÑÔºåÂ≠óÂÖ∏ÔºåÈõÜÂêàÁöÑ‰ΩøÁî® ÂàóË°®ÁöÑËØªÂèñÊñπÂºèÔºö files[1] numpyÊï∞ÁªÑPython Numpy Êï∞ÁªÑÁöÑÂàùÂßãÂåñÂíåÂü∫Êú¨Êìç‰Ωú numpyËÆæÁΩÆËæìÂá∫Á≤æÂ∫¶ numpy ‰∏≠ÁöÑÊ∑±ÊµÖÂ§çÂà∂ ‚ÄúÁ≠â‰∫éËµãÂÄº‚ÄùÁõ∏ÂΩì‰∫éÊ†áÁ≠æ 1ÔºâÂΩìÊµÖÂ§çÂà∂ÁöÑÂÄºÊòØ‰∏çÂèØÂèòÂØπË±°ÔºàÊï∞ÂÄºÔºåÂ≠óÁ¨¶‰∏≤ÔºåÂÖÉÁªÑÔºâÊó∂Âíå‚ÄúÁ≠â‰∫éËµãÂÄº‚ÄùÁöÑÊÉÖÂÜµ‰∏ÄÊ†∑ÔºåÂØπË±°ÁöÑidÂÄº‰∏éÊµÖÂ§çÂà∂ÂéüÊù•ÁöÑÂÄºÁõ∏Âêå„ÄÇ 2ÔºâÂΩìÊµÖÂ§çÂà∂ÁöÑÂÄºÊòØÂèØÂèòÂØπË±°ÔºàÂàóË°®ÂíåÂÖÉÁªÑÔºâÊó∂‰ºö‰∫ßÁîü‰∏Ä‰∏™‚Äú‰∏çÊòØÈÇ£‰πàÁã¨Á´ãÁöÑÂØπË±°‚ÄùÂ≠òÂú®„ÄÇÊúâ‰∏§ÁßçÊÉÖÂÜµ ‰∏çÂêåÊï∞ÊçÆÁ±ªÂûã Êü•ÁúãÊï∞ÊçÆÁ±ªÂûãÔºötype(object) ‰∏çÂêåÁöÑÊï∞ÊçÆÁªìÊûÑ ÂàóË°® ÂèØÈáçÂ§çÔºåÁ±ªÂûãÂèØ‰∏çÂêåÔºåÂèØ‰ª•ÈÅçÂéÜ extend (Êâ©Â±ï) Ôºö‰ª•ÂàóË°®Â¢ûÂä† append (ËøΩÂä†)Ôºö‰∏çÂêåÁ±ªÂûãÁöÑÊï∞ÊçÆ [‚Äòa‚Äô, ‚Äòb‚Äô, ‚Äòc‚Äô, 1, 2, [1, 2]] ÂÖÉÁªÑ ÂèØÈáçÂ§çÔºåÁ±ªÂûãÂèØ‰∏çÂêåÔºõÂèØ‰ª•ÈÅçÂéÜ Âè™ËØªÁöÑÔºå‰∏çËÉΩ‰øÆÊîπ tuple1 = (1,2,‚Äôa‚Äô,4,‚Äô5‚Äô,6) numpyÁöÑÊï∞ÁªÑ Á±ªÂûã‰∏ÄÊ†∑ b = np.array([6, 7, 8]) Â≠óÂÖ∏ ÈîÆÂíåÂÄºÔºåÂèØ‰ª•‰∏çÂêåÁ±ªÂûãÔºåÊó†Â∫èÂ≠òÂÇ® ÂèØÂèòÔºõ‰ªéÂ≠óÂÖ∏‰∏≠Âà†Èô§ÂÖÉÁ¥† del dict1[‚Äòsex‚Äô]ÔºõÊ∏ÖÈô§ÊâÄÊúâÂÖÉÁ¥†dict1.clear()ÔºõÂ¢ûÂä†ÂÖÉÁ¥† ÈõÜÂêà ÈîÆÔºåÊó†Â∫èÁªÑÂêà ÂèØ‰ª•Â¢ûÂä†Âà†Èô§ÂÖÉÁ¥†set2.add(10)Ôºåset2.remove(6)Ôºåset2.discard(6)(ÂèØ‰ª•Âà†Èô§Á©∫ÂÖÉÁ¥†); ‰∏çÂêåÁöÑÈõÜÂêàÊîØÊåÅunion(ËÅîÂêà), intersection(‰∫§), difference(Â∑Æ)Âíåsysmmetric difference(ÂØπÁß∞Â∑ÆÈõÜ)Á≠âÊï∞Â≠¶ËøêÁÆóÔºõ ‰∏çÊîØÊåÅ Á¥¢Âºï, ÂàÜÁâá, ÊàñÂÖ∂ÂÆÉÁ±ªÂ∫è(sequence-likeÔºâ ÂèØÂ∞ÜÂÖÉÁ•ñÂíåÂàóË°®ËΩ¨Âåñ‰∏∫ÈõÜÂêàset2 = set(list1) ÂèØÂèòÔºöÂàóË°®„ÄÅÂ≠óÂÖ∏„ÄÅÈõÜÂêàÔºàÂ≠òÂú®Âõ∫ÂÆöÈõÜÂêàfrozensetÔºâ ‰∏çÂèØÂèòÔºöÂÖÉÁªÑ„ÄÅint„ÄÅ string„ÄÅ float ÂΩì‰º†ËøáÊù•ÁöÑÊòØÂèØÂèòÁ±ªÂûã(list,dict)Êó∂ÔºåÊàë‰ª¨Âú®ÂáΩÊï∞ÂÜÖÈÉ®‰øÆÊîπÂ∞±‰ºöÂΩ±ÂìçÂáΩÊï∞Â§ñÈÉ®ÁöÑÂèòÈáè„ÄÇËÄå‰º†ÂÖ•ÁöÑÊòØ‰∏çÂèØÂèòÁ±ªÂûãÊó∂Âú®ÂáΩÊï∞ÂÜÖÈÉ®‰øÆÊîπÊîπÂèòÈáèÂπ∂‰∏ç‰ºöÂΩ±ÂìçÂáΩÊï∞Â§ñÈÉ®ÁöÑÂèòÈáèÔºåÂõ†‰∏∫‰øÆÊîπÁöÑÊó∂ÂÄô‰ºöÂÖàÂ§çÂà∂‰∏Ä‰ªΩÂÜç‰øÆÊîπ„ÄÇ Êü•Áúã‰∏çÂêåÊï∞ÊçÆÁ±ªÂûãÁöÑÈïøÂ∫¶ Torch.tensor Êï∞ÊçÆÁ±ªÂûãÁöÑËΩ¨Âåñhttps://blog.csdn.net/A632189007/article/details/77989287 ‰æãÂ¶ÇÔºöÂ≠óÁ¨¶‰∏≤Êï∞ÁªÑËΩ¨Êç¢‰∏∫Êï∞ÂÄºÂûã 1numeric_strings = np.array(['1.2','2.3','3.2141'], dtype=np.string_) Êñá‰ª∂Êìç‰Ωú Ëé∑ÂèñÊñá‰ª∂ÂÜÖÁöÑÊñá‰ª∂ÂêçÂ≠ó 123456import ospath = "d:\\data" # ËÆæÁΩÆË∑ØÂæÑdirs = os.listdir(path) # Ëé∑ÂèñÊåáÂÆöË∑ØÂæÑ‰∏ãÁöÑÊñá‰ª∂for i in dirs: # Âæ™ÁéØËØªÂèñË∑ØÂæÑ‰∏ãÁöÑÊñá‰ª∂Âπ∂Á≠õÈÄâËæìÂá∫ if os.path.splitext(i)[1] == ".csv": # Á≠õÈÄâcsvÊñá‰ª∂ print i ÁªÑÊàêË∑ØÂæÑÂêçÂ≠ó Â∫ìImport Ê®°ÂùóÂíåÂåÖÔºöÂåÖÊòØ‰∏∫‰∫ÜËß£ÂÜ≥Ê®°ÂùóÈáçÂëΩÂêçÁöÑÈóÆÈ¢ò„ÄÇ Ê®°ÂùóÔºöÂ∞±ÊòØ‰∏Ä‰∫õ.pyÊñá‰ª∂ÔºåÂèØ‰ª•ÂåÖÂê´ÂáΩÊï∞„ÄÅÂèòÈáè„ÄÅÁ±ªÁ≠âÁ¨¶Âè∑Ôºõ ÂåÖÔºöÁî±Ê®°ÂùóÂèäÂ≠êÂåÖÁªÑÊàê Âú®Ê®°ÂùóA‰∏≠ from math import sqrtÔºåÈÇ£‰πàsqrtÂáΩÊï∞‰ºöÁõ¥Êé•ÂØºÂÖ•Âà∞ÂΩìÂâçÁöÑÂëΩÂêçÁ©∫Èó¥‰∏≠Êù•ÔºåÂπ∂Ê≤°ÊúâÂàõÂª∫Êñ∞ÁöÑÂëΩÂêçÁ©∫Èó¥ „ÄÇÊâÄ‰ª•Â∞±ÂèØ‰ª•Âú®AÁõ¥Êé•‰ΩøÁî®sqrt()ÂáΩÊï∞‰∫Ü„ÄÇÂú®ÊüêÊ®°ÂùóA‰∏≠import mathÊó∂Ôºå‰ºöÂú®A‰∏≠ÂàõÂª∫‰∏Ä‰∏™ÂëΩÂêçÁ©∫Èó¥ÔºåÂπ∂Âú®Ëøô‰∏™ÂëΩÂêçÁ©∫Èó¥‰∏≠ÊâßË°åmath.pyÂΩì‰∏≠ÁöÑ‰ª£Á†ÅÔºåÂπ∂‰∏îÂú®A‰∏≠ÂàõÂª∫‰∫ÜmathËøô‰∏™ÂêçÁß∞Êù•ÂºïÁî®Ëøô‰∏™ÂëΩÂêçÁ©∫Èó¥„ÄÇ ÂçïÁã¨ÂØºÂÖ•ÂåÖÂêç(import package)‰∏ç‰ºöÂØºÂÖ•ÂåÖ‰∏≠ÊâÄÂåÖÂê´ÁöÑÊâÄÊúâÂ≠êÊ®°Âùó„ÄÇ ÂåÖÁöÑinit.pyÊñá‰ª∂‰∏∫Á©∫Êó∂ÔºåÂØºÂÖ•ÂåÖÂêçÊ≤°Ê≥ï‰ΩøÁî®ÂåÖÂÜÖÁöÑÂ≠êÂåÖÂèäÊ®°Âùó ÂåÖÁöÑinit.pyÂπ∂‰∏ç‰∏∫Á©∫ ÔºåËØ•Êñá‰ª∂ÂèØ‰ª•ÂàùÂßãÂåñÔºåÂØºÂÖ•‰∏Ä‰∫õÂ∏∏Áî®ÁöÑÂåÖ** Â∫ìÁöÑÂçáÁ∫ß1pip install --upgrade requests // mac,linux,unix Âú®ÂëΩ‰ª§ÂâçÂä† sudo -H Â≠óÁ¨¶‰∏≤Â§ÑÁêÜ+/Ôºöhttps://blog.csdn.net/qq_878799579/article/details/74279842 os.path.joinÔºö ÂèåÂºïÂè∑ÂíåÂçïÂºïÂè∑ÁöÑÂå∫Âà´Ôºö Â∞èÂÜôÂ§ÑÁêÜ lower() ÊñπÊ≥ïËΩ¨Êç¢Â≠óÁ¨¶‰∏≤‰∏≠ÊâÄÊúâÂ§ßÂÜôÂ≠óÁ¨¶‰∏∫Â∞èÂÜô„ÄÇ 1str.lower() Áü©ÈòµÂ§ÑÁêÜPython Ëø≠‰ª£Âô®‰∏éÁîüÊàêÂô®ÁîüÊàêÂô®ÂíåËø≠‰ª£Âô®ÁöÑÂÖ≥Á≥ª: ÁîüÊàêÂô®ÊòØËø≠‰ª£Âô®ÁöÑ‰∏ÄÁßç ÁîüÊàêÂô®ÈÄöËøá‰∏Ä‰∏™ÂáΩÊï∞ÂàõÂª∫ÂàóË°®Ôºå‰ΩÜÊòØ‰∏ç‰∏ÄÊ¨°ÊÄßÂàõÂª∫ÂÆåÊØïÔºåÂõ†ËÄåËäÇÁúÅÂÜÖÂ≠òÔºåÂπ∂‰∏îË°®Áé∞ÂæóÂç¥ÂÉèÊòØËø≠‰ª£Âô®„ÄÇ ÂèØËø≠‰ª£ÂØπË±°ÔºàÂèØ‰ª•Áî®Âú® for ËØ≠Âè•ËøõË°åÂæ™ÁéØÁöÑÂØπË±°Ôºâ 1.Êï∞ÊçÆÁ±ªÂûãÔºàÂàóË°®„ÄÅÂÖÉÁªÑ„ÄÅÂ≠óÁ¨¶‰∏≤„ÄÅÂ≠óÂÖ∏Á≠âÔºâ 123451.for i in [1, 2, 3]: print(i)2.obj = &#123;"a": 123, "b": 456&#125;for k in obj: print(k) 2.Ëá™Â∑±ÂàõÂª∫ÁöÑËø≠‰ª£Âô® Ëø≠‰ª£Âô®ÁöÑÂàõÂª∫ÊñπÊ≥ï: ‰∏∫ÂÆπÂô®ÂØπË±°Ê∑ªÂä† iter() Âíå next() ÊñπÊ≥ï 12345678910111213141516class Container: def __init__(self, start = 0, end = 0): self.start = start self.end = end def __iter__(self): print("[LOG] I made this iterator!") return self def __next__(self): print("[LOG] Calling __next__ method!") if self.start &lt; self.end: i = self.start self.start += 1 return i else: raise StopIteration()c = Container(0, 5) ÂÜÖÁΩÆÂáΩÊï∞ iter() Â∞ÜÂèØËø≠‰ª£ÂØπË±°ËΩ¨Âåñ‰∏∫Ëø≠‰ª£Âô® 1234567ita = iter([1, 2, 3])print(type(ita))ita = iter([1, 2, 3])print(type(ita))print(type([1, 2, 3]))&lt;class 'list_iterator'&gt;&lt;class 'list'&gt; ÁîüÊàêÂô®ÔºàgeneratorÔºâ 1234567def container(start, end): while start &lt; end: yield start start += 1c = container(0, 5)Python&lt;class 'generator'&gt; ÂáΩÊï∞splitÈÄöËøáÊåáÂÆöÂàÜÈöîÁ¨¶ÂØπÂ≠óÁ¨¶‰∏≤ËøõË°åÂàáÁâáÔºåÂ¶ÇÊûúÂèÇÊï∞num ÊúâÊåáÂÆöÂÄºÔºåÂàô‰ªÖÂàÜÈöî num ‰∏™Â≠êÂ≠óÁ¨¶‰∏≤ 1234#!/usr/bin/pythonstr = "Line1-abcdef \nLine2-abc \nLine4-abcd";print str.split( );print str.split(' ', 1 ); findÊ£ÄÊµãÂ≠óÁ¨¶‰∏≤‰∏≠ÊòØÂê¶ÂåÖÂê´Â≠êÂ≠óÁ¨¶‰∏≤ str ÔºåÂ¶ÇÊûúÊåáÂÆö begÔºàÂºÄÂßãÔºâ Âíå endÔºàÁªìÊùüÔºâ ËåÉÂõ¥ÔºåÂàôÊ£ÄÊü•ÊòØÂê¶ÂåÖÂê´Âú®ÊåáÂÆöËåÉÂõ¥ÂÜÖÔºåÂ¶ÇÊûúÂåÖÂê´Â≠êÂ≠óÁ¨¶‰∏≤ËøîÂõûÂºÄÂßãÁöÑÁ¥¢ÂºïÂÄºÔºåÂê¶ÂàôËøîÂõû-1„ÄÇ 1str.find(str, beg=0, end=len(string)) print1print('t=&#123;&#125;,loss=&#123;:.6f&#125;'.format(t,loss)) numpyÁöÑËæìÂá∫1234567891011# ‰ΩøÁî®set_printoptionsËÆæÁΩÆËæìÂá∫ÁöÑÁ≤æÂ∫¶import numpy as npx=np.random.random(10)np.set_printoptions(precision=3)print(x)# ÊäëÂà∂‰ΩøÁî®ÂØπÂ∞èÊï∞ÁöÑÁßëÂ≠¶ËÆ∞Êï∞Ê≥ïy=np.array([1.5e-10,1.5,1500])print(y)# [ 1.500e-10 1.500e+00 1.500e+03]np.set_printoptions(suppress=True)print(y) ÂêàÂπ∂‰∏§‰∏™Áü©Èòµ1234#hstack()Âú®Ë°å‰∏äÂêàÂπ∂ Ëøô‰∏™ÂÆûÈ™åÁªìÊûú‰∏çÂØπ np.hstack((a,b)) #vstack()Âú®Âàó‰∏äÂêàÂπ∂ np.vstack((a,b)) squeezeËØ≠Ê≥ïÔºönumpy.squeeze(a,axis = None) 1ÔºâaË°®Á§∫ËæìÂÖ•ÁöÑÊï∞ÁªÑÔºõ2ÔºâaxisÁî®‰∫éÊåáÂÆöÈúÄË¶ÅÂà†Èô§ÁöÑÁª¥Â∫¶Ôºå‰ΩÜÊòØÊåáÂÆöÁöÑÁª¥Â∫¶ÂøÖÈ°ª‰∏∫ÂçïÁª¥Â∫¶ÔºåÂê¶ÂàôÂ∞Ü‰ºöÊä•ÈîôÔºõ3ÔºâaxisÁöÑÂèñÂÄºÂèØ‰∏∫None Êàñ int Êàñ tuple of ints, ÂèØÈÄâ„ÄÇËã•axis‰∏∫Á©∫ÔºåÂàôÂà†Èô§ÊâÄÊúâÂçïÁª¥Â∫¶ÁöÑÊù°ÁõÆÔºõ ‰ªéÊï∞ÁªÑÁöÑÂΩ¢Áä∂‰∏≠Âà†Èô§ÂçïÁª¥Â∫¶Êù°ÁõÆÔºåÂç≥Êääshape‰∏≠‰∏∫1ÁöÑÁª¥Â∫¶ÂéªÊéâ ‰ΩúÁî®Ôºö‰ªéÊï∞ÁªÑÁöÑÂΩ¢Áä∂‰∏≠Âà†Èô§ÂçïÁª¥Â∫¶Êù°ÁõÆÔºåÂç≥Êääshape‰∏≠‰∏∫1ÁöÑÁª¥Â∫¶ÂéªÊéâ ‰æãÂ≠êÔºö 123456789101112131415161718e = np.arange(10).reshape(1,10,1)e: array([[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]]])np.squeeze(e)e: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])#Ê≠£Â∏∏ÊòæÁ§∫ÂõæÁ§∫Ê°à‰æã#ÈÄöËøánp.squeeze()ÂáΩÊï∞ËΩ¨Êç¢ÂêéÔºåË¶ÅÊòæÁ§∫ÁöÑÊï∞ÁªÑÂèòÊàê‰∫ÜÁß©‰∏∫1ÁöÑÊï∞ÁªÑÔºåÂç≥Ôºà5ÔºåÔºâplt.plot(np.squeeze(squares)) plt.show() getattr123456789101112131415161718# Ëé∑Âæó‰∏Ä‰∏™Ê†áÈáè&gt;&gt;&gt;class A(object):... bar = 1... &gt;&gt;&gt; a = A()&gt;&gt;&gt; getattr(a, &apos;bar&apos;) # Ëé∑ÂèñÂ±ûÊÄß bar ÂÄº1# Ëé∑Âæó‰∏Ä‰∏™ÂáΩÊï∞&gt;&gt;&gt; class A(object): ... def set(self, a, b):... x = a ... a = b ... b = x ... print a, b &gt;&gt;&gt; a = A() &gt;&gt;&gt; c = getattr(a, &apos;set&apos;)&gt;&gt;&gt; c(a=&apos;1&apos;, b=&apos;2&apos;)2 1 ÈÄªËæëÂ§ÑÁêÜ Êù°‰ª∂ËØ≠Âè• 1 x = int(input(‚ÄúPlease enter an integer: ‚Äú)) Please enter an integer: 42if x &lt; 0: ‚Ä¶ x = 0 ‚Ä¶ print(‚ÄòNegative changed to zero‚Äô) ‚Ä¶ elif x == 0: ‚Ä¶ print(‚ÄòZero‚Äô) ‚Ä¶ elif x == 1: ‚Ä¶ print(‚ÄòSingle‚Äô) ‚Ä¶ else: ‚Ä¶ print(‚ÄòMore‚Äô) ‚Ä¶ 12&gt;&gt;&gt; &gt;&gt;&gt; pythonÁöÑÊ≥®ÈáäÊ†ºÂºèpythonÁöÑÊ≥®ÈáäÊ†ºÂºè Python ÂõæÂÉè „Äêpytorch„ÄëÂõæÂÉèÂü∫Êú¨Êìç‰Ωú ‰∏çÂêåÁöÑËØªÂèñÊñπÂºè: cv2 ski.. PILÂ∫ìÁöÑ‰ΩøÁî® import matplotlib ImageËØªÂá∫Êù•ÁöÑÊòØPILÁöÑÁ±ªÂûãÔºåËÄåskimage.iÁöÑÂØπÊØî PILÊãÜÂàÜ„ÄÅÂêàÂπ∂„ÄÅÂêàÊàêËßÜÈ¢ë Áî®PILÊòæÁ§∫ÂõæÂÉè ÂØπÂõæÂÉèÂä†Âô™Â£∞„ÄÅÊª§Ê≥¢Â§çÂéü https://www.cnblogs.com/lynsyklate/p/8047510.html Debug [x] Êñá‰ª∂ÈòÖËØªÊó∂ÔºåÂá∫Áé∞Êó†Ê≥ïÂàõÂª∫Êñá‰ª∂ÁöÑÈóÆÈ¢ò„ÄÇÔºàËØ•Êñá‰ª∂Ë¢´Âè¶‰∏ÄËøõÁ®ãÈòÖËØª‰∏≠Ôºâ why can the same file not opened by several processes? @wqn628 Because that requires the hdf5-library to be built with parallel extensions. You can open an HDF5-file for read-only in multiple processes, but you cannot open it for read/write in more than one process unless the library has been built with parallel enabled.The reason for this is because HDF5-files write to the file the moment you close them, not the moment you tell them to write. Therefore, in serial, corruption would be very likely. The best way to deal with this is by simply opening the HDF5-file for read-only in both Python scripts. That should work perfectly fine. [x] NoneType‰πãÊâÄ‰ª•Âá∫Áé∞ÔºåËØ•ÂèÇÊï∞Ê≤°ÊúâË¢´ÂàõÂª∫ÊàñËÄÖËµãÂÄºÔºåÂè™Ë¢´Âèñ‰∫ÜÂêçÂ≠ó„ÄÇ Ë¶ÅÁêÜËß£Ëøô‰∏™ÔºåÈ¶ñÂÖàË¶ÅÁêÜËß£PythonÂØπË±°ÔºåpythonÂØπË±°ÂÖ∑Êúâ‰∏â‰∏™ÁâπÊÄßÔºöË∫´‰ªΩ„ÄÅÁ±ªÂûã„ÄÅÂÄº„ÄÇ Ëøô‰∏â‰∏™ÁâπÊÄßÂú®ÂØπË±°ÂàõÂª∫Êó∂Ë¢´ËµãÂÄº„ÄÇÂè™ÊúâÂÄºÂèØ‰ª•ÊîπÂèòÔºåÂÖ∂‰ªñÂè™ËØª„ÄÇÁ±ªÂûãÊú¨Ë∫´‰πüÊòØÂØπË±°„ÄÇ Null‰∏éNoneÊòØPythonÁöÑÁâπÊÆäÁ±ªÂûãÔºåNullÂØπË±°ÊàñËÄÖÊòØNone TypeÔºåÂÆÉÂè™Êúâ‰∏Ä‰∏™ÂÄºNone. ÂÆÉ‰∏çÊîØÊåÅ‰ªª‰ΩïËøêÁÆó‰πüÊ≤°Êúâ‰ªª‰ΩïÂÜÖÂª∫ÊñπÊ≥ï. NoneÂíå‰ªª‰ΩïÂÖ∂‰ªñÁöÑÊï∞ÊçÆÁ±ªÂûãÊØîËæÉÊ∞∏ËøúËøîÂõûFalse„ÄÇ NoneÊúâËá™Â∑±ÁöÑÊï∞ÊçÆÁ±ªÂûãNoneType„ÄÇ‰Ω†ÂèØ‰ª•Â∞ÜNoneÂ§çÂà∂Áªô‰ªª‰ΩïÂèòÈáèÔºå‰ΩÜÊòØ‰Ω†‰∏çËÉΩÂàõÂª∫ÂÖ∂‰ªñNoneTypeÂØπË±°„ÄÇ ‰∏ÄÂè•ËØùÊÄªÁªìÔºöNullÂØπË±°ÊòØpythonÂØπË±°ÔºåÂèàÂè´ÂÅöNoneTypeÔºåNoneÊòØËøô‰∏™ÂØπË±°ÁöÑÂÄº„ÄÇ ÁúãËøá‰∫ÜNoneTypeÁöÑËß£ÈáäÔºå‰πãÊâÄ‰ª•Âá∫Áé∞NoneÂ∞±ÂæàÂ•ΩÁêÜËß£‰∫Ü„ÄÇ Ë¶ÅÊ≠£Á°ÆÂÆö‰ΩçbugÂá∫Áé∞ÁöÑ‰ΩçÁΩÆÔºå‰πãÂâçÈÇ£‰∏™logwriteÊ≤°ÊúâÂÆö‰ΩçÂáÜÁ°ÆÔºåÂØºËá¥Êâæ‰∏çÂà∞ÂéüÂõ†„ÄÇ Ë¶ÅÂÖ≥Ê≥®ÈîôËØØ‰ø°ÊÅØ„ÄÇ Áü©ÈòµÊìç‰Ωú NumpyÊ±ÇÊúÄÂ§ßÂÄº„ÄÅ ÊúÄÂ∞èÂÄº) argsÂíå*kwargsÂ¶Ç‰ΩïÂú®Python3‰∏≠‰ΩøÁî®argsÂíå*kwargs]]></content>
      <categories>
        <category>Ê∑±Â∫¶Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂéªÂô™‰º†ÁªüÊñπÊ≥ïËÆ∫ÊñáÁªºËø∞]]></title>
    <url>%2Fp%2F8245.html</url>
    <content type="text"><![CDATA[ÊúüÂàä‰ºöËÆÆ ËÆ°ÁÆóÊú∫ËßÜËßâÊúüÂàä AÁ±ª TPAMI: IEEE Trans on Pattern Analysis and Machine Intelligence IJCV: International Journal of Computer Vision TIP: IEEE Transactions on Image Processing BÁ±ª CVIU: Computer Vision and Image Understanding Pattern Recognition CÁ±ª IET-CVI: IET Computer Vision IVC: Image and Vision Computing IJPRAI: International Journal of Pattern Recognition and Artificial Intelligence Machine Vision and Applications PRL: Pattern Recognition Letters ËÆ°ÁÆóÊú∫ËßÜËßâ‰ºöËÆÆ AÁ±ª ICCV: International Conference on Computer Vision CVPR: International Conference on Computer Vision and Pattern Recognition AAAI: AAAI Conference on Artificial Intelligence ICML: International Conference on Machine Learning NIPS: Annual Conference on Neural Information Processing Systems ACM MM: ACM International Conference on Multimedia BÁ±ª ECCV: European Conference on Computer Vision CÁ±ª ACCV: Asian Conference on Computer Vision ICPR: International Conference on Pattern Recognition BMVC: British Machine Vision Conference Â∫îÁî®Êï∞Â≠¶ÊúüÂàä JMIV: Journal of Mathematical Imaging and Vision Â∫îÁî®Êï∞Â≠¶‰ºöËÆÆ Ê£ÄÁ¥¢Â∑•ÂÖ∑ ÊúüÂàäÂΩ±ÂìçÂõ†Â≠êÊü•ËØ¢ÁΩëÁ´ôÔºö‰∏≠Êñá„ÄÅ Ëã±ÊñáÁΩëÁ´ô Âá∫ÁâàÂïÜ„ÄÅÊï∞ÊçÆÂ∫ì„ÄÅÊ£ÄÁ¥¢Â∑•ÂÖ∑ IEEEÂíåSpringerÊòØÂá∫ÁâàÂïÜÔºåÂπ∂‰∏îÊã•ÊúâËá™Â∑±ÁöÑÊï∞ÊçÆÂ∫ìÂíåÊ£ÄÁ¥¢Â∑•ÂÖ∑„ÄÇ Â¶ÇÔºöIEEEÊúâIEEExplorerÊ£ÄÁ¥¢„ÄÇ ÂÖ∂‰ªñÊï∞ÊçÆÂ∫ìËá™Â∑±ÔºàÊØîÂ¶ÇEI, EBSCOhostÁ≠âÁ≠âÔºâÂèØ‰ª•ÊäìÂèñÂá∫ÁâàÂïÜÊï∞ÊçÆÂ∫ìÈáåÈù¢ÁöÑÊñáÁ´†„ÄÇÊØîÂ¶ÇEngineeringVillage (EI)Âú®IEEExplorerÊäìÂèñÊñáÁ´†ÁöÑÂÜÖÂÆπÔºõËøôÊó∂ÂÄô‰ΩúËÄÖÁöÑÊñáÁ´†Â∞±ËÉΩÂú®EIÈáåÈù¢Êü•Âà∞‰∫Ü„ÄÇ Google/Google Scholar/Scirus/ScienceDirect/IEEExplorer/ISIËøô‰∫õÈÉΩÊòØÊ£ÄÁ¥¢Â∑•ÂÖ∑ SCI(Science Citation Index)ÊòØÂΩ±ÂìçÂõ†Â≠êÔºå‰πüÊòØISIÔºàInstitute Scientific InformationÔºâÂÅöÁöÑÊï∞ÊçÆÂ∫ì„ÄÇ SCI‰∏çÊòØÂá∫ÁâàÂïÜÔºåÂè™ÊòØÊï∞ÊçÆÂ∫ìÔºå‰∏çÊòØÂÖ∑‰ΩìÊüêÁØáÊñáÁ´†ÂÜÖÂÆπÁâàÊùÉÁöÑÊã•ÊúâËÄÖÔºõÊâÄ‰ª•Âú®SCIÈáåÈù¢ÔºåËÉΩÁúãÂà∞Âè™ÊòØÈ¢òÁõÆ+ÊëòË¶Å+ÂèÇËÄÉÊñáÁåÆ„ÄÇSCIÁöÑÂÜÖÂÆπ‰∏çÊòØÂéüÂßãÊñáÁåÆÂÖ®ÊñáÔºåÂçñÁÇπÊòØÊØèÂπ¥Êé®Âá∫JCRÔºåÈáåÈù¢ÁªôÂá∫ÂΩ±ÂìçÂõ†Â≠ê„ÄÇ SIAMÁÆÄ‰ªãÔºöÂõΩÈôÖÂ∑•‰∏ö‰∏éÂ∫îÁî®Êï∞Â≠¶Âçè‰ºö(SIAM), Êóó‰∏ãÂá∫ÁâàÊúâÂ∫îÁî®Êï∞Â≠¶Áõ∏ÂÖ≥ÁöÑËÆ∏Â§öÂõΩÈôÖËëóÂêçÊúüÂàäÊùÇÂøó ÊñáÁåÆÈìæÊé•2019 CVPR Ê±áÊÄª ÂèòÂàÜÁÆóÊ≥ï total variation TV-based image restoration: Rudin Osher and Fatermi in 1992. ‰ºòÁÇπÔºöpreserves edges well, but has sometimes undesirable staircase effect, namely the trans- formation of smooth regions into piecewise constant regions (stairs), which implied that the finer details in the original im- age may not be recovered satisfactorily. Áº∫ÁÇπÔºöstaircasing ‰ªÄ‰πàÊòØstaircasing„ÄÇÂ¶Ç‰ΩïÂèëÁîü„ÄÇÂú®Âì™‰∫õÊÉÖÂÜµ‰∏ãÊõ¥ÂÆπÊòìÂèëÁîü„ÄÇ Èô§‰∫Ünon-local meanÂíåBM3DÔºåÈÉΩÊòØoversmoothed„ÄÇ ÊîπËøõÔºöÂá†Â§ßÁ±ªÊñπÊ≥ï È´òÈò∂ÂÖ®ÂèòÂàÜÊ®° Âûã [8] „ÄÅÂπø‰πâÂÖ®ÂèòÂàÜÊ®°Âûã [9] ÂíåËá™ÈÄÇÂ∫îÂÖ®ÂèòÂàÜÊ®°Âûã [5] Á≠â [7] L.I. Rudin, S.Osher, and E. Fatemi. Nonlinear total variation based noise removal algorithms. Physica D(Nonlinear phenomena), 1992, 60(1 /2 /3 /4) : 259-268. [8] Y. You and M. Kaveh. Fourth-Order partial differential equations for noise removal. IEEE trans on image processing, 2000, 9(10) : 1723-1730. [9] B. Kristian, K. Karl, and P. Thomas. Total generalized variation. SIAM Journal on imaging sciences, 2010, 3(3):492-526. [5] P. Blomgren, T. Chan, P. Mulet, and C. Wong. Total variation image restoration: numerical methods and extensions. In IEEE international conferance on image processing, pages III, 384-387, 1997. Âü∫‰∫éÂ∞èÊ≥¢Ê°ÜÊû∂ÁöÑÂèòÂàÜÊ®°Âûã [14-19] 14„ÄÅChan, Raymond H., et al. ‚ÄúWavelet algorithms for high-resolution image reconstruction.‚Äù SIAM Journal on Scientific Computing 24.4 (2003): 1408-1432 17„ÄÅChan, Raymond, Lixin Shen, and Zuowei Shen. ‚ÄúA framelet-based approach for image inpainting.‚Äù Res. Rep 4 (2005): 325. 16„ÄÅDong, Bin, and Zuowei Shen. ‚ÄúMRA based wavelet frames and applications.‚Äù IAS Lecture Notes Series, Summer Program on ‚ÄúThe Mathematics of Image Processing‚Äù, Park City Mathematics Institute 19 (2010). 15„ÄÅCai, Jian-Feng, Stanley Osher, and Zuowei Shen. ‚ÄúSplit Bregman methods and frame based image restoration.‚Äù Multiscale modeling &amp; simulation 8.2 (2009): 337-369. 19„ÄÅCai, Jian-Feng, et al. ‚ÄúImage restoration: total variation, wavelet frames, and beyond.‚Äù Journal of the American Mathematical Society 25.4 (2012): 1033-1089. 20„ÄÅCai, Jian-Feng, et al. ‚ÄúData-driven tight frame construction and image denoising.‚Äù Applied and Computational Harmonic Analysis 37.1 (2014): 89-105. ÊúÄËøëÂª∫Á´ã‰∫ÜÂ∞èÊ≥¢Ê°ÜÊû∂Âíå ÂèòÂàÜÊ®°Âûã‰πãÈó¥ÁöÑËÅîÁ≥ª„ÄÇ ËøôÁßçËÅîÁ≥ªÁªôÂá∫‰∫ÜÂü∫‰∫éÂ∞èÊ≥¢Ê°Ü Êû∂ÁöÑÂèòÂàÜÊ®°Âûã‰ºò‰∫éÂÖ∂‰ªñÊüê‰∫õÂèòÂàÜÊ®°ÂûãÁöÑÁêÜËÆ∫‰æùÊçÆÔºå Âç≥Âü∫‰∫éÂ∞èÊ≥¢Ê°ÜÊû∂ÁöÑÂèòÂàÜÊ®°ÂûãÂèØ‰ª•Ê†πÊçÆÊΩúÂú®ÁöÑËß£ÁöÑÂ•á ÁÇπÁöÑÈ°∫Â∫èÔºåÂú®ÁªôÂÆöÂõæÂÉèÁöÑ‰∏çÂêåÂå∫Âüü‰∏≠Ëá™ÈÄÇÂ∫îÂú∞ÈÄâÊã©ÂæÆ ÂàÜÁÆóÂ≠ê„ÄÇÂèàÂü∫‰∫éÂõæÂÉèÊï∞ÊçÆÁªìÊûÑÁâπÂæÅÔºå ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊï∞ÊçÆÈ©±Âä®Á¥ß Ê°ÜÊû∂Ôºå ËØ•Ê°ÜÊû∂ÊØî‰ª•ÂæÄÁöÑÊ®°ÂûãÊõ¥ËÉΩÁ≤æÁ°ÆÂú∞ÈáçÊûÑÂõæÂÉè„ÄÇ ÂéªÂô™ ‰∏çÂêåÁöÑÊª§Ê≥¢Âô®Áî®‰∫é‰∏çÂêåÁöÑÂô™Â£∞ÔºåÊüê‰∏Ä‰∏™ÈôçÂô™Êª§Ê≥¢Âô®ÂæàÈöæÁ¨¶ÊâÄÊúâÁöÑÂô™Â£∞„ÄÇ È¶ñÂÖàÔºåËØ¥‰∏Ä‰∏ãÂô™Â£∞ÁöÑÁ±ªÂûãÔºåÂô™Â£∞ÁöÑÂàÜÁ±ªÂíåËØ•Âô™Â£∞ÁöÑÂàÜÂ∏ÉÁ¨¶Âêà‰ªÄ‰πàÊ®°ÂûãÊúâÂÖ≥ÔºåÂ∏∏ËßÅÁöÑÂô™Â£∞ÊúâÈ´òÊñØÁôΩÂô™Â£∞„ÄÅÊ§íÁõêÂô™Â£∞„ÄÅÊ≥äÊùæÂàÜÂ∏ÉÂô™Â£∞„ÄÅÊåáÊï∞ÂàÜÂ∏ÉÂô™Â£∞Á≠â„ÄÇ ÂÖ∂Ê¨°ÔºåÈááÁî®ÁöÑÊª§Ê≥¢Âô®ÊúâÁ©∫ÂüüÊª§Ê≥¢Âô®ÔºåÊØîÂ¶ÇÂùáÂÄºÊª§Ê≥¢Âô®„ÄÅ‰∏≠ÂÄºÊª§Ê≥¢Âô®„ÄÅ‰ΩéÈÄöÊª§Ê≥¢Âô®„ÄÅÈ´òÊñØÊª§Ê≥¢Á≠âÔºõÈ¢ëÂüüÊª§Ê≥¢Âô®ÔºåÊØîÂ¶ÇÂ∞èÊ≥¢ÂèòÊç¢„ÄÅÂÇÖÈáåÂè∂ÂèòÊç¢„ÄÅ‰ΩôÂº¶ÂèòÊç¢Á≠âÔºõÂΩ¢ÊÄÅÂ≠¶Êª§Ê≥¢Âô®Ôºå‰∏ªË¶ÅÊòØÈÄöËøáËÜ®ËÉÄÂíåËÖêËöÄÁ≠âÂΩ¢ÊÄÅÂ≠¶Êìç‰ΩúËøõË°åÂéªÂô™„ÄÇ Á¨¨‰∏âÔºåÂØπÂ∫îÂú∫Âêà„ÄÇ‰∏ÄËà¨Âπ≥Êó∂ËßÅÁöÑÊØîËæÉÂ§öÊòØÊòØÈ´òÊñØÁôΩÂô™Â£∞ÔºåÂÉèÁî®ÂùáÂÄºÊª§Ê≥¢„ÄÅ‰∏≠ÂÄºÊª§Ê≥¢„ÄÅÈ´òÊñØÊª§Ê≥¢ÂèØ‰ª•ÂéªÂô™„ÄÇËøòÊúâÂú®‰ΩéÁÖßÂ∫¶‰∏ãÔºåÊØîÂ¶ÇÊôö‰∏äÊãçÁÖßÊó∂ÁöÑÂõæÂÉèÔºå‰∏ÄËà¨Â±û‰∫éÊ≥äÊùæÂàÜÂ∏ÉÁöÑÂô™Â£∞ÔºåÂèØ‰ª•ÈááÁî®‰∏Ä‰∫õ3dÂéªÂô™ÁÆóÊ≥ïÔºåÊØîÂ¶ÇÊïàÊûú‰∏çÈîôÁöÑBM3DÁÆóÊ≥ï„ÄÇÂÉèÊ§íÁõêÂô™Â£∞Ôºå‰∏ÄËà¨Áî®‰∏≠ÂÄºÊª§Ê≥¢Âü∫Êú¨ÂèØ‰ª•ÂéªÂô™„ÄÇ ÊñáÁåÆÂõûÈ°æ‰ª•Âèä‰ª£Á†ÅgithubÂéªÂô™ÊäÄÊúØÁöÑÊñπÊ≥ïÂíå‰ª£Á†ÅÂÆûÁé∞ÊÄªÁªì Êª§Ê≥¢Ê≥ïÔºöÁ©∫Èó¥ÂüüÂíåÂèòÊç¢Âüü (Á©∫Èó¥Âüü) Gaussian filter (ËΩ¨ÂåñÂüü) Wavelet-based(ËØ¶ËßÅTight-frame): tight frame Â∞èÊ≥¢ÂèòÂåñÊñáÁåÆÂõûÈ°æ È©¨Â∞îÂèØÂ§´Âú∫ Markov denoising ÁêÜËß£ ÂÖ®ÂèòÂàÜÊ®°ÂûãÔºàÂèòÂàÜÊ≥ïÁöÑ‰∏ÄÁßçÔºâ ROFÊ®°Âûã, 1992 L. Rudin, S. Osher, E. Fatemi, Nonlinear Total Variation based noise removal algorithm, Physica D 60 259-268, 1992. ++paper \min _{u} \int_{\Omega}\left(\alpha|\nabla u|+\frac{1}{2}(u-z)^{2}\right) ‰∏éROFÁõ∏ÂÖ≥ËÅîÁöÑÂÅèÂæÆÂàÜÊñπÁ®ã‰ª•ÂèäÊé®ÂØº ÁõÆÊ†áÊñπÁ®ãÔºö \begin{array}{l}{J[u(x, y)]=\iint_{\Omega}|\nabla u(x, y)| \mathrm{d} x \mathrm{d} y+\quad \frac{\lambda}{2} \iint_{\Omega}\left(u(x, y)-u^{0}(x, y)\right)^{2} \mathrm{d} x \mathrm{d} y}\end{array}ËØ•Ê≥õÂáΩÊòØ J[u(x, y)]=\iint_{\Omega} F\left(x, y, u, \frac{\partial u}{\partial x}, \frac{\partial u}{\partial y}\right) \mathrm{d} x \mathrm{d} yÂûãÁöÑÊ≥õÂáΩÔºåÂÖ∂‰∏≠(Âºè1) \begin{aligned} F=&|\nabla u(x, y)|+\frac{\lambda}{2}\left(u(x, y)-u^{0}(x, y)\right)^{2}= \\&\sqrt{\left(\frac{\partial u(x, y)}{\partial x}\right)^{2}+\left(\frac{\partial u(x, y)}{\partial y}\right)^{2}}+\frac{\lambda}{2}\left(u(x, y)-u^{0}(x, y)\right)^{2} \end{aligned} $$ {222} ËØ•Á±ªÂáΩÊï∞Ê±ÇÊûÅÂÄºÁöÑÂøÖË¶ÅÊù°‰ª∂ÔºåÂç≥Ê¨ßÊãâ-ÊãâÊ†ºÊúóÊó•ÊñπÁ®ã(PDE):F_{H}-\frac{\partial}{\partial x}\left\{F_{p}\right\}-\frac{\partial}{\partial y}\left\{F_{q}\right\}=0 ÂÖ∂‰∏≠, $p=\frac{\partial u(x, y)}{\partial x}, q=\frac{\partial u(x, y)}{\partial y}$. ÂØπ‰∫éÂºè1ÔºåÊúâ$F_{H}=\lambda\left(u-u^{0}\right), F_{p}=\frac{\frac{\partial u}{\partial x}}{|\nabla u|}, F_{q}=\frac{\frac{\partial u}{\partial y}}{|\nabla u|}$, ‰ª£ÂÖ•ÂêéÊúâÔºö\begin{array}{l}{\lambda\left(u-u^{0}\right)-\left\{\frac{\partial}{\partial x}\left\{\left(\frac{\frac{\partial u}{\partial x}}{|\nabla u|}\right)\right\}+\frac{\partial}{\partial y}\left\{\frac{\frac{\partial u}{\partial y}}{|\nabla u|}\right\}\right\}=0} \\ {\Rightarrow \lambda\left(u-u^{0}\right)-\left(\frac{\partial}{\partial x}, \frac{\partial}{\partial y}\right) \cdot\left(\frac{\frac{\partial u}{\partial x}}{|\nabla u|}, \frac{\frac{\partial u}{\partial y}}{|\nabla u|}\right)=0} \\ {\Rightarrow \lambda\left(u-u^{0}\right)-\left(\frac{\partial}{\partial x}, \frac{\partial}{\partial y}\right) \cdot\left(\frac{1}{|\nabla u|}\left(\frac{\partial u}{\partial x}, \frac{\partial u}{\partial y}\right)\right)=0} \\ {\Rightarrow \lambda\left(u-u^{0}\right)-\nabla \cdot\left(\frac{\nabla u}{|\nabla u|}\right)=0}\end{array} ÂÖ∂‰∏≠Ôºå$\nabla=\left(\frac{\partial}{\partial x}, \frac{\partial}{\partial y}\right)$‰∏∫Ê¢ØÂ∫¶ÁÆóÂ≠ê„ÄÇ TVÂ§çÂéüÊ®°ÂûãÁöÑÊ¨ßÊãâ‰∏ÄÊãâÊ†ºÊúóÊó•ÊñπÁ®ã‰∏∫ Ôºö-\nabla \cdot\left(\frac{\nabla u}{|\nabla u|}\right)+\lambda\left(u-u^{0}\right)=0$$ using a gradient projection method. Áº∫ÁÇπÔºöÈò∂Ê¢ØÂùóÊïàÂ∫î Ë°®Áé∞ÂΩ¢ÂºèÔºö ‰∫ßÁîüÂéüÂõ†Ôºö ÊîπËøõÊñπÊ≥ï ÂèØ‰ª•ÂàÜ‰∏∫‰∏âÁ±ªÔºö(1) ÂØπl_1ËøõË°åÊîπËøõ (2) È´òÈò∂ÂèòÂàÜ (3) È´òÈò∂ÂÖ®ÂèòÂàÜÊ®°Âûã[8]„ÄÅÂπø‰πâÂÖ®ÂèòÂàÜÊ®°Âûã[9]ÂíåËá™ÈÄÇÂ∫îÂÖ®ÂèòÂàÜÊ®°Âûã[5] (Âú®Ë∞ãÁØá‰∏≠ÊñáÊúüÂàäÁúãÂà∞Ëøá) ‰∫åÈò∂(È´òÈò∂)ÊñπÊ≥ïÊîπËøõstaircasing Â±ÄÈôêÊÄßÔºöÈÄöÂ∏∏ÈúÄË¶ÅÊõ¥Â§çÊùÇÁöÑËæπÁïåÊù°‰ª∂‰ª•ÂèäÁªìÊûúÂæàÂèØËÉΩ‰ºöËøáÂÖâÊªë (‰∫åÈò∂) G. Geman and G. Reynolds, 1992, IEEE Trans. Pattern Anal. Mach. Intel. „ÄäConstrained restoration and the recovery of discontinuities„Äã (‰∫åÈò∂) Chambolle and Lions, 1997, Numer. Math. „ÄäImage recovery via total variation minimization and related problems„Äã: Chambolle and Lions do this by minimizing the inf-convolution of the TV norm and a second order functional. \begin{array}{l}{\min _{u_{1}, u_{2}} \int_{\Omega}\left|\nabla u_{1}\right|+\alpha\left|d^{2} u_{2}\right|+\lambda\left|u_{1}+u_{2}-u_{0}\right|^{2}} \\ {=\min _{u, v} \int_{\Omega}|\nabla u-\nabla v|+\alpha|\nabla(\nabla v)|+\lambda\left|u-u_{0}\right|^{2}}\end{array} \min _{u} \int_{\Omega}\left(\alpha \left|d^{2} u\right|+|\nabla u|+\frac{1}{2}(u-z)^{2}\right) (ÊØçÈ∏°) P. Blomgren, T. F. Chan, and P. Mulet, 1997 „ÄäExtensions to total variation denoising„Äã: The approach is performed by redefining the Total Variation functional R(u) in view of the properties of TV-norm and H1-seminorm. However, it is not completely clear how to choose a function Œ¶, which makes the regularizing functional R(u) being convex. (ÂõõÈò∂) Chan T, Marquina A, Mulet P., 2000, SIAM J Sci Comput, „ÄäHigh-order total variation-based image restoration„Äã: ‚ÄùIn this paper we present an improved model, constructed by adding a nonlinear fourth order diffusive term to the Euler‚ÄìLagrange equations of the variational TV model. ‚Äú \int_{\Omega}\left(\alpha|\nabla u|_{\beta}+\mu \Phi(|\nabla u|)(\mathcal{L}(u))^{2}+\frac{1}{2}(u-z)^{2}\right)where, $\mathcal{L}(u)$ is an elliptic operator and $\Phi(|\nabla u|)$ is the adaptive function. This model retain the good properties of the TV functional and penalize ‚Äúwrong‚Äù edges created in regions which ‚Äúshould‚Äù be smooth. The adaptive functional, in which the action of the second order term is lessened where the gradient is large(avoid oversmooth). (‰∫åÈò∂) O. M. Lysaker and X.-C. Tai, Int. J. Comp. Vis., 2006 „ÄäIterative image restoration combining total variation minimization and a second-order functional„Äã:Instead of combing TV norm and second order derivatives within one regularization functional, Lysaker and Tai [5] use two regularization functionals. ‰∏§‰∏™ÂºèÂ≠êÔºåÂçïÁã¨ÁöÑ‰∏§‰∏™regularization (ÂõõÈò∂ÔºâLi F, Shen C, Fan J, 2007, J Vis Commun Image R „ÄäImage restoration combining a total variational filter and a fourth-order filter„Äã (ÊØçÈ∏°Ôºåhigher-order)Liu G, Huang T, Liu J, 2014, Comput Math Appl „ÄäHigh-order TVL1-based images restoration and spatially adapted regularization parameter selection„Äã TGV, Bredies, K., Kunisch, K., &amp; Pock, T. (2010), SIAM Journal on Imaging Sciences \mathrm{TGV}_{\alpha}^{k}=\left(\sum_{l=0}^{k-1} I_{K_{\alpha_{l}}^{l}}\right)^{*} \operatorname{TGV}_{\alpha}^{k}(u)=\underset{w_{0}+\ldots+u_{k-1}=u \atop l=0, \ldots, k-1}{\inf } \sum_{l=0}^{k-1} \alpha_{l}\left\|\nabla^{k-l} u_{l}+w_{l}\right\|_{1}„ÄäTotal generalized variation.„Äã code link here, paper link limitation: converge slowly ‰∏Ä‰∏™Âä†ÈÄüÁâàÊú¨ÔºöK. Shirai, M. Okuda, (2014), ‚ÄúFFT based solution for multivariable l2 equations using KKT system via FFT and efficient pixel-wise inverse calculation,‚Äù IEEE ICASSP, paper link A. Beck, and M. Teboulle, A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems, SIAM J. Imaging Sci., Vol. 2, 183‚Äì202, 2009. inÔ¨Åmal convolution Euler‚Äôs elastica K Papafitsoros, (2014), JMIV „ÄäA combined first and second order variational approach for image reconstruction. „Äã J(u)=\frac{1}{2}\left\|u_{0}-T u\right\|_{2}^{2}+\alpha\|\nabla u\|_{1}+\beta\left\|\nabla^{2} u\right\|_{1} ‰ªéMAPÁöÑËßíÂ∫¶Âá∫Âèë C. Louchet and L. MoisanÔºå 2008 „ÄäTotal variation denoising using posterior expectation„Äã: Louchet and Moisan proposed an alternative to the minimization of the total variation by considering the TV-LSE filter. C. Louchet and L. MoisanÔºå 2014 „ÄäTotal Variation Denoising using Iterated Conditional Expectation„Äã ÂàÜÊûê‰∫Üstaircasing‰∫ßÁîüÁöÑÂéüÂõ† M. Nikolova, 2000, SIAM J. Appl. Math „ÄäLocal strong homogeneity of a regularized estimator„ÄãÔºöNikolova proves that the staircasing effect is related to the non-differentiability of the total variation term Â¢ûÂä†ÁªÜËäÇÁöÑÊîπËøõÔºönon-local+TVÁöÑÊñπÊ≥ï. NLTV, Gilboa and Osher, 2004, Multiscale Model. Simul. „ÄäNonlocal operators with applications to image processing„Äã J_{\mathrm{NLTV}}(u)+\lambda\|u-I\|^{2} \int_{\mathcal{P}} \sqrt{\int_{\mathcal{B}}(u(p)-u(p+q))^{2} v(p, q) \mathrm{d} q \mathrm{d} p} NLTVG, Peyr√©, G., Bougleux, S., Cohen, L.D, 2011, Inverse Probl. Imaging „ÄäNon-local regularization of inverse problems.„Äã RNLTV, Z Li, F Malgouyres, T ZengÔºå2017, JMIV „ÄäRegularized Non-local Total Variation and Application in Image Restoration„Äã Âü∫‰∫éÂõæÂÉèÁöÑËá™Áõ∏‰ººÊÄß: ‰∏§ÁßçÂõæÂÉèÈôçÂô™ÊñπÊ≥ïËÆ∫ÊñáËß£ËØª‰ª•Âèä‰ª£Á†ÅÂÆûÁé∞ Non-local means, 2005, code link here Buades, A., Coll, B., &amp; Morel, J. M. (2005, June). A non-local algorithm for image denoising. In 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR‚Äô05) (Vol. 2, pp. 60-65). IEEE.ÔºàBM3DÔºâ Exploit the inter-patch correlations BM3D, 2007, code link Dabov, K., Foi, A., Katkovnik, V., &amp; Egiazarian, K. (2007). Image denoising by sparse 3-D transform-domain collaborative filtering. Image Processing, IEEE Transactions on 16 (8), pp. 2080-2095. inter-patch correlationsÔºõwavelet shrinkage LSSC(Learned Simultaneous Sparse Coding), 2009 Mairal, J., Bach, F. R., Ponce, J., Sapiro, G., &amp; Zisserman, A. (2009, September). Non-local sparse models for image restoration. In ICCV (Vol. 29, pp. 54-62). Ëøô‰∏™ÁÆóÊ≥ïÊòØNL-meansÔºåLSC(Learned Sparse Coding), Block matching 3DÁöÑÁõ∏ÁªìÂêà Âü∫‰∫éÁ®ÄÁñèË°®ËææÔºàÂú®ÂèòÊç¢ÂüüÔºâ There exists a transform T such that applying T to patches will admit a sparse representation. Wavelet transform Á®ÄÁñèË°®Ëææ Wavelet thresholding Â±û‰∫é‰∏ÄÁßçÊª§Ê≥¢Ê≥ï Âü∫‰∫éÈ©¨Â∞îÂèØÂ§´Âú∫ Âü∫‰∫éÊ∑±Â∫¶Â≠¶‰π† ËÆ∫ÊñáÊÄªÁªì È´òÊñØÂô™Â£∞ÂùáÂÄº‰∏∫0ÔºåÂπ≥ÊñπÂ∑Æ‰∏∫$\sigma^2$ÁöÑÈ´òÊñØÁôΩÂô™Â£∞„ÄÇ 1234567891011121314# Ë∞ÉÁî®imnoiseg = imnoise(I, (noise_level/255)^2)g = I + sqrt((noise_level/255)^2)*randn(M,N);ÂÖ∂‰∏≠ÁöÑIÊòØÁªèËøáim2double(I) % I = I/255ÂΩí‰∏ÄÂåñÁöÑ„ÄÇcase 'gaussian' % Gaussian white noise b = a + sqrt(p4)*randn(sizeA) + p3; # Áõ¥Êé•g = I + sigma * randn(M,N);ÂÖ∂‰∏≠IÊòØÂΩí‰∏ÄÂåñÂêéÁöÑÔºåsigma = noise_level/255;# Â¶ÇÊûúIÊòØ[0,255]‰πãÈó¥ÁöÑÂéüÂõæ„ÄÇg = I + alpha * randn(size(S)); ÈÇ£‰πàÔºåalpha = sigma*255; ÊñëÁÇπÂô™Â£∞Ôºà‰πòÊÄßÂô™Â£∞Ôºâ Âô™Â£∞Ê®°ÂûãËØ∂ f=u n p(f | u, L)=\frac{2 L^{L}}{\Gamma(L) u^{2 L}} f^{2 L-1} e^{-\frac{L f^{2}}{u^{2}}} TVÂéªÂô™Ê®°Âûã ÔºàAAÊ®°ÂûãÔºâG. Aubert and J. Aujol. (2008). A variational approach to remove multiplicative noise. SIAM J. Appl. Math., 68:925‚Äì946, . \inf _{u \in S(\Omega)} \int_{\Omega}\left(\log (A u)+\frac{f}{A u}\right) d x+\lambda \int_{\Omega}|D u| Dong, Y., &amp; Zeng, T. (2013). A convex variational model for restoring blurred images with multiplicative noise. SIAM Journal on Imaging Sciences, 6(3), 1598-1625. \inf _{u \in \overline{S}(\Omega)} E(u) :=\int_{\Omega}\left(\log u+\frac{f}{u}\right) d x+\alpha \int_{\Omega}\left(\sqrt{\frac{u}{f}}-1\right)^{2} d x+\lambda \int_{\Omega}|D u| Fang, F., Fang, Y., &amp; Zeng, T. (2018). On the Convex Model of Speckle Reduction: IVLOPDE, Bergen, Norway, August 29 ‚Äì September 2, 2016. https://doi.org/10.1007/978-3-319-91274-5_6 Ê≥äÊùæÂô™Â£∞ Ê≥äÊùæÂô™Â£∞Êó¢‰∏çÊòØÂä†ÊÄßÂô™Â£∞Ôºå‰πü‰∏çÊòØ‰πòÊÄßÂô™Â£∞ÔºåËÄåÊòØ‰∏ÄÁßç‰ø°Âè∑‰æùËµñÂô™Â£∞„ÄÇ Âä†Âô™Ê®°ÂûãÔºöf= 10*poissrnd(u/10)Ôºånoiselevel=10 \operatorname{Pr}(\boldsymbol{g} | \boldsymbol{f})=\prod_{i, j} \frac{\left[\boldsymbol{f}_{i, j}\right]^{g_{i, j}} \exp \left(-\boldsymbol{f}_{i, j}\right)}{\left(\boldsymbol{g}_{i, j}\right) !} TVÂéªÂô™ Ôº£sisÔΩö√°r [Ôºë] ÊúÄÊó©ÊèêÂá∫‰∫Ü KullbaÔΩÉkÔºçLeibler Ôºà KL )ÔºçdivergenÔΩÉe ‰øùÁúüÈ°πÁî®‰∫éÂéªÈô§ ÁÅ∞Ëâ≤ÂõæÂÉè‰∏≠ÁöÑÊ≥äÊùæÂô™Â£∞Ôº£sisÔΩö√°r IÔºé WÔΩày least squares and ÔΩçaxiÔΩçuÔΩç entrÔΩèpy Ôº°n Ôº°xiÔΩèÔΩçatiÔΩÉ Ôº°pprÔΩèaÔΩÉÔΩà tÔΩè InferenÔΩÉe fÔΩèr linear Inverse Ôº∞rÔΩèbleÔΩçs[J]Ôºé Ôº°nnals ÔΩèf StatistiÔΩÉs Ôºå ÔºëÔºôÔºôÔºë Ôºå ÔºëÔºô Ôºà Ôºî Ôºâ : ÔºíÔºê3ÔºíÔºçÔºíÔºêÔºñÔºñ Luisier Á≠â [Ôºí] Âú®Â∞èÊ≥¢ÂèòÊç¢‰∏≠ÊûÑ ÈÄ†‰∫Ü‰∏Ä‰∏™ SURE ‰º∞ËÆ°ÈáèÁî®‰∫éÊ≥äÊùæÂô™Â£∞ÁöÑÂéªÈô§„ÄÇ GÔΩèng Á≠â [3] ÊèêÂá∫‰∫Ü‰∏Ä‰∏™ l Ôºë +l Ôºí ‰øùÁúüÈ°πÂéªÈô§Ê≥äÊùæÂô™Â£∞Âèä‰∏ÄÂàáÊú™ Áü•Âô™Â£∞„ÄÇ ZÔΩàang Á≠âÂ≠¶ËÄÖ [ÔºîÔºç5] ‰ΩøÁî®ÈáçÊñ∞ËµãÊùÉÁöÑ l Ôºí Êñπ Ê≥ïÈÄºËøë KLÔºçdivergenÔΩÉe ‰øùÁúüÈ°π Wen, Y., Chan, R. H., &amp; Zeng, T. (2016). Primal-dual algorithms for total variation based image restoration under Poisson noise. Science China Mathematics, 59(1), 141-160. ÊèèËø∞‰∫ÜADMMÁÆóÊ≥ïÂíåPrimal DualÁöÑÁÆóÊ≥ïËß£ÂÜ≥‰ª•‰∏ãÈóÆÈ¢ò Using the Bayesian rule, the Poisson image restoration problem can be represented as a minimization problem \min _{f \in S} \Psi(\boldsymbol{f}) \equiv D_{K L}(H \boldsymbol{f}+\boldsymbol{b}, \boldsymbol{g})+\lambda \operatorname{TV}(\boldsymbol{f}) D_{K L}(\boldsymbol{z}, \boldsymbol{g})=\left\langle\boldsymbol{g}, \ln \frac{\boldsymbol{g}}{\boldsymbol{z}}\right\rangle+\langle\mathbf{1}, \boldsymbol{z}-\boldsymbol{g}\rangle code link: BM3D for Poisson Ê§íÁõêÂô™Â£∞ Âô™Â£∞Ê®°Âûã ËÆ≤‰∏ÄÈÉ®ÂàÜÂÉèÁ¥†ÂèòÊàê0ÊàñËÄÖ255 TVÂéªÂô™ ÔºàNikolova in 2004Ôºâ \underset{u \in \mathbb{R}^{\Omega}}{\operatorname{argmin}}\|u-v\|_{1}+\lambda \sum_{i} \phi(\nabla u(i)) $\underset{u \in \mathbb{R}^{\Omega}}{\operatorname{argmin}}|u-v|_{0}+\lambda \sum_{i} \phi(\nabla u(i))$ÔºàÂõ†‰∏∫nonconvexÔºåÂÖàÁ†îÁ©∂‰∫ÜÁ¨¨‰∏Ä‰∏™Êõø‰ª£ÈóÆÈ¢òÔºå‰πãÂêéÂá∫Áé∞ÂØπËØ•ÈóÆÈ¢òÊ±ÇËß£Ôºâ 2015 CVPR: A New Method for Image Restoration in the Presence ofImpulse Noise with code:C [2019 JMIV: Mixing Non-Local and TV-Lp methods] ChanÊèêÂá∫‰∫ÜÂÖàËØïÁî®noise detectorÁöÑÊñπÊ≥ï NL-means approach [2016 JSC] Removing mixture of gaussian and impulse noise by patch-based weighted means 2019 JMIV: Mixing Non-Local and TV-Lp methods ÂéªÊ®°Á≥ä ÊñáÁåÆ An image sharpening Operator Combined with Framelet for Image Deblurring ÊèêÂá∫ÁöÑÊ®°Âûã \min _{u} \mathcal{J}(u) \equiv \frac{\lambda}{2}\|A u-f\|_{2}^{2}+\|W u\|_{1}+\mu\|u-g\|_{1} ÈááÁî®ÂèòÂàÜÊ≥ïÔºåÊ≠£ÂàôÈ°πÈÄâÊã©ÈÄâÊã©‰∫ÜTight frameÔºö|WtW|=1 Â∞Ü‰∏Ä‰∏™sharpenÁÆóÂ≠êÂíå‰º†Áªütight frameÁöÑÊñπÊ≥ïÁªìÂêà‰∏ÄËµ∑ÔºöÁî®‰∏Ä‰∏™ÊñπÊ≥ïËÆ°ÁÆóÂá∫ÊúâÂä©‰∫ésharpÁöÑÂõæÂÉèg, Âπ∂Áî®L1-nirmÂéªÈù†Ëøë„ÄÇÔºàÂíåÂéªÊ®°Á≥äÁöÑÊûÑÈÄ†Ê≠£Ëß£‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºüÂæÖËß£ÂÜ≥Ôºâ Ë∂ÖÂàÜËæ® ÊñáÁåÆ [2019 CVPR] Deep Plug-and-Play Super-Resolution for Arbitrary Blur Kernels ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑSR degradationÊ®°ÂûãÔºöADMMÂíåDNNÁöÑÁªìÂêà ÂæÖËØªÊñáÁ´† Fooling automated surveillance cameras: adversarial patches to attack person detectionÔºàÂØπÊäóÊÄßË°•‰∏ÅÔºâ ÂæÆ‰ø°Êé®ÈÄÅÔºöÂåÖÊã¨ËÆ∫ÊñáÂú∞ÂùÄÂíå‰ª£Á†ÅÂú∞ÂùÄ ÂØπÊäóÊÄßË°•‰∏Å‚Äù(adversarial patch)ÔºåÊ≠£ÊòØËøôÂùóË°•‰∏Å ‚ÄúÊ¨∫È™ó‚Äù ‰∫Ü AI Á≥ªÁªü Â¶Ç‰ΩïÂÜô‰∏ÄÁØá‰ºòÁßÄÁöÑËÆ∫Êñá1.Á¥ßË∑üÁªÜÂàÜÈ¢ÜÂüüÁ†îÁ©∂ÂâçÊ≤øÔºåÁ°ÆÂÆöÁ†îÁ©∂ËßíÂ∫¶ Ë¶ÅÂÅöÂà∞Ëøô‰∏ÄÁÇπÔºåÊúÄÁÆÄÂçïÁöÑÊñπÊ≥ïÊòØÊâæ‰∏ÄÁØáÊùÉÂ®ÅÁöÑÁªºËø∞Á±ªÊñáÁ´†ÔºåÂèØ‰ª•ÊòØ‰∏≠ÊñáÁöÑÔºåÊúÄÂ•ΩÊòØËã±ÊñáÁöÑ„ÄÇÊ†πÊçÆÁªºËø∞‰∏≠ÊèêÂà∞ÁöÑ‰ΩúËÄÖ„ÄÅÂºïÁî®ÁöÑÊñáÁåÆÔºå‰∏çÊñ≠ÊäΩ‰∏ùÊã®ËåßÔºåÂéªÊêúÁ¥¢‰∏ãËΩΩÂéüÊñáËøõË°åÁ†îËØªÔºåÂπ∂‰∏îÂΩ¢Êàê‰Ω†Ëá™Â∑±ÂØπËøô‰∏™È¢ÜÂüüÁöÑÊñáÁåÆÁªºËø∞„ÄÇ 2.ÁÜüÁªÉÊéåÊè°‰∏ÄÂ•óÂÆûËØÅÁ†îÁ©∂ÊñπÊ≥ïÂíåÂ∑•ÂÖ∑ 3.‰∏çÊñ≠Ê®°‰ªø‰ºòÁßÄÁöÑËÆ∫Êñá Â¶ÇÊûú‰Ω†ÊÉ≥Âú®AÁ±ª‰∏≠ÊñáÊ†∏ÂøÉÊúüÂàä‰∏äÂèëË°®ËÆ∫ÊñáÔºåÈÇ£‰πà‰Ω†Â∞±ÂøÖÈ°ªË¶ÅÂú®„ÄäÁÆ°ÁêÜ‰∏ñÁïå„Äã„ÄäÁÆ°ÁêÜËØÑËÆ∫„ÄãÁ≠âAÁ±ªÊúüÂàä‰∏ä‰∏ãËΩΩ‰ºòÁßÄËÆ∫ÊñáÔºåÊ®°‰ªø‰ªñ‰ª¨ÁöÑÈÅ£ËØçÁî®Âè•ÔºåÂÅáËÆæÊé®ÂØº„ÄÅÂÅáËÆæÊ£ÄÈ™å„ÄÅÁ†îÁ©∂ÊñπÊ≥ï„ÄÅÁªìÊûúÊé¢ËÆ®Á≠âÁ≠â„ÄÇ 4.Ê∞∏ËøúËÆ∞‰ΩèÔºö‰∏ÄÂàáÂàùÁ®øÈÉΩÊòØÁãóÂ±éÔºå‰øÆÊîπ‰∏ÄÁØáÊñáÁ´†ËøúÊØîÂÜô‰∏ÄÁØáÊñ∞ÁöÑÊñáÁ´†‰ªòÂá∫ÁöÑÂøÉË°ÄË¶ÅÂ§ö„ÄÇ ‰∏ÄÁØáÊñáÁ´†ÂÜôÂÆåÂêéÔºåÂçÉ‰∏á‰∏çË¶ÅÊÄ•ÈúÄÂèëË°®Ôºå‰øÆÊîπÂ∑•‰ΩúÂçÅÂàÜÈáçË¶Å„ÄÇÈ¶ñÂÖàÔºåÊâìÂç∞Âá∫Êù•ÔºåËá™Â∑±ÈÄêÂè•ÈÄêÂ≠óËÆ§ËÆ§ÁúüÁúüÈÄöËØª‰∏ÄÈÅçÔºåÊää‰∏çÈÄöÈ°∫ÁöÑËØ≠Âè•ÔºåÈîôÂà´Â≠óÔºåÊ†áÁÇπÁ¨¶Âè∑Á≠âÂÖ®ÈÉ®ÊîπÊ≠£Ôºå‰øùËØÅ‰∏çÂá∫Áé∞‰ΩéÁ∫ßÈîôËØØ„ÄÇ 5.‰øùÊåÅË∂≥Â§üÁöÑËÄêÂøÉ ËÆ∫ÊñáË°®ËææÊëòÂΩïËÆ∫ÊñáÂè•ÂºèÊëòË¶Å Ëã±ÊñáÁßëÊäÄÂÜô‰ΩúÂè•ÂûãÂíåËØçÊ±áË°®ËææÊÄªÁªì(2010-) ÊèíÂÖ•ËØ≠ ÊúâÂøÖË¶ÅÊèê‰∏ÄÂè• It‚Äôs necessary to mention thatÔºõFor completion, we remark that‚Ä¶ ÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØ It should be noted that; It is noteworthy that;It‚Äôs worth nothing that; It must be noted that;Significantly ËØ¥Ë¥°ÁåÆ To the best of our knowledge, the deÔ¨Ånition of discrete TV-seminorm (3) as well as the role of the Raviart‚ÄìThomas Ô¨Ånite element space to establish dual representation (4) are novel contributions of the present work. ÊèèËø∞‰∏Ä‰∏™ÊñπÊ≥ï ÊîπÈÄ†ÊÄßÂº∫ The primal-dual algorithm proposed in this paper can beeasily adapted to different problems, is easy to implement and can be effectively accelerated on parallel hardware such as graphics processing units (GPUs). ËØÑËÆ∫‰∏Ä‰∏™ÊñπÊ≥ïÁöÑÂΩ±ÂìçÂäõÂ§ß/ÊïàÊûúÂ•Ω achieve/provide/reach remarkable performance on the .. problem is an efficient network that provide an end-to-end mapping/estimation between the .. ÂæàÂ§öÊñπÊ≥ïË¢´ÊèêÂá∫ To avoid the heuristic edge selection step, numerous algorithms based on natural image prior have been proposed, including normalized sparsity [16], L0 gradients [38] and dark channel prior [27]. Recent years have witnessed significant advances in sin-gle image deblurring. We focus our discussion on recent optimization-based and learning-based methods. Thus, it is of great interest to develop a general image prior which is able to deal with different scenarios with the MAP framework ÂõæÁâáÂêçÁß∞ Figure 7: Some examples of RCF. From top to bottom: BSDS500 [2], NYUD [49], Multicue-Boundary [41], and Multicue-Edge [41]. From left to right: origin image, ground truth, RCF edge map, origin image, ground truth, and RCF edge map. ÂõæÂÉèÁöÑÂêàÊàê The noisy inputs are synthesized by adding i.i.d. Gaussian white noise with diÔ¨Äerent standard deviation œÉ to the original images. ÊñπÊ≥ïÁöÑÊØîËæÉ ‰∏§‰∏™ÊñπÊ≥ïÂ∑Æ‰∏çÂ§öÁöÑÊÉÖÂÜµ There are images on which the K-SVD method performed better and there are some on which our approaches performed better. Overall, the performances of our proposed method and the K-SVD method are comparable in terms of PSNR value, and so is the visual quality. We compared the computational eÔ¨Éciency of Algorithm 1 against that of the K-SVD method in terms of the running time on the same hardware conÔ¨Åguration.]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
      </categories>
      <tags>
        <tag>denoising</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Á¨¨‰∏Ä‰∏™ÂçöÂÆ¢Êê≠Âª∫]]></title>
    <url>%2Fp%2F9748.html</url>
    <content type="text"><![CDATA[GithubÊê≠Âª∫ÂçöÂÆ¢ Ëß£ÂÜ≥Êï∞Â≠¶ÂÖ¨ÂºèÁöÑÊòæÁ§∫ÈóÆÈ¢ò(Êñá‰ª∂Âä©Êâã) githubÊê≠Âª∫ÁªìÊûÑÁöÑÂü∫Êú¨Ê°ÜÊû∂(Êñá‰ª∂Âä©Êâã) gitÁöÑ‰ΩøÁî®ÔºåÂªñÈõ™Â≥∞ ÂõæÁâáÊòæÁ§∫ÈóÆÈ¢ò Êñ∞Êµ™ÂõæÁâáÂ§ñÈìæÂú®ÂçöÂÆ¢‰∏≠Êó†Ê≥ïÊòæÁ§∫ÁöÑÂéüÂõ† Êñ∞Êµ™ÂõæÂ∫äÁõ¥Êé•ËÆøÈóÆÊ≤°ÊúâÊùÉÈôêÔºöAccess Denied You don‚Äôt have permission to access Mac‰∏ãiPicÁöÑ‰ΩøÁî®ÊñπÊ≥ï ‰∏çÂêåÁöÑÂõæÂ∫ä‰∏çÂêåÁöÑÂõæÂ∫ä ‰∏ÉÁâõ‰∫ëÁöÑAPI iPic‰∏≠Ê∑ªÂä†‰∏ÉÁâõ ÈòøÈáå‰∫ëÔºöhttps://oss.console.aliyun.com/overview ÂõæÂ∫äË∑ëË∑ØÊÄé‰πàÂäû https://github.com/wisp-x/lsky-pro Ëß£ÂÜ≥ÊõøÊç¢ÂõæÂ∫äÁöÑËÑöÊú¨ ÂÖ¨ÂºèÁöÑÊòæÁ§∫ÈóÆÈ¢òÂçöÂÆ¢listÂ§öÁ´ØËÆøÈóÆiphone/ipad]]></content>
      <categories>
        <category>ÂÖ∂‰ªñ</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[latex‰ΩøÁî®Á¨îËÆ∞]]></title>
    <url>%2Fp%2F5904.html</url>
    <content type="text"><![CDATA[latex‰ΩøÁî®Á¨îËÆ∞ ÂèÇËÄÉËµÑÊñôÂ≠¶ÊúØÂÜô‰ΩúÂà©Âô®‚Äî‚ÄîLaTeXÂÖ•Èó®Á¨îËÆ∞Êï¥ÁêÜÔºà‰∏çÂÆöÊúüÊõ¥Êñ∞ÔºåÈôÑÂä†‰ΩøÁî®ÂøÉÂæó) Âú®Á∫øÂ∑•ÂÖ∑ Âú®Á∫øÁîªÂõæ Âú®Á∫øÁîªË°®Ê†ºÔºåËΩ¨ÂåñÊàêlatex‰ª£Á†Å WinEdtÂø´Êç∑ÈîÆÊü•ÊâæÔºå‰ª•ÂèäÊü•Êâæ‰∏ã‰∏Ä‰∏™Ôºö ctrl+I Ê∑ªÂä†Ê≥®ÈáäÁöÑÂø´Êç∑ÈîÆ‰∏∫: Left+Shift+Ctrl+Alt Âà†Èô§Ê≥®ÈáäÁöÑÂø´Êç∑ÈîÆ‰∏∫: Right+Shift+Ctrl+Alt AtomÂø´Êç∑ÈîÆÂíåÈÖçÁΩÆÊú¨ÊñáÊìç‰ΩúÁ§∫‰æãÂü∫‰∫é Mac OS„ÄÇ mac air texshopÂùóÊ≥®ÈáäÔºöcmd+shift+{/} ÁâπÊÆäÁ¨¶Âè∑$8^{\circ}$: 8^{\circ} (ÂèØ‰ª•ÈÄöËøáËá™ÂÆö‰πâÊù•ÁÆÄÂåñÔºå\def\degree{${}^{\circ}$} Ôºå90\degree ) $8^{\circ}C$: 8^{\circ}C Ëá™ÂÆö‰πâÂëΩ‰ª§Á¨¶ Ëá™ÂÆö‰πâÈ¢úËâ≤ RGBÈ¢úËâ≤Êü•ËØ¢ 123\usepackage&#123;xcolor&#125;\definecolor&#123;myorange&#125;&#123;rgb&#125;&#123;1, 0.44, 0.11&#125;\newcommand&#123;\grammar&#125;[1]&#123;\textcolor&#123;myorange&#125;&#123;#1&#125;&#125; `‰∏Ä‰∫õÊï∞Â≠¶Á¨¶Âè∑ 12345\newcommand &#123;\Argmin&#125;[1] &#123;\underset&#123;#1&#125;&#123;\argmin&#125;&#125;\DeclareMathOperator &#123;\prox&#125; &#123;prox&#125;\newcommand &#123;\Prox&#125;[3] &#123; &#123;\prox&#125;_&#123;#1&#125;^&#123;#2&#125;\left( #3 \right) &#125;\newcommand &#123;\TV&#125;[2] &#123; TV\left( #1, #2\right) &#125;\newcommand &#123;\PS&#125;[2] &#123;\left\langle #1, #2\right\rangle&#125; ÁîªÂõæ Âú®Á∫øÁîªÂõæËøûÊé•Ôºö Á•ûÁªèÁΩëÁªú ÂõæÁâá Ë∞ÉÊï¥ÂõæÁâáÂ§ßÂ∞èËá≥È°µÈù¢ÂÆΩÂ∫¶ \includegraphics[width=\textwidth]{images/EdgeNet2.png} ÂçïÊ†èÂõæÁâáÊèíÂÖ• 123456789% For one-column wide figures use\begin&#123;figure&#125;% Use the relevant command to insert your figure file.% For example, with the graphicx package use \includegraphics&#123;example.eps&#125;% figure caption is below the figure\caption&#123;Please write your figure caption here&#125;\label&#123;fig:1&#125; % Give a unique label\end&#123;figure&#125; ÂèåÊ†èÂõæÁâáÊèíÂÖ• 123456789% For two-column wide figures use\begin&#123;figure*&#125;% Use the relevant command to insert your figure file.% For example, with the graphicx package use \includegraphics[width=0.75\textwidth]&#123;example.eps&#125;% figure caption is below the figure\caption&#123;Please write your figure caption here&#125;\label&#123;fig:2&#125; % Give a unique label\end&#123;figure*&#125; Â§öÂº†ÂõæÁâáÂπ∂ÂàóÊèíÂÖ• ‰ΩøÁî®subfigureÔºåÂ¶ÇÊûúÊÉ≥Êç¢Ë°åÔºåÂú®ÂõæÁâáÂêéÈù¢Âä†‰∏äÂõûËΩ¶ÈîÆ 1234567891011121314151617181920212223242526272829303132333435\begin&#123;figure&#125;[htbp]\centering\subfigure[pic1.]&#123;\begin&#123;minipage&#125;[t]&#123;0.25\linewidth&#125;\centering\includegraphics[width=1in]&#123;images/MSRB1.png&#125;%\caption&#123;fig1&#125;\end&#123;minipage&#125;%&#125;%\subfigure[pic2.]&#123;\begin&#123;minipage&#125;[t]&#123;0.25\linewidth&#125;\centering\includegraphics[width=1in]&#123;images/MSRB1.png&#125;%\caption&#123;fig2&#125;\end&#123;minipage&#125;%&#125;%[ÂõûËΩ¶]\subfigure[pic3.]&#123;\begin&#123;minipage&#125;[t]&#123;0.25\linewidth&#125;\centering\includegraphics[width=1in]&#123;images/MSRB1.png&#125;%\caption&#123;fig2&#125;\end&#123;minipage&#125;&#125;%\subfigure[pic4.]&#123;\begin&#123;minipage&#125;[t]&#123;0.25\linewidth&#125;\centering\includegraphics[width=1in]&#123;images/MSRB1.png&#125;%\caption&#123;fig2&#125;\end&#123;minipage&#125;&#125;%[ÂõûËΩ¶]\centering\caption&#123; pics&#125;\end&#123;figure&#125; ‰∏ÄÂàóÂ§öÂº†Âõæ ÂéªÊéâÂõæÁâáÁöÑÂ∫èÂàóÂè∑ Âà©Áî®minipage‰∏ãÁöÑ\centerline‰ª•Âèäsubfigure*„ÄÇ‰æãÂ¶ÇÔºö 123456789101112131415161718\documentclass[a4paper,UTF8]&#123;article&#125;\usepackage&#123;ctex&#125;\usepackage&#123;caption&#125;\usepackage&#123;graphicx&#125;\begin&#123;document&#125;\begin&#123;figure&#125;[ht]\begin&#123;minipage&#125;&#123;0.48\linewidth&#125;\centerline&#123;\includegraphics[width=1\textwidth]&#123;a1.jpg&#125;&#125;\centerline&#123;‰º§ÂøÉÂõæ&#125;\end&#123;minipage&#125;\qquad\begin&#123;minipage&#125;&#123;0.48\linewidth&#125;\centerline&#123;\includegraphics[width=1\textwidth]&#123;a2.jpg&#125;&#125;\centerline&#123;ÂºÄÂøÉÂõæ&#125;\end&#123;minipage&#125;\caption*&#123;ÈÉΩÊòØË°®ÊÉÖÂõæ&#125;\end&#123;figure&#125;\end&#123;document&#125; ËÆæÁΩÆcaption‰∏≠ÁöÑÂ≠ó‰ΩìÂ§ßÂ∞è ÊéßÂà∂ÂõæÁâáÊèíÂà∞ÁöÑ‰ΩçÁΩÆ ÂÖ∂‰∏≠[htbp]Â∞±ÊòØÊµÆÂä®Ê†ºÂºè ‚Äúh ÂΩìÂâç‰ΩçÁΩÆ„ÄÇÂ∞ÜÂõæÂΩ¢ÊîæÁΩÆÂú®Ê≠£ÊñáÊñáÊú¨‰∏≠ÁªôÂá∫ËØ•ÂõæÂΩ¢ÁéØÂ¢ÉÁöÑÂú∞Êñπ„ÄÇÂ¶ÇÊûúÊú¨È°µÊâÄÂâ©ÁöÑÈ°µÈù¢‰∏çÂ§üÔºåËøô‰∏ÄÂèÇÊï∞Â∞Ü‰∏çËµ∑‰ΩúÁî®„ÄÇ t È°∂ÈÉ®„ÄÇÂ∞ÜÂõæÂΩ¢ÊîæÁΩÆÂú®È°µÈù¢ÁöÑÈ°∂ÈÉ®„ÄÇ b Â∫ïÈÉ®„ÄÇÂ∞ÜÂõæÂΩ¢ÊîæÁΩÆÂú®È°µÈù¢ÁöÑÂ∫ïÈÉ®„ÄÇ p ÊµÆÂä®È°µ„ÄÇÂ∞ÜÂõæÂΩ¢ÊîæÁΩÆÂú®‰∏ÄÂè™ÂÖÅËÆ∏ÊúâÊµÆÂä®ÂØπË±°ÁöÑÈ°µÈù¢‰∏ä„ÄÇ‚Äù Ë°®Ê†º Âú®Á∫øÁîªË°®Ê†ºÔºåËΩ¨ÂåñÊàêlatex‰ª£Á†Å ÂèÇËÄÉÂçöÂÆ¢ ‰æãÂ≠ê(ÊëòËá™ËÆ∫ÊñáFFDNet) https://ws1.sinaimg.cn/large/006tNc79gy1g37p8ux09hj313c0rgk7f.jpg ‰∏âÁ∫øË°® latexÂíåmatlabË°®Ê†ºÁöÑËøûÊé• matlabÁöÑËæìÂá∫Ê®°ÂºèËßÑËåÉÊàê[&amp;&amp;\\\]ÁöÑÊ®°Âºè latexÂºïÁî®ÂåÖÔºåÊääcsvËØªÂèñÊàêË°®Ê†ºÊ®°Âºè Ë°®Ê†ºÊ∫¢Âá∫ 123456789\begin&#123;table*&#125;[!t]\centering\caption&#123;***&#125;\label&#123;***&#125;\resizebox&#123;\textwidth&#125;&#123;!&#125;&#123;\begin&#123;tabular&#125;&#123;***&#125;***\end&#123;tabular&#125;&#125;\end&#123;table*&#125; ÂèåÊ†èË°®Ê†º‰æãÂ≠ê 12345678910111213\begin&#123;table&#125;[htbp]\caption&#123;The different data-fidelity terms used in the experiments.&#125;\begin&#123;center&#125;\begin&#123;tabular&#125;&#123;|l|*&#123;1&#125;&#123;c|&#125;&#125;\hline\textbf&#123;&#125;&amp;&#123;$D(u)$&#125;\\\hlineinpainting and zooming&amp;$\lambda \|Hu-I\|^2$ \\\hlinedenoising (synthetic image)&amp;$\one&#123;\|u-I\|^2\leq \tau&#125;(u)$\\\hlinedenoising (natural image)&amp;$\lambda \|u-I\|^2$ \\\hline\end&#123;tabular&#125;\end&#123;center&#125;\label&#123;tab:data_term&#125;\end&#123;table&#125; ÂÖ¨Âºè ÂÖ¨ÂºèÊ∫¢Âá∫ÁöÑÈóÆÈ¢ò \! Áº©Â∞èÈó¥Ë∑ù Êç¢Ë°å Â§öË°åÂÖ¨ÂºèÂØπÈΩêÔºåÂπ∂ÊòæÁ§∫‰∏Ä‰∏™Â∫èÂè∑ 12345678910\documentclass[review]&#123;elsarticle&#125;\usepackage&#123;amsmath&#125;\begin&#123;document&#125;\begin&#123;equation&#125; \label&#123;eqn2&#125; \begin&#123;split&#125; n&amp;=\left[\frac&#123;b-a&#125;&#123;0.01&#125;\right]+1, \\ S&amp;=\frac&#123;1&#125;&#123;n&#125;\sum\limits_&#123;j=1&#125;^&#123;n&#125;(\lambda_&#123;0j&#125;-\lambda_&#123;j&#125;). \end&#123;split&#125;\end&#123;equation&#125;\end&#123;document&#125; ÂÖ¨ÂºèÊç¢Ë°å multiline 1234\begin&#123;multline&#125;TV(v+h,u)=\sum_&#123;p\in\PP_1&#125; \Psi_\mu\left( \sqrt&#123;(\Au v)_p + (\Au h)_p&#125; \right) \\+\sum_&#123;p\in\PP_2&#125; \frac&#123; (\Au v)_p + (\Au h)_p &#125;&#123; 2\mu &#125;.\end&#123;multline&#125; alignedÁªìÂêà\qquad 123456789101112\begin&#123;equation&#125; \begin&#123;aligned&#125;&amp;\qquad\sum_&#123;p\in\PP_1&#125; \Psi_\mu\left( \sqrt&#123;(\Au v)_p + (\Au h)_p&#125; \right)\\&amp;=\sum_&#123;p\in\PP_1&#125; \Psi_\mu\left( \sqrt&#123;(\Au v)_p&#125;+ \frac&#123;(\Au h)_p&#125;&#123;2\sqrt&#123;(\Au v)_p&#125;&#125; +o\left(|(\Au h)_p|\right)\right)\\&amp;=\sum_&#123;p\in\PP_1&#125; \Psi_\mu\left( \sqrt&#123;(\Au v)_p&#125;\right) \\&amp;\qquad+ \Psi&apos;_\mu\left( \sqrt&#123;(\Au v)_p&#125; \right)\frac&#123;(\Au h)_p&#125;&#123;2\sqrt&#123;(\Au v)_p&#125;&#125;+o\left(|(\Au h)_p|\right)\\ \end&#123;aligned&#125;\end&#123;equation&#125; split 1234567\begin&#123;equation&#125; \begin&#123;split&#125; (a + b)^3 &amp;= (a + b) (a + b)^2 \\ &amp;= (a + b)(a^2 + 2ab + b^2) \\ &amp;= a^3 + 3a^2b + 3ab^2 + b^3 \end&#123;split&#125;\end&#123;equation&#125; ÂÖ¨ÂºèÁº©Ëøõ+\!+ ÂÖ¨ÂºèÂ§ßÊã¨Âè∑12345\begin&#123;equation&#125;\label&#123;&#125;(u^*(v))_p = \left\&#123;\begin&#123;array&#125;&#123;ll&#125;\frac&#123;1&#125;&#123;2 \sqrt&#123;(\Au v)_p&#125;&#125; &amp;\mbox&#123;, if &#125; \sqrt&#123;(\Au v)_p&#125; \geq \mu,\\\frac&#123;1&#125;&#123;2\mu&#125;&amp;\mbox&#123;, if &#125; \mu \geq \sqrt&#123;(\Au v)_p&#125;\geq 0.\end&#123;array&#125;\right.\end&#123;equation&#125; ÂºïÁî® Âêå‰∏ÄÂ§ÑÂºïÁî®Â§ö‰∏™ÂèÇËÄÉÊñáÁåÆ ÊñπÊ≥ï‰∏ÄÔºöÂä†ÂåÖ \usepackage{cite} ,Â§ÑÁêÜÂ§ö‰∏™ÊñáÁåÆÂëΩ‰ª§Ôºö\cite{name1,name2,‚Ä¶,nameN} ÊñπÊ≥ï‰∫åÔºö‰∏çÂä†ÂåÖÔºå\cite{name1},\cite{name2}. Êï∞Â≠¶ÂÖ¨ÂºèÁöÑÂºïÁî® Âä†ËΩΩ amsmath Â∑•ÂÖ∑ÂåÖÔºå‰ΩøÁî® \eqref ÂëΩ‰ª§„ÄÇÊïàÊûúÂ¶Ç‰∏ãÔºö As the choice of parameter in the TV model (3) latexÂºïÁî®ÂêÑÁßçÂÖ¨Âºè„ÄÅÊñáÁåÆ ÁÆóÊ≥ï ‰ª•‰∏ã‰∏çÈúÄË¶Åalgorithm package 12345678910111213141516171819202122232425%\usepackage&#123;algorithm&#125;%\usepackage&#123;algorithmic&#125;\begin&#123;algorithm&#125;[ht] % \SetLine \KwIn&#123; \\ $I$: Degraded image\\ $H$: Linear operator to invert\\ $\BB$: Support of the weights \\ $\Ne$: Support for the finite differences defining $R$\\ $\gamma$, $\mu$, $\lambda/\tau$: parameters &#125; \KwOut&#123;\\ $u$: Restored image \\ $v$: Weights \\\ \\ &#125; \Begin&#123; Initialize the image $u$ and $v$;\\ \While&#123; not converged &#125; &#123;step 1: Update $u$: \begin&#123;equation&#125;\label&#123;&#125;u = \Prox&#123;L&#125;&#123;D&#125;&#123; u- L^&#123;-1&#125; \nabla_u \TV&#123;v&#125;&#123;u&#125; &#125;\end&#123;equation&#125; \\ step 2: Update $v$:$v=&#123;\prox&#125;^&#123;\one&#123;\UU^&#123;\PP&#125;&#125;&#125;\left(v-\frac&#123;\nabla_&#123;v&#125;\TV&#123;v&#125;&#123;u&#125;+\nabla R(v)&#125;&#123;l+l&apos;&#125;\right)$ &#125;&#125;\caption&#123;Overview of the algorithm&#125;\label&#123;algo:1&#125;\end&#123;algorithm&#125; ÂÆöÁêÜ„ÄÅÊé®ËÆ∫ proposition 123456789101112131415161718192021222324252627\newtheorem&#123;prop&#125;&#123;Proposition&#125;----------------------------\begin&#123;prop&#125; \label&#123;propTVu&#125;For any $u\in \RP$, we have\begin&#123;equation&#125;\label&#123;&#125;\nabla_u \TV&#123;v&#125;&#123;u&#125; = \Dv^* w^*(u),\end&#123;equation&#125;where $w^*(u)\in\RR^\PB$ is the maximizer of \eqref&#123;TV-Max&#125; and is provided in closed form by:\begin&#123;equation&#125;\label&#123;&#125;w^*(u)_&#123;p,q&#125; = \left\&#123;\begin&#123;array&#125;&#123;ll&#125;\frac&#123;(\Dv u)_&#123;p,q&#125;&#125;&#123;\mu&#125; &amp; \mbox&#123;, if &#125; \|(\Dv u)_p\| \leq \mu,\\\frac&#123;(\Dv u)_&#123;p,q&#125;&#125;&#123;\|(\Dv u)_p\| &#125; &amp; \mbox&#123;, otherwise.&#125;\end&#123;array&#125;\right.\end&#123;equation&#125;Moreover, $u\rightarrow \nabla_u \TV&#123;v&#125;&#123;u&#125;$ is Lipschitz continuous with Lipschitz constant\begin&#123;equation&#125;\label&#123;&#125;l&quot; = \frac&#123;\sqrt&#123;2&#125; \sqrt&#123;|\BB| +1&#125;&#125;&#123;\mu&#125;.\end&#123;equation&#125;As a consequence, we have for any $u$ and $u&apos;\in \RP$\begin&#123;equation&#125;\label&#123;QMTV-prop&#125;\begin&#123;aligned&#125;\TV&#123;v&#125;&#123;u&apos;&#125;&amp;\leq\TV&#123;v&#125;&#123;u&#125; \\&amp;\quad+ \PS&#123;\nabla_u \TV&#123;v&#125;&#123;u&#125;&#125;&#123;u&apos;-u&#125;\\&amp;\quad+\frac&#123;l&quot;&#125;&#123;2&#125;\|u&apos;-u\|^2.\end&#123;aligned&#125;\end&#123;equation&#125;\end&#123;prop&#125; È°µÈù¢ÁºñËæë LatexÊ∑ªÂä†Êñ∞‰∏ÄÈ°µ‚Äî‚ÄîÁî®‚Äú\clearpage‚Äù ‰∏çË¶ÅÁî®‚Äú\newpage‚Äù„ÄÇÈÄö‰øóÁÇπËÆ≤Â∞±ÊòØÂΩì‰Ω†Êñ∞Âä†ÁöÑ‰∏ÄÈ°µÂÜÖÂÆπËæÉÂ§öÊó∂Ôºå‰∏§ËÄÖÂü∫Êú¨‰∏ÄÊ†∑ÔºåÂΩìÊñ∞Âä†ÁöÑ‰∏ÄÈ°µÂÜÖÂÆπËæÉÂ∞ëÊó∂Ôºå‚Äú\newpage‚ÄùÂ∞±Êó†Ê≥ïÂÆûÁé∞‰Ω†ÊÉ≥Ë¶ÅÁöÑÊïàÊûúÔºå‰ΩÜ‚Äú\clearpage‚ÄùÂèØ‰ª•„ÄÇ ‰∏≠ÊñáÁºñËØësharelatexÂÆòÊñπÊñá‰ª∂ ÁÇπÂáªmenuÔºåÂ∞ÜÁºñËØëÂô®ËΩ¨Êç¢XeLatex ErrorÂíåWarningLatex‰∏≠Êü•ÁúãÈ´ò‰∫ÆerrorÂíåwarning ÂëΩ‰ª§Ë°åÊ≥®Èáä Â§öË°åÊ≥®ÈáäÔºö‰ΩøÁî®\usepackage{verbatim}ÂÆèÂåÖÔºåÁÑ∂ÂêéÂú®ÂæÖÊ≥®ÈáäÁöÑÈÉ®ÂàÜ‰∏äÂä†ÂÖ•\begin{comment} ‚Ä¶ \end{comment}\begin{comment} ‚Ä¶ \end{comment}ÔºåÈÇ£‰πà‰∏≠Èó¥ÁöÑÈÉ®ÂàÜÂç≥Ë¢´Ê≥®ÈáäÊéâÔºõ ‰ΩøÁî®\iffalse ‚Ä¶. \fi ÔºåÈÇ£‰πà‰∏≠Èó¥Ë¢´ÂåÖÂê´ÁöÑÈÉ®ÂàÜÂ∞±Ë¢´Ê≥®ÈáäÊéâ‰∫ÜÔºõ ÂèåÊ†èÂÖ¨ÂºèÈªòËÆ§‰∏çÂ±Ö‰∏≠Ôºå‰∏çË¶Å‰ΩøÁî®.. ÈÄâÊã©ÂçïÊ†èÊàñËÄÖÂèåÊ†èÊèíÂÖ•ÔºöË°®Ê†º„ÄÅÂõæÁâáÁ≠â Debug begin{equation*} ÁéØÂ¢É‰∏çÂ≠òÂú®ÁöÑÈóÆÈ¢ò \usepackage{amsmath} \bibliography{reference.bib}Ê≤°ÊúâÂèçÂ∫îÁöÑÊó∂ÂÄô ÂèØËÉΩÊòØÂõ†‰∏∫Ê≤°ÊúâÂÆö‰πâÂºïÁî®ÁöÑÊ†ºÂºè \bibliographystyle{spbasic} % basic style, author-year citations\bibliographystyle{spmpsci} % mathematics and physical sciences\bibliographystyle{spphys} % APS-like style for physics ÂõæÁâáÂíåË°®Ê†ºÂºïÁî®ÁöÑÊó∂ÂÄôÊòæÁ§∫‰∏çÂØπ Figure \ref{}; Table \ref{} Ëß£ÂÜ≥ÔºöÂõ†‰∏∫Êää\labelÊèíÂú®‰∫Ü\caption‰πãÂâçÔºåÈªòËÆ§ÈúÄË¶ÅÂú®\caption‰πãÂêé„ÄÇ ÂõæÁâáÊèíÂÖ•Âà∞‰∫Üreference‰∏≠ Â∞ÜhtbpËΩ¨ÂåñÊàêH, ‰∏çÂèØ‰ª•ÊòØh. Â¶ÇÔºö\begin{figure}[H] ÈúÄË¶ÅÂ§¥Êñá‰ª∂Ôºö\usepackage{float} Package Inputenc error : Unicode Char fi(U+FB01) [duplicate] ‚Äúfi‚ÄùË¢´ÊâìÂú®Âêå‰∏Ä‰∏™Â≠óÁ¨¶‰∏ã subcaption documentclass{}‰∏ãÁöÑ\journalname LaTeX Warning: Reference `Split Bregman‚Äô on page 13 undefined on input line 62 ! Undefined control sequence.ÊàñËÄÖincomplete \ifodd , all text was ignored‚Ä¶ ÂèØËÉΩÊòØÂõ†‰∏∫‰∏çÂÆåÊï¥ÁöÑÊã¨Âè∑ Âú®winedt‰∏≠ÔºåÂ§ö‰ΩôÁöÑÊã¨Âè∑ÁºñËæëÊó∂ÊòæÁ§∫ÊòØÁ∫¢Ëâ≤ÁöÑ ! LaTeX Error: Bad math environment delimiter. Êï∞Â≠¶ÁéØÂ¢ÉÈáçÂ§çÔºöÂ¶Ç$$Âíå\(ÈÉΩÊòØË°®Á§∫ÂÖ¨Âºè Overflow: ÂéüÂõ†ÊòØÈÅáÂà∞‰∏Ä‰∫õÁ≥ªÁªüÊó†Ê≥ï‰∏∫‰ªñÂàÜÂâ≤ÁöÑÂçïËØçÔºåÂ¶Çschemes, Âõ†ËÄåÊ∫¢Âá∫„ÄÇ Ëß£ÂÜ≥ÂäûÊ≥ïÔºöÂº∫Âà∂ÂàÜËØç„ÄÇÂ¶ÇÔºåsche-mes. latexmk: failure in some parts of making files Âú®ÁºñËØëÊñá‰ª∂Â§πÂÜÖÊúâÂ§ö‰ΩôÁöÑÁªÑÂª∫Êñá‰ª∂ÔºåÂ¶ÇÊúâ‰∏â‰∏™.bstÊñá‰ª∂ÔºåÂç≥‰æøÊ≤°ÊúâË∞ÉÁî®Âè¶Â§ñ‰∏§‰∏™Ôºå‰æùÁÑ∂Êä•Èîô„ÄÇ]]></content>
      <categories>
        <category>ËΩØ‰ª∂</category>
      </categories>
      <tags>
        <tag>latex</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ê∑±Â∫¶Â≠¶‰π†ÁΩëÁªúÂ≠¶‰π†]]></title>
    <url>%2Fp%2Fb08c.html</url>
    <content type="text"><![CDATA[ÁΩëÁªúÊû∂ÊûÑÂ≠¶‰π† ËØæÁ®ãÈìæÊé•-tensorflow‰∏≠ÊñáÁâàÊïôÁ®ã ÊúÄÊñ∞ËµÑËÆØÂíåÈìæÊé•ËøëÊúüÂøÖËØªÁöÑ10ÁØáACL 2019„ÄêÂõæÁ•ûÁªèÁΩëÁªúÔºàGNNÔºâ+NLP„ÄëÁõ∏ÂÖ≥ËÆ∫ÊñáÂíå‰ª£Á†Å Âç∑ÁßØÁ•ûÁªèÁΩëÁªúCNN ÊñáÁåÆ AlexNet VGG ResNet He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition. InProceedings of the IEEE conference on computer vision and pattern recognition 2016 (pp. 770-778). Alex netAlex net‰πãÂâçÁöÑÂ∑•‰Ωú‰ª•ÂèäAlexNet‰∏≠ÁöÑÂàõÊñ∞ÁÇπ ËÆ∫ÊñáÁ¨îËÆ∞ VGGRESNETResNet, 2015, ÂæÆËΩØ‰∫öÊ¥≤Á†îÁ©∂Èô¢ÁöÑ‰ΩïÂáØÊòéÁ≠â‰∫∫ÊèêÂá∫ He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition. InProceedings of the IEEE conference on computer vision and pattern recognition 2016 (pp. 770-778). ‰∏ªË¶ÅË¥°ÁåÆÔºöÁΩëÁªúÂ±ÇÊï∞‰ªé32Â±ÇÊèêÂà∞152Â±Ç ÁâπÁÇπÔºö ÁΩëÁªúËæÉÁò¶ÔºåÊéßÂà∂‰∫ÜÂèÇÊï∞Êï∞ÈáèÔºõ Â≠òÂú®ÊòéÊòæÂ±ÇÁ∫ßÔºåÁâπÂæÅÂõæ‰∏™Êï∞ÈÄêÂ±ÇÈÄíËøõÔºå‰øùËØÅËæìÂá∫ÁâπÂæÅË°®ËææËÉΩÂäõÔºõ ‰ΩøÁî®‰∫ÜËæÉÂ∞ëÁöÑÊ±†ÂåñÂ±ÇÔºåÂ§ßÈáè‰ΩøÁî®‰∏ãÈááÊ†∑ÔºåÊèêÈ´ò‰º†Êí≠ÊïàÁéáÔºõ Ê≤°Êúâ‰ΩøÁî®DropoutÔºåÂà©Áî®BNÂíåÂÖ®Â±ÄÂπ≥ÂùáÊ±†ÂåñËøõË°åÊ≠£ÂàôÂåñÔºåÂä†Âø´‰∫ÜËÆ≠ÁªÉÈÄüÂ∫¶Ôºõ Â±ÇÊï∞ËæÉÈ´òÊó∂ÂáèÂ∞ë‰∫Ü3x3Âç∑ÁßØ‰∏™Êï∞ÔºåÂπ∂Áî®1x1Âç∑ÁßØÊéßÂà∂‰∫Ü3x3Âç∑ÁßØÁöÑËæìÂÖ•ËæìÂá∫ÁâπÂæÅÂõæÊï∞ÈáèÔºåÁß∞ËøôÁßçÁªìÊûÑ‰∏∫‚ÄúÁì∂È¢à‚Äù(bottleneck)„ÄÇ ÊÆãÂ∑ÆÂçïÂÖÉÔºö ÂÖãÊúç‰∫ÜÊ¢ØÂ∫¶Ê∂àÂ§±ÁöÑÈóÆÈ¢ò Âç∑ÁßØÁ•ûÁªèÁΩëÁªú‰∏≠ÁöÑÁªÑÊàêÊ≠•ÈïøÂíåË°•Èõ∂ Âç∑ÁßØÊ†∏Ôºö‰∏âÁª¥ÁªìÊûÑ Ê±†ÂåñÂ±ÇÊ±†ÂåñÂ±ÇÁöÑËæìÂÖ•‰∏ÄËà¨Êù•Ê∫ê‰∫é‰∏ä‰∏Ä‰∏™Âç∑ÁßØÂ±ÇÔºå‰∏ªË¶Å‰ΩúÁî®ÊòØÊèê‰æõ‰∫ÜÂæàÂº∫ÁöÑÈ≤ÅÊ£íÊÄßÔºà‰æãÂ¶Çmax-poolingÊòØÂèñ‰∏ÄÂ∞èÂùóÂå∫Âüü‰∏≠ÁöÑÊúÄÂ§ßÂÄºÔºåÊ≠§Êó∂Ëã•Ê≠§Âå∫Âüü‰∏≠ÁöÑÂÖ∂‰ªñÂÄºÁï•ÊúâÂèòÂåñÔºåÊàñËÄÖÂõæÂÉèÁ®çÊúâÂπ≥ÁßªÔºåpoolingÂêéÁöÑÁªìÊûú‰ªç‰∏çÂèòÔºâÔºåÂπ∂‰∏îÂáèÂ∞ë‰∫ÜÂèÇÊï∞ÁöÑÊï∞ÈáèÔºåÈò≤Ê≠¢ËøáÊãüÂêàÁé∞Ë±°ÁöÑÂèëÁîü„ÄÇÊ±†ÂåñÂ±Ç‰∏ÄËà¨Ê≤°ÊúâÂèÇÊï∞ÔºåÊâÄ‰ª•ÂèçÂêë‰º†Êí≠ÁöÑÊó∂ÂÄôÔºåÂè™ÈúÄÂØπËæìÂÖ•ÂèÇÊï∞Ê±ÇÂØºÔºå‰∏çÈúÄË¶ÅËøõË°åÊùÉÂÄºÊõ¥Êñ∞„ÄÇ InceptionÊ®°Âùó bottle layerÁöÑ‰ΩúÁî®Âæ™ÁéØÁ•ûÁªèÁΩëÁªúRNN 4.30 ÈòÖËØª Pytorch Example: A character-level RNN ËØÜÂà´ÂêçÂ≠óÁöÑÁßçÁ±ª ÂâçÈ¶àÁ•ûÁªèÁΩëÁªúÁöÑÂ±ÄÈôê ËäÇÁÇπ‰πãÈó¥Ê≤°ÊúâËÅîÁ≥ª ËæìÂÖ•ÂíåËæìÂá∫ÁöÑÁª¥Â∫¶Âõ∫ÂÆö„ÄÇÊó†Ê≥ïÂ§ÑÁêÜÂèòÈïøÁöÑÂ∫èÂàóÊï∞ÊçÆÔºüÁª¥Â∫¶ÊîπÂèòÁöÑÊó∂Â∫èÈóÆÈ¢ò Êó∂Â∫èÁöÑÈïøÂ∫¶ÊòØ‰ªÄ‰πàÔºü‰∏Ä‰∏™Â≠óÁ¨¶‰∏≤ÁöÑÈïøÂ∫¶Ôºü ÊØèÊ¨°ËæìÂá∫Âè™‰æùËµñ‰∫éÂΩìÂâçËæìÂÖ• Âæ™ÁéØÁ•ûÁªèÁΩëÁªúÁöÑÈöæÁÇπ ÊåâÁÖßÊó∂Â∫èÂèçÂêë‰º†Êí≠ÁöÑÊó∂ÂÄôÂ≠òÂú®Ê¢ØÂ∫¶ÁàÜÁÇ∏ÂíåÊ¢ØÂ∫¶Ê∂àÂ§±„ÄÇËß£ÂÜ≥ÂäûÊ≥ïÔºöÂºïÂÖ•Èó®ÊéßÊú∫Âà∂„ÄÇ A character-level RNN Âº∫ÂåñÂ≠¶‰π†ÂØπÊäóÁ•ûÁªèÁΩëÁªúGAN ÈòÖËØª ‰ªÄ‰πàÊòØÁîüÊàêÂºèÂØπÊäóÁΩëÁªúGAN 2017ÁéãÈ£ûË∑ÉÁ≠âÔºöÁîüÊàêÂºèÂØπÊäóÁΩëÁªú GAN ÁöÑÁ†îÁ©∂ËøõÂ±ï‰∏éÂ±ïÊúõhttps://www.msra.cn/zh-cn/news/features/gan-20170511) 2019ËÆ∫ÊñáÔºöÂõæÂÉèË°•‰∏ÅË∫≤ËøáÂõæÂÉèËØÜÂà´Ôºà19.05.02Ôºâcode ÁîüÊàêÂØπÊäóÁΩëÁªúÁöÑÂ∑•‰ΩúÂéüÁêÜÔºö‰∏Ä‰∏™ÊòØÊëÑÂΩ±Â∏àÔºàÁî∑ÁîüÔºâÔºå‰∏Ä‰∏™ÊòØÊëÑÂΩ±Â∏àÁöÑÂ•≥ÊúãÂèãÔºàÂ•≥ÁîüÔºâ„ÄÇÁî∑Áîü‰∏ÄÁõ¥ËØïÂõæÊãçÂá∫ÂÉè‰ºóÂ§ö‰ºòÁßÄÊëÑÂΩ±Â∏à‰∏ÄÊ†∑ÁöÑÂ•ΩÁÖßÁâáÔºåËÄåÂ•≥Áîü‰∏ÄÁõ¥‰ª•ÊåëÂâîÁöÑÁúºÂÖâÊâæÂá∫‚ÄúËá™Â∑±Áî∑ÊúãÂèã‚ÄùÊãçÁöÑÁÖßÁâáÂíå‚ÄúÂà´‰∫∫ÂÆ∂ÁöÑÁî∑ÊúãÂèã‚ÄùÊãçÁöÑÁÖßÁâáÁöÑÂå∫Âà´„ÄÇ‰∫éÊòØ‰∏§ËÄÖÁöÑ‰∫§ÊµÅËøáÁ®ãÁ±ª‰ºº‰∫éÔºöÁî∑ÁîüÊãç‰∏Ä‰∫õÁÖßÁâá -&gt;Â•≥ÁîüÂàÜËæ®Áî∑ÁîüÊãçÁöÑÁÖßÁâáÂíåËá™Â∑±ÂñúÊ¨¢ÁöÑÁÖßÁâáÁöÑÂå∫Âà´-&gt;Áî∑ÁîüÊ†πÊçÆÂèçÈ¶àÊîπËøõËá™Â∑±ÁöÑÊäÄÊúØÔºåÊãçÊñ∞ÁöÑÁÖßÁâá-&gt;Â•≥ÁîüÊ†πÊçÆÊñ∞ÁöÑÁÖßÁâáÁªßÁª≠ÊèêÂá∫ÊîπËøõÊÑèËßÅ-&gt;‚Ä¶‚Ä¶ÔºåËøô‰∏™ËøáÁ®ãÁõ¥Âà∞ÂùáË°°Âá∫Áé∞ÔºöÂç≥Â•≥Áîü‰∏çËÉΩÂÜçÂàÜËæ®Âá∫‚ÄúËá™Â∑±Áî∑ÊúãÂèã‚ÄùÊãçÁöÑÁÖßÁâáÂíå‚ÄúÂà´‰∫∫ÂÆ∂ÁöÑÁî∑ÊúãÂèã‚ÄùÊãçÁöÑÁÖßÁâáÁöÑÂå∫Âà´„ÄÇ ÁîüÊàêÂØπÊäóÁΩëÁªúÁöÑÂ∑•‰ΩúÂéüÁêÜÔºö‰ª•ÂõæÂÉèÁîüÊàêÊ®°Âûã‰∏æ‰æã„ÄÇÂÅáËÆæÊàë‰ª¨Êúâ‰∏Ä‰∏™ÂõæÁâáÁîüÊàêÊ®°ÂûãÔºàgeneratorÔºâÔºåÂÆÉÁöÑÁõÆÊ†áÊòØÁîüÊàê‰∏ÄÂº†ÁúüÂÆûÁöÑÂõæÁâá„ÄÇ‰∏éÊ≠§ÂêåÊó∂Êàë‰ª¨Êúâ‰∏Ä‰∏™ÂõæÂÉèÂà§Âà´Ê®°ÂûãÔºàdiscriminatorÔºâÔºåÂÆÉÁöÑÁõÆÊ†áÊòØËÉΩÂ§üÊ≠£Á°ÆÂà§Âà´‰∏ÄÂº†ÂõæÁâáÊòØÁîüÊàêÂá∫Êù•ÁöÑËøòÊòØÁúüÂÆûÂ≠òÂú®ÁöÑ„ÄÇÈÇ£‰πàÂ¶ÇÊûúÊàë‰ª¨ÊääÂàöÊâçÁöÑÂú∫ÊôØÊò†Â∞ÑÊàêÂõæÁâáÁîüÊàêÊ®°ÂûãÂíåÂà§Âà´Ê®°Âûã‰πãÈó¥ÁöÑÂçöÂºàÔºåÂ∞±ÂèòÊàê‰∫ÜÂ¶Ç‰∏ãÊ®°ÂºèÔºöÁîüÊàêÊ®°ÂûãÁîüÊàê‰∏Ä‰∫õÂõæÁâá-&gt;Âà§Âà´Ê®°ÂûãÂ≠¶‰π†Âå∫ÂàÜÁîüÊàêÁöÑÂõæÁâáÂíåÁúüÂÆûÂõæÁâá-&gt;ÁîüÊàêÊ®°ÂûãÊ†πÊçÆÂà§Âà´Ê®°ÂûãÊîπËøõËá™Â∑±ÔºåÁîüÊàêÊñ∞ÁöÑÂõæÁâá-&gt;¬∑¬∑¬∑¬∑ÔºàËÆ≠ÁªÉËøáÁ®ãÁî±ÁîüÊàêÊ®°ÂûãÂíåÂà§Âà´Ê®°ÂûãÁªÑÊàêÔºâ ÊúÄÁÆÄÂçïÁöÑÊï∞ÊçÆÁîüÊàêÊ®°ÂûãÔºöÂ¶ÇÊûúÊúâÊï∞ÊçÆÈõÜS={x1Ôºå‚Ä¶xn}ÔºåÂÅáËÆæËøô‰∫õÊï∞ÊçÆÁöÑÂàÜÂ∏ÉP{X}Êúç‰ªég(x;Œ∏)ÔºåÂú®ËßÇÊµãÊï∞ÊçÆ‰∏äÈÄöËøáÊúÄÂ§ßÂåñ‰ººÁÑ∂ÂáΩÊï∞ÂæóÂà∞Œ∏ÁöÑÂÄºÔºåÂç≥ÊúÄÂ§ß‰ººÁÑ∂Ê≥ïÔºö\max _{\theta} \sum_{i=1}^{n} \log g\left(x_{i} ; \theta\right)„ÄÇÂΩìËøô‰∏™ÁîüÊàêÊ®°ÂûãÊòØÁ•ûÁªèÁΩëÁªúÁöÑÊó∂ÂÄôÔºåÂ∞±ÊòØÁîüÊàêÂºèÂØπÊäóÁΩëÁªúÔºàGANÔºâ ÊñáÁåÆÁªºËø∞ ÁΩëÁªúÁªòÂõæÁîªÂõæËΩØ‰ª∂ Visio NN-SVGÔºåÈÄÇÂêàÂç∑ÁßØÁ•ûÁªèÁΩëÁªú, Âú®Á∫øÈìæÊé• PlotNeuralNetÔºåÂü∫‰∫éLatexÔºågithubÁöÑÈìæÊé•ÔºåÂØºÂá∫pdf Êèê‰æõÂæàÂ§öÊ®°ÁâàÁöÑÂú®Á∫øÁîªÂõæÁΩëÈ°µ Á•ûÁªèÁΩëÁªúÁöÑ‰æãÂ≠ê Edge detection: HED multi-scale: ‰∏çÂêåÂ§ßÂ∞èÁöÑÂç∑ÁßØÊ†∏ multi-level: receptive field: ÁΩëÁªúÂ±ÇÊ¨°Ë∂äÊ∑±ÔºåË∂äÂ§ßÔºåË∂äÊäΩË±° weighted-fusion layer: MSRB MSRB for SR MSRB for denoising SR: MSRN Â∏∏ËßÅÈóÆÈ¢ò DNNÔºàDeep Neural NetworkÔºâÂíåDeep CNNÁöÑÂå∫Âà´ ËøáÂéª‰º†ÁªüÁöÑÁ•ûÁªèÁΩëÁªúANNÔºàArtifical Neural NetworkÔºâÔºåÈÉΩÊòØÂ±ÇÊ¨°ËæÉÂ∞ëÁöÑÁΩëÁªúÂûãÁªìÊûÑÔºåÊâÄ‰ª•ÂèàË¢´Áß∞‰∏∫ÊµÖÂ±ÇÁΩëÁªúÔºàshallow neural networkÔºâÔºåDNN‰∏é‰º†ÁªüSNNÁöÑÂå∫Âà´Â∞±Âú®‰∫éÂÖ∂ÁΩëÁªúÂ±ÇÊ¨°ÁªìÊûÑÊõ¥Â§öÔºåÁ≠âÂ§çÊùÇÔºåÂõ†Ê≠§Áî±‰∫éÂÖ∂Â±ÇÊ¨°Êõ¥Â§öÔºåÂú®ÂõæËÆ∫‰∏äËØ¥Â∞±ÊòØÂõæÁöÑÊ∑±Â∫¶Êõ¥Ê∑±ÔºåÊâÄ‰ª•Ë¢´ÂÜ†Âêç‰∏∫Ê∑±Â∫¶Á•ûÁªèÁΩëÁªúÔºàDeep Neural Network) Deep CNNÊòØ‰ΩøÁî®‰∫ÜÂç∑ÁßØÁöÑÁΩëÁªú„ÄÇDNNÊòØÊúÄÂü∫Êú¨ÁöÑÁΩëÁªúÁªìÊûÑ„ÄÇ]]></content>
      <categories>
        <category>Ê∑±Â∫¶Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>ÁΩëÁªúÁªìÊûÑ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PytorchÂ≠¶‰π†Á¨îËÆ∞]]></title>
    <url>%2Fp%2Fef8a.html</url>
    <content type="text"><![CDATA[PytorchÂ≠¶‰π†Á¨îËÆ∞‚Äî‚ÄîÈöèÊó∂Êõ¥Êñ∞ PytorchÁéØÂ¢É Êü•ÁúãpytorchÁâàÊú¨ 1234&gt;&gt;&gt; import torch&gt;&gt;&gt; print(torch.__version__)0.4.0# Êõ¥Êñ∞‰πãÂêé Êõ¥Êñ∞pytorch 1conda update pytorch torchvision Backward Propagation ÁÆóÊ≥ï Êú∫Âô®Â≠¶‰π†‰∏≠ÁöÑÁ∫øÊÄß‰ª£Êï∞‰πãÁü©ÈòµÊ±ÇÂØº ÂêëÈáèÔºåÊ†áÈáèÂØπÂêëÈáèÊ±ÇÂØºÊï∞ GPU Êü•Áúãcuda‰ª•ÂèäpytorchÁâàÊú¨ 123print(torch.cuda.current_device()) import pytorchprint(torch.__version__) ÊåáÂÆöcuda ÊåáÂÆötorchÁöÑËÆæÂ§á 12345678torch.device('cuda',0) or torch.device('cuda:0') orvar = torch.device('cuda:0')a = torch.randn((2,3),device=var)b = torch.randn(2,3).to_sparse().requires_grad_(True)torch.randn((2,3), 'cuda:1'), cuda1= torch.device('cuda:1')Ôºå torch.randn((2,3), device=cuda1) Êï∞ÊçÆËøÅÂæôÔºöÂ∞ÜPytorchÊ®°Âûã‰ªéCPUËΩ¨Êç¢ÊàêGPU Êï∞ÊçÆÂ§ÑÁêÜtorch.ToTensorÔºöÂ∞Ü[0,255]‰πãÈó¥ÁöÑÂõæÂÉèÊàñËÄÖnumpyËΩ¨ÂåñÊàê[0,1]‰πãÈó¥ÁöÑtensor„ÄÇ torch.from_numpyÔºöÂ∞ÜnumpyËΩ¨ÂåñÊàêtensor, Âπ∂‰∏ç‰ºöÊîπÂèòÊï∞ÊçÆÂ§ßÂ∞è„ÄÇ TensorÂº†Èáè ÈÄöËøápytorchÂàõÂª∫Âº†Èáè 123x = torch.randn(M,NÔºâ.type(dtype)# ÂéüÊù•ÊòØÈÄöËøánumpyÂàõÂª∫Êï∞ÁªÑ, numpyÊèê‰æõ‰∫ÜÂæàÂ§öÁü©ÈòµÊï∞Â≠¶ËÆ°ÁÆóx = np.random.randn(N, I) Â∞ÜÂº†ÈáèÊîæÂú®GPU‰∏ä Âº†ÈáèÂú®cpuÂíågpu‰πãÈó¥ÁöÑËΩ¨Êç¢ ‰ªécpu ‚Äì&gt; gpuÔºå‰ΩøÁî®data.cuda()‰ªégpu ‚Äì&gt; cpuÔºå‰ΩøÁî®data.cpu() Âº†Èáè‰πãÈó¥ÁöÑËΩ¨Êç¢ tensorÁöÑÂàõÂª∫ Áõ¥Êé•ÂàõÂª∫Ôºö 12torch.tensor([..]).type(..)torch.FloatTensor() ÂàõÂª∫ÈöèÊú∫Áü©ÈòµÔºö 123dtype = torch.Floatensor dtype = torch.cuda.Floatensor torch.randn((M,N),type(dtype) ‰ªéÂÖ∂‰ªñÊï∞ÊçÆÁ±ªÂûã: 12data = [[1,2],[3,4]]tensor = torch.FloatTensor(data) ÊâæÂá∫ÂÖ∂‰∏≠ÊúÄÂ§ßÂÖÉÁ¥† torch.max(input) Áü©ÈòµÊìç‰Ωú Â¢ûÂä†Áª¥Â∫¶ ÂáèÂ∞ëÁª¥Â∫¶ torchÁöÑÁü©ÈòµÊìç‰Ωú PytorchÂèØËßÜÂåñÂà©Áî®tensorboardÁîªÂõæ ÈÄöËøáloggerÊñá‰ª∂ÂèØËßÜÂåñËÆ≠ÁªÉËøáÁ®ã„ÄÅÂÆòÁΩë„ÄÅÂà´‰∫∫ÂÜôÁöÑtensorflow‰∏ãÊØîËæÉÂÖ∑‰ΩìÁöÑÂèØËßÜÂåñ Âá∫Áé∞ÁöÑÈóÆÈ¢ò Á´ØÂè£ÂÜ≤Á™ÅÈÄöËøáÊåáÂÆöÁ´ØÂè£Ëß£ÂÜ≥Ôºö 12tensorboard --logdir=/tmp --port=8008 #ÁªùÂØπË∑ØÂæÑtensorboard --logdir=./tmp --port=8008 #Áõ∏ÂØπË∑ØÂæÑ tensorbardÂëΩ‰ª§Êó†Ê≥ïÊâæÂà∞Ôºö 1python3 -m tensorboard.main --logdir=~/my/training/dir ËøõÂÖ•ÁõÆÂΩïÔºö 123pip show tensorflowcd /home/abc/xy/.local/lib/python2.7/site-packagespython main.py --logdir=/path/to/log_file/ Ë∑ØÂæÑÁöÑÂêçÁß∞Ë¶ÅÂ∞èÂøÉÔºåË∑ØÂæÑÂæóÊòØÊ†πÁõÆÂΩï, ‰∏çÈúÄË¶ÅÂºïÂè∑ 1yyfang@mai:~$ ge/ERRNet_Code/logs --port=8008 ÂèØËßÜÂåñ 1234567891011121314151617181920212223242526272829303132if iteration % 100 == 0: print("===&gt; Epoch[&#123;&#125;](&#123;&#125;/&#123;&#125;): Loss: &#123;:.6f&#125;".format(epoch, iteration, len(training_data_loader),loss.data.item())) info = &#123; 'loss': loss.data.item()&#125; itera = (epoch-1)*len(training_data_loader)+iteration for tag, value in info.items(): logger.scalar_summary(tag, value, itera) for tag, value in model.named_parameters(): # print(value.grad) logger.histo_summary(tag, to_np(value), itera) logger.histo_summary(tag+'/grad', to_np(value.grad), iteration) images = input * 255. # ?[0,1]?????[0,255]?? images[images &lt; 0] = 0 images[images &gt; 255.] = 255. a =to_np(images.view(-1, 64, 64)[:8]) # info_input = &#123;'input': to_np(images.view(-1, 64, 64)[:2])&#125; imagelabel = label * 255. # ?[0,1]?????[0,255]?? imagelabel[imagelabel &lt; 0] = 0 imagelabel[imagelabel &gt; 255.] = 255. b = to_np(imagelabel.view(-1, 64, 64)[:8]) c = np.hstack((a,b)) # print(images) info_label = &#123;'inpput/label': c&#125; for tag, images in info_label.items(): logger.image_summary(tag, images, itera) # for tag, images in info_label.items(): # logger.image_summary(tag, images, iteration) if iteration % 5000 == 0: number = opt.number save_checkpoint_iter(model, number) opt.number += 1 Êï∞ÊçÆÈõÜ ËÆ≠ÁªÉÈõÜ(train set) È™åËØÅÈõÜ(validation set) ÊµãËØïÈõÜ(test setÔºâ training setÔºö Áî®Êù•ËÆ≠ÁªÉÊ®°Âûã validation set : Áî®Êù•ÂÅömodel selectionÔºàÂæÄÂæÄÊàë‰ª¨ÈúÄË¶ÅÂØπÂ§öÁßçÊ®°ÂûãËøõË°åËÆ≠ÁªÉÔºåËÆ≠ÁªÉÂÆå‰πãÂêéÂ∞±‰ºöÂæóÂà∞Â§ö‰∏™Ê®°ÂûãÁöÑÁªìÊûúÔºåÊàë‰ª¨Â∏åÊúõ‰ªéËøô‰∫õËÆ≠ÁªÉÂ•ΩÁöÑÊ®°Âûã‰∏≠ÈÄâÊã©ÊúÄÈÄÇÂêàÁöÑÊ®°ÂûãÔºâ test set : Áî®Êù•ËØÑ‰º∞ÊâÄÈÄâÂá∫Êù•ÁöÑmodelÁöÑÂÆûÈôÖÊÄßËÉΩ Âá†‰∏™Â∏∏Áî®Êï∞ÊçÆÈõÜ BSD500Ôºö DIV2KÔºö ÂáΩÊï∞ Áü©ÈòµÁõ∏‰πò/ÁÇπ‰πò 123456789data = [[1,2],[3,4]]tensor = torch.FloatTensor(data)# numpynp.matmual(data, data)# tensortorch.mm(tensor, tensor) # Áü©ÈòµÁõ∏‰πòtensor.mm(tensor.t())torch.mul(tensor,tenor.t()) #ÁÇπ‰πòtensor.mul(tensor) Â∞ÜÊï∞ÁªÑÊà™ÂèñÂà∞‰∏Ä‰∏™Âå∫Èó¥ 12h_relu = h.clamp(min=0)h_relu2 = torch.clamp(h, min=0) To_npÂáΩÊï∞: ËΩ¨ÂåñÊï∞ÊçÆÁ±ªÂûã ÂåÖÂê´Âú®Â∫ìfastai‰∏≠ 1from fastai.basics import * ÁΩëÁªúÁªìÊûÑ-nnÂåÖtorch_nn‰∏≠ÊñáÊñáÊ°£ torch.nnÁöÑÁ∫øÂΩ¢Â±Ç torch.nnÁöÑÂç∑ÁßØÂ±Ç Âç∑ÁßØÊ†∏ÁöÑÂ§ßÂ∞è: [out_Channel, in_Channel, kernel_size, kernel_size] biasÁöÑÂ§ßÂ∞è:[out_Channel] ÁªßÊâønn.modleËá™ÂÆö‰πâÊ®°Âùó ÈóÆÈ¢ò Â¶Ç‰ΩïÂàùÂßãÂåñmodel‰∏≠ÁöÑÂèÇÊï∞ ‰∏∫‰ªÄ‰πàÈúÄË¶Åmodel.zero_grad‰πãÂêéÂÜçbackward(), ‰æãÂ¶Ç model.zero_grad() optimizer.zero_grad() ‰ºòÂåñÂô®optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) ÊçüÂ§±ÂáΩÊï∞ Â¶Ç‰ΩïËá™ÂÆö‰πâÊçüÂ§±ÂáΩÊï∞ Âπ∂Ë°åËøêÁÆóParallelpytorch‰∏≠Â¶ÇÊûú‰ΩøÁî®DataParallelÔºåÈÇ£‰πà‰øùÂ≠òÁöÑÊ®°ÂûãkeyÂÄºÂâçÈù¢‰ºöÂ§öÂá∫‚Äômodules.‚ÄôÔºåËøôÊ†∑Â¶ÇÊûúËÆ≠ÁªÉÁöÑÊó∂ÂÄô‰ΩøÁî®ÁöÑÊòØÂ§öGPUÔºåËÄåÊµãËØïÁöÑÊó∂ÂÄô‰ΩøÁî®ÁöÑÊòØÂçïGPUÔºåÊ®°ÂûãËΩΩÂÖ•Â∞±‰ºöÂá∫Áé∞ÈóÆÈ¢ò„ÄÇÊîæÂà∞cpu‰∏ç‰ºöÊúâÈóÆÈ¢ò 1.nn.para 2..todevice() ÂõæÂÉèÂ§ÑÁêÜ„Äêpytorch„ÄëÂõæÂÉèÂü∫Êú¨Êìç‰Ωú ‰æãÂ≠êÔºöËÆæÁΩÆGPUÂíåÈ¢ÑËÆ≠ÁªÉÊ®°Âûã1234567891011121314151617181920212223242526272829 criterion = nn.MSELoss(size_average=False)# ËÆæÁΩÆGPU print("===&gt; Setting GPU") if cuda: # Ë∞ÉÁî®Â§ö‰∏™GPU model = nn.DataParallel(model, device_ids=[0, 1, 2, 3]).cuda() # Ë∞ÉÁî®Âçï‰∏™GPU model = model.cuda() criterion = criterion.cuda() else: model = model.cpu() # Âä†ËΩΩÈ¢ÑÈ¢ÑËÆ≠ÁªÉÂ•ΩÁöÑÊ®°ÂûãÂèäÊùÉÈáç if opt.pretrained: if os.path.isfile(opt.pretrained): print("=&gt; loading model '&#123;&#125;'".format(opt.pretrained)) weights = torch.load(opt.pretrained) model.load_state_dict(weights['model'].state_dict()) else: print("=&gt; no model found at '&#123;&#125;'".format(opt.pretrained)) # ‰øùÂ≠òÊ®°ÂûãÁöÑÂèÇÊï∞ # Save checkpoint save_file = os.path.join(TMP_DIR, 'checkpoint_epoch&#123;&#125;.pth'.format(epoch)) save_checkpoint(&#123; 'epoch': epoch, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict() &#125;, filename=save_file) Ëá™ÂÆö‰πâLossFunction PytorchÂ¶Ç‰ΩïËá™ÂÆö‰πâÊçüÂ§±ÂáΩÊï∞ GPUËÆ°ÁÆóÂä†ÈÄü01 : AIÊó∂‰ª£‰∫∫‰∫∫ÈÉΩÂ∫îËØ•‰∫ÜËß£ÁöÑGPUÁü•ËØÜ GPUÂä†ÈÄü02:Ë∂ÖËØ¶ÁªÜPython CudaÈõ∂Âü∫Á°ÄÂÖ•Èó®ÊïôÁ®ãÔºåÊ≤°ÊúâÊòæÂç°‰πüËÉΩÂ≠¶ÔºÅ Ëá™ÂÆö‰πâLossTV 123456789101112131415161718192021222324252627282930import torchimport torch.nn as nnfrom torch.autograd import Variableclass TVLoss(nn.Module): def __init__(self,TVLoss_weight=1): super(TVLoss,self).__init__() self.TVLoss_weight = TVLoss_weight def forward(self,x): batch_size = x.size()[0] h_x = x.size()[2] w_x = x.size()[3] count_h = self._tensor_size(x[:,:,1:,:]) count_w = self._tensor_size(x[:,:,:,1:]) h_tv = torch.pow((x[:,:,1:,:]-x[:,:,:h_x-1,:]),2).sum() w_tv = torch.pow((x[:,:,:,1:]-x[:,:,:,:w_x-1]),2).sum() return self.TVLoss_weight*2*(h_tv/count_h+w_tv/count_w)/batch_size def _tensor_size(self,t): return t.size()[1]*t.size()[2]*t.size()[3]def main(): x = Variable(torch.FloatTensor([[[1, 2, 3], [2, 3, 4], [3, 4, 5]], [[1, 2, 3], [2, 3, 4], [3, 4, 5]]]).view(1, 2, 3, 3),requires_grad=True) addition = TVLoss() z = addition(x) print x print z.data z.backward() print x.grad Debug Anaconda‰∏≠ÔºåimportÂíåÂÆûÈôÖÁöÑ‰∏çÁ¨¶ AnacondaÊ∏ÖÈô§ÂéÜÂè≤ÔºåÂê¶ÂàôÂêå‰∏Ä‰∏™Ê†ºÂ≠êÂà∑Êñ∞ÔºåÂπ∂‰∏ç‰ºöÂΩ±ÂìçÂâçÈù¢Â∑≤ÁªèimportÁöÑÂÜÖÂÆπ torchÁâàÊú¨Â∏¶Êù•ÁöÑbug loss.data[0] -&gt;loss.data.item() Mac air(Êú™Ëß£ÂÜ≥) ËΩΩÂÖ•Ê®°ÂûãÂèÇÊï∞Êó∂Êä•ÈîôÔºàÂú®ubuntu‰∏ã‰∏çÊä•ÈîôÔºåubuntuÁöÑÁâàÊú¨ÊòØ1.0.1.post2, air‰∏ãÊòØ0.4.0Ôºâ 1AttributeError: Can&apos;t get attribute &apos;_rebuild_parameter&apos; on &lt;module &apos;torch._utils&apos; from &apos;/Users/yingyingfang/anaconda3/lib/python3.6/site-packages/torch/_utils.py&apos;&gt; Ubuntu‰∏ãËÆ≠ÁªÉRCFÊ®°ÂûãÊó∂Êä•ÈîôÔºàËß£ÂÜ≥Ôºâ 12345expected object of backend cpu but got backend cuda for argument #2 'weight'# Ëß£ÂÜ≥ÂäûÊ≥ïinput=input.cuda()net = net.cuda()net(input) Â¶Ç‰ΩïÊèêÈ´òËÆ≠ÁªÉÈÄüÂ∫¶ Âπ∂Ë°åËøêÁÆó RuntimeError: Input type (torch.cuda.DoubleTensor) and weight type (torch.cuda.FloatTensor) should be the same ‰∫ßÁîüÂéüÂõ†ÔºöÂàõÂª∫‰∫Ü‰∏Ä‰∏™È´òÊñØÈöèÊú∫ÂàÜÂ∏É‰πãÂêéÔºü Ëß£ÂÜ≥ÂäûÊ≥ïÔºöÂ∞ÜÊï∞ÊçÆÁ±ªÂûãËΩ¨Êç¢ÊàêFloatTensorÂç≥ÂèØÔºåÂ¶Ç‰∏ãÔºåÂä†‰∏ÄË°å‰ª£Á†Å 123train_label_batch = torch.from_numpy(train_label_batch)train_label_batch = train_label_batch.type(torch.FloatTensor) # ËΩ¨Floattrain_label_batch = train_label_batch.cuda() # ËΩ¨cuda RuntimeError: all tensors must be on devices[0] ÈóÆÈ¢ò Â¶Ç‰ΩïÊåáÂÆögpuËÆ≠ÁªÉ Â¶Ç‰Ωïmulti-gpuËÆ≠ÁªÉ]]></content>
      <categories>
        <category>Ê∑±Â∫¶Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UbuntuÊúçÂä°Âô®]]></title>
    <url>%2Fp%2F6fe1.html</url>
    <content type="text"><![CDATA[ÊúçÂä°Âô®Â≠¶‰π† ÈÖçÁΩÆÁªàÁ´ØÂëΩ‰ª§Ë°åÂÜÖÂÖ≥ÈîÆÂ≠óÂõûÊ∫ØÂéÜÂè≤ÂëΩ‰ª§ ËÆ©‰Ω†ÁöÑiTermÊõ¥Geek! Âø´Êç∑ÈîÆÂú®ÊúçÂä°Âô®ÈáåÂàáÊç¢ÁïåÈù¢Ôºöalt+tab ÈìæÊé•‰ΩøÁî®ÂëΩ‰ª§ÁöÑÂëΩ‰ª§„ÄÇ ÁúãÂÆåËøôÁØáLinuxÂü∫Êú¨ÁöÑÊìç‰ΩúÂ∞±‰ºö‰∫Ü https://github.com/jlevy/the-art-of-command-line/blob/master/README-zh.md ‰∏Ä‰∏™Â≠¶‰π†linuxÁöÑÁΩëÁ´ô ÂëΩ‰ª§Ë°åÊ∏ÖÂçï ÂÆö‰πâÂèòÈáè1your_name=&quot;qinjx&quot; Áî®ÂºïÂè∑ÔºåÁ≠âÂè∑ÊóÅËæπ‰∏çËÉΩÊúâÁ©∫Ê†º„ÄÇÂê¶Âàô‰ºöË¢´ÁúãÊàêÊó†Ê≥ïËØÜÂà´ÁöÑÂëΩ‰ª§ ÂëΩÂêçÂè™ËÉΩ‰ΩøÁî®Ëã±ÊñáÂ≠óÊØçÔºåÊï∞Â≠óÂíå‰∏ãÂàíÁ∫øÔºåÈ¶ñ‰∏™Â≠óÁ¨¶‰∏çËÉΩ‰ª•Êï∞Â≠óÂºÄÂ§¥„ÄÇ‰∏≠Èó¥‰∏çËÉΩÊúâÁ©∫Ê†ºÔºåÂèØ‰ª•‰ΩøÁî®‰∏ãÂàíÁ∫øÔºà_Ôºâ„ÄÇ‰∏çËÉΩ‰ΩøÁî®Ê†áÁÇπÁ¨¶Âè∑„ÄÇ‰∏çËÉΩ‰ΩøÁî®bashÈáåÁöÑÂÖ≥ÈîÆÂ≠óÔºàÂèØÁî®helpÂëΩ‰ª§Êü•Áúã‰øùÁïôÂÖ≥ÈîÆÂ≠óÔºâ ÊêúÁ¥¢ ÊêúÁ¥¢Êñá‰ª∂Â§πÂÜÖÂá∫Áé∞ÁöÑÂ≠óÁ¨¶‰∏≤ findÂíågrepÁöÑÂå∫Âà´ 12grep -n "get_spg2lsf" -r ./grep -n "data_test" -r ./ 12345678910111213141516171819202122232425262728293031323334353637383940 ËØ•ÂëΩ‰ª§‰ºöÊü•ÊâæÂΩìÂâçÁõÆÂΩïÂèäÂÖ∂Â≠êÁõÆÂΩï‰∏ãÊâÄÊúâÂåÖÂê´ÊåáÂÆöÂ≠óÁ¨¶‰∏≤ÁöÑÊñá‰ª∂Ôºå‰ºöÂàóÂá∫Êñá‰ª∂‰ΩçÁΩÆ„ÄÅËØ•Ë°åÁöÑÂÜÖÂÆπ‰ª•ÂèäË°åÂè∑„ÄÇ # Êñá‰ª∂Â§ÑÁêÜ## ÊòæÁ§∫ÈöêËóèÊñá‰ª∂ls -aÊ°åÈù¢Èù¢ÂèØËßÜÂåñÁ™óÂè£ÔºåËøõÂÖ•ctrl + h ÔºåÂàôÊòæÁ§∫ÈöêËóèÊñá‰ª∂## ÂàõÂª∫ÁõÆÂΩïMkdir## Â§çÂà∂Âà†Èô§Êñá‰ª∂cprm##‰∏ãËΩΩÊñá‰ª∂ftp‰∏ãËΩΩ‚Äã Â¶ÇÊûú‰∏ãËΩΩ[ftpÊúçÂä°Âô®](https://www.baidu.com/s?wd=ftp%E6%9C%8D%E5%8A%A1%E5%99%A8&amp;tn=24004469_oem_dg&amp;rsv_dl=gh_pl_sl_csd)‰∏äÁöÑÊñá‰ª∂ÔºåÂèØ‰ª•Áî®ftpÂëΩ‰ª§„ÄÇÁÑ∂ÂêéÁî®getÂëΩ‰ª§‰∏ãËΩΩÊñá‰ª∂ÁΩëÂùÄ‰∏ãËΩΩ‚Äã```bashwget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip1.WgetÂ∏∏Áî®ÂèÇÊï∞ ‚óÜ-bÔºöÂêéÂè∞‰∏ãËΩΩÔºåWgetÈªòËÆ§ÁöÑÊòØÊääÊñá‰ª∂‰∏ãËΩΩÂà∞ÂΩìÂâçÁõÆÂΩï„ÄÇ ‚óÜ-OÔºöÂ∞ÜÊñá‰ª∂‰∏ãËΩΩÂà∞ÊåáÂÆöÁöÑÁõÆÂΩï‰∏≠„ÄÇ ‚óÜ-PÔºö‰øùÂ≠òÊñá‰ª∂‰πãÂâçÂÖàÂàõÂª∫ÊåáÂÆöÂêçÁß∞ÁöÑÁõÆÂΩï„ÄÇ ‚óÜ-tÔºöÂ∞ùËØïËøûÊé•Ê¨°Êï∞ÔºåÂΩìWgetÊó†Ê≥ï‰∏éÊúçÂä°Âô®Âª∫Á´ãËøûÊé•Êó∂ÔºåÂ∞ùËØïËøûÊé•Â§öÂ∞ëÊ¨°„ÄÇ ‚óÜ-cÔºöÊñ≠ÁÇπÁª≠‰º†ÔºåÂ¶ÇÊûú‰∏ãËΩΩ‰∏≠Êñ≠ÔºåÈÇ£‰πàËøûÊé•ÊÅ¢Â§çÊó∂‰ºö‰ªé‰∏äÊ¨°Êñ≠ÁÇπÂºÄÂßã‰∏ãËΩΩ„ÄÇ ‚óÜ-rÔºö‰ΩøÁî®ÈÄíÂΩí‰∏ãËΩΩ git‰∏ãËΩΩ 123git clone &lt;https://github.com/LimBee/NTIRE2017.git&gt; Ëß£ÂéãÊñá‰ª∂ Unzip https://www.cnblogs.com/chinareny2k/archive/2010/01/05/1639468.html) test Êü•ÁúãÂä®ÊÄÅÊñá‰ª∂tailÂëΩ‰ª§ 12341„ÄÅtail -f filenameËØ¥ÊòéÔºöÁõëËßÜfilenameÊñá‰ª∂ÁöÑÂ∞æÈÉ®ÂÜÖÂÆπÔºàÈªòËÆ§10Ë°åÔºåÁõ∏ÂΩì‰∫éÂ¢ûÂä†ÂèÇÊï∞ -n 10ÔºâÔºåÂà∑Êñ∞ÊòæÁ§∫Âú®Â±èÂπï‰∏ä„ÄÇÈÄÄÂá∫ÔºåÊåâ‰∏ãCTRL+C„ÄÇ2„ÄÅtail -n 20 filenameËØ¥ÊòéÔºöÊòæÁ§∫filenameÊúÄÂêé20Ë°å„ÄÇ Êñá‰ª∂ÁºñËæëvimÂú®vi‰∏≠ÊåâuÂèØ‰ª•Êí§ÈîÄ‰∏ÄÊ¨°Êìç‰Ωú; Ctrl+r ÊÅ¢Â§ç‰∏ä‰∏ÄÊ≠•Ë¢´Êí§ÈîÄÁöÑÊìç‰Ωú vimÂ∏∏Áî®ÂëΩ‰ª§‰πãÂ§öË°åÊ≥®ÈáäÂíåÂ§öË°åÂà†Èô§ Êñá‰ª∂ÂÜÖÊêúÁ¥¢linux Êü•ÊâæÊüêÁõÆÂΩï‰∏ãÂåÖÂê´ÂÖ≥ÈîÆÂ≠óÂÜÖÂÆπÁöÑÊñá‰ª∂ ËøõÁ®ã ÂëΩ‰ª§ fg„ÄÅbg„ÄÅjobs„ÄÅ&amp;„ÄÅctrl + zÈÉΩÊòØË∑üÁ≥ªÁªü‰ªªÂä°ÊúâÂÖ≥ÁöÑÔºåËôΩÁÑ∂Áé∞Âú®Âü∫Êú¨‰∏ä‰∏çÊÄé‰πàÈúÄË¶ÅÁî®Âà∞Ëøô‰∫õÂëΩ‰ª§Ôºå‰ΩÜÂ≠¶‰ºö‰∫Ü‰πüÊòØÂæàÂÆûÁî®ÁöÑ 1.&amp; ÊúÄÁªèÂ∏∏Ë¢´Áî®Âà∞ Ëøô‰∏™Áî®Âú®‰∏Ä‰∏™ÂëΩ‰ª§ÁöÑÊúÄÂêéÔºåÂèØ‰ª•ÊääËøô‰∏™ÂëΩ‰ª§ÊîæÂà∞ÂêéÂè∞ÊâßË°å 2.ctrl + z ÂèØ‰ª•Â∞Ü‰∏Ä‰∏™Ê≠£Âú®ÂâçÂè∞ÊâßË°åÁöÑÂëΩ‰ª§ÊîæÂà∞ÂêéÂè∞ÔºåÂπ∂‰∏îÊöÇÂÅú 3.jobs Êü•ÁúãÂΩìÂâçÊúâÂ§öÂ∞ëÂú®ÂêéÂè∞ËøêË°åÁöÑÂëΩ‰ª§ 4.fg Â∞ÜÂêéÂè∞‰∏≠ÁöÑÂëΩ‰ª§Ë∞ÉËá≥ÂâçÂè∞ÁªßÁª≠ËøêË°å Â¶ÇÊûúÂêéÂè∞‰∏≠ÊúâÂ§ö‰∏™ÂëΩ‰ª§ÔºåÂèØ‰ª•Áî® fg %jobnumberÂ∞ÜÈÄâ‰∏≠ÁöÑÂëΩ‰ª§Ë∞ÉÂá∫Ôºå%jobnumberÊòØÈÄöËøájobsÂëΩ‰ª§Êü•Âà∞ÁöÑÂêéÂè∞Ê≠£Âú®ÊâßË°åÁöÑÂëΩ‰ª§ÁöÑÂ∫èÂè∑(‰∏çÊòØpid) 5.bg Â∞Ü‰∏Ä‰∏™Âú®ÂêéÂè∞ÊöÇÂÅúÁöÑÂëΩ‰ª§ÔºåÂèòÊàêÁªßÁª≠ÊâßË°å Â¶ÇÊûúÂêéÂè∞‰∏≠ÊúâÂ§ö‰∏™ÂëΩ‰ª§ÔºåÂèØ‰ª•Áî®bg %jobnumberÂ∞ÜÈÄâ‰∏≠ÁöÑÂëΩ‰ª§Ë∞ÉÂá∫Ôºå%jobnumberÊòØÈÄöËøájobsÂëΩ‰ª§Êü•Âà∞ÁöÑÂêéÂè∞Ê≠£Âú®ÊâßË°åÁöÑÂëΩ‰ª§ÁöÑÂ∫èÂè∑(‰∏çÊòØpid) ÂêéÂè∞ÊâßË°åËøõÁ®ãlinuxÂêéÂè∞ÊâßË°åÂëΩ‰ª§Ôºö&amp;Âíånohup command &amp;ÔºöÂÖ≥ÊéâÂ±èÂπïÔºåËøõÁ®ãÁªìÊùüÔºå‰∏çÂç†Áî®Â±èÂπïËÄåÂ∑≤ nohup commnd &amp;ÔºöÁúüÊ≠£Âú®ÂêéÂè∞ÊâßË°å PSÔºöÈúÄË¶ÅÁî®Êà∑‰∫§‰∫íÁöÑÂëΩ‰ª§‰∏çË¶ÅÊîæÂú®ÂêéÂè∞ÊâßË°å„ÄÇ ÊúâÂ§ßÈáèÁöÑËæìÂá∫ÔºåÂ∞±ËøõË°åÈáçÂÆöÂêë„ÄÇ 12yyfang@mai:~/Documents/Deeplearning_edge/ERRNet_edge/ERRNet_Code$ nohup python main.py --cuda --dataset="../../../dataset/data_edge_35.h5" &gt;result.txt 2&gt;&amp;1 &amp;[1] 22223 ÊòæÁ§∫ÊúÄÂêéÁöÑÂçÅË°å ÁõëËßÜËøõÁ®ãhttps://blog.csdn.net/shenhuan1104/article/details/75808146 Êü•ÁúãËøõÁ®ã ps -aux | grep xrdp ÊùÄÊ≠ªËøõÁ®ã $ kill -s 9 ËøõÁ®ãÂè∑ ÁÆ°ÈÅìÁ¨¶‚Äú|‚ÄùÁî®Êù•ÈöîÂºÄ‰∏§‰∏™ÂëΩ‰ª§ÔºåÁÆ°ÈÅìÁ¨¶Â∑¶ËæπÂëΩ‰ª§ÁöÑËæìÂá∫‰ºö‰Ωú‰∏∫ÁÆ°ÈÅìÁ¨¶Âè≥ËæπÂëΩ‰ª§ÁöÑËæìÂÖ•„ÄÇ ÊääpsÁöÑÊü•ËØ¢ÁªìÊûúÈÄöËøáÁÆ°ÈÅìÁªôgrepÊü•ÊâæÂåÖÂê´ÁâπÂÆöÂ≠óÁ¨¶‰∏≤ÁöÑËøõÁ®ã„ÄÇ $ ps -ef | grep firefox ÁõëËßÜGPU3.ÁõëËßÜGPUÁöÑ‰ΩøÁî®ÊÉÖÂÜµ 12$ nvidia-smi $ watch -n 10 nvidia-smi %10sÈíüËæìÂá∫‰∏ÄÊ¨° ÊåáÂÆöGPU ÂêØÁî®Áõ∏ÂÖ≥ËΩØ‰ª∂ÂíåÁ®ãÂ∫èmatlabhttps://blog.csdn.net/u013066730/article/details/80944063 ÂëΩ‰ª§Ë°å‰πãË°åmatlab 1234562.ËøêË°åmÊñá‰ª∂Â¶ÇÊûúmÊñá‰ª∂Âêç‰∏∫matlabfile.m(1)ÊñπÊ≥ï‰∏ÄËøõÂÖ•mÊñá‰ª∂ÊâÄÂú®ÁõÆÂΩïÂêéÔºåËøêË°å$ matlab -nodesktop -nosplash -r matlabfileÂè™Áî®Êñá‰ª∂ÂêçmatlabfileÔºå‰∏çËÉΩÊ∑ªÂä†.m Êõ¥ÊîπÂø´Êç∑ÈîÆ anacondaÂú®ÁªàÁ´ØËæìÂÖ•anaconda-navigator ÈÄÄÂá∫base ÊâßË°åpythonÂèÇÊï∞ËæìÂÖ• Positional argument v.s. keyword argument In other words, keyword arguments are only ‚Äúoptional‚Äù because they will be set to their default value if not specifically supplied. Â§öÂèÇÊï∞ËæìÂÖ• ËøúÁ®ãËøûÊé•xrdp ÊúçÂä°Áõ∏ÂÖ≥ SSDÁÆ°ÁêÜÈ¢ÑÂ§ÑÁêÜÊï∞ÊçÆÁöÑÊó∂ÂÄôÔºåË¶ÅÊ£ÄÊü•Á°¨ÁõòÊòØÂê¶ÊúâË∂≥Â§üÂ§ßÁöÑÁ©∫Èó¥ df -h GPUÁî±ÊòæÂç°ÂíåGPUÁªÑÊàê Áõ∏ÂΩì‰∫éÂÜÖÂ≠òÂíåCPUÁöÑÂå∫Âà´ ÂΩìÊòæÂç°ÂÜÖÂ≠ò‰∏çÂ§üÊó∂ÔºåÂíåbatchsizeÊúâÂÖ≥ÂíåÊï∞ÊçÆÈõÜÁöÑÂ§ßÂ∞èÊ≤°ÊúâÂÖ≥Á≥ªÔºå‰∏ÄÂùóÊòæÂç°Ôºå64*64ÁöÑbatchsize=16ËÄå‰∏çËÉΩËÆæÁΩÆÊàê32 ÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆanacondaÁéØÂ¢ÉÂèòÈáèÔºåÂú®ÁªàÁ´ØËæìÂÖ•Ôºö 1export PATH=~/anaconda/bin:$PATH ÊòæÁ§∫ÂΩìÂâçcondaÁâàÊú¨‰ø°ÊÅØÔºåÂú®ÁªàÁ´ØËæìÂÖ•Ôºö 1conda --version ‰πãÂêéÊàë‰ª¨ÂÜçÊ¨°ËæìÂÖ•ÂëΩ‰ª§ÂàóÂá∫AnacondaËá™Â∏¶ÁöÑÂåÖÔºåÂú®ÁªàÁ´ØËæìÂÖ•Ôºö 1conda list Â∏∏ËßÅÈóÆÈ¢ò ËøúÁ®ãÊ°åÈù¢Ê≠ªÊú∫ Áü•ÈÅìÊúçÂä°Âô®ËøúÁ®ãÊ°åÈù¢ÁöÑÊúçÂä°ÊâÄ‰ΩøÁî®ÁöÑÂçèËÆÆÔºåÂÖ≥ÊéâÁõ∏Â∫îËøõÁ®ãÂç≥ÂèØ„ÄÇ ‰∏çÁü•ÈÅìÁöÑÊÉÖÂÜµ‰∏ãÔºåÂèØÁåúÊµãÂØπÊñπÊâÄ‰ΩøÁî®ÁöÑËøõÁ®ãÔºà‰æãÂ¶ÇÁåúÊµã‰ΩøÁî®xrdpÔºâ Â¶ÇÊûúÊòØxrdpÁöÑËØùËøôË°åÂëΩ‰ª§Â∫îËØ•‰ºöÊúâË∂ÖËøá‰∏Ä‰∏™ÁöÑÁªìÊûúÔºöps -aux | grep xrdp yyfang@mai:~$ kill 22722 # ÂØπÂ∫îÁöÑËøõÁ®ãÊòØÂêØÂä®Ê°åÈù¢ Êü•ÁúãÊúçÂä°Âô®ÂÆπÈáè Â¶Ç‰ΩïË∞ÉÂá∫Ëøô‰∏™ÊòæÁ§∫Ôºå‰ª£Ë°®ÁöÑÊòØ‰ªÄ‰πàÂÆπÈáèÔºåÂ∫îËØ•Ê≤°ÊúâÂåÖÊã¨Êï∞ÊçÆÁöÑÂ§ßÂ∞è Linux du ÂëΩ‰ª§ du -sh Êü•ÁúãÂΩìÂâçÁõÆÂΩïÁöÑÂ§ßÂ∞è du -h test Êñπ‰æøÈòÖËØªÁöÑÊ†ºÂºèÊòæÁ§∫testÁõÆÂΩïÊâÄÂç†Á©∫Èó¥ÊÉÖÂÜµ 12345678910111213141516# du log2012.log 300 log2012.log# du -h test608K test/test6308K test/test44.0K test/scf/lib4.0K test/scf/service/deploy/product4.0K test/scf/service/deploy/info12K test/scf/service/deploy16K test/scf/service4.0K test/scf/doc4.0K test/scf/bin32K test/scf8.0K test/test31.3M test# du -sh * ÊòæÁ§∫‰∏ÄÁ∫ßÁõÆÂΩï ÊúçÂä°Âô®‰∏äÊñá‰ª∂DatasetÁΩë‰∏ä‰∏ãËΩΩÁöÑ‰∏Ä‰∫õÊï∞ÊçÆÈõÜ train: ÁîüÊàêÁöÑ‰∏Ä‰∫õ.h5ËÆ≠ÁªÉÊï∞ÊçÆ test.h5 Áî®ljcÁöÑËæπÁºòÔºåÊú™ÂΩí‰∏ÄÂåñÔºåÁî®‰∫Ü400Âº†Âõæ poisson10.h5 noiselevel=10ÁöÑÊ≥äÊùæÂô™Â£∞ Edge_net generate_data: ÁîüÊàê.h5Êï∞ÊçÆ Loggers05 Poisson10_‚Ä¶ 10:22PMÂºÄÂßã /python/compare_models: ‰∏çÂêåÁöÑ.pth ‰øùÂ≠òÊñá‰ª∂]]></content>
      <categories>
        <category>Ê∑±Â∫¶Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>ÊúçÂä°Âô®</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂØåÂ£´X100ÔºöÊÖ¢ÊãçÁöÑ‰ºòÈõÖ]]></title>
    <url>%2Fp%2Fb371.html</url>
    <content type="text"><![CDATA[Áõ∏Êú∫ÊàêÂÉèÂéüÁêÜÂ∞èÂ≠îÊàêÂÉèÔºöËøõÂÖâ„ÄÅÂÄíÁ´ã Â≠îÂ§™Â§ß‰∫ÜÊó†Ê≥ïÊàêÂÉèÔºåÊØè‰∏™ÁÇπÂåÖÂê´‰∫ÜÊï¥‰∏™ÊàêÂÉèÁâ©Ôºõ Â∞èÂ≠îÂèòÂ∞èÔºåÂõæÂÉè‰ºöÊõ¥Ê∏ÖÊô∞ÔºåÂÖâÁ∫øÂèòÊöó Áõ∏Êú∫ÁöÑÂÖâÂúàÁ±ªÊØî‰∫éÂ∞èÂ≠î Èó™ÂÖâÁÅØÁöÑ‰ΩúÁî® Âú®ÂÖâÁ∫øÂÖÖË∂≥ÁöÑÂú∞ÊñπÔºöÂ¢ûÂä†ÂÖâÊïàÔºåÁ™ÅÂá∫Á´ã‰ΩìÊÑü Âú®ÂÖâÁ∫ø‰∏çË∂≥ÁöÑÂú∞ÊñπÔºöË°•ÂÖâ ÈÄÜÂÖâÊó∂Ôºö‰∫∫Áâ©ÁöÑÈù¢ÈÉ®ÂÖâÁ∫øÊõ¥‰∏∫ÊüîÂíå X100‰∏ãÂÖ∑ÊúâËá™Âä®ÊõùÂÖâÂäüËÉΩ„ÄÇËèúÂçïÁöÑ‰ΩçÁΩÆÔºöÈó™ÂÖâÁÅØÁöÑËá™Âä®Ê®°ÂºèÔºåÈó™ÂÖâÁÅØÁöÑÂäõÂ∫¶Â§ßÂ∞èÔºåÈÖçÂêàÈó™ÂÖâÁÅØÁöÑÊ∂àÈô§Á∫¢Áúº ÊµãÂÖâÊ®°Âºè X100ÂÖ∑ÊúâÂ§öÈáç„ÄÅÁÇπÊµãÂÖâ„ÄÅÂπ≥Âùá‰∏âÁßçÊµãÂÖâÊ®°Âºè„ÄÇ Â§öÈáçÊµãÂÖâÊòØÁÇπÂíåÂπ≥ÂùáÁöÑ‰∏≠Âíå„ÄÇÂ§úÊôöÊó∂ÔºåÁîªÈù¢ÂÆπÊòìÂÅè‰∫Æ„ÄÇ ÁÇπÊµãÂÖâÁöÑÁâπÁÇπÔºöÈÄÇÂêàÊãçÊëÑ‰∏ªÈ¢òÊòéÊòæÁöÑÁîªÈù¢ÔºåËê•ÈÄ†Ê∞õÂõ¥„ÄÇÂΩìÊµãÂÖâÂú®‰∫ÆÈÉ®Êó∂ÔºåÊï¥‰Ωì‰ºöÂÅèÊöóÔºõÂΩìÊµãÂÖâÂú®ÊöóÈÉ®Êó∂ÔºåÊï¥‰Ωì‰ºöÂÅè‰∫Æ„ÄÇ(ÁÇπÊµãÂÖâ‰∏ãÔºåÂèØ‰ª•ÊîπÂèòÊµãÂÖâÁÇπÂêóÔºöÂçäËá™Âä®ÊµãÂÖâÔºâ Âπ≥ÂùáÊµãÂÖâÁöÑÁâπÁÇπÔºöÈÄÇÂêàÊãçÊëÑÈùôÁâ©ÂíåÈ£éÊôØ„ÄÇÊµãÂÖâÂπ≥ÂùáÂÄºÊØîËæÉÁ®≥ÂÆö„ÄÇÁîªÈù¢ÂÆπÊòìÂÅèÊöó Ê≥®ÊÑèÔºöMFÊ®°Âºè‰∏ãÔºåÊµãÂÖâÊñπÂºè‰∏çÂΩ±ÂìçÊõùÂÖâÁîªÈù¢„ÄÇÁî±ÂÖâÂúàÂø´Èó®ÂÜ≥ÂÆö„ÄÇ ÊõùÂÖâË°•ÂÅø Â¢ûÂä†ÊõùÂÖâË°•ÂÅøÔºö ‰æãÂ≠êÔºö Èôç‰ΩéÊõùÂÖâË°•ÂÅøÔºö ÁôΩÂπ≥Ë°° ‰ΩúÁî®ÔºöÂ¢ûÂä†Ê∞õÂõ¥Ôºõ‰∏≠Âíå‰∏çÊ≠£Â∏∏ÁöÑÂÖâÁ∫ø Âá†ÁßçË∞ÉËäÇÊñπÂºèÔºöËá™Âä®ÁôΩÂπ≥Ë°°„ÄÅËá™ÂÆö‰πâÁôΩÂπ≥Ë°°„ÄÅÁôΩÂπ≥Ë°°ÂÅèÁßª ÁôΩÂπ≥Ë°°ÂÅèÁßªÔºö ‰∏çÂêåÂú∫ÊôØÁöÑÊãçÊëÑÂ§ïÈò≥ÁöÑÊãçÊëÑÊäÄÂ∑ß Ëâ≤ÂΩ©ÁöÑÂ≠¶‰π† ËØæÂ†ÇÈìæÊé• Ëâ≤ÂΩ©ÁöÑÈ•±ÂíåÂ∫¶ÔºöÊâÄÂê´ÂΩ©Ëâ≤Âº∫Â∫¶ÁöÑÊµìÂ∫¶„ÄÇ Ëâ≤ÂΩ©ÁöÑÊòéÂ∫¶ÔºöËâ≤ÂΩ©ÁöÑ‰∫ÆÂ∫¶„ÄÇÂÖ∂‰∏≠ÈªÑËâ≤ÊòéÂ∫¶ÊúÄÈ´òÔºåÁ¥´Ëâ≤ÊòéÂ∫¶ÊúÄ‰ΩéÔºåÁªø„ÄÅÁ∫¢„ÄÅËìù„ÄÅÊ©ôÁöÑÊòéÂ∫¶Áõ∏ËøëÔºå‰∏∫‰∏≠Èó¥ÊòéÂ∫¶„ÄÇ Ëâ≤ÂΩ©ÁöÑÊê≠ÈÖçÊñπÂºè ÂçïËâ≤„ÄÅÂØπÊØîËâ≤„ÄÅÂàÜÁ¶ªË°•Ëâ≤„ÄÅÂÜ∑ÊöñËâ≤ ÈóÆÈ¢ò ÂÖ®ÁîªÂπÖÂíåÂçäÁîªÂπÖÁöÑÂå∫Âà´]]></content>
      <categories>
        <category>ÊëÑÂΩ±</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>%2Fp%2F0.html</url>
    <content type="text"><![CDATA[ËØªÂèñÂíåÂÜôÂÖ•write ÂÜôË°®Ê†º A = table([‚Äòa‚Äô;‚Äôb‚Äô;‚Äôc‚Äô;‚Äôd‚Äô;‚Äôe‚Äô],PSNR); writetable(results,‚Äôresults of noise.txt‚Äô); Êï∞ÊçÆ‰øùÁïôÂ∞èÊï∞ÂèòÈáèÂêçÂíåÂ≠óÁ¨¶‰∏≤‰πãÈó¥ÁöÑËΩ¨ÂåñMatlabÂèòÈáèÂêç‰∏éÂ≠óÁ¨¶‰∏≤ÁöÑ‰∫íÁõ∏ËΩ¨Êç¢ matlab Â≠óÁ¨¶‰∏≤ÊãºÊé•Âπ∂ËΩ¨Êç¢‰∏∫ÂèòÈáèÂêçÂ≠ó ÂõæÁâáÊòæÁ§∫ Ëé∑ÂèñÂõæÁâá‰∏≠ÂÉèÁ¥†ÁÇπÁöÑÂùêÊ†á 123%1.1 ÊòæÁ§∫ÂõæÁâámainf=imshow(data); %show the picture%1.2 ÂëΩ‰ª§Ê°Ü‰∏≠ËæìÂÖ•impixelinfoÔºåÁÇπÂáªÂõæÁâáÂç≥ÂèØ Ê†áÈ¢ò‰∏≠Ê∑ªÂä†latexÁ¨¶Âè∑ 1title('TV \lambda=0.07'); Matlab‰∏≠ÊèíÂÖ•latex ÂõæÂÉèÂ§ÑÁêÜ Â∞ÜÁÅ∞Â∫¶ÂõæËΩ¨ÂåñÊàê[0,1]Âå∫Èó¥ÁöÑÂõæÂÉè It = im2double(uint8(I)); j=Âä†Âô™Â£∞ imnoiseËøô‰∏™ÂáΩÊï∞ËæìÂÖ•ÁöÑÂõæÂÉèÈúÄË¶ÅÂΩí‰∏ÄÂåñ BM3D: z = y + sigma/255) Âä†ËΩΩÂõæÂÉèËá≥$[0,1]$ y = im2double(imread(image)) 12345678910111213141516171819202122232425262728# oursnoise_level=15;g = double(imnoise(uint8(ftrue),'gaussian',0, noise_level^2/255^2));psnr(ftrue,g,255) #[0,255]‰πãÈó¥ÁöÑdouble# BM3Dsigma = 15y = im2double(uint8(image_name));z = y + (sigma/255)*randn(size(y));psnr(ftrue,g) #[0,1]‰πãÈó¥ÁöÑdouble# Non-localI = imread('cameraman.tif');noisyImage = imnoise(I,'gaussian',0,0.0015);[filteredImage,estDoS] = imnlmfilt(noisyImage);montage(&#123;noisyImage,filteredImage&#125;)title (['Estimated degree of smoothing, ', 'estDoS = ',num2str(estDoS)]);# Ljzhi NLTVsigm_array= [0.1 0.16 0.2]; # fingerprint[in_clean,map] = imread([fileName,'.png']);in_clean = double(in_clean); in_clean = in_clean/ max(in_clean(:));in_polluted = in_clean + sigm*randn(size(in_clean));# TGVn = 0.1I = im2double(imread(fname)); % ËæìÂÖ•ÂøÖÈ°ªÊòØuint8I = imnoise(I, 'gaussian', 0, n^2); % I = I + n*randn()sigma/255 = sigm = n Êñá‰ª∂Êìç‰Ωú Â∞ÜÊñá‰ª∂Â§π‰∏ãÁöÑÊñá‰ª∂Âä†Âà∞Ë∑ØÂæÑ‰∏ã 123addpath(genpath('matlab'))addpath Functionsaddpath Functions/WaveletFunctions Â∞ÜÊñá‰ª∂Â§πÂΩì‰ΩúÁ±ª ÂØªÊâæÊñá‰ª∂Â§πÂÜÖÊåáÂÆöÊñá‰ª∂ Êñá‰ª∂ÂêçÁªÑÂêà imgName = [‚Äòimg_‚Äô, num2str(imgID, ‚Äò%03d‚Äô), ‚Äò_SRF_4_LR.png‚Äô]; ‰øùÂ≠òÂä†ËΩΩ123# Âä†ËΩΩÂçï‰∏™ÂèòÈáèload handel.mat yload('handel.mat','y') ÂèòÈáè MATLAB‰∏≠ÊéßÂà∂ËæìÂá∫Ê†ºÂºè‰∏≠Â∞èÊï∞ÁÇπÂêéÁöÑ‰ΩçÊï∞(Êú™Ëß£ÂÜ≥) https://blog.csdn.net/xiakexiaohu/article/details/53760946 ÂèØ‰ª•ÊîπÂèòÂà∞Êüê‰∏ÄÁ≤æÂ∫¶Ôºå‰ΩÜÊòØÊòæÁ§∫ÁöÑÊó∂ÂÄôÔºå‰ΩÜÊòØÂêåÊó∂‰∫ßÁîü‰∫Ü3*13 sym ÁîªÂõæMatlabÂèØËßÜÂåñÁºñÁ®ã ExcelÁîªÂõæ Áõ¥ÊñπÂõæstem„ÄÅhist„ÄÅimhist 123x = linspace(-1, 1, (256*2))';y = hist(edge(:),x)'; % ÊåâÁÖßxËøõË°åÁªüËÆ°ÔºåÂ∞Ü‰∫åÁª¥Êï∞ÁªÑËΩ¨ÂåñÊàê‰∏ÄÁª¥ÂêëÈáèfigure, stem(x,y, 'Marker', 'none') ‰∏âÁª¥ÂõæÂÉè123456789101112x=100:10:2000;y=x;[X,Y]=meshgrid(x,y); %ÁΩëÊ†ºÂåñx„ÄÅyZ=X.*(1-Y./(X+Y)); %ËÆ°ÁÆóZmesh(X,Y,Z); %ÁîªÂá∫ÂõæÂΩ¢zmax=max(max(Z)); %ÊâæÂá∫ZÁöÑÊúÄÂ§ßÂÄºzmax[id_ymax,id_xmax]=find(Z==zmax);xmax=x(id_xmax);ymax=y(id_ymax); %ÊâæÂá∫ZÁöÑÊúÄÂ§ßÂÄºÂØπÂ∫îÁöÑÊ®™Á∫µÂùêÊ†áxmax„ÄÅymaxhold onplot3(xmax,ymax,zmax,'k.','markersize',20) %Ê†áËÆ∞‰∏Ä‰∏™ÈªëËâ≤ÁöÑÂúÜÁÇπtext(xmax,ymax,zmax,[' x=',num2str(xmax),char(10),' y=',num2str(ymax),char(10),' z=',num2str(zmax)]); %Ê†áÂá∫ÂùêÊ†á Debug strÊï∞ÁªÑ str = [‚Äònoise15‚Äô,‚Äônoise35‚Äô,‚Äônoise50‚Äô] str(1,:) = ‚Äònoise15‚ÄôËÄå‰∏çÊòØstr(0) = ‚Äòn‚Äô ÈóÆÈ¢ò [x] Âá∫Áé∞‚Äô._200.png‚ÄôÁ±ªÊñá‰ª∂. Invisible files with ‚Äú.‚Äù prefix are created on some shared volumes and external disks [ ] ‰øùÂ≠ò ‚Äò.mat‚Äô 12save test.mat X % command formsave('test.mat','X') % function form ÂõæÁâáÔºöepsÊ†ºÂºè 12345678fileName = 'FarmerStats'; % your FILE NAME as stringA = imread(fileName,'png');set(gcf,'visible','off') %suppress figureimage(A); axis image % resolution based on imageaxis off % avoid printing axis set(gca,'LooseInset',get(gca,'TightInset')); % removing extra white space in figuresaveas(gcf,fileName,'epsc'); % save as COLOR eps file Êàñ‰ΩøÁî®Ôºöexport_figÂåÖ]]></content>
  </entry>
  <entry>
    <title><![CDATA[MacÂø´Êç∑ÈîÆ‰ª•Âèä‰∏Ä‰∫õÂø´ÈÄüÊìç‰Ωú]]></title>
    <url>%2Fp%2F5d54.html</url>
    <content type="text"><![CDATA[Âø´Êç∑ÊâìÂºÄÊñπÂºèÁªàÁ´Ø ÊâìÂºÄMac‰∏ãËá™Â∏¶ÁöÑËΩØ‰ª∂ Automator Êñ∞Âª∫ÊñáÁ®ø ÂàõÂª∫‰∏Ä‰∏™ÊúçÂä° ‰øÆÊîπÊ°ÜÂÜÖÁöÑËÑöÊú¨ 123456on run &#123;input, parameters&#125; tell application &quot;Terminal&quot; reopen activate end tellend run ËøêË°åÔºöcommand + RÔºåÂ¶ÇÊûúÊ≤°ÊúâÈóÆÈ¢òÔºåÂàô‰ºöÊâìÂºÄÁªàÁ´Ø ‰øùÂ≠òÔºöCommand + SÔºåÂ∞ÜÂÖ∂ÂëΩÂêç‰∏∫ÊâìÂºÄÁªàÁ´ØÊàñ‰Ω†ÊÉ≥Ë¶ÅÁöÑÂêçÂ≠ó ËÆæÁΩÆÂø´Êç∑ÈîÆ Âú® Á≥ªÁªüÂÅèÂ•ΩËÆæÁΩÆ -&gt; ÈîÆÁõòËÆæÁΩÆ -&gt; Âø´Êç∑ÈîÆ -&gt; ÊúçÂä° ÈÄâÊã©Êàë‰ª¨ÂàõÂª∫Â•ΩÁöÑ ‚ÄòÊâìÂºÄÁªàÁ´Ø‚ÄòÔºåËÆæÁΩÆ‰Ω†ÊÉ≥Ë¶ÅÁöÑÂø´Êç∑ÈîÆÔºåÊØîÊàëÊàëËÆæÁΩÆ‰∫Ü‚åò+Á©∫Ê†º Âà∞Ê≠§ÔºåËÆæÁΩÆÂÆåÊàê„ÄÇ ËÅ™ÊòéÁöÑ‰Ω†‰πüËÆ∏‰ºöÂèëÁé∞ÔºåËøô‰∏™ÊäÄÂ∑ßËÉΩ‰∏∫ÊâÄÊúâÁöÑÁ®ãÂ∫èËÆæÁΩÆÂø´Êç∑ÂêØÂä®„ÄÇ Â∞ÜËÑöÊú¨‰∏≠ÁöÑ Terminal ÊõøÊç¢Êàê ÂÖ∂‰ªñÁ®ãÂ∫èÂ∞±ÂèØ‰ª• 123456on run &#123;input, parameters&#125; tell application &quot;Terminal&quot; reopen activate end tellend run ÈªëÊäÄËÉΩÊó¢ÁÑ∂Â≠¶‰∫Ü Automator ÔºåÈÇ£Â∞±Âú®ÈôÑ‰∏ä‰∏Ä‰∏™ÈªëÊäÄËÉΩÂêß„ÄÇ‰∏∫‰Ω†ÁöÑ‰ª£Á†ÅÊéíÂ∫è„ÄÇÂú® Xcode8‰ª•ÂâçÔºåÊúâ‰∏™Êèí‰ª∂ËÉΩ‰∏∫‰ª£Á†ÅÂø´ÈÄüÊéíÂ∫èÔºå‰∏çËøáÊó∂ËøáÂ¢ÉËøÅ~ ÂØπ‰∫éÊ≤°Áî®ÁöÑÊèí‰ª∂ËÄå‰∏îÂèàÊúâÊÇ£ÊúâÂº∫Ëø´ÁóáÁöÑÁöÑÂ∞è‰ºô‰º¥ÔºåÂè™ËÉΩÊâãÂä®ÊéíÂ∫è‰∫ÜÔºàüòÇÔºâ. È¶ñÂÖàËøòÊòØÂàõÂª∫‰∏Ä‰∏™ÊúçÂä° ÂàõÂª∫‰∏Ä‰∏™ShellËÑöÊú¨Ôºå ÂãæÈÄâ:Áî®ËæìÂá∫ÂÜÖÂÆπÊõøÊç¢ÊâÄÈÄâÊñáÊú¨ ËæìÂÖ•Ôºösort|uniq ‰øùÂ≠òÔºö Â≠ò‰∏∫Sort &amp; Uniq ÈÄâ‰∏≠‰Ω†ÁöÑ‰ª£‰ª£Á†Å -&gt; Èº†Ê†áÂè≥ÈîÆ -&gt; Servies -&gt; Sort&amp;Uniq ÊéíÂ∫èÂêéÁöÑ‰ª£Á†ÅÔºö MacÁöÑ‰∏Ä‰∫õÂø´Êç∑Êìç‰Ωú Â¢ûÂä†Êñá‰ª∂ÁöÑÂø´Êç∑ÊñπÂºè Êåâ‰∏ãoption+cmdÔºåÂ∞ÜÊñá‰ª∂ÊãñÂà∞Ê°åÈù¢Ôºå‰∫ßÁîüÊúâÁÆ≠Â§¥Ê†áËÆ∞ÁöÑÊñá‰ª∂Â§π„ÄÇ Ë∞∑Ê≠åÊµèËßàÂô®ÊâìÂºÄÂàöÂÖ≥Èó≠ÁöÑÈ°µÈù¢: cmd+shift+T Terminal Âà†Èô§Êñá‰ª∂Â§πÔºàÊó†ËÆ∫Êñá‰ª∂Â§πÊòØÂê¶‰∏∫Á©∫ÔºâÔºå‰ΩøÁî® -rf ÂëΩ‰ª§Âç≥ÂèØ„ÄÇ ‰ΩøÁî®Ëøô‰∏™rm -rfÁöÑÊó∂ÂÄô‰∏ÄÂÆöË¶ÅÊ†ºÂ§ñÂ∞èÂøÉÔºåÂà†Èô§‰πãÂêéÊ≤°ÂäûÊ≥ïÂú®ÂûÉÂúæÁ´ôÊâæÂõû„ÄÇ RDPÂ§çÂà∂Á≤òË¥¥ÈóÆÈ¢òhttps://www.technipages.com/unable-to-copy-and-paste-to-remote-desktop-session windows AtomÊâìÂºÄÊéßÂà∂Èù¢ÊùøÔºöcmd-shift-P LatexÁºñËØëÔºöctrl-option-B LatexÊ∏ÖÁ©∫Ôºö http://mazhuang.org/atom-flight-manual/chapter-2-using-atom/autocomplete.html SnipMac Âä®ÊÄÅÂ£ÅÁ∫∏http://teach.apple543.com/download-dynamic-wallpaper-on-mac/ https://www.newmobilelife.com/2019/05/06/macos-mojave-dynamic-wallpaper/ Dynamic Wallpaper ClubGalleryCreate) VSCodehttps://juejin.im/post/5a08d1d6f265da430f31950e ÈÖçÁΩÆtex https://zhuanlan.zhihu.com/p/38178015 https://www.jianshu.com/p/57f8d1e026f5 MindnodeÊç¢Ë°åÔºöoption+return Bug Âá∫Áé∞ÁôΩÊù° ÂéüÂõ†ÔºöËæìÂÖ•Ê≥ïÁöÑbug„ÄÇÂú®Ëã±ÊñáËæìÂÖ•Ê≥ïÁöÑÊó∂ÂÄôËæìÂÖ•‰ºöÁõ¥Êé•ÂÆö‰ΩçÂà∞Â≠óÊØçÂºÄÂ§¥ÁöÑÊñá‰ª∂ÔºåÂ¶ÇÊûú‰∏≠ÊñáÂ∞±‰ºöÂá∫Áé∞ÁôΩÊù°ÔºåÁÑ∂ÂêéÁôΩÊù°ËæìÂÖ•ÂÆå‰ºöÂÆö‰ΩçÂà∞‰∏≠ÊñáÂºÄÂßãÁöÑÊñá‰ª∂„ÄÇ Ëß£ÂÜ≥ÔºöÁÇπÂáªÁôΩÊù°‰∏Ä‰∏ãÔºåÊåâÈîÆÁõòesc„ÄÇÊàñËÄÖÈáçÂêØfinder/killall Finder„ÄÇ]]></content>
      <categories>
        <category>ËΩØ‰ª∂</category>
      </categories>
      <tags>
        <tag>Mac</tag>
        <tag>ÊïàÁéá</tag>
      </tags>
  </entry>
</search>
