<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title></title>
      <link href="/p/0.html"/>
      <url>/p/0.html</url>
      
        <content type="html"><![CDATA[<h1 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h1><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><p>[11] M. Elad, M. Ahron, Image denoising via sparse and redundant representations over learned distionaries, IEEE Trans. on Image Processing 54 (12) (2006) 3736–3745.</p><p>2013_tight frame比较的这篇</p></li><li><p>Eric的个人网页</p><p><a href="https://elad.cs.technion.ac.il/software/" target="_blank" rel="noopener">https://elad.cs.technion.ac.il/software/</a></p><p>KSVD的网页: <a href="http://www.cs.technion.ac.il/~ronrubin/software.html" target="_blank" rel="noopener">http://www.cs.technion.ac.il/~ronrubin/software.html</a></p></li><li><p>Matlab tool中的介绍</p><p><a href="http://www.ux.uis.no/~karlsk/dle/" target="_blank" rel="noopener">http://www.ux.uis.no/~karlsk/dle/</a></p></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>服务器和本地文件共享</title>
      <link href="/p/f933.html"/>
      <url>/p/f933.html</url>
      
        <content type="html"><![CDATA[<h1 id="服务器上访问本地文件-局域网"><a href="#服务器上访问本地文件-局域网" class="headerlink" title="服务器上访问本地文件(局域网)"></a>服务器上访问本地文件(局域网)</h1><h1 id="本地电脑访问服务器"><a href="#本地电脑访问服务器" class="headerlink" title="本地电脑访问服务器"></a>本地电脑访问服务器</h1><ul><li><p>方法一：安装samba服务</p><p><a href="https://chubuntu.com/questions/29466/how-do-i-access-shared-folders-on-ubuntu-server-from-mac-os.html" target="_blank" rel="noopener">Ubuntu 16.04安装配置Samba服务</a></p><p><a href="https://www.wikihow.com/Connect-to-a-Server-on-a-Mac" target="_blank" rel="noopener">Mac上的连接方法</a></p><p>服务器上配置samba服务</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190817181307603.png" alt="image-20190817181307603"></p></li><li><p>方法二[最简易]：<a href="https://github.com/libfuse/sshfs" target="_blank" rel="noopener">sshfs</a>客户端直接安装</p><ul><li><p>安装FUSE for Mac和SSHFS客户端</p><p>下载链接：<a href="https://osxfuse.github.io/" target="_blank" rel="noopener">https://osxfuse.github.io/</a></p></li><li><p>测试sshfs</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190817191249940.png" alt="image-20190817191249940"></p></li><li><p>使用sshfs进行挂载</p><ol><li><p>创建本地文件夹Server</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190817192106441.png" alt="image-20190817192106441"></p></li><li><p>sshfs yyfang@mai.math.cuhk.edu.hk:/home/yyfang Server</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190817191751907.png" alt="image-20190817191751907"></p></li><li><p>终止挂载</p><p>umount Server</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190817191946699.png" alt="image-20190817191946699"></p></li><li><p>为了简化命令，方便挂载，改一下~/.ssh/config</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open ~/.ssh/config</span><br></pre></td></tr></table></figure><p>在文件中添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Host []//Server</span><br><span class="line">Hostname ]mai.math.cuhk.edu.hk</span><br><span class="line">User yyfang</span><br><span class="line">Port 22</span><br></pre></td></tr></table></figure></li><li><p>简化后的命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh Server</span><br><span class="line">sshfs Server: Server</span><br></pre></td></tr></table></figure></li></ol></li></ul></li><li><p>方法三：sshfs，按照<a href="https://github.com/libfuse/sshfs" target="_blank" rel="noopener">github</a>的步骤安装</p></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><p><a href="https://chubuntu.com/questions/29466/how-do-i-access-shared-folders-on-ubuntu-server-from-mac-os.html" target="_blank" rel="noopener">如何从Mac OS访问Ubuntu服务器上的共享文件夹？</a></p></li><li><p><a href="https://www.cnblogs.com/bubaya/p/8004730.html" target="_blank" rel="noopener">利用 ssh 的用户配置文件 config 管理 ssh 会话</a></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 服务器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Graph model</title>
      <link href="/p/3b7a.html"/>
      <url>/p/3b7a.html</url>
      
        <content type="html"><![CDATA[<h1 id="Opening"><a href="#Opening" class="headerlink" title="Opening"></a>Opening</h1><p>今天我讲的内容是第十六章，图模型。主要包含三个基本问题：图模型的结构、推断、学习。表示问题，利用图结构表示彼岸两之间的依赖关系</p><p>推断问题，推断预测变量的后验分布。在观测到部分变量e时候，计算其它变量的某个子集 q = {q 1 , q 2 , · · · , q n } 的后验概率 p(q|e)。以及学习问题, 图结构的学习和图中参数的学习。</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190805205029413.png" alt="image-20190805205029413"></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190805183117338.png" alt="image-20190805183117338"></p><p>在前面几周，已经介绍了一些推断的方法，以及参数的学习方法，例如EM算法。今天，我将首先补充一下图结构的知识。并通过举例一些实际应用例子，来看图结构如何协同推断和学习来解决一个问题，如同如文本分类、以及图像去噪。</p><h1 id="有向图结构"><a href="#有向图结构" class="headerlink" title="有向图结构"></a>有向图结构</h1><ul><li><p>图结构分为无向图和有向图</p><p>有向图：Directed Graphical model，也称为贝叶斯网络（Bayesian Network），或信念网络（Belief Network）</p><p>无向图：</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190805194737417.png" alt="image-20190805194737417"></p></li><li><p>有向图的联合分布</p><p>以图(a)为例，p(x1,x2,x3,x4)=p(x1)p(x2|x1)p(x3|x1,x2)p(x4|x1,x2,x3 )。</p><p>根据性质$X_{2} \perp X_{3} | X_{1}$, $p\left(x_{2} | x_{1}, x_{3}\right)=p\left(x_{2} | x_{1}\right)$, 以及图结构上的独立性，</p><p>我们有p(x2|x1)=p(x2|x1,x3) ，p(x4|x3,x2)=p(x4|x3,x2,x1)</p><p>因此右边可以简化为p(x1)p(x2|x1 )p(x3|x1)p(x4|x2, x3)</p><hr><blockquote><p>For any acyclic Bayesian network G, the joint probability distribution of X can be decomposed into a multiplicative form of the local conditional probability of each random variable X.</p><p>In this graph, then the </p></blockquote><p>对于任意一个无环贝叶斯网络G，X 的联合概率分布可以分解为每个随机变量 $X_k$ 的<strong>局部条件概率的连乘形式</strong></p><script type="math/tex; mode=display">p(\mathbf{x})=\prod_{k=1}^{K} p\left(x_{k} | \mathbf{x}_{\pi_{k}}\right)</script><p>其中$x_{\pi k}$表示节点k的父节点。P(Xk|Xπk)是局部条件概率</p><p>根据这个公式：我们遍历图（a）中的每一个节点，即可以得到联合分布</p><p>p(x)=p(x1)p(x3|x1)p(x2|x1)p(x4|x3,x2). ——和我们之前的结果一样。</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190805202457364.png" alt="image-20190805202457364"></p><hr><p>现在我们来讨论用一个图结构来表示概率分布的优点。</p><p>假设X1 , X2 , X3 , X4 是二值变量，在没有图中变量依赖关系的情况下，可以用<strong>一个联合概率表</strong>来显式地记录每一种取值的概率P(X)，共需要2^4 −1 = 15个参数。如果我们用4 个表格来记录这 4 个局部条件概率的乘积，只需要 1 + 2 + 2 + 4 = 9 个独立参数。</p><p>因此当概率模型中的变量数量比较多时，其条件依赖关系也比较复杂。使用图结构的方式可以将概率模型可视化，，以一种直观、简单的方式描述出随机变量之间的条件独立性的性质，并可以将一个复杂的联合概率模型分解为一些简单条件概率模型的组合。</p><blockquote><p>Therefore, when the number of variables in the probability model is relatively large, the conditional dependence is also complicated. The use of graph structure can visualize the probability model, describe the nature of conditional independence between random variables in an intuitive and simple way, and decompose a complex joint probability model into some simple conditional probability models. combination.</p></blockquote></li><li><p>几种常见的有向图（不讲）</p><p>很多经典的机器学习模型可以使用有向图模型来描述，比如朴素贝叶斯分类器、隐马尔可夫模型、深度信念网络等。各自具有特定的结构，适用于不同的任务。</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190805211242662.png" alt="image-20190805211242662"></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190805211207481.png" alt="image-20190805211207481"></p></li></ul><h1 id="有向图—文本分类"><a href="#有向图—文本分类" class="headerlink" title="有向图—文本分类"></a>有向图—文本分类</h1><ul><li>图结构：一个常用的<strong>有向图结构</strong>，朴素贝叶斯模型。</li></ul><p><img src="/Users/yyf/Library/Application%20Support/typora-user-images/image-20190805204929639.png" alt="image-20190805204929639"></p><ul><li>参数的学习</li></ul><ul><li><p>后验分布可以分解为</p><p><img src="/Users/yyf/Library/Application%20Support/typora-user-images/image-20190805210626683.png" alt="image-20190805210626683"></p></li><li><p>这里我要强调一下两个概念。<strong>生成模型和判别模型的区别</strong>。</p></li></ul><h1 id="生成模型和判别模型的区别"><a href="#生成模型和判别模型的区别" class="headerlink" title="生成模型和判别模型的区别"></a>生成模型和判别模型的区别</h1><p>我们经常提到的生成模型和判别模型。我们可能通常错误的以为生成模型就是图像应用中数据重建的意思，其实不然。生成模型除了重建也可以用来判别。</p><ul><li>简单来说。生成模型是计算一个p(x,y)的联合分布，而判别模型是生成p(y|x)，</li></ul><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190805232955885.png" alt="image-20190805232955885"></p><ul><li>两个模型的应用。生成模型和判别模型都可以用来进行分类问题。</li></ul><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190805233143964.png" alt="image-20190805233143964"></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190805233307927.png" alt="image-20190805233307927"></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190805233213328.png" alt="image-20190805233213328"></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190805233118468.png" alt="image-20190805233118468"></p><ul><li><p>两个模型的建模以及我的总结</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190805233903604.png" alt="image-20190805233903604"></p></li></ul><h1 id="有向图—高斯混合模型"><a href="#有向图—高斯混合模型" class="headerlink" title="有向图—高斯混合模型"></a>有向图—高斯混合模型</h1><p>高斯混合模型（Gaussian Mixture Model，GMM)。假设样本 x 是从 K 个高斯分布中生成的。</p><p>高斯混合模型的概率密度函数为：$p(x)=\sum_{k=1}^{K} \pi_{k} \mathcal{N}\left(x | \mu_{k}, \sigma_{k}\right)$</p><p>有向图结构的定义：Y-&gt;X</p><p>在这个图中，我们定义$P(X|Y=k)=\mathcal{N}\left(x | \mu_{k}, \sigma_{k}\right)$, $P(Y=k)=\pi_k, \sum_{k=1}^{K} \pi_{k}=1$.</p><p>根据这个图：我们可以得到x的边际概率：$p(x)=\sum_{k=1}^{K} \pi_{k} \mathcal{N}\left(x | \mu_{k}, \sigma_{k}\right)$</p><p>参数估计：用最大似然的方法来进行参数估计，给定N 个训练样本D = {x (i) }, 1 ≤ i ≤ N，其训练集的对数边际似然为 $\mathcal{L}(\mathcal{D} | \theta)=\frac{1}{N} \sum_{i=1}^{N}\left(\log p\left(\mathbf{x}^{(i)}, \theta\right)\right.$,并通过EM算法来求解获得参数$u_k,\sigma_k,\pi_k$, </p><p>推断：计算后验分布 p(Y=k|x)$\pi_{k} \mathcal{N}\left(x^{(n)} | \mu_{k}, \sigma_{k}\right)$</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190805231018118.png" alt="image-20190805231018118"></p><h1 id="无向图结构"><a href="#无向图结构" class="headerlink" title="无向图结构"></a>无向图结构</h1><ul><li><p>应用场景</p><p>我们可以看到，在有向图中，通常存在明确方向上的因果关系。当相互的作用并没 有本质性的指向，或者是明确的双向相互作用时，使用<strong>无向模型</strong>更加合适。作为一个这种情况的例子，假设我们希望对三个二值随机变量建模。X1-X2-X3。其中X1，X2，X3分别代表你的室友，你和你的同事是否😷。我们假设，你的室友和同事 并不认识，所以他们不太可能直接相互传染一些疾病，因而我们的模型中两者之间没有直接的连接。然而，你传染给你的室友和你的室友传染给你都是非常容易的，所以模型不存在一个明确的单向箭头。并且，你的室友和你很有可能其中之一将感冒传染给你，然后通过你再传染给了另一个人。</p><p>现在我们来考虑三者健康状况的联合分布。p(X1,X2,X3)</p></li><li><p>无向图的联合分布的分解方式</p><p>无向图模型，也称为马尔可夫随机场（Markov Random Field，MRF）或 马尔可夫网络（Markov Network）</p><p>无向图的联合分布方式：对于一个马尔可夫随机场G,当p(x)可以表示为,一系列定义在最大团上的非负函数的乘积形式,即<script type="math/tex">p(\mathbf{x})=\frac{1}{Z} \prod_{c \in \mathcal{C}} \phi_{c}\left(\mathbf{x}_{c}\right)</script>。其中：最大团（Maximal Clique）就是其中的点是全连接的子集，并且无法被一个更大的团包含。对于 图中的每一个团C，一个 因子（factor）ϕ(C)(也称为 团势能（clique potential)，衡量了团中变量每一种可能的联合状态所对应的密切程度，因而必须为0。为了归一化</p></li></ul><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190805215740555.png" alt="image-20190805215740555"></p><ul><li><p>例子中的计算方法</p><p>在我们这个模型中，我们可以为你和你的室友定义这样一个势能函数。</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190805215043749.png" alt="image-20190805215043749"></p><p>状态为 1 代表了健康的状态，相对的状态为 0 则表示不好的健康状态（即感染 了感冒）。你们两个通常都是健康的，所以对应的状态拥有最高的密切程度。两个人 中只有一个人是生病的密切程度是最低的，因为这是一个很罕见的状态。两个人都生病的状态（通过一个人来传染给了另一个人）有一个稍高的密切程度，尽管仍然 不及两个人都健康的密切程度。 同样地，我们可以为你和你的同事定义一个。</p><p>现在我们可以得到非归一化的概率分布。如hc=0，hy=1，hx=1的情况下，p；hc=0，hy=1，hx=1的情况下，p。和我们预设的情形相符合。</p></li><li><p>无向图中联合分布的能量表达方法</p><p>现在我们返回到这个联合分布的定义。我们注意到，为了有效定义每一种情况，势能函数必须大于0. 由于势能函数必须为正的，因此我们一般定义为$\phi_{c}\left(\mathbf{x}_{c}\right)=\exp \left(-E_{c}\left(\mathbf{x}_{c}\right)\right)$，其中E(xc)为能量函数（energy function) 。因此，无向图上定义的概率分布可以表示为：</p><script type="math/tex; mode=display">\begin{aligned} P(\mathbf{x}) &=\frac{1}{Z} \prod_{c \in \mathcal{C}} \exp \left(-E_{c}\left(\mathbf{x}_{c}\right)\right) \\ &=\frac{1}{Z} \exp \left(\sum_{c \in \mathcal{C}}-E_{c}\left(\mathbf{x}_{c}\right)\right)\\&=\frac{1}{Z} \exp \left(-E\left(\mathbf{x}\right)\right) \end{aligned}</script><p>这种形式的分布又称为玻尔兹曼分布（Boltzmann Distribution）。任何一个无向图模型都可以用公式(11.21) 来表示其联合概率。服从式 (16.7) 形式的任意分布都是 玻尔兹曼分布（Boltzmann distribution） 的一个实例。正是基于这个原因， 我们把许多基于能量的模型称为玻尔兹曼机（Boltzmann Machine）。现在我们来讲一个基于无向图的应用，去噪。</p></li><li><p>常见的无向图(不讲)</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190805211429187.png" alt="image-20190805211429187"></p></li><li><p>总结</p><p>利用图模型的局部马尔可夫性，我们可以对多变量的联合概率进行简化，从而降低建模的复杂度。（可加到有向图的后面）Using the local Markov property of the graph model, we can simplify the joint probability of multivariates, thus reducing the complexity of modeling. (can be added to the back of the directed graph)</p><p>局部马尔可夫性质：对一个更一般的贝叶斯网络，其局部马尔可夫性质为：每个随机变量在给定父节点的情况下，条件独立于它的非后代节点。对与一个无向图而言，即一个变量 Xk 在给定它的邻居的情况下独立于所有其它变量。</p></li></ul><h1 id="无向图—图像去噪"><a href="#无向图—图像去噪" class="headerlink" title="无向图—图像去噪"></a>无向图—图像去噪</h1><p>无向图：图像去噪。</p><ul><li><p><a href="http://deanhan.com/2018/04/22/MRF/" target="_blank" rel="noopener">基于马尔科夫随机场的图像去噪方法+python代码</a></p></li><li><p><a href="https://blog.csdn.net/jzwong/article/details/69948615" target="_blank" rel="noopener">马尔可夫去噪+matlab：能量函数有点不同</a></p></li></ul><h1 id="受限玻耳兹曼机"><a href="#受限玻耳兹曼机" class="headerlink" title="受限玻耳兹曼机"></a>受限玻耳兹曼机</h1><p>A widely used model of Undirected graph is Boltzman’s machine。 下面我们有请Ms Tang，来介绍some details about the Boltzman’s machine and its extentions in deep learning models.</p><p>玻耳兹曼机是一个无向图</p><p>发展：1986Hinton发明了玻耳兹曼机-&gt;2002Hinton发明了CD(对比散度)来计算梯度-&gt;2006Hinton提出了受限玻耳兹曼机</p><p>模型构建：<a href="https://deeplearning4j.org/cn/restrictedboltzmannmachine.html" target="_blank" rel="noopener">Introduction to Restricted Boltzmann Machines Using PyTorch</a>、<a href="https://skymind.ai/wiki/restricted-boltzmann-machine" target="_blank" rel="noopener">英文原文</a></p><p>计算原理：<a href="https://blog.csdn.net/itplus/article/details/19168937" target="_blank" rel="noopener">预备知识</a>、<a href="https://blog.csdn.net/itplus/article/details/19207371" target="_blank" rel="noopener">梯度上升法</a>、<a href="https://blog.csdn.net/itplus/article/details/19408773" target="_blank" rel="noopener">评价效果的方法</a></p><p>代码：<a href="https://github.com/MichelDeudon/RBM-for-MNIST" target="_blank" rel="noopener">受限玻耳兹曼姬重构：tf版本</a>、<a href="https://github.com/bacnguyencong/rbm-pytorch/blob/master/Notebook.ipynb" target="_blank" rel="noopener">受限玻耳兹曼姬重构：pytorch版本</a>、<a href="https://heartbeat.fritz.ai/guide-to-restricted-boltzmann-machines-using-pytorch-ee50d1ed21a8" target="_blank" rel="noopener">Introduction to Restricted Boltzmann Machines Using PyTorch</a>、<a href="https://github.com/GabrielBianconi/pytorch-rbm/blob/master/mnist_example.py" target="_blank" rel="noopener">pytorch-rbm</a>、</p><h1 id="受限玻耳兹曼姬和深度学习的关系"><a href="#受限玻耳兹曼姬和深度学习的关系" class="headerlink" title="受限玻耳兹曼姬和深度学习的关系"></a>受限玻耳兹曼姬和深度学习的关系</h1>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>图像处理相关问题综述</title>
      <link href="/p/23e4.html"/>
      <url>/p/23e4.html</url>
      
        <content type="html"><![CDATA[<h1 id="deblur"><a href="#deblur" class="headerlink" title="deblur"></a>deblur</h1><ul><li><p><a href="http://faculty.ucmerced.edu/mhyang/papers/cvpr2018_discriminative_prior.pdf" target="_blank" rel="noopener">Learning a Discriminative Prior for Blind Image Deblurring</a></p><script type="math/tex; mode=display">\min _{I, k}\|I \otimes k-B\|_{2}^{2}+\gamma\|k\|_{2}^{2}+p(I)</script><blockquote><p>The key to the success of this framework lies on the latent<br>image prior p(I), which favors clear images over blurred<br>images when minimizing (2). Therefore, the image prior<br>p(I) should have lower responses for clear images and<br>higher responses for blurred images.</p></blockquote></li></ul><a id="more"></a><p>test $a+b=\beta$</p><h1 id="super-resolution"><a href="#super-resolution" class="headerlink" title="super-resolution"></a>super-resolution</h1><ul><li><a href="https://www4.comp.polyu.edu.hk/~cslzhang/paper/CVPR19_DPSR.pdf" target="_blank" rel="noopener">Deep Plug-and-Play Super-Resolution for Arbitrary Blur Kernels</a></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.zhihu.com/question/41250817/answer/284449311" target="_blank" rel="noopener">在图像处理领域的不同的研究问题</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>hexo博客搭建</title>
      <link href="/p/7ab7.html"/>
      <url>/p/7ab7.html</url>
      
        <content type="html"><![CDATA[<ul><li><p>安装node.js</p><p><a href="https://nodejs.org/en/" target="_blank" rel="noopener">https://nodejs.org/en/</a></p></li><li><p>sudo npm install —unsafe-perm —verbose -g hexo；hexo version 测试</p></li><li><p>自带了git，否则需要安装</p></li><li><p>初始化博客文件夹</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ hexo init &lt;folder&gt;</span><br><span class="line">$ cd &lt;folder&gt;</span><br><span class="line">$ npm install</span><br></pre></td></tr></table></figure></li><li><p>测试生成网页</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo s 重新编译，并在本地显示</span><br><span class="line">hdxo g 重新编译</span><br><span class="line">hexo d 上传至github</span><br></pre></td></tr></table></figure></li><li><p>选主题<a href="https://hexo.io/themes/" target="_blank" rel="noopener">https://hexo.io/themes/</a> 下载</p><p>git clone <a href="https://github.com/theme-next/hexo-theme-next" target="_blank" rel="noopener">https://github.com/theme-next/hexo-theme-next</a></p><p>将它放到theme下，并重命名</p></li><li><p>修改 站点配置文件_config.yml中的主题</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Extensions</span><br><span class="line">## Plugins: https://hexo.io/plugins/</span><br><span class="line">## Themes: https://hexo.io/themes/</span><br><span class="line"># theme: landscape</span><br><span class="line">theme: next</span><br></pre></td></tr></table></figure><ul><li><p>重新编译</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190806232759873.png" alt="image-20190806232759873"></p></li><li><p>修改主题风格</p></li></ul><h1 id="生成的github文件"><a href="#生成的github文件" class="headerlink" title="生成的github文件"></a>生成的github文件</h1><p>我的github链接：<a href="https://github.com/ysix7/ysix7.github.io/tree/master/2019" target="_blank" rel="noopener">https://github.com/ysix7/ysix7.github.io/tree/master/2019</a></p><p>参考blog： <a href="https://hellozhaozheng.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" target="_blank" rel="noopener">https://hellozhaozheng.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/</a> </p><h1 id="本地更新文件"><a href="#本地更新文件" class="headerlink" title="本地更新文件"></a>本地更新文件</h1><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190807010049690.png" alt="image-20190807010049690"></p><p>Hero s 本地看</p><h1 id="新增的功能"><a href="#新增的功能" class="headerlink" title="新增的功能"></a>新增的功能</h1><p>分级目录：<a href="https://blog.csdn.net/wugenqiang/article/details/88609066" target="_blank" rel="noopener">https://blog.csdn.net/wugenqiang/article/details/88609066</a></p><p>新增分类：<a href="http://www.iooeo.com/2017/07/20/Hexo-%E6%96%B0%E5%BB%BA%E8%8F%9C%E5%8D%95-menu-%E5%AD%98%E6%94%BE%E5%BD%92%E6%A1%A3/" target="_blank" rel="noopener">http://www.iooeo.com/2017/07/20/Hexo-%E6%96%B0%E5%BB%BA%E8%8F%9C%E5%8D%95-menu-%E5%AD%98%E6%94%BE%E5%BD%92%E6%A1%A3/</a></p><h1 id="分类以及标签"><a href="#分类以及标签" class="headerlink" title="分类以及标签"></a>分类以及标签</h1><p>深度学习：pytorch，python, 机器学习，服务器</p><p>美食类：西安,香港..</p><p>软件：latex</p><p>图形处理：denoising,segmentation</p><h1 id="主页自定义"><a href="#主页自定义" class="headerlink" title="主页自定义"></a>主页自定义</h1><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">npm install --save hexo-generator-search</span><br><span class="line">npm install hexo-generator-searchdb --save 添加本地搜索</span><br><span class="line">npm install hexo-generator-sitemap --save</span><br><span class="line">npm install hexo-generator-baidu-sitemap --save 生成sitemap，用来被百度谷歌收录</span><br><span class="line">npm install --save hexo-symbols-count-time 添加统计字数</span><br><span class="line">npm install hexo-generator-index --save</span><br><span class="line">npm install hexo-generator-index-pin-top --save 博客置顶</span><br><span class="line">npm install hexo-abbrlink --save 优化链接</span><br></pre></td></tr></table></figure><h1 id="主题配置文件"><a href="#主题配置文件" class="headerlink" title="主题配置文件"></a>主题配置文件</h1><ul><li><p>头像 ：theme-source-imgs</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190813002011973.png" alt="image-20190813002011973"></p></li><li><p>页面左上角图标</p><p>链接：<a href="https://www.iconfont.cn/home/index?spm=a313x.7781069.1998910419.2" target="_blank" rel="noopener">https://www.iconfont.cn/home/index?spm=a313x.7781069.1998910419.2</a></p><p>文件保存位置：</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190813002701508.png" alt="image-20190813002701508"></p></li><li><p>分类图标</p><p>链接：<a href="http://fontawesome.dashgame.com/" target="_blank" rel="noopener">http://fontawesome.dashgame.com/</a></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190813002106807.png" alt="image-20190813002106807"></p></li><li><p>开启站内搜索</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190813003015418.png" alt="image-20190813003015418"></p></li></ul><h1 id="修改页边距"><a href="#修改页边距" class="headerlink" title="修改页边距"></a>修改页边距</h1><h1 id="公式渲染问题"><a href="#公式渲染问题" class="headerlink" title="公式渲染问题"></a>公式渲染问题</h1><ul><li><p>开启公式：scaffolds-post.md中修改默认模版</p><p>模板里面只写mathjax: ，只在需要公式的地方写true。模版中写true，会导致网页显示变慢。</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190813002414041.png" alt="image-20190813002414041"></p></li><li><p><a href="https://blog.csdn.net/wgshun616/article/details/81019687" target="_blank" rel="noopener">解决mathjax默认渲染将一些符号转义的问题</a></p></li></ul><h1 id="新建草稿博客"><a href="#新建草稿博客" class="headerlink" title="新建草稿博客"></a>新建草稿博客</h1><p>hexo n title： 默认用的是post布局</p><p>hexo n draft title： 会在post同级建一个draft文件夹放草稿source/_drafts</p><p>草稿的默认结构在scaffolds里的<a href="draft.md">draft.md</a>里面改</p><h1 id="出现过的问题"><a href="#出现过的问题" class="headerlink" title="出现过的问题"></a>出现过的问题</h1><ul><li>文章不显示在列表：tags以及catogories的填写格式有问题</li><li>全局搜索不出现的问题</li></ul>]]></content>
      
      
      <categories>
          
          <category> 其他 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>生成模型vs判别模型</title>
      <link href="/p/44f5.html"/>
      <url>/p/44f5.html</url>
      
        <content type="html"><![CDATA[<h1 id="不同的应用"><a href="#不同的应用" class="headerlink" title="不同的应用"></a>不同的应用</h1><p>判别式模型，这种模型的形式主要是根据原始图像推测图像具备的一些性质，例如根据数字图像推测数字的名称，根据自然场景图像推测物体的边界；而生成模型恰恰相反，通常给出的<strong>输入是图像具备的性质</strong>，而<strong>输出是性质对应的图像</strong>。这种生成模型相当于构建了图像的分布，因此利用这类模型，我们可以完成<u>图像自动生成（采样）、图像信息补全等工作。</u></p><p>生成模型可以用来重构、也可以用来判别。当用于判别时</p><p>生成模型可以是监督的，也可以是无监督的？</p><p>常用的生成网络：VAE、GAN、GAN</p><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>生成模型的输入是什么？</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li><p><a href="http://www.sohu.com/a/164497415_610300" target="_blank" rel="noopener">十个生成模型(GANs)的最佳案例和原理 | 代码+论文</a></p></li><li><p><a href="https://mp.weixin.qq.com/s/3Kj2Dww4HqRWqauQtaHXBQ" target="_blank" rel="noopener">GNN论文分门别类，16大应用200+篇论文最新推荐</a></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>胰脏分割-Unet相关论文</title>
      <link href="/p/f54.html"/>
      <url>/p/f54.html</url>
      
        <content type="html"><![CDATA[<p>胰脏分割</p><p>从coarse到fine</p><p>Attention U-net： 关注点在前景，比Unet多了attention gate；</p><h1 id="Unet"><a href="#Unet" class="headerlink" title="Unet"></a>Unet</h1><p>图像分割综述</p><p><a href="https://zhuanlan.zhihu.com/p/43422162" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/43422162</a></p><p><a href="https://arxiv.org/pdf/1505.04597.pdf" target="_blank" rel="noopener">U-Net论文</a></p><p><a href="https://blog.csdn.net/dugudaibo/article/details/82934731" target="_blank" rel="noopener">U-Net论文笔记</a></p><p><a href="https://zhuanlan.zhihu.com/p/37496466" target="_blank" rel="noopener">U-Net论文笔记</a></p><p><a href="https://zhuanlan.zhihu.com/p/37496466" target="_blank" rel="noopener">U-Net论文笔记知乎</a></p><h1 id="论文清单"><a href="#论文清单" class="headerlink" title="论文清单"></a>论文清单</h1><h1 id="需要补充"><a href="#需要补充" class="headerlink" title="需要补充"></a>需要补充</h1><p>一些常用层的作用：如up，downsample，deconvolution，pooling, batch normalization</p><p>normalization有很多方法，VGG-Net，Stride</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190731201343360.png" alt="image-20190731201343360"></p>]]></content>
      
      
      <categories>
          
          <category> 图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> segmentation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图形边缘提取</title>
      <link href="/p/be62.html"/>
      <url>/p/be62.html</url>
      
        <content type="html"><![CDATA[<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><p><a href="http://www.me.umn.edu/courses/me5286/vision/VisionNotes/2017/ME5286-Lecture7-2017-EdgeDetection2.pdf" target="_blank" rel="noopener">Edge detection ppt</a></p></li><li><p><a href="http://www.aishack.in/tutorials/sobel-laplacian-edge-detectors/" target="_blank" rel="noopener">Edge detection blog</a></p></li><li><p><a href>Edge detection matlab</a></p></li><li><p><a href="https://blog.csdn.net/saltriver/article/details/78990575" target="_blank" rel="noopener">图像的二阶信息</a></p></li></ul><h1 id="传统数学方法"><a href="#传统数学方法" class="headerlink" title="传统数学方法"></a>传统数学方法</h1><p>发展过程</p><p>一阶、二阶、优点、缺点、鲁棒性</p><p>canny</p><ul><li><p>Sobel <a href="https://blog.csdn.net/zhufanqie/article/details/8709910" target="_blank" rel="noopener">code++</a></p><p>I. Sobel. <strong>Camera models and machine perception.</strong> Technical report, DTIC Document, 1970.</p><p>thresholding the gradient map.</p></li><li><p>Canny：an extension of Sobel, more <strong>robust</strong> to noise.  <a href>code++</a></p><p> J. Canny. <strong>A computational approach to edge detection.</strong> IEEE TPAMI, 8(6):679–698, 1986.</p><p>Gaussian smoothing as a preprocessing step </p></li><li><p>Laplacian: 用一个线性算子即可 </p><p>Ansitropic nabla^2 = uxx+uyy.  (右边取绝对值)</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190623174549671.png" alt="image-20190623174549671"></p></li></ul><h1 id="深度学习方法"><a href="#深度学习方法" class="headerlink" title="深度学习方法"></a>深度学习方法</h1><ul><li><p>Xie, S., Tu, Z.: <strong>Holistically-nested edge detection.</strong> In: Proceedings of the IEEE international conference on computer vision, pp. 1395–1403 (2015)</p></li><li><p>Liu, Y., Cheng, M.M., Hu, X., Wang, K., Bai, X.: <strong>Richer convolutional features for edge detection.</strong> In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 3000–3009 (2017)</p></li></ul><h1 id="Laplacian的方法"><a href="#Laplacian的方法" class="headerlink" title="Laplacian的方法"></a>Laplacian的方法</h1><h1 id="边缘加强去噪"><a href="#边缘加强去噪" class="headerlink" title="边缘加强去噪"></a>边缘加强去噪</h1><p>二阶算子或者一阶算子</p><p>边缘</p><ul><li>二阶算子对应其他边缘 如canny边缘或者sobel边缘 能否有这个结果</li><li></li></ul>]]></content>
      
      
      <categories>
          
          <category> 图像处理 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Proof_解的存在性</title>
      <link href="/p/e1d.html"/>
      <url>/p/e1d.html</url>
      
        <content type="html"><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><ul><li>存在性：存在收敛的序列</li><li>唯一性，凸性</li></ul><h1 id="解存在性证明例子1"><a href="#解存在性证明例子1" class="headerlink" title="解存在性证明例子1"></a>解存在性证明例子1</h1><ul><li><p>证明 $\inf _{\Omega} f \leq u^{*} \leq \sup _{\Omega} f$</p><p>通过有界性说明</p></li><li><p>证明有界性</p></li><li><p>BV的有界性</p></li></ul><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/2019-08-12-153611.png" alt="image-20190724131348088"></p><h1 id="解存在性证明例子2"><a href="#解存在性证明例子2" class="headerlink" title="解存在性证明例子2"></a>解存在性证明例子2</h1><h2 id="问题的转化"><a href="#问题的转化" class="headerlink" title="问题的转化"></a>问题的转化</h2><p>1.原问题：The natural space for the functional H to be deﬁned in, is $W^{2,1}(\Omega)$</p><script type="math/tex; mode=display">\begin{aligned} H(u)=& \frac{1}{2} \int_{\Omega}\left(u_{0}-T u\right)^{2} d x+\alpha \int_{\Omega} f(\nabla u) d x +\beta \int_{\Omega} g\left(\nabla^{2} u\right) d x \end{aligned}</script><p>缺点：this space is not <u>reﬂexive</u>(自反空间), and thus existence of minimisers cannot be guaranteed.</p><blockquote><p>每个有限维赋范向量空间都是自反空间。</p><p>所有的<a href="https://wiki.kfd.me/wiki/希尔伯特空间" target="_blank" rel="noopener">希尔伯特空间</a>都是自反空间。比如说，$\mathrm{L}^2$空间是自反空间。</p></blockquote><p>2.Extended problem：extend the functional H in (3.5) to $\mathrm{BH}(\Omega)$</p><script type="math/tex; mode=display">H_{e x}(u)=\left\{\begin{array}{l}{\frac{1}{2} \int_{\Omega}\left(u_{0}-T u\right)^{2} d x+\alpha \int_{\Omega} f(\nabla u) d x} \\ {+\beta \int_{\Omega} g\left(\nabla^{2} u\right) d x \quad \text { if } u \in W^{2,1}(\Omega)} \\ {+\infty \text { if } f \in \mathrm{BH}(\Omega) \backslash W^{2,1}(\Omega)}\end{array}\right.</script><p>缺点：$H_{ex}$ is not <u>sequentially</u> <u>lower semicontinuous</u> with respect to the strict topology in BH(Ω) and hence it is neither with respect to the  $weak^∗$ topology in $[\mathrm{BH}(\Omega)]^{n}$</p><blockquote><ol><li><p>为什么需要lower semicontinuous?</p></li><li><p>$BH$空间,</p><p>$\mathrm{BH}(\Omega)=\left\{u \in W^{1,1}(\Omega) : \nabla u \in[\mathrm{BV}(\Omega)]^{2}\right\}$</p></li><li><p>the $weak^∗$ topology in BH(Ω) provides a good <u>compactness property</u> which is inherited from the weak ∗ topology in $[\mathrm{BV}(\Omega)]^{n}$</p></li></ol></blockquote><p>3.Relaxed functional</p><p>将$\nabla$改成可$D$, 再将$D$分解</p><script type="math/tex; mode=display">\begin{aligned} \overline{H_{e x}}(u) :=& \frac{1}{2} \int_{\Omega}\left(u_{0}-T u\right)^{2} d x+\alpha \int_{\Omega} f(\nabla u) d x \\ &+\beta g\left(D^{2} u\right)(\Omega) \\=& \frac{1}{2} \int_{\Omega}\left(u_{0}-T u\right)^{2} d x+\alpha \int_{\Omega} f(\nabla u) d x \\ &+\beta \int_{\Omega} g\left(\nabla^{2} u\right) d x \\ &+\beta \int_{\Omega} g_{\infty}\left(\frac{D^{s} \nabla u}{\left|D^{s} \nabla u\right|}\right) d\left|D^{s} \nabla u\right| \end{aligned}</script><blockquote><p>Relaxed function：</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190816101314838.png" alt="image-20190816101314838"></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190816101458245.png" alt="image-20190816101458245"></p></blockquote><p>优点： lower semicontinuous。</p><p><strong>Theorem 3.6</strong> The functional $\overline{H_{e x}}(u)$ is lower semicontinuous with respect to the <u>strict topology</u> in $\mathrm{BH}(\Omega)$.</p><p>which means,  $\overline{H_{e x}}(u)\le\lim_{k\to\infty}\inf\overline{H_{e x}}(u_k)$, when $u_k\to u$, in $\mathrm{BH}{(\Omega)}$</p><p>Also, </p><p>$\overline{H_{e x}}(u)\le\lim_{k\to\infty}\inf\overline{H_{e x}}(u_k)$, when $u_k\rightarrow^{w^*} u$, in $\mathrm{BH}{(\Omega)}$</p><h2 id="证明步骤"><a href="#证明步骤" class="headerlink" title="证明步骤"></a>证明步骤</h2><blockquote><p>目标方程：$\inf _{u \in \mathrm{BH}(\Omega)} \overline{H_{e x}}(u)$</p></blockquote><p>目标方程：$\inf _{u \in \mathrm{BH}(\Omega)} \overline{H_{e x}}(u)$</p><p>1.test</p><p>2.test</p><ol><li>取一个minimizing sequence $\{u_k\}$ </li><li><p>证明$\{u_k\}$ is bounded in BH(Ω).</p></li><li><p>利用BH的compactness, 得到$u_k\rightarrow u$ weakly 在BH空间</p></li><li><p>利用${H_{ex}}$的下半连续性，得到</p><p>$\overline{H_{e x}}(u)\le\lim_{k\to\infty}\inf\overline{H_{e x}}(u_k)$</p><p>which implies that(因为$u_k$minimizing):</p><p>$u=\min _{u \in \mathrm{BH}(\Omega)} \overline{H_{e x}}(u)$</p></li><li><p>利用 property of the relaxed functional：$\min _{x \in X} F(x)=\inf _{x \in X} F(x)$</p><p>问题：？那不是只能说明F存在下界？ inf F(x) = min F(x) </p></li></ol><h2 id="离散化"><a href="#离散化" class="headerlink" title="离散化"></a>离散化</h2><h2 id="Bregman算法"><a href="#Bregman算法" class="headerlink" title="Bregman算法"></a>Bregman算法</h2><h1 id="级数的收敛"><a href="#级数的收敛" class="headerlink" title="级数的收敛"></a>级数的收敛</h1><p>级数：一个有穷或无穷的序列的和<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6aef35d06fab2b7a3b1470988e6ff6da3a090b77" alt="{\displaystyle s=u_{1}+u_{2}+u_{3}+\ldots }">称为<strong>级数</strong>。根据项数分为：有穷级数和<strong>无穷级数</strong></p><p>无穷级数的收敛性：如果当$n$趋于正无穷大时，<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d671890050b21484dde3087d000700c97fc3b03c" alt="s_{n}">趋向一个有限的极限。如果当<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" alt="n">趋于正无穷大时，<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d671890050b21484dde3087d000700c97fc3b03c" alt="s_{n}">趋向一个有限的<a href="https://zh.wikipedia.org/wiki/極限_(數列" target="_blank" rel="noopener">极限</a>)：<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e6f96f0cfc3596fca8b37c7ada51b69d1ddc1a74" alt="s=\lim _{n\to \infty }s_{n}"></p><p>条件收敛：如果<strong>任意项级数</strong><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1996a53b9365ee5e345fe7dc1b86df610634e7af" alt="\sum _{n=1}^{\infty }u_{n}">收敛，而<strong>级数</strong><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/805c73495ba5e17474f02014105b819d9a571100" alt="\sum _{n=1}^{\infty }|u_{n}|">发散，则称<strong>级数</strong><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1996a53b9365ee5e345fe7dc1b86df610634e7af" alt="\sum _{n=1}^{\infty }u_{n}"><a href="https://zh.wikipedia.org/wiki/条件收敛" target="_blank" rel="noopener">条件收敛</a>。</p><p>绝对收敛：如果级数<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/805c73495ba5e17474f02014105b819d9a571100" alt="\sum _{n=1}^{\infty }|u_{n}|">收敛，则称级数<a href="https://zh.wikipedia.org/wiki/绝对收敛" target="_blank" rel="noopener">绝对收敛</a>。绝对收敛-&gt;条件收敛</p><p>收敛级数的性质：当<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" alt="n">趋向无限大时，任何一个收敛级数的通项都趋于0：<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c93a30874c887769d0835535ab67fec95916b59d" alt="\lim _{n\to \infty }u_{n}=0"></p><h1 id="序列的收敛性"><a href="#序列的收敛性" class="headerlink" title="序列的收敛性"></a>序列的收敛性</h1><h2 id="有界"><a href="#有界" class="headerlink" title="有界"></a>有界</h2><ul><li><p>定义</p><p>Thus a <a href="https://en.wikipedia.org/wiki/Sequence" target="_blank" rel="noopener">sequence</a> <em>f</em> = (<em>a</em>0, <em>a</em>1, <em>a</em>2, …) is bounded if there exists a real number <em>M</em> such that</p></li><li><p>实数中的定义</p><p>如果存在一个实数 <em>k</em>，使得对于所有 <em>S</em> 中的 <em>s</em> 有 <em>k</em> ≥ <em>s</em>，实数集合 <em>S</em> 被称为“上有界”的，这个数 <em>k</em> 被称为 <em>S</em> 的<strong>上界</strong>。可用类似的定义术语“下有界”和<strong>下界</strong>。</p></li><li><p>度量空间中的定义</p><p>度量空間 (<em>M</em>, <em>d</em>) 的子集<em>S</em> 是<strong>有界</strong>的，如果它包含在有限半徑的球內，就是說如果對於所有 <em>S</em> 中的 <em>s</em>，存在 <em>M</em> 中的 <em>x</em> 並且 <em>r</em> &gt; 0，使得 <strong>d(<em>x</em>, <em>s</em>) &lt; <em>r</em></strong>。<em>M</em> 是有界度量空間（或 <em>d</em> 是有界度量），如果 <em>M</em> 作為自身的子集是有界的。</p></li></ul><h2 id="空间"><a href="#空间" class="headerlink" title="空间"></a>空间</h2><ul><li><p>向量空间、函数空间</p></li><li><p>Lp空间</p><p><strong>Lp空间</strong>是由p次可<strong>积函数组成的空间</strong>；对应的<strong>ℓp空间</strong>是由<em>p</em>次可和序列组成的空间，有时叫做勒贝格空间。</p></li><li><p>Sobolev spaces: $W^{1,1}$, $W^{2,1}$</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190816001648069.png" alt="image-20190816001648069"></p><p>Equipped with the norm <img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/436cf0b0b0a6801965c92205b5629cac0c589edd" alt="{\displaystyle \|\cdot \|_{k,p},W^{k,p}}"> becomes a <a href="https://en.wikipedia.org/wiki/Banach_space" target="_blank" rel="noopener">Banach space</a>.</p></li><li><p>Banach空间：完备(柯西收敛即收敛)+赋范, <u>属于Hilbert空间</u></p><p>A Banach space is a <a href="https://en.wikipedia.org/wiki/Vector_space" target="_blank" rel="noopener">vector space</a> <em>X</em> over any scalar field K, which is equipped with a <a href="https://en.wikipedia.org/wiki/Norm_(mathematics" target="_blank" rel="noopener">norm</a>) <img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0431b3963e8a873a339dc8e1933d0a076b61b94e" alt="{\displaystyle \|\cdot \|_{X}}"> and which is <a href="https://en.wikipedia.org/wiki/Complete_metric_space" target="_blank" rel="noopener">complete</a> with respect to the distance function induced by the norm, that is to say, for every <a href="https://en.wikipedia.org/wiki/Cauchy_sequence" target="_blank" rel="noopener">Cauchy sequence</a> ${x_n}$ in <em>X</em>, there exists an element <em>x</em> in <em>X</em> such that $\lim _{n \rightarrow \infty} x_{n}=x$</p></li><li><p><a href="https://en.wikipedia.org/wiki/Bounded_variation" target="_blank" rel="noopener">BV空间</a></p><ul><li><p>One variable</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190816150519847.png" alt="image-20190816150519847"></p></li><li><p>Functions of bounded variation, BV <a href="https://en.wikipedia.org/wiki/Function_(mathematics" target="_blank" rel="noopener">functions</a>), are functions whose distributional <a href="https://en.wikipedia.org/wiki/Directional_derivative" target="_blank" rel="noopener">derivative</a> is a <a href="https://en.wiktionary.org/wiki/finite" target="_blank" rel="noopener">finite</a><a href="https://en.wikipedia.org/wiki/Bounded_variation#cite_note-5" target="_blank" rel="noopener">[5]</a> <a href="https://en.wikipedia.org/wiki/Radon_measure" target="_blank" rel="noopener">Radon measure</a>.</p></li></ul><p>$|u|_{\mathrm{BV}(\Omega)} :=\int_{\Omega}|u| d x+|D u|(\Omega)$</p></li><li><p>$BV^2$空间</p><p>$|u|_{\mathrm{BV}(\Omega)} :=\int_{\Omega}|u| d x+|D u|(\Omega)$</p></li><li><p>BH空间, 属于Banach空间</p><p>$\mathrm{BH}(\Omega)=\left\{u \in W^{1,1}(\Omega) : \nabla u \in[\mathrm{BV}(\Omega)]^{2}\right\}$</p><p>$\mathrm{BH}(\Omega)$ is a Banach space equipped with the norm $|u|_{B H(\Omega)}=|u|_{B V(\Omega)}+\left|D^{2} u\right|(\Omega)$.</p><ul><li><p>Deﬁnition 3.1 ($Weak^∗$ Convergence in BH(Ω))</p><p>We say that $(u_k ),k\in N$ converges to $u$ $weakly^∗$ in $\mathrm{BH}(\Omega)$ if</p><p>$u_{k} \rightarrow u, \quad \text {in} L^{1}(\Omega)$ and $\nabla u_{k} \rightarrow \nabla u \quad \text {weakly }^{*} \text { in }[\mathrm{BV}(\Omega)]^{2},\text{as } k \rightarrow \infty$</p><p>or in other words: </p><script type="math/tex; mode=display">\begin{array}{l}{\left\|u_{k}-u\right\|_{L^{1}(\Omega)} \rightarrow 0} \\ {\left\|\nabla u_{k}-\nabla u\right\|_{\left[L^{1}(\Omega)\right]^{2}} \rightarrow 0} \\ {\int_{\Omega} \phi d D^{2} u_{k} \rightarrow \int_{\Omega} \phi d D^{2} u, \quad \forall \phi \in C_{0}(\Omega)}\end{array}</script></li></ul></li><li><p>Theorem 3.2 <u>(Compactness in $\mathrm{BH}(\Omega)$)</u>: 可根据bounded得到收敛的序列</p><p>Suppose that the sequence $\left(u_{k}\right)_{k \in \mathbb{N}}$ is bounded in $\mathrm{BH}(\Omega)$. Then there exists a subsequence $\left(u_{k_{\ell}}\right)_{\ell \in \mathbb{N}}$ and a function $u \in \mathrm{BH}(\Omega)$ such that  $\left(u_{k_{\ell}}\right)_{\ell \in \mathbb{N}}$ converges to u $weakly^∗$ in $\mathrm{BH}(\Omega)$.</p></li><li><p>Deﬁnition 3.3 (Strict Convergence in BH(Ω))</p><p>We say that $(u_k ),k\in N$ converges to $u$ $strictly$ in $\mathrm{BH}(\Omega)$ if</p><p>$u_{k} \rightarrow u, \quad \text {in } L^{1}(\Omega)$ and <img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190816013439422.png" alt="image-20190816013439422"></p></li></ul><blockquote><p>t<u>he weak ∗ topology in BH(Ω) provides a good compactness property</u> which is inherited from the weak ∗ topology in [BV(Ω)] n.</p><p>Compactness：可根据bounded得到收敛的序列</p></blockquote><ul><li><p>Lebesgue space </p><p>就是Lp空间？</p></li><li><p>各类空间</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190816101107875.png" alt="image-20190816101107875"></p></li></ul><h2 id="序列"><a href="#序列" class="headerlink" title="序列"></a>序列</h2><ul><li><p>柯西序列</p><p>定义：</p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY_blog/数学_解的存在性证明/image-20190812153123025.png" alt="image-20190812153123025"></p><p>和收敛序列的关系：任何收敛数列必然是柯西列，任何柯西列必然是<a href="https://zh.wikipedia.org/wiki/有界集合" target="_blank" rel="noopener">有界</a>序列。</p></li></ul><blockquote><p>无限维度中的有界序列具体含义：见“有界”</p><p><a href="https://www.zhihu.com/question/29917059" target="_blank" rel="noopener">柯西列是否一定是收敛的？</a></p></blockquote><ul><li><p>序列收敛的定义</p><p>收敛(强)：定义在norm</p><p>弱(weak)收敛：定义在内积</p><p>weak*收敛：</p></li><li><p>实数序列收敛的判别方法</p><p><strong>Bolzano-Weierstrass:</strong> 任一<strong>有限维</strong>实向量空间$\mathbb {R} ^{n}$中的有界序列<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/70f0c27000fbc03d920b5b678949a0043ad269bd" alt="{\displaystyle (a_{n})_{n\in \mathbb {N} }}">都至少包含一个收敛的子列。</p><p>有界不一定收敛</p><p>有界序列是什么意思？</p></li><li><p>有界序列</p><p><strong>Theorem 3.2</strong> (Compactness in $\mathrm{BH}(\Omega)$) Suppose that the sequence $(u_k)_{k \in N}$ is bounded in $\mathrm{BH}(\Omega)$. Then there exists a subsequence $\left(u_{k_{\ell}}\right)_{\ell \in \mathbb{N}}$ and a function $u \in \mathrm{BH}(\Omega)$ such that $\left(u_{k_{\ell}}\right)_{\ell \in \mathbb{N}}$ converges to $u$ weakly∗ in $\mathrm{BH}(\Omega)$.</p></li></ul><h2 id="不同的收敛速度"><a href="#不同的收敛速度" class="headerlink" title="不同的收敛速度"></a>不同的收敛速度</h2><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/2019-08-12-043016.png" alt="image-20190724181456673"></p><ul><li><p>converge sublinearly</p><p>$\lim _{k \rightarrow \infty} \frac{\left|x_{k+1}-L\right|}{\left|x_{k}-L\right|}=1$</p></li><li><p><em>converge linearly</em> </p><p>$\lim _{k \rightarrow \infty} \frac{\left|x_{k+1}-L\right|}{\left|x_{k}-L\right|}=\mu, \mu \in(0,1)$ </p></li><li><p><em>converge superlinearly</em> </p><p>$\lim _{k \rightarrow \infty} \frac{\left|x_{k+1}-L\right|}{\left|x_{k}-L\right|}=0$</p></li><li><p><em>Q-linear convergence</em>: distinguish superlinear rates of convergence. </p><p>$\lim _{k \rightarrow \infty} \frac{\left|x_{k+1}-L\right|}{\left|x_{k}-L\right|^{q}}&lt;M$</p></li><li><p>Monotone operator</p></li></ul><h2 id="不同的收敛模式"><a href="#不同的收敛模式" class="headerlink" title="不同的收敛模式"></a>不同的收敛模式</h2><ul><li><p>强收敛</p></li><li><p>弱收敛</p></li></ul><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190725143410105.png" alt="image-20190725143410105"></p><h1 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h1><h2 id="Fatous-lemma"><a href="#Fatous-lemma" class="headerlink" title="Fatous lemma"></a>Fatous lemma</h2><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190725145706825.png" alt="image-20190725145706825"></p><h2 id="Lower-semi-continuous"><a href="#Lower-semi-continuous" class="headerlink" title="Lower semi-continuous"></a>Lower semi-continuous</h2><ul><li>A lower semi-continuous function. $f(x)=\lceil x \rceil$ is lower semi-continuous.</li></ul><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Lower_semi.svg/220px-Lower_semi.svg.png" alt="img"></p><ul><li><p>An upper semi-continuous function. </p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Upper_semi.svg/220px-Upper_semi.svg.png" alt="img"></p></li></ul><h2 id="Distributional-derivative"><a href="#Distributional-derivative" class="headerlink" title="Distributional derivative"></a>Distributional derivative</h2><p> weak derivative</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190816143252525.png" alt="image-20190816143252525"></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190816143354216.png" alt="image-20190816143354216"></p><ul><li><p>Reference</p><p><a href="https://www.math.arizona.edu/~kglasner/math456/GREENS1.pdf" target="_blank" rel="noopener">Distributions and distributional derivatives</a></p><p><a href="http://publish.illinois.edu/yubo-paul-yang/files/2014/09/Distributional-Derivative.pdf" target="_blank" rel="noopener">Distributional Derivative</a></p></li></ul><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><ol><li><p>证明中的问题</p><ul><li>minimizing sequence就不是bounded in BH？</li><li>分解的前提只需要g是连续的，convex，不需要coercivity condition</li><li>证明bounded in BH的充分条件是什么</li><li>BH空间的扩展中，从nabla到D的过程转变</li></ul></li><li><p>K-SVD code</p></li><li><p>线性增长是否一定等价于下述不等式？作用是什么？以及分解的作用？</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190819110536317.png" alt="image-20190819110536317"></p></li><li><p>coercivity condition 是什么？一定等价于？在此处的作用是什么？</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190819110653616.png" alt="image-20190819110653616"></p></li></ol><h1 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h1><ol><li><p>Linear growth 为什么需要$1+|x|$</p></li><li><p>$Du=\nabla u$  当且仅当$u \in W^{1,1}$</p></li><li><p>$\nabla$替换成D，为什么可以将方程relaxed, 继而对g的分解</p><p>g分解的前提和依据？</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190819110536317.png" alt="image-20190819110536317"></p></li><li><p>minimizing sequence是任意取的未必在${W^{1,1}}$中，那么为什么<img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190820144131278.png" alt="image-20190820144131278"></p></li><li><p>Du bounded, L1 bounded-&gt; bounded in BH?</p></li><li><p>relaxed $\overline H$有解，为什么代表原问题有解</p><p>$\min \overline{H}=\inf H$</p></li></ol><h1 id="离散化-1"><a href="#离散化-1" class="headerlink" title="离散化"></a>离散化</h1><h1 id="Splitting-bregman的收敛性"><a href="#Splitting-bregman的收敛性" class="headerlink" title="Splitting bregman的收敛性"></a>Splitting bregman的收敛性</h1>]]></content>
      
      
      <categories>
          
          <category> 数学 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>概率图模型</title>
      <link href="/p/d0e9.html"/>
      <url>/p/d0e9.html</url>
      
        <content type="html"><![CDATA[<h1 id="统计学知识"><a href="#统计学知识" class="headerlink" title="统计学知识"></a>统计学知识</h1><ul><li>极大似然估计与最大后验概率估计</li></ul><p>极大似然估计：p(X=头痛|Y=中风)=0.8 P(X=头痛|Y=感冒)=0.5 P(X=头痛|Y=)</p><p>X=头痛  Y=argmaxP(X=头痛|Y)  Y=中风</p><p>最大后验概率：Y = argmax p(Y|X=头痛)=P(X|Y)P(Y)</p><ul><li>生成模型和判别模型的区别</li></ul><p>判别模型 p(y|x), 给一个X，判断y=1的值。</p><p>生产模型 p(y|x)等价于p(x|y)p(y)=p(x,y)。需要构造一个p(x|y=1)p(y=1)的根据黄牛特征得到的黄牛模型，p(x|y=0)p(y=0)的水牛模型，比较联合概率密度。</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190805094448732.png" alt="image-20190805094448732"></p><p>深度学习中的生成模型：深度学习的三大生成模型：<a href="https://cloud.tencent.com/developer/article/1077346" target="_blank" rel="noopener">VAE、GAN、GAN</a>、<a href="http://www.sohu.com/a/164497415_610300" target="_blank" rel="noopener">十个生成模型(GANs)的最佳案例和原理</a>、</p><h2 id="概率图模型-structured-probabilistic-models"><a href="#概率图模型-structured-probabilistic-models" class="headerlink" title="概率图模型 structured probabilistic models."></a>概率图模型 structured probabilistic models.</h2><p>概率图模型：用图论表现随机变量之间的条件依赖关系的<u>建模方法</u>。典型的概率图模型包括贝叶斯网络和马尔可夫随机场，分别对应着有向图模型和无向图模型。</p><p>它们提供了将概率模型的结构可视化的简单方式，而对图形的观察可以加深对模型性质的认识，其中最主要的性质就是变量之间的条件独立性。此外，概率图模型还可以表示学习和推断过程中的复杂计算，隐式地承载了图形背后的数学表达。</p><p>优点：图模型建模方式的优点是：多变量分布通常可以表示为一些<strong>局部函数</strong>（<em>local functions</em>）的乘积，而每个局部函数依赖于更小的变量子集。通过因子化（<em>factorization</em>）和条件独立性（<em>conditional independence</em>），使得复杂的多变量分布可以用少得多的参数进行刻画。</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190729131441690.png" alt="image-20190729131441690"></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190729131908499.png" alt="image-20190729131908499"></p><blockquote><p>1、概率模型是利用训练样本数据，通过学习条件概率分布P(X|Y)来进行推断决策，而非概率模型是通过学习得到决策函数Y=f(X)来进行决策。</p><p>2、生成模型的目标是求联合概率分布P(X,Y)，然后由条件公式求取条件概率分布P(X|Y)。即P(X|Y) = P(X,Y) / P(X)。</p><p>3、判别模型是由训练数据直接求取决策函数Y=f(x)或者条件分布P(X|Y)。它并不需要关心X与Y之间的生成关系，它关心的是对于给定输入X应该得到怎么样的输出Y。</p><p>4、机器学习大部分模型都是判别模型，判别模型得到条件概率或者决策函数直接用于预测，准确率会更高；而生成模型用于数据预测，所以它的应用领域会更加广泛。</p><p>5、<strong>常见的判别模型有</strong>：K近邻、SVM、决策树、感知机、线性判别分析（LDA）、线性回归、传统的神经网络、逻辑斯蒂回归、boosting、条件随机场</p><p><strong>常见的生成模型有</strong>：朴素贝叶斯、隐马尔可夫模型、高斯混合模型、文档主题生成模型（LDA）、限制玻尔兹曼机</p><p>作者：decan5958<br>来源：CSDN<br>原文：<a href="https://blog.csdn.net/decan5958/article/details/76607082" target="_blank" rel="noopener">https://blog.csdn.net/decan5958/article/details/76607082</a> </p></blockquote><h2 id="深度学习和概率图模型的关系"><a href="#深度学习和概率图模型的关系" class="headerlink" title="深度学习和概率图模型的关系"></a>深度学习和概率图模型的关系</h2><ul><li><p>参考</p><p><a href="https://www.jianshu.com/p/b5520c30ba43?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation" target="_blank" rel="noopener">深度学习之外的人工智能——概率图模型</a></p></li><li><p>与深度学习的关系</p></li></ul><ol><li><p>两者者使用 同的基本计算工具：近似推断？损失函数？学习过程？</p></li><li><p>深度学习潜变量：比可观察变量更多；不包含特定含义；</p><p>概率图模型潜变量：数量通常很少；通常被赋予一些特定含义；</p></li><li><p>深度学习的连接方式：其他单元组全连接</p><p>概率图的连接方式：具有非常少的连接， 并且每个变量的连接选择可以单独设计。 模型结构的设计与推断算法的选择紧密相关。图模型的传统方法通常旨在保持精确 推断的可解性。</p></li><li><p><u>推断方式</u>：什么是推断？作用？</p><p>图模型的传统方法通常旨在保持精确推断的可解性。</p><p>大规模图模型和深度图模型最大的区别之一就是<u>深度学习中几乎从来不会使用环状信念传播</u>。相反的，许多深度学习模型可以<u>设计来加速 Gibbs 采样或者变分推断</u>。</p></li><li><p>图模型如何用于深度学习的典型例子：受限玻尔兹曼机（Restricted Boltzmann Machine, RBM）</p><p>特点：它的单元被分成很大的组，这种组称作层，层之间 的连接由矩阵描述，连通性相对密集。该模型被设计为能够进行高效的 Gibbs 采样， 并且模型设计的重点在于以很高的自由度来学习潜变量。</p><p>标准的 RBM 是具有二值的可见和隐藏单元的基于能量的模型。其能量函数为$E(\boldsymbol{v}, \boldsymbol{h})=-\boldsymbol{b}^{\top} \boldsymbol{v}-\boldsymbol{c}^{\top} \boldsymbol{h}-\boldsymbol{v}^{\top} \boldsymbol{W h}$</p></li></ol><h2 id="概率图-结构化-模型的优点"><a href="#概率图-结构化-模型的优点" class="headerlink" title="概率图(结构化)模型的优点"></a>概率图(结构化)模型的优点</h2><ul><li><p>显著降低表示概率分布、学习和推断的成本。如有向图中的参数表示。1+4+4+9的例子</p></li><li><p>有向模型中采样还可以被加速，但是对于无向模型情况则较为复杂。？</p></li></ul><h2 id="概率图模型的应用"><a href="#概率图模型的应用" class="headerlink" title="概率图模型的应用"></a>概率图模型的应用</h2><ul><li><p><a href="https://blog.csdn.net/jzwong/article/details/69948615" target="_blank" rel="noopener">MRF去噪</a>：无向图中的马尔可夫模型？    </p><p>能否看到一个具体的学习、建模过程。</p></li></ul><h1 id="有向图模型-贝叶斯网络-信念网络"><a href="#有向图模型-贝叶斯网络-信念网络" class="headerlink" title="有向图模型/贝叶斯网络/信念网络"></a>有向图模型/贝叶斯网络/信念网络</h1><ul><li><p>有向图模型以及联合分布</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190729142335602.png" alt="image-20190729142335602"></p></li></ul><ul><li><p>常见的有向图：sigmoid 信念网络、朴素贝叶斯分类器、隐马尔可夫模型(HMM)</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190730121750632.png" alt="image-20190730121750632"></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/26811689" target="_blank" rel="noopener">一个能看懂的HMM例子：每天观察一个病人的状态</a></p></li></ul><h1 id="无向图-马尔可夫随机场-马尔可夫网"><a href="#无向图-马尔可夫随机场-马尔可夫网" class="headerlink" title="无向图/马尔可夫随机场/马尔可夫网"></a>无向图/马尔可夫随机场/马尔可夫网</h1><ul><li><p>常见的无向图：对数线性模型、条件随机场(CRF）</p></li><li><p>无向图模型</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190729142122283.png" alt="image-20190729142122283"></p></li><li><p>无向图的联合概率可以分解为一系列定义在最大团上的非负函数的乘积形式。</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190729142014942.png" alt="image-20190729142014942"></p><p>组成：配分函数$Z=\int \tilde{p}(\mathbf{x}) d \mathbf{x}$。</p></li></ul><h2 id="常见的无向图：条件随机场-词性分类"><a href="#常见的无向图：条件随机场-词性分类" class="headerlink" title="常见的无向图：条件随机场, 词性分类"></a>常见的无向图：条件随机场, 词性分类</h2><ul><li><a href="https://www.jianshu.com/p/bc375efc5e4e" target="_blank" rel="noopener">条件随机场进行词性分类</a></li><li><a href="https://zhuanlan.zhihu.com/p/28465510" target="_blank" rel="noopener">线性链条件随机场-tutorial（一）</a></li><li><a href="https://zhuanlan.zhihu.com/p/28492322" target="_blank" rel="noopener">线性链条件随机场-tutorial（二）</a></li></ul><h2 id="常见的无向图：去噪"><a href="#常见的无向图：去噪" class="headerlink" title="常见的无向图：去噪"></a>常见的无向图：去噪</h2><ul><li><a href="http://deanhan.com/2018/04/22/MRF/" target="_blank" rel="noopener">基于马尔科夫随机场的图像去噪方法+python代码</a></li><li><a href="http://stanford.edu/class/ee367/Winter2018/yue_ee367_win18_report.pdf" target="_blank" rel="noopener">马尔可夫随机场彩色图去噪</a></li><li><a href="https://blog.csdn.net/jzwong/article/details/69948615" target="_blank" rel="noopener">马尔可夫去噪+matlab：能量函数有点不同</a></li></ul><h1 id="采样"><a href="#采样" class="headerlink" title="采样"></a>采样</h1><p>去获取满足一个分布的样本。</p><p>例如：需要获得一个泊松分布，知道某事件符合此分布的话，可以通过采集这个事件的信息，来获得样本。</p><ul><li>拒绝采样：利用一个容易获取样本的分布q，先获得一个样本，再通过判断$\alpha(\hat{x})=\frac{\hat{p}(\hat{x})}{k q(\hat{x})}$，来决定是否留下这个样本x</li><li>Gibbs采样：一种满足稳态转移的马尔可夫采样法。</li></ul><p>参考：</p><p><a href="https://blog.csdn.net/step_forward_ML/article/details/80333166" target="_blank" rel="noopener"><strong>直观理解概率图模型中的采样(sampling)技术</strong></a></p><p><a href="https://zhuanlan.zhihu.com/p/25072161" target="_blank" rel="noopener">浅谈Gibbs</a></p><p><a href="https://www.cnblogs.com/pinard/p/6638955.html" target="_blank" rel="noopener">一篇MCMC解释的不错的文章</a></p><p>问题：和推断的关系？</p><p><a href="https://zhuanlan.zhihu.com/p/37121528" target="_blank" rel="noopener">蒙特卡洛采样</a>、<a href="https://zhuanlan.zhihu.com/p/32982140" target="_blank" rel="noopener">非数学话的解释蒙特卡洛采样</a>、</p><h1 id="推断"><a href="#推断" class="headerlink" title="推断"></a>推断</h1><p>利用图的结构，来计算出一些变量的后验信息</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190729194524762.png" alt="image-20190729194524762"></p><p>推断和最大似然任务的关系：在计算最大对数似然函数的时候，中间步骤需要一些变量的后验信息。</p><p>例子：EM算法</p><ol><li><p>本质是最大化似然函数：$p(\mathbf{x|\theta})$</p></li><li><p>通过隐含结点z，来表示x的编辑概率：$p(\mathbf{x} | \theta)=\sum_{\mathbf{Z}} p(\mathbf{x}, \mathbf{z} | \theta)$</p></li><li><p>通过变分函数q(z)(z的先验信息)，来获得一个下界。</p></li><li><p>EM迭代q和$\theta$, 使得$p(x|\theta)$越来越小. 其中每一次迭代时的$ q(\mathbf{z})=p(\mathbf{z} | \mathbf{x}, \theta)$，因此需要计算$p(z|x)$。此时用到的就是<strong>推断</strong>。根据图的定义，$p(x|z)和p(x),p(z)$是已知的。</p><p><img src="https://cdn.mathpix.com/snip/images/BoYo4j40Vwd6QP_7xPqn0mVOtUnXcqccFwDph72E8PQ.original.fullsize.png" alt></p></li></ol><h1 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h1><p>如上述的EM算法，学习参数的优化算法。</p><h1 id="玻耳兹曼机-RBM"><a href="#玻耳兹曼机-RBM" class="headerlink" title="玻耳兹曼机(RBM)"></a>玻耳兹曼机(RBM)</h1><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/22794772" target="_blank" rel="noopener">一个写的不错的受限玻尔兹曼机（RBM）学习笔记</a></p><p><a href="https://blog.csdn.net/itplus/article/details/9079973" target="_blank" rel="noopener">博客：算法描述</a></p><p><a href="https://blog.csdn.net/itplus/article/details/19408701" target="_blank" rel="noopener">对上一个博客的笔记：对比散度(CD)算法</a></p><p><a href="https://github.com/MichelDeudon/RBM-for-MNIST" target="_blank" rel="noopener">code: RBM-for-MNIST</a></p><p>其他：</p><p><a href="https://www.jiqizhixin.com/articles/2017-11-08-4" target="_blank" rel="noopener">如何使用TensorFlow和VAE模型生成手写数字</a></p><p><a href="https://stats.stackexchange.com/questions/114844/how-to-compute-the-free-energy-of-a-rbm-given-its-energy" target="_blank" rel="noopener">free energy的推算</a></p><p>特点：它的单元被分成很大的组，这种组称作层，层之间 的连接由矩阵描述，连通性相对密集。该模型被设计为能够进行高效的 Gibbs 采样， 并且模型设计的重点在于以很高的自由度来学习潜变量。</p><p><a href="https://blog.csdn.net/jzwong/article/details/69948615" target="_blank" rel="noopener">马尔可夫去噪+matlab：能量函数有点不同</a></p><p>我对玻耳兹曼姬的理解：求出转移的条件概率以后，GIbbs采样，通过一系列的往返操作，可以采出满足p（V）分布的样本。再通过gibbs采样，获得满足p(v)的样本。</p><h1 id="采样："><a href="#采样：" class="headerlink" title="采样："></a>采样：</h1><ul><li><p>推断和采样的关系</p></li><li><p>什么时候需要采样</p></li></ul><h1 id="其他参考"><a href="#其他参考" class="headerlink" title="其他参考"></a>其他参考</h1><p><a href="https://blog.csdn.net/libing_zeng/article/details/74625849" target="_blank" rel="noopener">联合概率、边际概率、条件概率</a></p><p><a href="https://zhuanlan.zhihu.com/p/54101808" target="_blank" rel="noopener">一个完整的概率图模型笔记</a>、<a href="https://www.cnblogs.com/ironstark/p/5128276.html" target="_blank" rel="noopener">这系列相关的一个博客</a></p><p><a href>概率图模型的讲解</a></p><p><a href="https://www.cnblogs.com/reaptomorrow-flydream/p/9688730.html" target="_blank" rel="noopener">隐马尔可夫(HMM)模型</a></p><p><a href="https://www.cnblogs.com/ironstark/p/5125757.html" target="_blank" rel="noopener">CPD(conditional probability distribution)概率图模型</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自编码器</title>
      <link href="/p/221.html"/>
      <url>/p/221.html</url>
      
        <content type="html"><![CDATA[<ul><li><p>参考</p><p><a href="https://zhuanlan.zhihu.com/p/34238979" target="_blank" rel="noopener">自编码器是什么？有什么用？这里有一份入门指南（附代码）</a></p><p><a href="https://www.jiqizhixin.com/graph/technologies/b9c4f5ac-15b2-42aa-a261-75158a8a8be7" target="_blank" rel="noopener">发展</a></p></li><li><p>自编码器</p><p><img src="https://pic1.zhimg.com/80/v2-ace24887b5ccf1696785bcc7b9abe218_hd.jpg" alt="img"></p><p>整个自编码器可以用函数g(f(x)) = r来描述，其中输出r与原始相近。</p></li><li><p>作用</p><p>如果自编码器的唯一目的是让输出值等于输入值，那这个算法将毫无用处。事实上，我们希望通过训练输出值等于输入值的自编码器，<strong>让潜在表征h将具有价值属性</strong>。自编码器能从数据样本中<strong>进行无监督学习</strong>，这意味着可将这个算法应用到某个数据集中，来取得良好的性能，且不需要任何新的特征工程，只需要适当地训练数据。</p></li><li><p>实现</p><ul><li><p><strong>限制h的维度使其小于输入x</strong>，这种情况下称作有损自编码器。通过训练有损表征，使得自编码器能学习到数据中最重要的特征。</p></li><li><p>正则</p></li></ul></li><li><p>应用</p><p>第一是<strong>数据去噪</strong>，第二是<strong><u>为进行可视化而降维</u></strong>。设置合适的维度和稀疏约束，自编码器可以学习到比<u>PCA等技术</u>更有意思的数据投影。</p></li><li><p>种类</p><ol><li><p>香草自编码器</p></li><li><p>多层自编码器</p></li><li><p>卷积自编码器</p></li><li><p>正则自编码器：使用损失函数来鼓励模型学习其他特性</p><p>常用两种正则自编码器</p><ul><li>稀疏自编码器：通过对损失函数施加惩罚项</li><li>降噪自编码器：是通过改变损失函数的<u>重构误差</u>项来学习一些有用信息。</li></ul></li></ol></li><li><p>去噪自编码器DAE</p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/2019-06-17-121048.png" alt="image-20190617201043895"></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>淘宝收藏</title>
      <link href="/p/4dde.html"/>
      <url>/p/4dde.html</url>
      
        <content type="html"><![CDATA[<h1 id="裤裤"><a href="#裤裤" class="headerlink" title="裤裤"></a>裤裤</h1><ul><li><p>短裤</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190720152120722.png" alt="image-20190720152120722"></p></li></ul><h1 id="衣服"><a href="#衣服" class="headerlink" title="衣服"></a>衣服</h1><ul><li>一家红裙子店</li></ul>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>粤语口语</title>
      <link href="/p/39a8.html"/>
      <url>/p/39a8.html</url>
      
        <content type="html"><![CDATA[<p>粤语学习笔记</p><ul><li><p>广东话和普通话的区别<br><a href="https://wenku.baidu.com/view/33face69011ca300a6c390cf.html" target="_blank" rel="noopener">https://wenku.baidu.com/view/33face69011ca300a6c390cf.html</a><br>粤语口语<br><a href="https://hal.archives-ouvertes.fr/hal-00271141/document" target="_blank" rel="noopener">https://hal.archives-ouvertes.fr/hal-00271141/document</a></p></li><li><p>学粤语的一个不错的网页，中文大学链接</p><p><a href="https://www.ilc.cuhk.edu.hk/chinese/canton_express/others/download.html" target="_blank" rel="noopener">https://www.ilc.cuhk.edu.hk/chinese/canton_express/others/download.html</a></p></li></ul><p>j带头的字</p><p>今 jin-&gt;gen</p><p>尽量 jin-&gt;zen</p><p>叫jiao-&gt;gao</p><p>静候 jing-&gt;zeng</p><p>自由：zi-&gt;zei you</p><p>坚持：jian-&gt;gin ci</p><p>枯枝-&gt;fuzi</p><p>收成：sou seng</p><p>这一次：zeiyici</p><p>你要：nei you </p><p>失守 sei sou </p><p>始终 si zhong</p><p>成-&gt;seng </p><p>记载-&gt;gei zai</p>]]></content>
      
      
      <categories>
          
          <category> 语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 粤语 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>生活中的英文口语</title>
      <link href="/p/ef9c.html"/>
      <url>/p/ef9c.html</url>
      
        <content type="html"><![CDATA[<h1 id="重读音"><a href="#重读音" class="headerlink" title="重读音"></a>重读音</h1><p>动词+介词：</p><ol><li>轻轻带过介词，如look at </li><li>重读介词如：take off</li></ol><p>动词+名词:</p><h1 id="日常摘录"><a href="#日常摘录" class="headerlink" title="日常摘录"></a>日常摘录</h1><h2 id="关于吃饭、点餐、结账"><a href="#关于吃饭、点餐、结账" class="headerlink" title="关于吃饭、点餐、结账"></a>关于吃饭、点餐、结账</h2><p><a href="https://mp.weixin.qq.com/s/RxP7LA77z6MZQJ9K7XAdhA" target="_blank" rel="noopener">6/13 续杯、点餐</a></p><p>split the fare</p><p>I have a god feeling</p><p>I could tell</p>]]></content>
      
      
      <categories>
          
          <category> 语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> English </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>presentation常用英文口语</title>
      <link href="/p/9de6.html"/>
      <url>/p/9de6.html</url>
      
        <content type="html"><![CDATA[<h1 id="英语pre摘录"><a href="#英语pre摘录" class="headerlink" title="英语pre摘录"></a>英语pre摘录</h1><p> It’s been a while 有阵子了</p><p><u>It all boils down to</u> realizing that it is natural (and interesting!) to consider different topologies on the same set 𝑋, each of which comes with a notion of convergence.这一切归结为</p><p>我的声音够大吗</p><p>你可以重复一下这个问题吗</p><p>我没有想过这个问题，但是我觉得</p><p>介绍下一位演讲嘉宾</p><p>对这部一部分你们应该有更深的印象</p><h1 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h1><p>Maximum a posteriori estimation MAP</p><p>posteriori probability 后验概率</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://wenku.baidu.com/view/be4d8c2aa55177232f60ddccda38376baf1fe0fb.html?re=view" target="_blank" rel="noopener">Presentation English(英语 演讲用到的各种表达)</a></p><p><a href="http://language.chinadaily.com.cn/2016-04/11/content_24431931.htm" target="_blank" rel="noopener">Presentation实用表达总结</a></p>]]></content>
      
      
      <categories>
          
          <category> 语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> English </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mac/ipad/iphone软件清单</title>
      <link href="/p/44bc.html"/>
      <url>/p/44bc.html</url>
      
        <content type="html"><![CDATA[<h1 id="Mac软件工具"><a href="#Mac软件工具" class="headerlink" title="Mac软件工具"></a>Mac软件工具</h1><h1 id="Ipad软件工具"><a href="#Ipad软件工具" class="headerlink" title="Ipad软件工具"></a>Ipad软件工具</h1><p>做笔记功能</p><ul><li><a href="https://www.zhihu.com/question/291326958" target="_blank" rel="noopener">notability功能介绍</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 软件 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Semismooth牛顿法</title>
      <link href="/p/157d.html"/>
      <url>/p/157d.html</url>
      
        <content type="html"><![CDATA[<p>参考文献</p><ul><li><a href="https://arxiv.org/pdf/1607.05428.pdf" target="_blank" rel="noopener">A highly efficient semismooth Newton augmented Lagrangian<br>method for solving Lasso problems</a>，<a href="http://www.math.nus.edu.sg/~mattohkc/SuiteLasso.html" target="_blank" rel="noopener">论文代码</a></li><li><a href="https://arxiv.org/pdf/1903.11460.pdf" target="_blank" rel="noopener">A sparse semismooth Newton based proximal<br>majorization-minimization algorithm for nonconvex<br>square-root-loss regression problems</a>, </li></ul><h1 id="h-Ax-p-x"><a href="#h-Ax-p-x" class="headerlink" title="h(Ax)+p(x)"></a>h(Ax)+p(x)</h1><ul><li><p>论文中的模型：Primal/Dual</p><script type="math/tex; mode=display">\text { (P) } \max -\{f(x)=h(\mathcal{A} x)-\langle c, x\rangle+ p(x)\}</script><script type="math/tex; mode=display">\text { (P) } \min  \{f(x)=h(\mathcal{A} x)-\langle c, x\rangle+p(x)\}</script><script type="math/tex; mode=display">\text { (D) } \min \left\{h^{*}(y)+p^{*}(z) | \mathcal{A}^{*} y+z=c\right\}</script><p>where, $\mathcal{A} \in R^{MN}​$, $p, h : \mathcal{Y} \rightarrow \Re \text { and } p : \mathcal{X} \rightarrow(-\infty,+\infty]​$ are two closed proper convex functions.</p><p>对于Dual问题：</p><p>$h^<em>$ is essentially smooth with  $\nabla h^{</em>}$ is locally Lipschitz continuous and directionally diﬀerentiable on int $\operatorname{int}\left(\operatorname{dom} h^{*}\right)$.</p></li><li><p>对偶问题的拉格朗日$l​$和增广拉格朗日$\mathcal{L}​$</p><script type="math/tex; mode=display">l(y, z, x)=h^{*}(y)+p^{*}(z)-\left\langle x, \mathcal{A}^{*} y+z-c\right\rangle, \quad \forall(y, z, x) \in \mathcal{Y} \times \mathcal{X} \times \mathcal{X}</script><script type="math/tex; mode=display">\begin{aligned}\mathcal{L}_{\sigma}(y, z ; x) &=l(y, z, x)+\frac{\sigma}{2}\left\|\mathcal{A}^{*} y+z-c\right\|^{2}, \quad \forall(y, z, x) \in \mathcal{Y} \times \mathcal{X} \times \mathcal{X}\\&=h^{*}(y)+p^{*}(z)+\frac{\sigma}{2}\left\|\mathcal{A}^{*} y+z-c-\frac{x}{\sigma}\right\|^{2}-\frac{1}{2 \sigma}\|x\|^{2}\end{aligned}</script></li><li><p>算法框架<strong>（第一层循环）</strong></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190625062337998.png" alt="image-20190625062337998"></p></li><li><p>将(18)中的拉格朗日方程转化成<strong>单变量</strong>拉格朗日方程</p><ul><li><p>Define $\min _{y, z} \Psi(y, z) :=\mathcal{L}_{\sigma}(y, z ; \tilde{x})​$</p></li><li><p>Define $\psi(y) :=\inf _{z} \Psi(y, z)​$</p></li><li><p>（18）中的拉格朗日转化成单变量光滑方程 </p><script type="math/tex; mode=display">\begin{aligned} \Psi(y) &=\inf _{z}\{ h^{*}(y)+p^{*}(z)+\frac{\sigma}{2}\left\|\mathcal{A}^{*} y+z-c-\frac{x}{\sigma}\right\|^{2}-\frac{1}{2 \sigma}\|x\|^{2}\} \\ &=h^*(y)+\sigma \inf _{z}\left\{\frac{1}{\sigma} p^*(z)+\frac{1}{2}\left\|z-(c-A^*y+\frac{x}{\sigma})\right\|^{2}\right\}-\frac{1}{2 \sigma}\|x\|^{2} \\ &=h^*(y)+\sigma M_{\frac{1}{\sigma}}p^*(c-A^*y+\frac{x}{\sigma})-\frac{1}{2 \sigma}\|x\|^{2} \end{aligned})</script><p>with $z = \arg\min_z  p^<em>(z)/\sigma+\frac{1}{2}\left|z-(c-A^</em>y+\frac{x}{\sigma})\right|^{2}=\operatorname{Prox}_{p^{<em>} / \sigma}\left(x / \sigma-\mathcal{A}^{</em>} \overline{y}+c\right)$ .</p></li><li><p>$\psi(y)$  is a smooth function whose gradient is derived as:</p></li></ul><script type="math/tex; mode=display">\begin{aligned} \nabla\Psi(y) &= \nabla h^{*}(y)-\mathcal{A} \operatorname{Prox}_{\sigma p}\left(\tilde{x}-\sigma\left(\mathcal{A}^{*} y-c\right)\right)\end{aligned}</script><ul><li><p>将 $z =\operatorname{Prox}_{p^{<em>} / \sigma}\left(x / \sigma-\mathcal{A}^{</em>} \overline{y}+c\right)​$ 代入 (18) 得到</p><script type="math/tex; mode=display">\psi(y)=h^{*}(y)+p^{*}\left(\operatorname{Prox}_{p^{*} / \sigma}\left(x / \sigma-\mathcal{A}^{*} y+c\right)\right)+\frac{1}{2 \sigma}\left\|\operatorname{Prox}_{\sigma p}\left(x-\sigma\left(\mathcal{A}^{*} y-c\right)\right)\right\|^{2}-\frac{1}{2 \sigma}\|x\|^{2}</script></li></ul><blockquote><p> Moreau-Yosida regularization and proximal mapping</p><script type="math/tex; mode=display">M_{\lambda} f(x) :=\min _{u} f(u)+\frac{1}{2 \lambda}\|u-x\|_{2}^{2}</script><script type="math/tex; mode=display">\nabla M_{\lambda} f(x)=\frac{1}{\lambda}\left(x-\operatorname{Prox}_{\lambda f}(x)\right)</script><script type="math/tex; mode=display">\operatorname{Prox}_{\lambda f}(x) :=\arg \min _{u \in \mathcal{X}} f(x)+\frac{1}{2 \lambda}\|u-x\|^{2}</script><script type="math/tex; mode=display">\operatorname{Prox}_{\lambda p}(x)+\lambda \operatorname{Prox}_{p^{*}(x) / \lambda}(x / \lambda)=x\operatorname{Prox}_{\lambda p}(x)+\lambda \operatorname{Prox}_{p^{*}(x) / \lambda}(x / \lambda)=x</script></blockquote></li><li><p>$\min _{y, z} \Psi(y, z) $等价于以下单变量非线形方程 <strong>(22)</strong></p><script type="math/tex; mode=display">\nabla\Psi(y)=0</script><p>whose the generalized Hessian of $\Psi$ at y is defined as</p><script type="math/tex; mode=display">\hat{\partial}^{2} \psi(y) :=\partial\left(\nabla h^{*}\right)(y)+\sigma \mathcal{A} \partial \operatorname{Prox}_{\sigma p}\left(\tilde{x}-\sigma\left(\mathcal{A}^{*} y-c\right)\right) \mathcal{A}^{*}</script><p>Defining the $H \in \partial^{2} h^{<em>}(y)$ and $U \in \partial \operatorname{Prox}_{\sigma p}\left(\tilde{x}-\sigma\left(\mathcal{A}^{</em>} y-c\right)\right)$, then, we have</p><script type="math/tex; mode=display">V :=H+\sigma \mathcal{A} U \mathcal{A}^{*}</script></li><li><p>利用牛顿法和Hessian 矩阵求解非线形等式(22) <strong>(第二层循环)</strong></p><ul><li><p>寻找方向$d$：$V_{j} d+\nabla \psi\left(y^{j}\right)=0$（24）</p><p>$V \in \hat{\partial}^{2} \psi(y)$, $\hat{\partial}^{2} \psi(y) :=\partial\left(\nabla h^{<em>}\right)(y)+\sigma \mathcal{A} \partial \operatorname{Prox}_{\sigma p}\left(\tilde{x}-\sigma\left(\mathcal{A}^{</em>} y-c\right)\right) \mathcal{A}^{*}$</p><p>$V :=H+\sigma \mathcal{A} U \mathcal{A}^{*}​$</p></li><li><p>步长：set $\alpha_{j}=\delta^{m_{j}}​$</p><p>$y^{j}+\delta^{m} d^{j} \in \operatorname{int}\left(\operatorname{dom} h^{*}\right) \quad \text { and } \quad \psi\left(y^{j}+\delta^{m} d^{j}\right) \leq \psi\left(y^{j}\right)+\mu \delta^{m}\left\langle\nabla \psi\left(y^{j}\right), d^{j}\right\rangle​$</p></li><li><p>更新：$y^{j+1}=y^{j}+\alpha_{j} d^{j}$</p></li><li><p>迭代终止条件：$\nabla \psi\left(y^{j}\right)$ is sufficiently small</p></li></ul></li><li><p>求解线性问题（24）$V_{j} d=-\nabla \psi\left(y^{j}\right)​$</p><ul><li><p>方法一：利用$V_j​$的稀疏性求出解析解</p><script type="math/tex; mode=display">\left(H+\sigma A U A^{T}\right) d=-\nabla \psi(y), H = LL^T</script><script type="math/tex; mode=display">\left(I_{m}+\sigma\left(L^{-1} A\right) U\left(L^{-1} A\right)^{T}\right)\left(L^{T} d\right)=-L^{-1} \nabla \psi(y)</script><p>考虑简化后的情况：</p><script type="math/tex; mode=display">\left(I_{m}+\sigma A U A^{T}\right) d=-\nabla \psi(y)</script><script type="math/tex; mode=display">\mbox{with } A U A^{T}=(A U)(A U)^{T}=A_{\mathcal{J}} A_{\mathcal{J}}^{T}</script><script type="math/tex; mode=display">\left(I_{m}+\sigma A U A^{T}\right)^{-1}=\left(I_{m}+\sigma A_{\mathcal{J}} A_{\mathcal{J}}^{T}\right)^{-1}=I_{m}-A_{\mathcal{J}}\left(\sigma^{-1} I_{r}+A_{\mathcal{J}}^{T} A_{\mathcal{J}}\right)^{-1} A_{\mathcal{J}}^{T}</script><p>维度降低：利用U是一个对角由0和1组成的对角矩阵，$\mathcal{O}\left(m^{2} n\right)$-&gt;$\mathcal{O}\left(m^{2} r\right)$-&gt;$\mathcal{O}\left(r^{2} m\right)$</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190627171823537.png" alt="image-20190627171823537"></p></li></ul></li></ul><ul><li><p>方法二：Pcg 循环（第三层循环）</p><p>Do $V_jd^j​$</p><p>Until $\left|V_{j} d^{j}+\nabla \psi\left(y^{j}\right)\right| \leq \min \left(\overline{\eta},\left|\nabla \psi\left(y^{j}\right)\right|^{1+\tau}\right)​$</p><p>尝试过的加速办法：</p><ul><li><p>与$\tau$的大小有关</p></li><li><p>将该循环写成c语言</p></li><li><p>每次牛顿迭代从上一次d的结果开始。在算法快收敛的时候可以加速。</p></li></ul></li></ul><ul><li><p>速度分析</p><ul><li><p>循环一：lnexact Lagrangian methd </p></li><li><p>循环二：牛顿法迭代求解问题（22）</p><p><strong>影响循环二迭代次数的因素：</strong></p><p>1.该循环的中止条件: $\left|\nabla \psi_{k}\left(y^{k+1}\right)\right|$ 足够小</p><p>2.循环三中的精度$\tau$：该循环的收敛速度与循环三中pcg的精度有关</p><script type="math/tex; mode=display">\left\|y^{j+1}-\overline{y}\right\|=O\left(\left\|y^{j}-\overline{y}\right\|^{1+\tau}\right)</script></li><li><p>循环三(若使用pcg的方法求解(24))：</p><p><strong>影响循环三迭代次数的因素: $\tau$的大小</strong></p><p>1.该循环终止条件：$\left|V_{j} d^{j}+\nabla \psi\left(y^{j}\right)\right| \leq \min \left(\overline{\eta},\left|\nabla \psi\left(y^{j}\right)\right|^{1+\tau}\right),\tau=(0,1]$</p></li></ul></li></ul><h1 id="h-x-p-Bx"><a href="#h-x-p-Bx" class="headerlink" title="h(x)+p(Bx)"></a>h(x)+p(Bx)</h1><ul><li><p>目标方程： $\min|y-g|+\lambda|\nabla y|_1$</p><p>无法套用论文中$h(Ay)+p(y)​$的Dual方法的原因：</p><p>如果$p(y)=\lambda|\nabla y|_1​$，那么p*的显式无法表达。</p><p>如果$h(Ay)=\lambda|\nabla y|_1, A=\nabla$, 那么依然无法将问题转化成单变量的<strong>smooth</strong>问题，因为h项会被保留</p></li><li><p>$\nabla$的矩阵形式</p><p>(补充)</p></li><li><p>提出模型 $h(y)+p(By),  h(y)=|Ay-g|, p(Bx)=|\nabla y|_1​$，$B=\nabla​$</p><p>（P）$\min h(y)+p(By)​$, $h(y)=|Ay-g|​$, $p(Bx)=|\nabla y|_1​$</p><p>（D）$\min \left\{h^{<em>}(y)+p^{</em>}(z) | \mathcal{B}^{<em>} z+y=c\right\}$, $h^{</em>}(y)=\frac{1}{2}|b+y|^{2}-\frac{1}{2}|b|^{2}$, $p^{*}(z)=I\left\{|z|_{\infty} \leq \lambda\right\}$</p><p>对于D问题，无法转化成单变量的smooth方程，<strong>推导见附录</strong>(待补充)。因此选择该模型的主问题。</p></li><li><p>对于(P) $h(y)+p(By)​$，转化成单变量的smooth方程</p><p>增广拉格朗日：$\mathcal{L}_{\sigma}(y, z ; x) :=h(y)+p(z)+<x, \mathcal{b} y-z>+\frac{\sigma}{2}|\mathcal{B} y-z|^{2}​$</x,></p><p>​                                $=h(y)+p(z)+\frac{\sigma}{2}\left|\mathcal{B} y+\frac{x}{\sigma}-z\right|^{2}-\frac{1}{2 \sigma}|x|^{2}​$</p><p>转化后的单变量方光滑方程：</p><p>$\mathcal{L}_{\sigma}(y ; x) :=h(y)+p\left(\operatorname{Prox} \frac{p}{\sigma}\left(\mathcal{B} y+\frac{x}{\sigma}\right)\right)+\frac{1}{2 \sigma}\left|\operatorname{Prox}_{\sigma p^{*}}\left(\sigma\left(\mathcal{B} y+\frac{x}{\sigma}\right)\right)\right|^{2}-\frac{1}{2 \sigma}|x|^{2}, \overline{z}=\operatorname{Prox}_{\frac{p}{\sigma}}\left(\mathcal{B} y+\frac{x}{\sigma}\right)$</p><p>$\nabla \mathcal{L}_{\sigma}(y) :=\nabla h(y)+\mathcal{B}^{<em>} \operatorname{Prox}_{\sigma p^{</em>}}(\sigma(\mathcal{B} y+\frac{x}{\sigma})$</p><p>$\partial\left(\nabla \mathcal{L}_{\sigma}(y)\right)  :=\partial(\nabla h(y))+\sigma \mathcal{B}^{<em>} \partial \operatorname{Prox}_{\sigma p^{</em>}}\left(\sigma\left(\mathcal{B} y+\frac{x}{\sigma}\right)\right) \mathcal{B}\\=\partial(\nabla h(y))+\sigma \mathcal{B}^{*}\left(I-\partial \operatorname{Prox}_{\frac{p}{\sigma}}\left(\mathcal{B} y+\frac{x}{\sigma}\right)\right) \mathcal{B}​$</p></li><li><p>求解$V_{j} d=-\nabla \psi\left(y^{j}\right)​$</p><ul><li><p>方法一：求逆</p><p>其中, $\partial \operatorname{Prox}_{\sigma p^{<em>}}\left(\sigma\left(\mathcal{B} y+\frac{x}{\sigma}\right)\right)​$的稀疏性随着图像的平滑减弱，因此直接利用该稀疏矩阵求逆，<em>*计算立马随着噪声的减弱而变慢</em></em>。相反，$\partial \operatorname{Prox}_{\frac{p}{\sigma}}\left(\mathcal{B} y+\frac{x}{\sigma}\right)​$的稀疏性随着图像的平滑变稀疏。</p><p>$\left(A^TA+\sigma \mathcal{B}^<em>\mathcal{B}-\sigma \mathcal{B}^{</em>}\partial \operatorname{Prox}_{\frac{p}{\sigma}}\left(\mathcal{B} y+\frac{x}{\sigma}\right)\mathcal{B}\right)d=-\nabla \psi\left(y^{j}\right) ​$</p><p>Denote  $U =\partial \operatorname{Prox}_{\frac{p}{\sigma}}\left(\mathcal{B} y+\frac{x}{\sigma}\right)​$ , $b =-\nabla \psi\left(y^{j}\right) ​$</p><p>we have $\left(A^TA+\sigma \mathcal{B}^<em>\mathcal{B}-\sigma \mathcal{B}^{</em>}U\mathcal{B}\right)d=-\nabla \psi\left(y^{j}\right) ​$</p><ul><li><p>如果没有U，就可以使用FFT快速变化，因为B可以当作[-1 1]构成的卷积</p></li><li><p><strong>如果对可以对$A^TA+\sigma \mathcal{B}^*\mathcal{B}$进行$LL^T$的分解。可将原问题转化成以下形式后求逆</strong></p><script type="math/tex; mode=display">\left(I_{m}+\sigma\left(L^{-1} A\right) U\left(L^{-1} A\right)^{T}\right)\left(L^{T} d\right)=-L^{-1} \nabla \psi(y)</script><p>例如在TV denoising的情况下：$A=I$，$B=[B1, B2]$, 则需对$I+\sigma B^*B$进行分解 </p><p><strong>(目前没有实现这个分解, 所以使用pcg求解该线性等式)</strong></p></li></ul></li><li><p><strong>方法二：Pcg 循环（第三层循环）</strong></p><p>Do $V_jd^j​$</p><p>Until $\left|V_{j} d^{j}+\nabla \psi\left(y^{j}\right)\right| \leq \min \left(\overline{\eta},\left|\nabla \psi\left(y^{j}\right)\right|^{1+\tau}\right)​$</p><p>尝试过的加速办法：</p><ul><li><p>将该循环写成c语言</p></li><li><p>加速的办法，每次牛顿迭代从上一次d的结果开始。在算法快收敛的时候可以加速</p></li></ul></li></ul></li><li><p>实验结果与实验设置</p><ul><li><p>循环一：lnexact Lagrangian methd </p></li><li><p>循环二：牛顿法迭代求解问题（22）</p><p>设置循环二的中止条件为: $\left|\nabla \psi_{k}\left(y^{k+1}\right)\right|$ &lt;{0.005}</p><p>ps：如果在小于0.005前达到收敛，则终止循环二，进入循环一的下一轮迭代</p><p>该循环的收敛速度与循环三中pcg的精度有关:</p><script type="math/tex; mode=display">\left\|y^{j+1}-\overline{y}\right\|=O\left(\left\|y^{j}-\overline{y}\right\|^{1+\tau}\right)</script></li><li><p>循环三<strong>(pcg)</strong>：</p><p><strong>影响循环三迭代次数的因素: $\tau​$的大小</strong></p><p>该循环终止条件：$\left|V_{j} d^{j}+\nabla \psi\left(y^{j}\right)\right| \leq \min \left(\overline{\eta},\left|\nabla \psi\left(y^{j}\right)\right|^{1+\tau}\right),\tau=(0,1]$</p><p>$\tau=1$:<strong>循环三循环(大概20)次，循环二收敛需要*次</strong>，循环一需要*次</p><p>$\tau=2$:<strong>循环三循环*次，循环二收敛需要*次</strong>，循环一需要*次</p><p>(实验结果需要补充)</p></li></ul></li><li><p>实验中存在的问题</p><p>循环二和循环三之间的收敛速度没有满足理论值：</p><script type="math/tex; mode=display">\left\|y^{j+1}-\overline{y}\right\|=O\left(\left\|y^{j}-\overline{y}\right\|^{1+\tau}\right)</script></li></ul><p>​    具体的说，循环1中的中间几次迭代中，循环二的收敛速度很慢，没有达到理论值，甚至比线性收敛还要慢。</p><p>​    <strong>（循环二的收敛图需要补充）</strong><br>​                    </p><h1 id="Non-convex-model"><a href="#Non-convex-model" class="headerlink" title="Non-convex model"></a>Non-convex model</h1><h2 id="1-General-Model"><a href="#1-General-Model" class="headerlink" title="1. General Model"></a>1. General Model</h2><ul><li>A nonconvex problem (square-root regression problem)  (3)</li></ul><script type="math/tex; mode=display">\min _{\beta \in \Re^{n}}\{g(\beta) :=\underbrace{h(X \beta)}_{f(\beta)}+\underbrace{p(\beta)-q(\beta)}_{r(\beta)}\}</script><p>​    $p : \Re^{n} \rightarrow(-\infty,+\infty] \text { is a proper closed convex function }​$</p><p>​    $q : \Re^{n} \rightarrow \Re \text { is a finite-valued (smooth, not essential) convex function. }$</p><p>​    $ \text {The proximal functions of h and p to be (strongly) semismooth.}$</p><ul><li><p>Examples</p><p>（等待补充）</p></li><li><p>因为原general model (3) 转化成模型 (10)/(P):</p><p>$\text { Given } \sigma&gt;0, \tau&gt;0, \tilde{\beta} \in \mathbb{R}^{n}, \tilde{v} \in \mathbb{R}^{n}, \text { and }\tilde{b} \in \mathbb{R}^{m}$</p><script type="math/tex; mode=display">\begin{aligned} \min _{\beta \in \mathbb{R}^{n}}\{h(\beta ; \sigma, \tau, \tilde{\beta}, \tilde{v}, \tilde{b}) :=&\|X \beta-b\|+\lambda p(\beta)-q(\tilde{\beta})-\langle\tilde{v}, \beta-\tilde{\beta}\rangle \\ &+\frac{\sigma}{2}\|\beta-\tilde{\beta}\|^{2}+\frac{\tau}{2}\|X \beta-\tilde{b}\|^{2} \} \end{aligned}</script><p>(1) Linearize the concave term: $-q(\beta)$. 因为此项nonconvex</p><p>(2) Add the proximal term：$\frac{\tau}{2}|X \beta-X \tilde{\beta}|^{2}$. 因为$h(\cdot)$和$p(\beta)$是nonsmooth</p></li><li><p>$\beta^{k+1}=\operatorname{Prox}_{\lambda p / \sigma^{2, k}}\left(\beta^{k}+\left(\nabla q\left(\beta^{k}\right)-X^{T} u^{k+1}\right) / \sigma^{2, k}\right)​$</p></li><li><p>问题</p><ul><li><p>[x] $\frac{\sigma}{2}|\beta-\tilde{\beta}|$的作用：因为是PPA算法</p></li><li><p>[ ] $\frac{\tau}{2}|X \beta-\tilde{b}|^{2}$这个Proximal项的由来</p></li><li><p>[ ] 针对该非凸模型的算法，解的唯一性和算法的收敛性能否被证明？只要是非凸问题，都无法保障解的唯一性？那么该算法的优点？</p></li><li>[ ] 该类问题本来的解法</li></ul></li></ul><h2 id="2-SSN-based-PPM-Algorithm"><a href="#2-SSN-based-PPM-Algorithm" class="headerlink" title="2. SSN-based PPM Algorithm"></a>2. SSN-based PPM Algorithm</h2><ul><li><p><strong>PPM algorithm：</strong> Proximal majorization-minimization</p><p>Initialize:  $\beta^{0} \approx \underset{\beta \in \mathbb{R}^{n}}{\operatorname{argmin}}\left\{h\left(\beta ; \sigma^{1}, \tau^{1}, 0,0, b\right)\right\}​$</p><p>Iteration:  <strong>step 1</strong> $\beta^{k+1}=\underset{\beta \in \mathbb{R}^{n}}{\operatorname{argmin}}\left\{h\left(\beta ; \sigma^{2, k}, \tau^{2, k}, \beta^{k}, \nabla q\left(\beta^{k}\right), X \beta^{k}\right)+\left\langle\delta^{k}, \beta-\beta^{k}\right\rangle\right\}$</p><p>​              <strong>step 2</strong> $\sigma^{2, k+1}=\rho_{k} \sigma^{2, k}, \tau^{2, k+1}=\rho_{k} \tau^{2, k}\text { with } \rho_{k} \in(0,1)​$</p><p>Until:  If $β_{k+1}​$ satisﬁes a prescribed stopping criterion, terminate;</p></li><li><p>Step 1:  solve  the dual of the (10)  which is（12）</p><script type="math/tex; mode=display">\begin{aligned} \min _{u \in \mathbb{R}^{m}} &\left\{\varphi(u) :=\langle u, b\rangle+\frac{\tau}{2}\left\|\tau^{-1} u+\tilde{b}-b\right\|^{2}-\left\|\operatorname{Prox}_{\tau^{-1}\|\cdot\|}\left(\tau^{-1} u+\tilde{b}-b\right)\right\|\right.\\ &-\frac{1}{2 \tau}\left\|\operatorname{Prox}_{\tau \delta_{B}}(u+\tau(\tilde{b}-b))\right\|^{2}+\frac{\sigma}{2}\left\|\tilde{\beta}+\sigma^{-1}\left(\tilde{v}-X^{T} u\right)\right\|^{2} \\ &-\lambda p\left(\operatorname{Prox}_{\sigma^{-1} \lambda p}\left(\tilde{\beta}+\sigma^{-1}\left(\tilde{v}-X^{T} u\right)\right)\right)-\frac{1}{2 \sigma}\left\|\operatorname{Prox}_{\sigma(\lambda p) *}\left(\sigma \tilde{\beta}+\tilde{v}-X^{T} u\right)\right\|^{2} \} \end{aligned} (12)</script><p>with $\overline{y}=\operatorname{Prox}_{\tau^{-1}| |}\left(\tau^{-1} \overline{u}+\tilde{b}-b\right), \quad \overline{\beta}=\operatorname{Prox}_{\sigma^{-1} \lambda p}\left(\tilde{\beta}+\sigma^{-1}\left(\tilde{v}-X^{T} \overline{u}\right)\right)​$.</p><p>and $\beta^{k+1}=\operatorname{Prox}_{\lambda p / \sigma^{2, k}}\left(\beta^{k}+\left(\nabla q\left(\beta^{k}\right)-X^{T} u^{k+1}\right) / \sigma^{2, k}\right)​$</p></li><li><p>(12) 的推导过程</p><ul><li><p>令$y=X \beta-b$将(10)转化成约束问题(11)</p><script type="math/tex; mode=display">\min _{\beta \in \mathbb{R}^{n}, y \in \mathbb{R}^{m}}\left\{\|X\beta-b\|+\lambda p(\beta)-\langle\tilde{v}, \beta-\tilde{\beta}\rangle+\frac{\sigma}{2}\|\beta-\tilde{\beta}\|^{2}+\frac{\tau}{2}\|y+b-\tilde{b}\|^{2} \right\}\\\text{subject to }X \beta-b=y\\</script></li><li><p>将约束问题转化成Lagrangian：</p><p>$L(y,\beta; u) = \left\{|y|+\lambda p(\beta)-\langle\tilde{v}, \beta-\tilde{\beta}\rangle+\frac{\sigma}{2}|\beta-\tilde{\beta}|^{2}+\frac{\tau}{2}|y+b-\tilde{b}|^{2} - <u, x \beta-y-b>\right\}​$ (11)</u,></p></li><li><p>Dual function of  (11)</p><script type="math/tex; mode=display">g(u):=\inf _{y,\beta} L(y, \beta;u)</script></li><li><p>对$L(y,\beta; u) ​$进行配方</p><script type="math/tex; mode=display">\begin{aligned}L(y,\beta; u) &= \|y\|+\lambda p(\beta)-\langle\tilde{v}, \beta-\tilde{\beta}\rangle+\frac{\sigma}{2}\|\beta-\tilde{\beta}\|^{2}+\frac{\tau}{2}\|y+b-\tilde{b}\|^{2} - \langle u, y-X \beta+b\rangle\\&=\{\|y\|+\frac{\tau}{2}\|y+b-\tilde{b}\|^{2}-\langle u,y\rangle\}+\{\lambda p(\beta)-\langle\tilde{v}, \beta-\tilde{\beta}\rangle+\frac{\sigma}{2}\|\beta-\tilde{\beta}\|^{2}+\langle X^T u,\beta\rangle\}-\langle u,b\rangle\\&=\{\|y\|+\frac{\tau}{2}\|y+b-\tilde{b}-\frac{u}{\tau}\|^{2}\}-\frac{u^2}{2\tau}+\langle \tilde b,u\rangle+\{\lambda p(\beta)+\frac{\sigma}{2}\|\beta-\tilde{\beta}\|^{2}+\langle X^Tu-\tilde{v}, \beta-\tilde{\beta}\rangle+\langle \tilde{\beta},X^Tu\rangle\}\\&=\{\|y\|+\frac{\tau}{2}\|y+b-\tilde{b}+\frac{u}{\tau}\|^{2}\}+\{\lambda p(\beta) + \frac{\sigma}{2}\|\beta-\tilde{\beta}+\frac{X^Tu-\tilde{v}}{\sigma}\|^{2}\}...\\&-\frac{u^2}{2\tau}+\langle \tilde b,u\rangle+\langle\tilde{\beta},X^Tu\rangle-\|\frac{X^Tu-\tilde{v}}{\sigma}\|^2 \\\end{aligned}</script></li></ul></li></ul><ul><li><p>(12) 的求解：A semismooth Newton‘s method</p><ul><li><p>最小化（12）等价于（12）的一阶条件</p><script type="math/tex; mode=display">\nabla \varphi(u)=\operatorname{Prox}_{\tau^{-1} \|}\left(\tau^{-1} u+\tilde{b}-b\right)-X \operatorname{Prox}_{\sigma^{-1} \lambda p}\left(\tilde{\beta}+\sigma^{-1}\left(\tilde{v}-X^{T} u\right)\right)+b\\\nabla \varphi(u)=0\qquad(13)\\</script></li><li><p>Solve nonlinear equation（13）by pcg</p><p>$\hat{\partial}^{2} \varphi(u) :=\sigma^{-1} X \partial \operatorname{Prox}_{\sigma^{-1} \lambda p}\left(\tilde{\beta}+\sigma^{-1}\left(\tilde{v}-X^{T} u\right)\right) X^{T}+\tau^{-1} \partial \operatorname{Prox}_{\tau^{-1} |}\left(\tau^{-1} u+\tilde{b}-b\right)$</p><p>$H:=\sigma^{-1} X U X^{T}+\tau^{-1} V \in \hat{\partial}^{2} \varphi(u)​$</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190707021520501.png" alt="image-20190707021520501"></p></li></ul></li></ul><h2 id="3-Problem"><a href="#3-Problem" class="headerlink" title="3. Problem"></a>3. Problem</h2><h2 id="4-Our-case"><a href="#4-Our-case" class="headerlink" title="4. Our case"></a>4. Our case</h2><ul><li><p>For the ROF model:</p><p>$h(X\beta)=|\nabla \beta|_1$</p><p>$p(\beta)=|\beta-b|_2^2,q(\beta)=0​$</p></li></ul><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><ul><li><p>转化成smooth单变量方程的推导过程</p><script type="math/tex; mode=display">\begin{aligned} \Psi(\hat{y}, \hat{z}) &=\inf _{z} \Psi(\hat{u}, z) \\ &=G(\hat{y})+\sigma \inf _{z}\left\{\frac{1}{\sigma} F(z)+\frac{1}{2}\left\|z-K \hat{y}-\frac{x}{\sigma}\right\|^{2}\right\}-\frac{1}{2 \sigma}\|x\|^{2} \\ &=G(\hat{y})+\sigma M(F / \sigma)(K \hat{y}+x)-\frac{1}{2 \sigma}\|x\|^{2} \end{aligned}</script><p>Using the Moreau-Yosida regularization:</p><script type="math/tex; mode=display">M_{\lambda} f(x) :=\min _{u} f(u)+\frac{1}{2 \lambda}\|u-x\|_{2}^{2}</script><script type="math/tex; mode=display">\nabla M_{\lambda} f(x)=\frac{1}{\lambda}\left(x-\operatorname{Prox}_{\lambda f}(x)\right)</script></li><li><p>$h(y)+p(By)$对偶问题无法转化成单变量smooth的原因</p><script type="math/tex; mode=display">\begin{array}{c}{\partial \psi(z)=\partial p^{*}(z)-\underline{A x}+\sigma\left(\mathcal{A}^{*} z+y-c\right)} \\ {0 \in \partial \psi(\overline{z})} \\ {0 \in \partial p^{*}(\overline{z})-\mathcal{A} x+\sigma\left(\mathcal{A}^{*} \overline{z}+y-c\right)} \\ {0 \in \sigma\left(\frac{\partial p^{*}(\overline{z})}{\sigma}+\mathcal{A}^{*} z-\left(c-y+\frac{1}{\sigma} \mathcal{A} x\right)\right)}\end{array}</script><p>$z$无法用proximal表示</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>变分不等式的收敛性证明</title>
      <link href="/p/f8c4.html"/>
      <url>/p/f8c4.html</url>
      
        <content type="html"><![CDATA[<h1 id="变分不等式"><a href="#变分不等式" class="headerlink" title="变分不等式"></a>变分不等式</h1><p>变分不等式(VI)的定义：</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190710190816957.png" alt="image-20190710190816957"></p><ul><li><p><strong>最优化问题的转化：</strong></p><p>​                                $x^{*}=\arg \min _{x \in X} f(x)​$</p></li></ul><p>​    等价于满足$\operatorname{VI}(\nabla f, X)​$即</p><p>​                                    $\nabla f\left(x^{<em>}\right)^{T}\left(x^{\prime}-x^{</em>}\right) \geq 0, \forall x^{\prime} \in X$</p><ul><li>优化问题</li></ul><script type="math/tex; mode=display">x^{*} \in \arg \min \{\theta(x)+f(x) | x \in \mathcal{X}\}</script><p>​    其中$f(x),\theta(x)$是convex function, $\theta$不一定可微, 等价于：</p><script type="math/tex; mode=display">x^{*} \in \mathcal{X}, \quad \theta(x)-\theta\left(x^{*}\right)+\left(x-x^{*}\right)^{T} \nabla f\left(x^{*}\right) \geq 0, \quad \forall x \in \mathcal{X}</script><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190710201934772.png" alt="image-20190710201934772"></p><p>​    </p><p>​        </p><p>​        </p><h1 id="优化问题转化VI不等式问题"><a href="#优化问题转化VI不等式问题" class="headerlink" title="优化问题转化VI不等式问题"></a>优化问题转化VI不等式问题</h1><p>将不同的优化问题转化成等价的VI问题：</p><ul><li><p>一元约束问题$\min \{\theta(x) | A x=b, x \in \mathcal{X}\}$</p><p>等价于拉格朗日：$L(x, \lambda)=\theta(x)-\lambda^{T}(A x-b), \quad(x, \lambda) \in \mathcal{X} \times \Re^{m}$</p><p>转化后等于VI inequality：$w^{<em>} \in \Omega, \quad \theta(x)-\theta\left(x^{</em>}\right)+\left(w-w^{<em>}\right)^{T} F\left(w^{</em>}\right) \geq 0, \quad \forall w \in \Omega$</p></li><li><p>二元三元。。</p></li><li><p>min-max问题: $\min _{x \in \mathcal{X}} \max _{y \in \mathcal{Y}}\left\{\mathcal{L}(x, y)=\theta_{1}(x)-y^{T} A x-\theta_{2}(y)\right\}$</p></li></ul><h1 id="PPA的收敛性用PI不等式证明"><a href="#PPA的收敛性用PI不等式证明" class="headerlink" title="PPA的收敛性用PI不等式证明"></a>PPA的收敛性用PI不等式证明</h1><p>方程：</p><script type="math/tex; mode=display">\min \{\theta(x)+f(x) | x \in \mathcal{X}\}</script><p>where θ(x) and f(x) are convex but θ(x) is not necessary smooth, X is a closed convex set.</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190710204453147.png" alt="image-20190710204453147"></p><h1 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h1><ul><li><p>Monotone operator</p><p>单调函数（x-y）（F（x）-F(y)）&gt;0， 则F是单调函数</p></li><li><p>凸函数满足的性质</p><script type="math/tex; mode=display">(x-y)^{T}(\nabla f(x)-\nabla f(y)) \geq 0</script><p>We say the gradient rf of the convex function f is a <strong>monotone operator.</strong></p></li><li><p>min max Lagrangian 和 max min Lagrangian的关系</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>L1算法综述</title>
      <link href="/p/65b3.html"/>
      <url>/p/65b3.html</url>
      
        <content type="html"><![CDATA[<ul><li>lowercontinuity</li></ul><h1 id="一阶算法"><a href="#一阶算法" class="headerlink" title="一阶算法"></a>一阶算法</h1><ul><li>Proximal point algorithm</li><li>Gradient projection method.</li><li><p>Dual-projection </p><ul><li>An Algorithm for Total Variation Minimization and Applications</li></ul></li><li>ALM和PPA</li></ul><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><h3 id="ADMM（1975，1976，2011）"><a href="#ADMM（1975，1976，2011）" class="headerlink" title="ADMM（1975，1976，2011）"></a>ADMM（1975，1976，2011）</h3><ul><li><p>Gabay, D., and Mercier, B., A dual algorithm for the solution of nonlinear variational problems via finite-element approximations, Comp. Math. Appl., 2 (1976), pp. 17-40.</p></li><li><p>Glowinski, R., and Marrocco, A., Sur lapproximation par elements finis dordre un, et la resolution par penalisation-dualite dune classe de problemes de Dirichlet nonlineaires, Rev. Francaise dAut. Inf. Rech. Oper., R-2 (1975), pp. 41-76.</p></li><li><p>Existing convergence theory for ADMM</p><p>Eckstein, J., and Bertsekas, D., On the Douglas-Rachford splitting method and the proximal point algorithm for maximal monotone operators, Mathematical Programming 55, NorthHolland, 1992.</p></li><li><p>Boyd, S., Parikh, N., Chu, E., Peleato, B., &amp; Eckstein, J. (2011). Distributed optimization and statistical learning via the alternating direction method of multipliers. <em>Foundations and Trends® in Machine learning</em>, <em>3</em>(1), 1-122.</p></li></ul><h3 id="Split-Bregman"><a href="#Split-Bregman" class="headerlink" title="Split Bregman"></a>Split Bregman</h3><ul><li><p>Bregman distance图像复原. Osher, S., Burger, M., Goldfarb, D., Xu, J., &amp; Yin, W. (2005). <a href="http://www.corc.ieor.columbia.edu/reports/techreports/tr-2004-03.pdf" target="_blank" rel="noopener">An iterative regularization method for total variation-based image restoration</a>. <em>Multiscale Modeling &amp; Simulation</em>, <em>4</em>(2), 460-489.  也是利用了Bregman distance 处理denoising</p></li><li><p>首次提出。Goldstein, T., &amp; Osher, S. (2009). The split Bregman method for L1-regularized problems. SIAM journal on imaging sciences, 2(2), 323-343.</p></li><li>和ADMM的等价性。Esser, E. (2009). Applications of Lagrangian-based alternating direction methods and connections to split Bregman. <em>CAM report</em>, <em>9</em>, 31.</li></ul><h2 id="Split-Bregman（1967，2009）"><a href="#Split-Bregman（1967，2009）" class="headerlink" title="Split Bregman（1967，2009）"></a>Split Bregman（1967，2009）</h2><ul><li><p>参考文献：</p><ul><li><p>Goldstein, T., &amp; Osher, S. (2009). The split Bregman method for L1-regularized problems. SIAM journal on imaging sciences, 2(2), 323-343. (下述文献编号的出处)</p></li><li><p><a href="http://web.math.ucsb.edu/~cgarcia/UGProjects/BregmanAlgorithms_JacquelineBush.pdf" target="_blank" rel="noopener">Bregman证明</a>（具体针对什么的证明）</p></li></ul></li><li><p>组成部分</p><ul><li>Bregman Iteration to unconstrained problem</li><li>Bregman Iteration  to constrained problem</li><li>Split Bregman to two variable problem</li></ul></li><li><p><u>Bregman distance</u></p></li><li><p>Bregman Iteration for unconstrained problem</p><ul><li><p>目标方程(2.1)：$\min_u E(u)+\lambda H(u)$, with $H$ is differentiable and $\min_u H(u)=0$. </p></li><li><p>Bregman Iteration: 由[4]提出</p><ul><li><script type="math/tex; mode=display">\begin{aligned} u^{k+1} &=\min _{u} D_{E}^{p}\left(u, u^{k}\right)+\lambda H(u) \\ &=\min _{u} E(u)-\left\langle p^{k}, u-u^{k}\right\rangle+\lambda H(u) \\ p^{k+1} &=p^{k}-\nabla H(u^{k+1}) \end{aligned}</script><p><u>得到的解是（2.4）的最小值，且满足$H(u)=0$?  应该只是收敛到H(u)=0</u></p><p>$H\left(u^{k}\right) \rightarrow 0$ as $k\rightarrow\infty$. and $H(u^{k+1})\le H(u^k)$.</p></li></ul></li><li><p>Bregman Iteration的收敛性</p><p>$u^*$: $H\left(u^{k}\right) \rightarrow 0$ as $k\rightarrow\infty$. </p><p>| Theorem 2.1                                                  |<br>| —————————————————————————————— |<br>| 1) Monotonic decrease in $H$: $H(u^{k+1})\leq H(u^k)$<br>2) Convergence to a minimizer of $H$ :$H(u^{k})\leq H(u^<em>)+J(u^</em>)/k$ |</p><p>Proof：参考文献[21]</p></li></ul></li><li><p>Bregman iteration for constrained problem</p><ul><li><p>目标方程(2.4)</p><script type="math/tex; mode=display">\min _{u} E(u) \text { such that } \mathrm{Au}=\mathrm{b}</script><p>等价于无约束问题(2.5)当$\lambda\rightarrow\infty$，如PPA算法，但是$\lambda$很大时不好求解</p><script type="math/tex; mode=display">\min _{u} E(u)+\frac{\lambda}{2}\|A u-b\|_{2}^{2}</script></li><li><p>对(2.5)使用Bregman iteration [30][21]</p><script type="math/tex; mode=display">\begin{aligned} u^{k+1} &=\min _{u} D_{E}^{p}\left(u, u^{k}\right)+\frac{\lambda}{2}\|A u-b\|_{2}^{2} \\ &=\min _{u} E(u)-\left\langle p^{k}, u-u^{k}\right\rangle+\frac{\lambda}{2}\|A u-b\|_{2}^{2} \\ p^{k+1} &=p^{k}-\lambda A^{T}\left(A u^{k+1}-b\right) \end{aligned}</script><p>当$A$是线性的时候，可简化为</p><script type="math/tex; mode=display">\begin{aligned} u^{k+1} &=\min _{u} E(u)+\frac{\lambda}{2}\left\|A u-b^{k}\right\|_{2}^{2} \\ b^{k+1} &=b^{k}+b-A u^{k} \end{aligned}</script></li><li><p>证明(2.5)的Bregman迭代可以获得(2.4)的解。（解的等价性证明）</p><p>| <strong>Theorem 2.2</strong>                                              |<br>| —————————————————————————————— |<br>| Let $H:R^n \rightarrow R$ be convex. Let $A: R^n \rightarrow R^m$  be linear. Consider the algorithm (2.9-2.10). Suppose that some iterate, $u^∗$ , satisﬁes $Au^∗ = b$(<strong>利用theorem2.1</strong>). Then $u^∗$ is a solution to the original constrained problem (2.4). |</p><p><strong>Proof1:</strong> 参考theorem 2.2</p><p>Assumption: $Au_{k+1}=b$,</p><p><strong>Proof2:</strong> “A Combined First and Second Order Variational Approach for Image Reconstruction”</p></li></ul></li></ul><pre><code>问题：意味着任何一个lambda下的2.5的迭代解，都等价于(2.4)的解？迭代所得的解未必是(2.5)的解</code></pre><ul><li>Bregman的优点：收敛快(原因见appendix); 可以保持$\lambda$是常数，不需要变大，因此稳定。 在其他$\lambda_k$增大的情况下，需要以一种极慢的步子增大，使得算法的效率变低。</li></ul><ul><li><p>Split Bregman for l1-regularized optimization problem (1.1) </p><ul><li>目标方程<script type="math/tex; mode=display">\min _{u}|\Phi(u)|+H(u)</script>where |·| denotes the l1-norm, and both |Φ(u)| and H(u) are convex functions, Φ(·) to be diﬀerentiable.</li></ul><p>引入一个变量d, 转化成一个约束问题</p><p>(3.1) $\min _{u, d}|d|+H(u) \text { such that } d=\Phi(u)$</p><p>转化成一个无约束问题</p><p>(3.2) $\min _{u, d}|d|+H(u)+\frac{\lambda}{2}|d-\Phi(u)|_{2}^{2}$</p><p>套用(2.6-2.8)并转化成(2.9-2.10)的形式，得到<strong>the Split Bregman Iteration</strong></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190625054707041.png" alt="image-20190625054707041"></p><p>通过iteratively minimizing解决（3.7）</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190625054906321.png" alt="image-20190625054906321"></p><p>整个算法</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190625055124896.png" alt="image-20190625055124896"></p><p>内循环N=1即可，直观理解</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190625055357144.png" alt="image-20190625055357144"></p></li><li><p>Application</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190625055621617.png" alt="image-20190625055621617"></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190625055607524.png" alt="image-20190625055607524"></p></li></ul><h2 id="ADMM"><a href="#ADMM" class="headerlink" title="ADMM"></a>ADMM</h2><h2 id="ADMM和Split-bregman的关系"><a href="#ADMM和Split-bregman的关系" class="headerlink" title="ADMM和Split bregman的关系"></a>ADMM和Split bregman的关系</h2><ul><li><p>和Split Bregman的等价性proof</p><p>Applications of Lagrangian-Based Alternating Direction Methods and Connections to Split Bregman [2009]</p></li><li><p>ADMM 最早分别由 Glowinski &amp; Marrocco 及 Gabay &amp; Mercier 于 1975 年和 1976 年提出，并被 Boyd 等人于 2011 年重新综述并证明其适用于大规模分布式优化问题。由于 ADMM 的提出早于大规模分布式计算系统和大规模优化问题的出现，所以在 2011 年以前，这种方法并不广为人知。</p></li><li><p>ADMM是一种ALM的方法。PPA也是。</p></li><li><p>Related Algorithm</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190723150552390.png" alt="image-20190723150552390"></p></li><li><p>来自Dual ascent+approximate</p><p>Primal ascent，因为函数不具有连续性，有很多断掉的极大值点。</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190723175554735.png" alt="image-20190723175554735"></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190723175611856.png" alt="image-20190723175611856"></p></li></ul><h2 id="PPA（1976）"><a href="#PPA（1976）" class="headerlink" title="PPA（1976）"></a>PPA（1976）</h2><h2 id="Primal-dual（2011）"><a href="#Primal-dual（2011）" class="headerlink" title="Primal-dual（2011）"></a>Primal-dual（2011）</h2><ul><li>A First-Order Primal-Dual Algorithm for Convex Problems with Applications to Imaging</li></ul><h1 id="二阶算法"><a href="#二阶算法" class="headerlink" title="二阶算法"></a>二阶算法</h1><h2 id="Inexact-Lagrangian-牛顿法"><a href="#Inexact-Lagrangian-牛顿法" class="headerlink" title="Inexact Lagrangian + 牛顿法"></a>Inexact Lagrangian + 牛顿法</h2><ul><li><p>A highly eﬃcient semismooth Newton augmented Lagrangian method for solving Lasso problems</p><p><a href="http://www.mypolyuweb.hk/~dfsun/" target="_blank" rel="noopener">code++</a>、<a href="http://www.math.nus.edu.sg/~mattohkc/SuiteLasso.html" target="_blank" rel="noopener">SuiteLasso</a></p></li><li><p>无约束问题转化成约束问题</p><script type="math/tex; mode=display">\text { (P) } \max -\{f(x)=h(\mathcal{A} x)-\langle c, x\rangle+ p(x)\}</script><script type="math/tex; mode=display">\text { (P) } \max -\{f(x)=h(\mathcal{A} x)-\langle c, x\rangle+ p(x)\}</script><script type="math/tex; mode=display">\text { (P) } \min  \{f(x)=h(\mathcal{A} x)-\langle c, x\rangle+p(x)\}</script></li></ul><script type="math/tex; mode=display">\text { (P) } \max -\{f(x)=h(\mathcal{A} x)-\langle c, x\rangle+ p(x)\}</script><script type="math/tex; mode=display">\text { (D) } \min \left\{h^{*}(y)+p^{*}(z) | \mathcal{A}^{*} y+z=c\right\}</script><p>  从(P)到(D)的转化过程：与增广拉格朗日的关系？</p><ul><li><p>Assumption:<img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190625062450759.png" alt="image-20190625062450759"></p></li><li><p>算法基础：An inexact augmented Lagrangian method for (D)[42]: $\lambda$是越来越大的 </p><script type="math/tex; mode=display">l(y, z, x)=h^{*}(y)+p^{*}(z)-\left\langle x, \mathcal{A}^{*} y+z-c\right\rangle, \quad \forall(y, z, x) \in \mathcal{Y} \times \mathcal{X} \times \mathcal{X}</script><script type="math/tex; mode=display">\mathcal{L}_{\sigma}(y, z ; x) :=l(y, z, x)+\frac{\sigma}{2}\left\|\mathcal{A}^{*} y+z-c\right\|^{2}, \quad \forall(y, z, x) \in \mathcal{Y} \times \mathcal{X} \times \mathcal{X}</script><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190625062337998.png" alt="image-20190625062337998"></p></li><li><p>算法核心</p><ul><li>将(18) 转化成 (22)</li></ul><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190625063019627.png" alt="image-20190625063019627"></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190625063050310.png" alt="image-20190625063050310"></p><ul><li><p>解决（22）：Ax = 0 的方法</p><p>牛顿法法</p></li></ul></li><li><p>收敛性分析</p></li><li><p>应用：Yuan, Y., Sun, D., &amp; Toh, K. C. (2018). An efficient semismooth Newton based algorithm for convex clustering. <em>arXiv preprint arXiv:1802.07091</em>.</p></li></ul><h2 id="Nonconvex-牛顿法"><a href="#Nonconvex-牛顿法" class="headerlink" title="Nonconvex  + 牛顿法"></a>Nonconvex  + 牛顿法</h2><ul><li>目标问题：square-root regression problem<script type="math/tex; mode=display">\min _{\beta \in \mathbb{R}^{n}}\{g(\beta) :=\|X \beta-b\|+\lambda p(\beta)-q(\beta)\}</script></li></ul><h1 id="收敛性证明"><a href="#收敛性证明" class="headerlink" title="收敛性证明"></a>收敛性证明</h1><p>一般流程：解的存在性、唯一性到算法的收敛性</p><p>先证明解的存在性、通过严格凸问题得到解的唯一性、假设存在唯一解，然后收敛到最小解</p><ul><li><p>例子：</p><p>存在性证明：A CONVEX VARIATIONAL MODEL FOR RESTORING BLURRED IMAGES WITH MULTIPLICATIVE NOISE; On the convex model of speckle reduction</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190625072208966.png" alt="image-20190625072208966"></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190625072239269.png" alt="image-20190625072239269"></p><p>唯一性：A CONVEX VARIATIONAL MODEL FOR RESTORING BLURRED IMAGES WITH MULTIPLICATIVE NOISE; On the convex model of speckle reduction</p><p>收敛性：</p></li></ul><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><ol><li>牛顿法中，P和D之间与拉格朗日的关系</li><li>semismooth到底什么意思</li><li>在Split Bregman中，Split Bregman下的任何lambda都是原约束问题的解？</li></ol>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>美食地图</title>
      <link href="/p/acef.html"/>
      <url>/p/acef.html</url>
      
        <content type="html"><![CDATA[<h1 id="尖沙咀"><a href="#尖沙咀" class="headerlink" title="尖沙咀"></a>尖沙咀</h1><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/2019-07-03-045243.png" alt="image-20190621155028543"></p><p>海港城旁边： DFS，Aqua spirit，</p><p>把地铁口也标上</p><p>买小熊饼干：在美丽华商厦，是个类似重庆大楼的开放的楼</p><p>旺记冰室/一兰拉面：</p><p> 妈咪鸡蛋仔和薯条/；</p><p>冰淇淋；送他们上船；</p><p>点心：好运添，唐宫小聚（新式）</p><p>火锅：火水爐冰室火鍋 旺角</p><p><a href="https://www.openrice.com/zh/hongkong/r-%E7%81%AB%E6%B0%B4%E7%88%90%E5%86%B0%E5%AE%A4%E7%81%AB%E9%8D%8B-%E6%97%BA%E8%A7%92-%E6%B8%AF%E5%BC%8F-%E7%81%AB%E9%8D%8B-r544211/reviews" target="_blank" rel="noopener">https://www.openrice.com/zh/hongkong/r-%E7%81%AB%E6%B0%B4%E7%88%90%E5%86%B0%E5%AE%A4%E7%81%AB%E9%8D%8B-%E6%97%BA%E8%A7%92-%E6%B8%AF%E5%BC%8F-%E7%81%AB%E9%8D%8B-r544211/reviews</a> </p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190623004929530.png" alt="image-20190623004929530"></p><h1 id="岛上"><a href="#岛上" class="headerlink" title="岛上"></a>岛上</h1><h1 id="拍照"><a href="#拍照" class="headerlink" title="拍照"></a>拍照</h1><p><img src="/Users/yyf/Library/Containers/com.tencent.xinWeChat/Data/Library/Application Support/com.tencent.xinWeChat/2.0b4.0.9/fe11254b8abd42aa6171c5844ef84c2e/Message/MessageTemp/9e20f478899dc29eb19741386f9343c8/Image/191563885086_.pic.jpg" alt="191563885086_.pic"></p><h1 id="购物"><a href="#购物" class="headerlink" title="购物"></a>购物</h1><p><img src="/Users/yyf/Library/Containers/com.tencent.xinWeChat/Data/Library/Application Support/com.tencent.xinWeChat/2.0b4.0.9/fe11254b8abd42aa6171c5844ef84c2e/Message/MessageTemp/9e20f478899dc29eb19741386f9343c8/Image/201563885236_.pic.jpg" alt="201563885236_.pic"></p><h1 id="清单"><a href="#清单" class="headerlink" title="清单"></a>清单</h1><p>去一个岛徒步/长洲岛/西贡，晚上坐船吃冰淇淋：夏天小清新风</p><p>去吃茶餐厅</p><p>去坐傍晚的叮叮车，吃shakeshack</p><p>去逛香港的超市，买寿司当晚餐，咸蛋黄鸡蛋仔</p><p>吃大排档：晚上</p><p>搬家+看演唱会</p><p>点心：周记点点心，</p><h1 id="西安"><a href="#西安" class="headerlink" title="西安"></a>西安</h1><ul><li><a href="https://www.zhihu.com/question/30342566" target="_blank" rel="noopener">西安及周边100公里内有哪些冷门但非常值得一去的地方？</a></li><li><a href="https://www.zhihu.com/question/19863530/answer/30543158?utm_source=wechat_session&amp;utm_medium=social&amp;utm_oi=31718778077184" target="_blank" rel="noopener">西安值得吃的地方</a></li><li><a href="https://www.zhihu.com/question/28309082/answer/93052568" target="_blank" rel="noopener">西安有哪些可以安静地待一下午的地方？</a></li><li>踩过的雷：top1的六🈴️汤包</li></ul><p><strong>市区：</strong></p><ul><li><p>大雁塔：美术馆、回民街、洒金桥、钟鼓楼</p></li><li><p>西安明城墙： 推荐环墙一周的自行车。西安城墙是中国现存规模最大、保存最完整的古代城垣。现存城墙为眀代建筑,全长13.7千米,位于西安市中心,送我们过去的司机师傅说起城墙那种油然而生发自內心的自豪感满满都是</p></li><li><p>大明宫遗址公园：这个是热门，但冷门玩法是傍晚去</p></li><li><p>八仙宫古玩市场，八仙庵，，离永兴坊不远</p></li><li><p>顺城巷：一侧是巍巍古城墙，一侧是秀丽端庄的明清古建。、食店、酒吧、咖啡屋，更有一些秦腔或相声曲艺社，院门半掩静待听客到访。</p></li><li><p>环城公园：以护城河为线，在城墙根下围绕着明城墙修建的环城公园，是西安本地人运动、散步、休闲的好去处</p></li></ul><p><strong>较远：</strong></p><ul><li><p>秦岭：东梁山(冷门)；黑河；楼观台；黎元坪。</p></li><li><p>西岳庙。一般游客都会去华山,很少会去西岳庙。但是西岳庙有着非常精美的明清建筑,而且面积</p></li></ul><p>巨大,文革期间用作军营所以保存的不错,不过这里和华山是联票,如果去华山的话一定要抽时间</p><p>去西岳庙。</p><ul><li>碑林博物馆。这个根本就不算冷门,不过还是小众一些,书法爱好者的圣地。而且这里面还有昭陵</li></ul><p>骏和景云钟。里面的佛像石刻更是精美绝伦。另外碑林旁边有一个卧龙寺,是陕西第一所寺庙,</p><p>也可以看看。</p><ul><li>关中民俗艺术博物院。坐标南五台</li></ul><p>坐标南五台。是一家私人关中民俗博物院,建筑精美,藏品丰富。</p><p>很感激有这样的收藏家能够将关中民俗有条理的收藏保存,对外开放,</p><p>门票略贵,120元,但还是非常值得去感受一下,尤其是如果身边有外国友人,非常推荐带他们来</p><p>这里,绝对会对西安、对中国会有更深一层的认识。</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190706003050116.png" alt="image-20190706003050116"></p><h1 id="西安吃的"><a href="#西安吃的" class="headerlink" title="西安吃的"></a>西安吃的</h1><p>马峰小炒（好吃！！但拍得不好看，见谅）：</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190706004524589.png" alt="image-20190706004524589"></p><p><strong>定家小酥肉</strong></p><p>地址：酿皮隔壁</p><p><strong>东南亚甑糕 西羊市</strong></p><p>面：<strong>马虎面馆 连锁店</strong>，<strong>马虎面馆 连锁店</strong>，<strong>英子牛肉面 景观路</strong></p><p>夜宵：小佐烤肉(开元路总店)</p><h1 id="咖啡馆、小情调"><a href="#咖啡馆、小情调" class="headerlink" title="咖啡馆、小情调"></a>咖啡馆、小情调</h1><ul><li><p><strong>曼蒂广场</strong></p><p>人不多的一个商场,店其实也不多。但是艺术感很强,经常有一些画或雕塑的小展览。里面的虫儿</p><p>咖啡、均记咖啡的装修风格我都很喜欢。就连这里的<strong>米家大雨泡馍</strong>都是咖啡馆式的木质深色装修风</p><p>格,很是雅致,如果请人吃泡馍还不想环境脏乱差的话可以考虑这里。</p></li><li><p><strong>陕西省图书馆</strong>。</p></li><li><p><strong>曲江书城</strong></p><p>书城提供很多座位、小沙发，看书很惬意。</p></li><li><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190706005746707.png" alt="image-20190706005746707"></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>模仿胶片色调</title>
      <link href="/p/3acf.html"/>
      <url>/p/3acf.html</url>
      
        <content type="html"><![CDATA[<h1 id><a href="#" class="headerlink" title=" "></a> </h1><p>06-14</p><p>课程链接：<a href="https://m.lizhiweike.com/classroom/12544288" target="_blank" rel="noopener">https://m.lizhiweike.com/classroom/12544288</a></p><p><a href="https://pan.baidu.com/s/1QCXJhicXgzQgHirQioIPSw" target="_blank" rel="noopener">https://pan.baidu.com/s/1QCXJhicXgzQgHirQioIPSw</a> 密码：4yqr</p><p>快速模仿胶片色调 @修图师李新颖</p><p>时尚博主：小象王国、fashionmodels</p><p>摄影师：张家诚</p><p>同学们，你们已经看完了这5个摄影师的作品了吧，其实呢，我们除了一些技法上还有思路上的提升，其实我们审美上的一个提升也是非常重要的，那么我们如何去提升审美呢？下面我介绍给大家一些提升自己的方法。</p><p>识一些国外的就是国际的，嗯比较厉害的摄影师的名字从认识摄影师的名字开始，然后呢，嗯，如果说你们一开始不知道<strong>一些国际摄影师的名字，那么我们可以在国内的一些微博啊，比如说微博博主分享一些时尚大片的微博</strong>，博主比如说小象王国啊，还有一个fashion models，然后呢，这两个时尚博主他也是会经常的分享一些国外的大片。</p><p>他分享的一些时尚大片的，他会艾特出来摄影师，然后我们找到我们喜欢的摄影师的名字去进行一个标记，然后去给摄影师的作品进行一个分类，比如说嗯，我们首先就是这个摄影师的名字进行一个标记，然后呢，我们再去把他的作品进行一个搜集，比如说那个海边的场景我们给它归类一个文件夹海边，然后呢，我们室内的文件夹就给它归类为室内，然后呢，我们那个草地的，然后就把作品分类为草地，这样子呢，可以有效的去提升我们找片子的效率。</p><p>两个时尚博主是我比较经常看的，他不止会分享一些时尚的大片，还会分享一些时尚的资讯，会让我在一个视觉啊，然后呢，还有我的那个审美上面会带给我一些新的灵感</p><p>收集摄影师的名字。多看国际标准的摄影作品。<br><strong>如何提高审美</strong>，每日不断的阅读，不断的去提升自己的眼界，开拓自己的视野。阅读方式也很重要，要找到自己喜欢的照片，有目的的去欣赏，这很重要。从以下几点进行欣赏。看片的话不是盲目的去看片子，看片子的话要就是有目的的去欣赏去分析</p><p>舒服的调子、光影层次、情绪、构图 、肢体语言、有趣的色彩对比、有创意有趣味性的画面或者干净、简洁、统一的画面</p><p>王家卫的风格都是色彩比较浓郁的，我们模拟的时候要嗯，要加一些大量的色温，或者是在曲线给他多加红啊，然后加黄就可以模拟出来王家卫那种嗯特别浓郁的色彩，然后记得按不给他，嗯，暗部的话加氢，然后呢加那个黄。</p><p>提灰：色阶、可选颜色、曲线都可以提灰</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190614200158279.png" alt="image-20190614200158279"></p><p>视频中提及的高光、中间调、暗部等小知识，大家可以看下下方这张图~</p><p><img src="https://static-1253442168.image.myqcloud.com/picture/12544288_1e3b11f081a379edd893960e7f751150.jpg" alt="img"></p><p>胶片照片的特点：高光比较柔，高光比较暗，暗部比较扎实，和中间调比较高亮有对比，线条明显，色彩多乱；胶片会色偏（红色往黄色偏）</p><p>数码照片的特点：过渡比较平缓，对比度低，像素高，细节多，丢失光感和立体感；质感退化</p><p>数码相机到胶片照片：质感退化，高光调暗，中间调提亮，暗部压实；曝光拉高</p><p>中间调提亮</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190614201512008.png" alt="image-20190614201512008"></p><p>厚重，就是明暗差别大，就像上妆重，高光特别亮，中间调特别暗</p><p>1.先调光影</p><p>减少对比度</p><p>增加曝光</p><p>色彩曲线：加深暗部（将曲线底部往右平移），提高中间调（把中间点固定在原来的位置），降低高光(降低)</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190614202553695.png" alt="image-20190614202553695"></p><ol><li><p>调色彩，色偏</p></li><li><p>前期</p><p>模仿胶片的照片，前期拍摄的话尽量顺光顺光拍摄，然后呢，尽量曝光稍微亮一点，不要就是曝光稍微要高一档，不要说太低了。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 摄影 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>小波域图像去噪</title>
      <link href="/p/2812.html"/>
      <url>/p/2812.html</url>
      
        <content type="html"><![CDATA[<h1 id="变换"><a href="#变换" class="headerlink" title="变换"></a>变换</h1><p>变换的作用：方便压缩、计算等</p><p>如：方便计算的特征向量基础，Tv=cv。eigenvector basis就是组成T的向量，T就是转换。</p><p>变换有：傅立叶变换、小波变换（傅立叶变化不属于小波变化。傅立叶变换和小波变换同属于变换）</p><h1 id="傅立叶变换"><a href="#傅立叶变换" class="headerlink" title="傅立叶变换"></a>傅立叶变换</h1><ul><li><p>特点：是正交基。正交基方便求出基的系数。</p></li><li><p>局限性</p><blockquote><p>最擅长的是把一维的，类三角波连续变量函数信号映射到一维系数序列上，但对于突变信号或任何高维的非三角波信号则几乎无能为力。</p></blockquote><p>如：</p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY/2019-06-13-144321.png" alt="image-20190604181734682"></p></li></ul><h1 id="小波变换"><a href="#小波变换" class="headerlink" title="小波变换"></a>小波变换</h1><ul><li><p>参考</p><p><a href="https://zhuanlan.zhihu.com/p/44215123" target="_blank" rel="noopener">小波变换完美通俗讲解系列之 （一）</a></p><p><a href="https://zhuanlan.zhihu.com/p/44217268" target="_blank" rel="noopener">小波变换完美通俗讲解系列之 （二）</a></p></li><li><p>波的定义</p><p>波：在时间域或者<u>空间域</u>的震荡方程</p><p>小波：集中在时域某一点的波；优点，能够分析瞬时时变信号；实现，通过对小波的伸缩平移对函数信号进行多尺度细分。</p></li><li><p>小波的特点</p><p>两两正交，归一化。</p><p>小波级数的展开同时在时域和频率上进行，也就是对应伸缩(频域)和平移(覆盖时域)，<u>傅立叶变换只在频域。</u></p></li><li><p>小波的构成：父小波和母小波的平移伸缩；scaling function+wavelet function(mother)</p><p>mother wavelet：母小波</p><p>father wavelet：<strong>scaling function</strong>/父小波/尺度函数</p><p>对任意V_j的function可以分解为：</p><p>（1）scaling fucntion的形式：</p><script type="math/tex; mode=display">\begin{array}{c}{\varphi_{j, k}} \end{array}</script><p>（2）第二种就是它上一个子空间的basis以及上一级子空间的wavelet function</p><script type="math/tex; mode=display">\begin{array}{c}{\varphi_{j-1, k}} \\ {\psi_{j-1, k}}\end{array}</script><p>（3）一直利用上上..级的scaling function，则得到<strong>小波展开形式</strong>：</p><script type="math/tex; mode=display">f(t)=\sum_{k=-\infty}^{\infty} c_{k} \varphi(t-k)+\sum_{k=-\infty}^{\infty} \sum_{j=0}^{\infty} d_{j, k} \psi\left(2^{j} t-k\right)</script><p>其中，$\varphi(t)$是父小波，$\psi_{j, k}(t)$是母小波。<br>scaling function不是凭空插进去的，而是通过不断的嵌套迭代出来的</p></li><li><p>为什么使用第3种方式（小波变换）来表达信号</p><p>计算</p><blockquote><p>那为什么我们最后选定的是这种选取方式呢?实际上，刚才介绍的这个性质已经告诉我们，对于任何的scale j0，我们都可以给我们的signal space找到一组orthonormal basis，这个basis是通过组合scale j0上的scaling function以及所有在scale j，j&gt;j0上的wavelets得到的。这样，基于这个orthonormal basis，所有信号空间中的信号都可以写成组成这个basis的functions的线性组合：</p><script type="math/tex; mode=display">\begin{array}{l}{c_{j_{0}, k}=\left\langle s(n), \varphi_{j_{0}, k}(n)\right\rangle} \\ { d_{j, k}=\left\langle s(n), \psi_{j, k}(n)\right\rangle}\end{array}</script></blockquote><p>两种函数相当于高通滤波和低通滤波的作用</p><blockquote><p>wavelet function和scaling function背后的物理意义了：wavelet function等同于对信号做高通滤波保留变化细节，而scaling function等同于对信号做低通滤波保留平滑的shape!</p></blockquote></li><li><p>scaling function 和 MRA的关系(scaling function在小波变换中的作用和意义）</p><p>在不同的子空间，对于同一个信号就有不同的诠释。诠释最好的当然是V3，完全不损失细节。这就是多解析度的意义。我们可以有嵌套的，由scaling function演变的basis function集合，每一个集合都提供对原始信号的某种近似，解析度越高，近似越精确。</p><p>物理意义：做低通滤波</p></li><li><p>小波变换的计算复杂度(还没理解)</p><blockquote><p>从信号算出展开系数a需要很方便。普遍情况下，小波变换的复杂度是O(Nlog(N))，和FFT相当。有不少很快的变换甚至可以达到O(N)，也就是说，计算复杂度和信号长度是线性的关系。小波变换的等式定义，可以没有积分，没有微分，仅仅是乘法和加法即可以做到，和现代计算机的计算指令完全match。</p></blockquote></li><li><p>哈尔小波是小波变换的一种。以哈尔小波为例</p><p>如：[9 7 3 5 ]-&gt;[8 4 1 -1]-&gt;[6 2 1 -1]</p></li><li><p>小波变换的基本流程</p><ol><li><p>选取合适的wavelet function和scaling function，从已有的信号中，反算出系数c和d。</p></li><li><p>对系数做对应处理</p></li><li><p>从处理后的系数中重新构建信号。</p></li></ol></li><li><p>小波变换的应用：系数处理</p><p>应用有压缩、去噪、水印、图像融合等等</p><p>例如：比如图像或者视频压缩，就希望选取能将能量聚集到很小一部分系数中的小波，然后抛弃那些能量很小的小波系数，只保留少数的这些大头系数，再反变换回去。这样的话，图像信号的能量并没有怎么丢失，图像体积却大大减小了。</p><ul><li><p>小波去噪的原理</p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY/2019-06-13-144406.png" alt="image-20190605173308156"></p></li></ul></li><li><p>小波分解树(以Haar小波为例)</p><p>由高频和低频组成</p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY/2019-06-13-144535.png" alt="哈尔小波分解树"></p></li><li><p>Matlab的实现（未完成，参考《图像处理中的数学》）</p><p>wavedec2</p></li></ul><h1 id="小波域去噪综述"><a href="#小波域去噪综述" class="headerlink" title="小波域去噪综述"></a>小波域去噪综述</h1><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY/2019-06-13-143107.png" alt="image-20190610194555792"></p><ul><li><p>问题：<u>是否所有小波域下的去噪方法都利用了稀疏性，所有小波转化都是为了得到稀疏性？</u></p></li><li><p>小波域的图像降噪</p><ul><li><p>基于filter,（利用sparsity）</p><p>H. Zhang, Aria Nosratinia, and R. O. Wells, Jr., “Image denoising via wavelet-domain spatially adaptive FIR Wiener filtering”, in IEEE Proc. Int. Conf. Acoust., Speech, Signal Processing, Istanbul, Turkey, June 2000.</p></li><li><p>利用小波奇异检测特性将信号与噪声分开。Mallat, 1992。计算量大，收敛缓慢，产生振荡和不稳定</p><p>Mallat, S., &amp; Hwang, W. L. (1992). Singularity detection and processing with wavelets. <em>IEEE transactions on information theory</em>, <em>38</em>(2), 617-643.</p></li><li><p>利用小波系数阈值收缩法来分开信号和噪声。Donoho，1992。Gibbs phenomena in the neighborhood of discontinuities – 即不连续点周围的信号能量会在一定尺度的范围上来回波动-to the lack of translation invariance of the wavelet basis。</p><p>(都不是MRA-based tight frame，那么是MRA-based tight frame什么又是其他tight frame)</p></li><li><p>改进Gibbs：R.R. Coifman and D.L. Donoho提出了平移不变量算法可<br>有效地避免这种现象的发生</p><p>首先让含有噪声的原始信号进行多次循环平移（比如进行 n 次）,其次运用阈值算法对平移后的信号进行去噪处理,然后再平均去噪的信号,此称为“平移-去噪-平均”的平移不变量算法的原理。</p><script type="math/tex; mode=display">\overline{T}\left(x,\left(S_{h}\right)_{h \in H_{n}}\right)=A v e_{h \in H_{k}} S_{-h}\left(T\left(S_{h}(x)\right)\right)</script><p>[57] R.R. Coifman and D.L. Donoho, Translation-invariant de-noising, Lecture Notes in Statistics-New York-Springer Verlag (1995), 125–125.</p></li><li><p>贝叶斯方法去噪(利用sparsity了没有？)，需要利用先验证模型</p><ul><li>先验模型是小波系数先验模型：利用联合分布，GGD</li><li>先验模型是小波系数的空间局部作用关系（马尔可夫模型）：HMM</li></ul></li><li><p>（基于框架的wavelet frame在图像还原中有很大的应用，谁最先先提出的）: wavelet frame.</p></li><li><p>（还有一种说法）引自基于稀疏表示的小波去噪_朱杰.pdf</p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY/2019-06-14-144426.png" alt="image-20190611183748135"></p></li><li><p>基于多尺度分析的紧框架结构 (MRA-based tight frame method): The community’s effort to develop redundant wavelet systems that have sparse approximations for various classes of functions has led to the development of the MRA-based wavelet frames.（those tight <em>wavelet frames</em> generated via a multiresolution analysis）（详见基于小波框架的变分模型）</p><ul><li><p>tight wavelet frame: 是一种变分法，因为u = Wt (Wu). u在W下不唯一。所以有三种方法来获取目标图像的稀疏近似值。</p><blockquote><p>Therefore, there are three formulations for the sparse approximation of the underlying images; namely, the analysis based approach, the synthesis based approach and the balanced approach.</p></blockquote><ul><li>Analysis based：The analysis based approach was ﬁrst proposed in [84, 170].</li></ul><script type="math/tex; mode=display">\min _{u \in \mathbb{R}^{n}} \frac{1}{2}\|A u-f\|_{D}^{2}+\|\mbox{diag}(\lambda) W u\|_{1}</script><p>[170] J.L. Starck, M. Elad, and D.L. Donoho, Image decomposition via the combination of sparse representations and a variational approach, IEEE transactions on image processing 14 (2005), no. 10, 1570–1582.</p><p>[84] M. Elad, J.L. Starck, P. Querre, and D.L. Donoho, Simultaneous cartoon and texture image inpainting using morphological component analysis (MCA), Applied and Computational Harmonic Analysis 19 (2005), no. 3, 340–358.</p></li><li><p>synthesis based: The synthesis based approach was first introduced in [66, 86, 87, 90, 91].</p><script type="math/tex; mode=display">\min _{\alpha \in \mathbb{R}^{m}} \frac{1}{2}\left\|A W^{\top} \alpha-f\right\|_{D}^{2}+\|\mbox{diag}(\lambda) \alpha\|_{1}</script><p>[90]M.A.T. Figueiredo and R.D. Nowak, An EM algorithm for wavelet-based image restoration, IEEE Transactions on Image Processing 12 (2003), no. 8, 906–916.</p><p>[91]A bound optimization approach to wavelet-based image deconvolution, Image Processing, 2005. ICIP 2005. IEEE International Conference on, vol. 2, IEEE, 2005, pp. II–782.</p><p>[86] M.J. Fadili and J.L. Starck, Sparse representations and bayesian image inpainting, Proc.</p><p>SPARS 5 (2005).</p><p>[66] I. Daubechies, G. Teschke, and L. Vese, Iteratively solving linear inverse problems under general convex constraints, Inverse Problems and Imaging 1 (2007), no. 1, 29.</p><p>[87]MJ Fadili, J.L. Starck, and F. Murtagh, Inpainting and zooming using sparse representations, The Computer Journal 52 (2009), no. 1, 64.</p></li><li><p>balanced method：The balanced approach was ﬁrst used in [34, 36] for high resolution image reconstruction.</p><script type="math/tex; mode=display">\min _{\alpha \in \mathbb{R}^{m}} \frac{1}{2}\left\|A W^{\top} \alpha-f\right\|_{D}^{2}+\frac{\kappa}{2}\left\|\left(I-W W^{\top}\right) \alpha\right\|_{2}^{2}+\|\mbox{diag}(\lambda) \alpha\|_{1}</script><p>求解算法：the proximal forward and backward splitting algorithm</p><p>[34]R.H. Chan, T.F. Chan, L. Shen, and Z. Shen, Wavelet algorithms for high-resolution image reconstruction, SIAM Journal on Scientiﬁc Computing 24 (2003), no. 4, 1408–1432.</p><p>[36]Tight frame: an eﬃcient way for high-resolution image reconstruction, Applied and Computational Harmonic Analysis 17 (2004), no. 1, 91–115.</p></li></ul></li></ul></li><li><p>小波域去噪综述</p><p>小波域去噪是利用信号稀疏表达的一个代表性的方法。此类方法主要就是对图像转化到小波域后的系数进行处理，再将处理后的小系数还原到空间域，从而得到复原后的图像。小波域的去噪方法大致可以分为三类：奇异值检测、阈值收缩以及基于贝叶斯的模型。其中小波阈值去噪由Do在在1992提出来， 是最被广为学习的一种方法。它的工作原理是根据噪声和自然图像在频率段不同的表现形式(噪声呈现出高频小幅值)，通过设定阈值将噪声从噪声图像中区分出来，并将噪声系数还原为0，从而消除噪声。大量论文针对阈值的选择进行了研究。然而，通过阈值收缩的方法，在去噪的同时容易抹去一些图像的高频信息，因此在图像不连续的区域容易产生振铃(Gibbs)的缺陷。R.R. Coifman and D.L. Donoho提出一种平移不变量算法，可有效减少此类缺陷。另一方面，随着框架理论的发展，小波紧框架系统被证明了是一种有效的稀疏逼近分段光滑图像的系统。因此，小波紧框架变换在图像恢复问题中应用十分广泛 [] 。( 基于多尺度分析的小波紧框架开始被成功地用于解决图像复原问题。基于小波框架的变分模型[14-19]被成功应用于图像去噪中，其中稀疏性的特点作为约束项。)然而，需要处理的图像是多种多样的，并没有一个静态的小波紧帧系统能够很好地处理恢复它们。因此Cai在[1]中提出了一种由图片数据驱动的设计tight frame wavelet的方法，来解决一类tight frame只能解决一类图片的问题。</p><blockquote><p>[1] Cai, J. F., Ji, H., Shen, Z., &amp; Ye, G. B. (2014). Data-driven tight frame construction and image denoising. </p></blockquote><p>one of the most studied</p><p>coefficients with small magnitude can be considered as pure noise and should be set to zero.</p><p>redundant wavelet systems that have sparse approximations for various classes of functions has led to the development of the MRA-based wavelet frames </p><p> A number of papers were proposed to select the threshold.a number of methods differs in the selection of the threshold parameter.</p><p>As for the coeﬃcients with small magnitude can be considered as pure noise and should be set to zero</p><p>The sparsity is later incorporated in the variational method.</p><blockquote><p>The most investigated domain in denoising using Wavelet Transform is the non-linear coefficient <strong>thresholding based methods.</strong></p><p>Most of the wavelet shrinkage literature is based on methods for choosing the optimal threshold which can be adaptive or non-adaptive to the image.</p><p>generates spurious blips, better known as artifacts</p><p>wavelet thresholding是由Donoho首先在1992提出来的，在这之前在wavelet domain的去噪也是有的。如H. Zhang, Aria Nosratinia, and R. O. Wells, Jr., “Image denoising via wavelet-domain spatially adaptive FIR Wiener filtering”, in IEEE Proc. Int. Conf. Acoust., Speech, Signal Processing, Istanbul, Turkey, June 2000.</p><p>Wavelet-based denoising aims to decompose the signal into the by high-frequency filter and low-frequency filter. {As for the coeﬃcients with small magnitude can be considered as pure noise and should be set to zero.} As for the detail coeﬃcients of the noise presented as high frequency with small magnitude while  a clean image tend to be many zeros. Thus </p></blockquote><p>stronger sparse expression: wavelet tight frame (limitation: not adaptive, a class of )</p></li></ul><h1 id="小波阈值去噪"><a href="#小波阈值去噪" class="headerlink" title="小波阈值去噪"></a>小波阈值去噪</h1><ul><li><p>问题</p><p>小波阈值去噪，选择的是哪种小波变换，属于tight frame吗，那么属于MRA-based tight frame吗。</p></li><li><p>原理</p><p>The coefficients of the wavelet transform are usually sparse. That is, most of the coefficients in a noiseless wavelet transform are effectively zero. Therefore, we may reformulate the problem of recovering f as one of recovering the coefficients of f which are relatively ”stronger” than the Gaussian white noise background. That is, coefficients with small magnitude can be considered as pure noise and should be set to zero. The approach in which each coefficient is compared with a threshold in order to decide whether it constitute a desirable part of the original signal or not, is called wavelet<br>thresholding.</p></li><li><p>过程</p><p>transform-based thresholding working in three steps:</p><ul><li><p>Transform the noisy data into an orthogonal domain.</p></li><li><p>Apply soft or hard thresholding to the resulting coefficients, thereby suppressing<br>those coefficients smaller than a certain amplitude.</p></li><li>Transform back into the original domain.</li></ul></li><li><p>两种分类方法</p><p>全局阈值和自适应阈值</p><p>软阈值和硬阈值</p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY/2019-06-13-144604.png" alt="image-20190606124827535"></p><p>soft-thresholding几乎用于所有的算法。Hard-thresholding会产生一种spurious blips的缺陷，as a result of unsuccessful attempts of removing moderately large noise coefficients。</p></li><li><p>阈值的选择影响很大</p><p>Large threshold lead to the details lost. </p><p>Small threshold lead to the noise unclean. </p></li><li><p>Reviews of literature：(1990s) Wavelet thresholding and wavelet shrinkage：VisuShrink，SureShrink，BayesShrink, NeighBlock</p><ul><li><p>[VisuShrink 1994] David L. Donoho and Jain M. Johnstone. Ideal spatial adaptation by wavelet shrinkage. Biometrika, 81(3):425–455, 1994. 3</p><p>全局阈值</p></li><li><p>[SureShrink 1995] David L. Donoho and Iain M. Johnstone. Adapting to unknown smoothness via wavelet shrinkage. Journal of the American Statistical Association, pages 1200–1224, 1995.</p><p>第一个adaptive</p></li><li><p>[BayesShrink 2000] Martin Vetterli S Grace Chang, Bin Yu. Adaptive wavelet thresholding for image denoising and compression. IEEE Transactions on Image Processing, 9(9):1532–1546, Sep 2000</p></li><li><p>[NeighBlock 2001] T.T. Cai and B.W. Silverman. Incorporating information on neighbouring coefficients into wavelet estimation. Sankhya, Series A, 63, 2001</p></li></ul></li></ul><h1 id="小波变分模型"><a href="#小波变分模型" class="headerlink" title="小波变分模型"></a>小波变分模型</h1><p><strong>基于小波框架的变分模型</strong>[14-19]被成功应用于图像去噪中。 研究表明，基于小波框架的变分模型比其他变分模型 例如 ROF 模型更好，这是因为小波框架的多分辨率结构和冗余。</p><ul><li><p>Chan, R. H., Chan, T. F., Shen, L., &amp; Shen, Z. (2003). Wavelet algorithms for high-resolution image reconstruction. <em>SIAM Journal on Scientific Computing</em>, <em>24</em>(4), 1408-1432.</p></li><li><p>Cai, J. F., Osher, S., &amp; Shen, Z. (2009). Split Bregman methods and frame based image restoration. <em>Multiscale modeling &amp; simulation</em>, <em>8</em>(2), 337-369.</p></li><li><p>Dong, B., &amp; Shen, Z. (2010). MRA based wavelet frames and applications. <em>IAS Lecture Notes Series, Summer Program on “The Mathematics of Image Processing”, Park City Mathematics Institute</em>, <em>19</em>．</p></li><li><p>Chan, R., Shen, L., &amp; Shen, Z. (2005). A framelet-based approach for image inpainting. <em>Res. Rep</em>, <em>4</em>, 325.</p><p>tight-frame</p></li><li><p>Cai, J. F., Osher, S., &amp; Shen, Z. (2009). Linearized Bregman iterations for frame-based image deblurring. <em>SIAM Journal on Imaging Sciences</em>, <em>2</em>(1), 226-252.</p></li><li><p>J.-F. Cai, S. Osher, and Z. Shen, “Split Bregman methods and frame based image restoration,” Multiscale Model. Simul., vol. 8, no. 2, pp. 337–369, Dec. 2010.</p></li><li><p>Cai, J. F., Dong, B., Osher, S., &amp; Shen, Z. (2012). Image restoration: total variation, wavelet frames, and beyond. <em>Journal of the American Mathematical Society</em>, <em>25</em>(4), 1033-1089.</p></li><li><p>Cai, J. F., Ji, H., Shen, Z., &amp; Ye, G. B. (2014). Data-driven tight frame construction and image denoising. <em>Applied and Computational Harmonic Analysis</em>, <em>37</em>(1), 89-105. 最近建立了小波框架和变分模型之间的联系，并提出了一种<strong>数据驱动紧框架</strong>， 该框架比以往的模型更能精确地重构图像。<a href="https://www.math.ust.hk/~jfcai/" target="_blank" rel="noopener">code++</a></p><p>提出了一种从图片本身设计tight frame wavelet的方法。来解决一类tight frame只能解决一类图片的问题。</p></li><li><p>代码实现</p><p><a href="https://zhuanlan.zhihu.com/p/35928430" target="_blank" rel="noopener">小波去噪的基本原理</a></p></li><li><p>影响去噪的因素</p><p>域值的选择，小波的选择，分解层次的选择</p></li><li><p>[2014 Cai]</p><p>《MRA-Based Wavelet Frames and Applications》[cam11-22]</p><blockquote><p>on wavelet frame based image restoration [35, 36, 37, 38, 39, 40, 41, 42, 43, 21].</p><p>Split Bregman methods and frame based image restoration. Therefore, there are mainly three formulations utilizing the sparseness of the wavelet frame coeﬃcients, namely <strong>analysis based approach, synthesis based approach,</strong> and balanced approach. Detailed and integrated descriptions of the three approaches can be found in [34].</p><p>[34] 一本书 B. Dong and Z. Shen, “MRA Based Wavelet Frames and Applications,” IAS Lecture Notes Series, Summer Program on “The Mathematics of Image Processing”, Park City Mathematics Institute, 2010</p><p>The analysis based approach was ﬁrst proposed in [84, 170].</p><p>[84] M. Elad, J.L. Starck, P. Querre, and D.L. Donoho, Simultaneous cartoon and texture image inpainting using morphological component analysis (MCA), Applied and Computational Harmonic Analysis 19 (2005), no. 3, 340–358.</p><p>[170] J.L. Starck, M. Elad, and D.L. Donoho, Image decomposition via the combination of sparse representations and a variational approach, IEEE transactions on image processing 14 (2005), no. 10, 1570–1582. 讲述了一种结合变分和转换与</p></blockquote></li></ul><h1 id="去噪综述"><a href="#去噪综述" class="headerlink" title="去噪综述"></a>去噪综述</h1><ul><li><p>参考文献：</p><ul><li>Survey of Image Denoising Techniques </li><li>小波域图像降噪概述</li><li>B. Dong and Z. Shen, “MRA Based Wavelet Frames and Applications,” IAS Lecture Notes Series, Summer Program on “The Mathematics of Image Processing”, Park City Mathematics Institute, 2010</li><li><a href="http://ir.gxun.edu.cn/online-view/530500/4587/1/%E5%9F%BA%E4%BA%8E%E5%B0%8F%E6%B3%A2%E7%9A%84%E4%BF%A1%E5%8F%B7%E5%8E%BB%E5%99%AA%E5%88%86%E6%9E%90.pdf" target="_blank" rel="noopener">模极大，域值，平移不变</a></li><li><a href="http://wenhuix.github.io/research/denoise.html" target="_blank" rel="noopener">NLM，BM3D去噪原理</a></li><li><a href="http://read.pudn.com/downloads70/ebook/254108/ch5.pdf" target="_blank" rel="noopener">维纳滤波器的时域解</a></li><li><a href><u>维纳滤波的频域解(尚未找到)</u></a></li><li><a href="https://blog.csdn.net/ytang_/article/details/75451934" target="_blank" rel="noopener">低通滤波</a></li><li><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY/2019-06-13-144621.png" alt="image-20190611162242926"></li><li><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY/2019-06-13-144627.png" alt="image-20190611162329876"></p></li><li><p><a href="https://wenku.baidu.com/view/73dae422ccbff121dd368387.html" target="_blank" rel="noopener">小波变换去噪基础知识整理</a></p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/2019-06-16-111151.png" alt></p></li></ul></li><li><p>综述</p><p>根据不同去噪方法的实现原理，我们将去噪方法大致分为以下五类：传统滤波法，基于稀疏表达约束法，基于图像自相似的方法，变分法，基于马尔可夫模型的法，以及目前的深度学习方法。每一类方法都可以在空间域以及转化域来实现。</p></li></ul><ol><li><p>传统滤波法包括均值滤波，中值滤波 [3] ，卡尔曼滤波 [4] ，维纳滤波[5]等。 </p><ul><li><p>均值滤波(Mean)是一种最简单的滤波器，其利用邻域内像素的平均值作为替换值来消除图像的孤立点噪声。通常伴有过模糊的问题。另一种均值滤波通过，通过对样本多次观察取平均来降噪。</p></li><li><p>维纳滤波(Weiner)是由Weinar在二十世纪四十年代提出来，通过最小均方差寻找准则，从噪声图像中提取最佳线性滤波的方法，因此也叫最小均方滤波/最佳线性滤波器。</p><script type="math/tex; mode=display">\begin{array}{c}{y(n)=\hat{s}(n)=\sum_{m=0}^{+\infty} h(m) x(n-m)} \\ \min_{x}{E\left[e^{2}(n)\right]=E\left[\left(s(n)-\sum_{m=0}^{+\infty} h(m) x(n-m)\right)^{2}\right]}\end{array}</script><p>其中h(m)是无污染信号，x(n)是线性滤波。</p><blockquote><p>Wiener, Norbert (1949), <em>Extrapolation, Interpolation, and Smoothing of Stationary Time Series</em>. New York: Wiley.</p></blockquote><p>比均值滤波的效果好，在高斯噪声中的效果最好，计算量大。也不能用于噪声为非平稳的随机过程</p></li></ul></li></ol><ul><li><p>中值滤波器(Median)是一种非线性滤波，最早由Tukey和 Pratt在1974和1978年提出 [1] [2]，并被广泛用于去噪问题[3]。这个方法，用领域内像素的中值作为像素值。最显著的优点是在临近像素显著不同区域内，让像素的灰度值与其邻近像素更加接近。缺点，在纹理复杂的图像中依然有模糊的问题。在点线尖的纹理较多的地方表现不好。</p><blockquote><p>The one-dimensional median filter was devised by Tukey [1]. Some discussion of it, and an extension to two dimensions, is given by Pratt [2]. </p><p>[1] Tukey. J.W. Exploratory Data Analysis. Addison-Wesley, Reading, Mass., 1974.</p><p>[2] William K. Pratt, Digital image processing, John Wiley &amp; Sons, Inc., New York, NY, 1978</p><p>[3] Brownrigg D R K, “The Weighted Median Filter,” Communications of the Acm,1984, 27(8):807-818. </p></blockquote></li><li><p>其他的滤波还有在转化域的低通滤波法，通过去掉傅立叶变换后中的高频成分，逆转化后得到复原图像。</p><blockquote><p>Adel Sedra &amp; Peter Brackett， Filter Theory and Design, Active and Passive,Matrix Publisher, Oregon 1978</p></blockquote></li></ul><ol><li><p>小波域去噪见小波域去噪综述</p></li><li><p>变分法是另外一大类重要的分支。它将病体问题转化成一个最小化方程问题。目标方程由一个包真项和正则项组成，保真项是 ，正则项，去噪的结果就是通过优化算法获得的方程解。在不同的正则项中，全变分最受欢迎。</p><ul><li>空间域：全变分</li><li>基于小波框架的变分模型(是不是都属于wavelet frame)</li></ul></li><li><p>NLM是第一个基于相似块的较为现代的方法。是在2005年由Baudes首先提出用来去噪的方法[1]。他通过搜寻与目标像素具有相似块的相似点作为参考值，对这些选择的像素点均值，权重由相似度决定，对目标像素进行去噪。与传统的滤波法不同，该方法利用了整幅图像的冗余性，比较好地去掉图像中存在的高斯噪声。</p><blockquote><p>[1] Buades, A., Coll, B., &amp; Morel, J. M. (2005, June). <strong>A non-local algorithm for image denoising.</strong> In <em>2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05)</em> (Vol. 2, pp. 60-65). IEEE.（BM3D）</p><p>[2] Dabov, K., Foi, A., Katkovnik, V., &amp; Egiazarian, K. (2007). <strong>Image denoising by sparse 3-D transform-domain collaborative filtering.</strong> Image Processing, IEEE Transactions on 16 (8), pp. 2080-2095.</p><p><a href="https://link.springer.com/content/pdf/10.1186%2Fs13640-017-0203-4.pdf" target="_blank" rel="noopener">patch-based methods</a></p></blockquote></li></ol><p>为了完备性，其他去噪方法还有基于马尔可夫模型的等。现在的方法大多是将这几类方法进行结合使用，来获得更好的效果。例如，最先进的BM3D主要就是NLM，小波滤波和维尼滤波的组合。整个过程有两步组成，第一个流程首先通过NLM相似块分组，第对每一个相似块组进行小波硬阈值处理后逆转换回图像块，将这些块进行加权后融合到原来的位置，得到初步去噪结果。第二个流程对噪声图和初步去噪结果分别进行相思的分组, <u>从离散余弦变换后的噪声块中提取维纳滤波系数对初步去噪块进行滤波处理后</u>，逆转化后融合成最后的去噪结果。</p><blockquote><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY/2019-06-13-144643.png" alt="image-20190613205402009"></p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY/2019-06-13-144650.png" alt="image-20190613205333996"></p></blockquote><ul><li><p>补充</p><ul><li><p>基于稀疏表达（sparsity approximation）的去噪方法<a href="https://wenku.baidu.com/view/ed8fc817c5da50e2524d7fe6.html" target="_blank" rel="noopener">https://wenku.baidu.com/view/ed8fc817c5da50e2524d7fe6.html</a></p><ul><li><p>基于全局图像稀疏去噪</p></li><li><p>基于稀疏字典的图像去噪方法</p></li><li><p>见小波域的去噪综述</p></li><li><p>MGA 去噪方法中的稀疏性应用</p></li><li><p>ICA 去噪方法中的稀疏性应用</p><blockquote><p>2010 年， Anjali 等人对 ICA 技术去噪进行了综述，指出 Fourier 方法局限于频率，小波变换虽能同时在空间域与频率 域，但都不具有数据的自适应性； 而 ICA 方法能从高阶去分析 多方向数据内在的适应性，噪声被认为是高斯随机变量，而图 ［61］ 像数据则是非高斯随机变量</p></blockquote></li></ul></li><li><p>马尔可夫模型</p></li><li><p>MRA，Wavelet frame, MRA-based wavelet frame，<strong>MRA-based tight wavelet frame</strong>(generalization) 的发展过程</p><blockquote><p>小波分析已用于多个领域，如信号处理，图像分析等方面，而框架理论是小波分析的一个重要工具。框架理论最初是由 Duffin 和 Schaffcf 在 1952 年研究非调和 Fourier 级数时提出来的，在最开始提出的时 候，框架并没有广泛地引起其他学者的研究兴趣。直到 1986 年，Daubechies、Grossmann 和 Meyer 对框架理论有了突破性的研究，至此框架理论才开始吸引了大批学者的关注。近些年来，在框架理论的研究 过程中，用到了算子理论以及 Banach 空间理论。直到 D. R. I. Arson、Deguang Han 和 Xingde Dai 等人把 算子代数理论运用到框架的研究中，框架理论研究才更上了一个层次，并从整体上把握和研究了框架和 基的性质 。至此，结合了算子理论的框架理论快速发展，其性质以及应用得到更加广泛地研究与推广。</p></blockquote><p><strong>Tight frame,</strong>1952, Duffin</p><blockquote><p>[80] R.J. Duﬃn and A.C. Schaeﬀer, A class of nonharmonic Fourier series, Transactions of the American Mathematical Society 72 (1952), no. 2, 341–366.</p></blockquote><p><strong>Wavelet frames</strong> (without a multiresolution structure) (see e.g. [61, 132]),</p><p>[61]Ten lectures on wavelets, vol. CBMS-NSF Lecture Notes, SIAM, nr. 61, Society for Industrial Mathematics, 1992.</p><p>[132] A wavelet tour of signal processing, vol. 2nd ed. New York: Academic, Academic press, 1999</p><p>and Applications:</p><p><strong>eg. Tight wavelet frames derived from over sampled orthonormal wavelet basis</strong> are already used in noise removal by [57, 77].</p><p>[57] R.R. Coifman and D.L. Donoho, Translation-invariant de-noising, Lecture Notes in Statistics-New York-Springer Verlag (1995), 125–125.</p><p>[77]  De-noising by soft-thresholding, IEEE transactions on information theory 41 (1995), no. 3, 613–627. De-Noising using the traditional orthogonal wavelet transform.</p><p><strong>MRA</strong>这个概念由Mallat在1989提出。最常用來分析<a href="https://zh.wikipedia.org/wiki/%E7%A6%BB%E6%95%A3%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2" target="_blank" rel="noopener">離散小波變換</a>〈DWT〉或是驗證<a href="https://zh.wikipedia.org/wiki/%E5%BF%AB%E9%80%9F%E5%B0%8F%E6%B3%A2%E8%BD%89%E6%8F%9B" target="_blank" rel="noopener">快速小波轉換</a>〈FWT〉理論的方法</p><blockquote><p>[131] S.G. Mallat, Multiresolution approximations and wavelet orthonormal bases of L 2 (R), Transactions of the American Mathematical Society 315 (1989), no. 1, 69–87.</p></blockquote><p><strong>MRA-based</strong> compactly supported <strong>orthonormal wavelet</strong> systems, Daubechies [60].</p><p>MRA-based compactly supported orthonormal wavelets of [60].</p><blockquote><p>[60] Daubechies, Orthonormal bases of compactly supported wavelets, Commun. Pure Appl. Math. 41 (1988), no. 7, 909–996.</p></blockquote><p><strong>MRA-based tight wavelet frames</strong>.(a generalization)  , 所以也有不是MRA-based</p><blockquote><p>[158] Aﬃne Systems in L 2 (R d ): The Analysis of the Analysis Operator, Journal of Functional Analysis 148 (1997), no. 2, 408–447.</p></blockquote></li><li><p>MRA-based wavelet 论文中在第五章介绍了不同应用中的具体模型</p><blockquote><ul><li><p>We discuss the model proposed in [18] on blind deblurring (motion deblurring to be speciﬁc) problems.</p></li><li><p>we present a frame based image segmentation model with a fast algorithm for the general image segmentation problems of [71].</p></li><li><p>we discuss the model proposed by [112] on reconstruction of scenes (visible surfaces) from scattered, noisy and possibly sparse range data (point clouds).</p></li></ul></blockquote></li></ul></li></ul><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><ul><li><p>[ ] 在做wavelet domain denoising的综述中，从来没有提到变分模型；wavelet frame的综述中，从来没有提到过thresholding的方法。</p><blockquote><p>框架理论最初是由 Duffin 和 Schaffcf 在 1952 年研究非调和 Fourier 级数时提出来的，在最开始提出的时 候，框架并没有广泛地引起其他学者的研究兴趣。直到 1986 年，Daubechies、Grossmann 和 Meyer 对框 架理论有了突破性的研究，至此框架理论才开始吸引了大批学者的关注。近些年来，在框架理论的研究 过程中，用到了算子理论以及 Banach 空间理论。直到 D. R. I. Arson、Deguang Han 和 Xingde Dai 等人把 算子代数理论运用到框架的研究中，框架理论研究才更上了一个层次，并从整体上把握和研究了框架和 基的性质 。至此，结合了算子理论的框架理论快速发展，其性质以及应用得到更加广泛地研究与推广。</p></blockquote></li><li><p>[ ] 基于稀疏表示的小波去噪，是否有不基于稀疏的小波去噪，我感觉小波就是利用了稀疏 。那么稀疏除了小波域，还有没有其他方法</p></li><li><p>[ ] 傅立叶变化,余弦变化,小波变化同属于转化，都是在搞基。其中小波的特点是稀疏。</p><p>紧框架也是一种转化，特点是冗余基，系属性更好。框架理论：包括傅立叶变化，小波变化。</p><p>基于多解析度的紧框架：具有快速重构和分解的优点。</p></li><li><p>[ ] MRA，Wavelet frame, MRA-based wavelet frame，<strong>MRA-based tight wavelet frame</strong>(generalization) 的发展过程</p></li><li><p>[ ] 图像有哪些wavelet transformation有哪些，tight frame有哪些，怎么样算属于MRA(Multi-resolution Analysis)</p></li><li><p>[ ] 如何选择这些不同的变换</p></li><li><p>[ ] (2D)<a href="https://ww2.mathworks.cn/matlabcentral/fileexchange/32086-dt-cwt-based-image-fusion" target="_blank" rel="noopener">DT-CWT</a>是什么、(1D)<a href="https://ww2.mathworks.cn/help/wavelet/examples/dual-tree-wavelet-transforms.html" target="_blank" rel="noopener">DT-WT</a> 这两个是什么，如何用matlab实现，应该是MRA-based tight frame的一种</p></li><li><p>[ ] 基于小波框架的变分模型哪篇论文中最先提出。参照MRA-Based Wavelet Frames and Applications的文献回顾即可</p></li></ul><script type="math/tex; mode=display">\left(\mathrm{P}_{1}\right) \quad \min _{x \in \mathbb{R}^{n}}\|x\|_{\ell_{1}} \quad \text { subject to } \quad y=\Phi x</script><ul><li><p>[x] 未选中什么是振铃现象，什么是Gibbs现象，图像中如何表现</p><p>两者形容的是同一种现象。振铃效应（Ringingeffect）是影响复原图像质量的众多因素之一，其典型表现是在图像灰度剧烈变化的邻域出现类吉布斯（Gibbs）分布</p><p>所谓“振铃”，就是指输出图像的灰度剧烈变化处产生的震荡，就好像钟被敲击后产生的空气震荡。如下图：</p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY/2019-06-14-082421.png" alt></p></li><li><p>[ ] CWT是什么：continuous wavelet transform </p></li><li><p>[ ] 图像有哪些wavelet transformation，去噪应该选择哪种转变（Haar是一种）</p></li><li><p>[ ] 是否所有小波域下的去噪方法都利用了稀疏性，所有小波转化都是为了得到稀疏性？</p></li></ul><h1 id="实验记录"><a href="#实验记录" class="headerlink" title="实验记录"></a>实验记录</h1><p>利用non-convex tight frame去噪记录</p><p>参考文献：Please cite as: A. Parekh and I. W. Selesnick. Convex Denoising Using Non-convex Tight Frame Regularization, IEEE Signal Processing Letters, 22(10): 1786-1790, Oct. 2015.</p><p>参考代码：<a href="https://github.com/aparek/cncTightFrame/blob/master/Documentation/demo2D.pdf" target="_blank" rel="noopener">https://github.com/aparek/cncTightFrame/blob/master/Documentation/demo2D.pdf</a></p><ul><li><p>结论1: tf在噪声50的情况下，不能必过TV，会有模糊的效果。</p><p>L1-tightframe 0.8/<strong>0.9</strong>/1.0</p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY/2019-06-13-144707.png" alt="image-20190601222251579"></p><p>nonconvex tightframe 1.0/<strong>1.1</strong>/1.2</p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY/2019-06-13-144710.png" alt="image-20190601222631705"></p></li><li><p>结论2: 在噪声低15的情况下</p><p>nonconvex的正则项可以超过TV</p></li><li><p>结论3: 在噪声35的情况下，复杂的图像很模糊，但是psnr依旧可以超过TV，</p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY/2019-06-13-144721.png" alt="image-20190601230055703"></p><p>PSNR_x =   25.9576   26.2444   26.1463   25.9175   25.6507   25.3786</p></li><li><p>换个W个会好些吗</p></li></ul><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul><li><p>小波、框架</p><ul><li><p><a href="http://orbit.dtu.dk/files/105634286/A_Short_Introduction_to_Frames.pdf" target="_blank" rel="noopener">A short introduction to frames, Gabor systems, and wavelet systems</a></p></li><li><p><a href="http://read.pudn.com/downloads151/ebook/654732/wavelettransform.pdf" target="_blank" rel="noopener">一个较好理解小波的ppt</a></p></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> denoising </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>健身清单</title>
      <link href="/p/4221.html"/>
      <url>/p/4221.html</url>
      
        <content type="html"><![CDATA[<p>健身list</p><p><a href="https://www.xiaohongshu.com/discovery/item/5cdd3a04000000000e02605a?xhsshare=CopyLink&amp;appuid=5ba5191e27890d0001c36c80&amp;apptime=1559482297" target="_blank" rel="noopener">臀部</a></p><p><a href="https://www.xiaohongshu.com/discovery/item/5cdd87bf000000000f02c05a?xhsshare=CopyLink&amp;appuid=5ba5191e27890d0001c36c80&amp;apptime=1559482722" target="_blank" rel="noopener">天鹅颈</a></p><p><a href="https://www.xiaohongshu.com/discovery/item/5c4bf705000000000f0229a5?xhsshare=CopyLink&amp;appuid=5ba5191e27890d0001c36c80&amp;apptime=1559483042" target="_blank" rel="noopener">双下巴</a></p><p><a href="https://www.zhihu.com/question/26547178" target="_blank" rel="noopener">脖子</a></p>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>电影清单</title>
      <link href="/p/ab3e.html"/>
      <url>/p/ab3e.html</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/mrxXquJT1mwieTUT4trB9A" target="_blank" rel="noopener">32部无论是色彩、构图还是场景都超棒的好电影</a></p>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 电影 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>菜谱Collection</title>
      <link href="/p/c077.html"/>
      <url>/p/c077.html</url>
      
        <content type="html"><![CDATA[<h1 id="简单食材菜谱"><a href="#简单食材菜谱" class="headerlink" title="简单食材菜谱"></a>简单食材菜谱</h1><ul><li><p>鸡蛋</p><ul><li><p>不同鸡蛋的特色<img src="https://cdn.hk01.com/di/media/images/686814/org/238d98257393d59af1413b84f536fa6a.png/kDUY4Mtzt76-THlB42SyMlSr2h79P7RJfNaPa3zWj2s?v=w1920" alt="img"></p></li><li><p><a href="https://www.dimcook.com/recipe/1644f56975/%E9%A6%99%E7%85%8E%E8%8A%99%E8%93%89%E8%9B%8B%E9%A3%AF" target="_blank" rel="noopener">芙蓉蛋炒饭</a></p></li><li><p>蒸蛋：以蛋水比例1:1.5，混合拂勻。用隔篩把蛋液注入碟內，再以小匙勺掉小氣泡。用錫紙蓋着。以中火隔水蒸5分鐘即成，加麻油、豉油同吃。<img src="https://cdn.hk01.com/di/media/images/1108019/org/f94ba97a89475014571787d5c8e9e216.jpg/WRYTNZ4tWDxsertjJSJXrwsvUt2s5aiOQ5EOXUORDl0?v=w1920" alt="ç¨å¾®æ³¢çåæ¨£è¸åºæ&quot;æºæ°´èãï¼è³æåçï¼"></p></li><li><p>温泉蛋/水波蛋的做法</p></li></ul></li><li><p>牛肉</p><ul><li><a href="http://www.etnet.com.hk/www/tc/lifestyle/foodiemap/homecooking/21007" target="_blank" rel="noopener">牛柳</a></li><li><a href="https://www.youtube.com/watch?v=SNg413EeLuc" target="_blank" rel="noopener">金针菇肥牛卷</a><ul><li><a href>番茄肥牛汤</a></li><li>日式肥牛</li><li><a href="https://www.youtube.com/watch?v=xe8hsJlCFDM" target="_blank" rel="noopener">7分鐘搞懂牛排部位！</a></li></ul></li></ul></li><li><p>带子</p><ul><li><a href="https://www.xinshipu.com/s/bcb1b6b3b4f8d7d3cab3c6d7/" target="_blank" rel="noopener">急冻带子菜谱</a></li></ul><p>豆腐带子：带子热水泡20分钟，煎带子，放豆瓣酱，放豆腐，放水煮2-3分钟，收汁。</p><ul><li><p>香煎带子：放油煎子，翻两次面即可，锁住肉里的汁。差不多煎熟的时候，放蒜蓉，为了有蒜香的同时不煎糊蒜蓉。</p></li><li><p><a href="https://www.youtube.com/watch?v=3L-H6ECFHHA" target="_blank" rel="noopener">莴笋带子</a></p></li></ul></li><li><p>鸡肉</p><ul><li><a href="https://www.youtube.com/watch?v=PQna_Xg6p-E&amp;list=PLyxXpXaJcYteiIOqJEHo4V3Zw3JQO30Le&amp;index=12&amp;t=0s" target="_blank" rel="noopener">葱烧鸡</a></li></ul></li><li><p>虾</p><ul><li><a href="https://www.youtube.com/results?search_query=%E5%86%B7%E5%86%BB%E5%A4%A7%E8%99%BE" target="_blank" rel="noopener">煮冷冻虾</a></li><li><a href="https://www.youtube.com/watch?v=Z6tUuSlUUV4" target="_blank" rel="noopener">西班牙蒜虾</a></li></ul><p>冻冻虾除腥：咖哩粉，淀粉，挑的时候要挑急速冷冻的</p></li></ul><h1 id="快手菜"><a href="#快手菜" class="headerlink" title="快手菜"></a>快手菜</h1><ul><li>麻婆豆腐</li><li>醋溜金针菇</li><li>意大利醋凉拌西红柿</li><li>皮蛋豆腐</li><li>水煮/蒜蓉西兰花</li><li><a href="https://mp.weixin.qq.com/s/5iw2n639Hbm5w4L-5-T3Ow" target="_blank" rel="noopener">番茄炒鸡蛋、菠萝咕噜肉、茄子鱼</a></li><li><a href="https://www.youtube.com/watch?v=wjagD6AOhEg" target="_blank" rel="noopener">辛拉面的做法</a></li><li><p><a href="https://www.youtube.com/watch?v=vqYHx1ggEkQ" target="_blank" rel="noopener">乌冬的做法</a></p></li><li><p><a href="https://www.youtube.com/watch?v=0sr4GXwXhZ4" target="_blank" rel="noopener">纳豆拌饭</a></p></li><li><p><a href="https://www.youtube.com/watch?v=UKQu7uJUEx4" target="_blank" rel="noopener">油淋茄子</a></p></li></ul><h1 id="早餐"><a href="#早餐" class="headerlink" title="早餐"></a>早餐</h1><ul><li><p>手抓饼</p></li><li><p><a href="http://huamei.haiwainet.cn/n/2016/0608/c3540917-29991098.html" target="_blank" rel="noopener">牛油果温泉蛋吐司</a></p><p><img src="http://images.haiwainet.cn/20160608/1465351114619683.jpg" alt="7.jpg"></p></li><li><p>葱油面</p></li></ul><h1 id="Foodie-Travel"><a href="#Foodie-Travel" class="headerlink" title="Foodie Travel"></a>Foodie Travel</h1><p><a href="https://mp.weixin.qq.com/s/MIQdlM2L37BUcMcj3U6SDg" target="_blank" rel="noopener">艾格吃饱了：上海馆子</a></p><p><a href="https://mp.weixin.qq.com/s/LKaPA-d8pugpZx-a7wsDOw" target="_blank" rel="noopener">艾格吃饱了：杭州馆子</a></p><h1 id="西安"><a href="#西安" class="headerlink" title="西安"></a>西安</h1><p>小六汤包</p>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>美妆笔记</title>
      <link href="/p/13be.html"/>
      <url>/p/13be.html</url>
      
        <content type="html"><![CDATA[<h1 id="刷头"><a href="#刷头" class="headerlink" title="刷头"></a>刷头</h1><ul><li><p>基础刷头</p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY/006tNc79gy1g3m245i05zj30jk0f4wgd.png" alt="image-20190601142831871"></p></li><li><p>眼影刷包括：大号打底铺色(偏硬, 比较宽)，晕染(偏软一点)，眼线刷(偏硬)。</p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY/006tNc79gy1g3m2474idvj30ew03u3yo.png" alt="image-20190601144023935"></p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY/006tNc79gy1g3m246719nj30gk03wjrl.png" alt="image-20190601144003757"></p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY/006tNc79gy1g3m246pcmwj30gm038aa7.png" alt="image-20190601144311547"></p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY/006tNc79gy1g3m245pu09j30f803uaa8.png" alt="image-20190601144330157"></p></li></ul><h1 id="眼妆"><a href="#眼妆" class="headerlink" title="眼妆"></a>眼妆</h1><ul><li><p>眼妆的步骤</p><p>眼影-眼线-假睫毛-夹睫毛-睫毛液</p><p>防晒-隔离(修正肤色、保湿等不同作用)-遮瑕-粉底液-眼妆-鼻影-修容-定妆</p><p>(眉毛在哪一步)</p></li><li><p>眼线的画法</p></li><li><p>假睫毛的粘贴</p></li><li><p>睫毛夹</p></li><li><p>遮泪沟</p><p>工具，innisfree遮瑕刷，橘色套装也包含</p><p><a href="https://www.bilibili.com/video/av13428348/?spm_id_from=333.788.videocard.4" target="_blank" rel="noopener"> 一支遮瑕膏层层叠加法</a></p><p><a href="https://www.bilibili.com/video/av26229143/?spm_id_from=333.788.videocard.2" target="_blank" rel="noopener">歌剧魅影6色遮瑕，橘色刷子</a></p><p><a href="https://www.bilibili.com/video/av23902865/?spm_id_from=333.788.videocard.2" target="_blank" rel="noopener">遮瑕评测</a></p></li></ul><h1 id="发色"><a href="#发色" class="headerlink" title="发色"></a>发色</h1><p><a href="http://www.faxingw.cn/faxingwsheji/fxsj/201901/98207_1_detail.html" target="_blank" rel="noopener">2019流行“不饱和发色”</a></p><p><a href="https://www.goody25.com/mind7661028" target="_blank" rel="noopener">2019年最夯最显白的TOP10发色！</a></p><p><img src="/Users/yyf/Library/Application%20Support/typora-user-images/image-20190619180753117.png" alt="image-20190619180753117"></p><h1 id="面膜推荐"><a href="#面膜推荐" class="headerlink" title="面膜推荐"></a>面膜推荐</h1><p>CNP黄色和蓝色</p><h1 id="墨镜选择"><a href="#墨镜选择" class="headerlink" title="墨镜选择"></a>墨镜选择</h1><p><a href="https://zhuanlan.zhihu.com/p/26573606" target="_blank" rel="noopener">不同脸型选择墨镜</a></p>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>理财知识</title>
      <link href="/p/e897.html"/>
      <url>/p/e897.html</url>
      
        <content type="html"><![CDATA[<h1 id="信用卡"><a href="#信用卡" class="headerlink" title="信用卡"></a>信用卡</h1><ul><li><p>信用卡周期</p><p><img src="http://www.uscreditcards101.com/wp-content/uploads/2015/10/201510241825209.bmp" alt="img"></p></li><li><p>statement balance是上个周期的欠款</p></li><li><p>account balance是目前总欠款 = 上个周期的欠款+上个周期-到当日的欠款</p></li><li><p>我的还款方式。月尾付account balance</p></li><li><p>付完之后account balance何时更新。假设6.3号付了account balance，6.3号之前信用卡还有一笔支出，还未显示在account balance中。都是按照出帐日期算的。</p></li><li><p>current balance是按照出帐日期算的，并不是按照消费当天的日期算的。如果消费当日在上一个周期，而出帐日是在下个周期，则属于下个周期。一般出帐时间需要两天。</p></li></ul><h1 id="保险知识"><a href="#保险知识" class="headerlink" title="保险知识"></a>保险知识</h1><ul><li><p>some links</p><p><a href="https://mp.weixin.qq.com/s/pvyhh7wwGUn-9Kokn4f27Q" target="_blank" rel="noopener">对保险的初步认识</a></p></li><li><p>医疗险0免赔额比1w免赔额好吗</p></li><li><p><a href="https://www.zhihu.com/question/49854906" target="_blank" rel="noopener">社保和其他保险</a></p></li><li><p>香港保险和内地保险</p><p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1g46hoeob31j30rs1g2e81.jpg" alt="image-20190619151842988"></p></li></ul><h1 id="我们家的保险"><a href="#我们家的保险" class="headerlink" title="我们家的保险"></a>我们家的保险</h1><ul><li><p>老爸的保险</p><ol><li><p>公司的社会养老保险：五险一金</p></li><li><p>新华保险：寿险（ 交完了）</p></li></ol><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190616124252625.png" alt="image-20190616124252625"></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190616125033031.png" alt="image-20190616125033031"></p></li><li><p>老妈的保险</p><p>生日：</p><p>社会养老保险：包括养老保险+医疗保险</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190616123942874.png" alt="image-20190616123942874"></p></li><li><p>我</p><p>我的中国平安的人身保险</p><p><img src="/Users/yyf/Library/Mobile Documents/com~apple~Preview/Documents/551560660438_.pic_hd copy.jpg" alt="551560660438_.pic_hd copy"></p></li><li><p>我妈考虑想买的</p><p><a href="https://zhuanlan.zhihu.com/p/38510343" target="_blank" rel="noopener">新华康健华贵B：这款百万医疗很平常</a></p><p><a href="http://www.doctorzz.cn/news/916677340280637.shtml" target="_blank" rel="noopener">新华康健华贵B保障范围和投保须知(案例)</a></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190616125154325.png" alt="image-20190616125154325"></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>少女私房照</title>
      <link href="/p/7d48.html"/>
      <url>/p/7d48.html</url>
      
        <content type="html"><![CDATA[<h1 id="拍摄主题"><a href="#拍摄主题" class="headerlink" title="拍摄主题"></a>拍摄主题</h1><p>港风阴天</p><p>香港雨天：文礼阁的雨，地上的水圈</p><p>寝室仙女的私房照One year ending</p><h1 id="Project-1-留学少女私房照"><a href="#Project-1-留学少女私房照" class="headerlink" title="Project 1: 留学少女私房照"></a>Project 1: 留学少女私房照</h1><ul><li><p>简介</p><p>港风留学少女相（私房照），体现和屋子的这个互动，作为我们这一年生活来的记录和留念，体现港风生活。</p></li><li><p>要求</p><p>力求拍出性感不色情的感觉。并且包含生活中最典型的场景。有港风味。不做作</p></li><li><p>场景设计</p><p>菲：做牛排（厨房），寝室准头搞怪那一下（看剧少女）</p><p>圈：晾衣服，回家的时候</p><p>玥：床上起身或梳妆台前。</p><p>大王：厨房，蒜蓉，和她的泡面锅。（拍摄的时候要注意，不要显得生活太过心酸和贫瘠，要有高大上的部分，如维尼饼干）</p></li><li><p>Idea</p><p>一张生活照，一张出门前的照，形成对比。内容比较有趣。</p><p>前一秒晾衣的邋遢女孩，出门的精致女孩，身份切换。</p></li></ul><h1 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h1><p>（1）找摄影师作品，看别人拍摄的作品，找到与自己符合或者相近的照片。前期可以用来模仿。</p><p>（2）了解私房照以及港风照的拍摄技巧，需要与后期调色符合。</p><p>（3）解决屋子里光线不足的情况</p><p>（4）设计方案：场景、服饰、妆容</p><p>（5）约拍</p><h1 id="作品"><a href="#作品" class="headerlink" title="作品"></a>作品</h1><p><a href="https://mp.weixin.qq.com/s/EvDUC3VvNr-zMXybyaoasA" target="_blank" rel="noopener">日系生活照</a></p><p><a href="https://mp.weixin.qq.com/s/PBdtxnoWacFBG40MN93iyQ" target="_blank" rel="noopener">最美私房照</a></p><p><a href="https://mp.weixin.qq.com/s/97eJ30hQ7C2ADR2WBJ_JYA" target="_blank" rel="noopener">人物和情绪</a></p><h1 id="拍摄"><a href="#拍摄" class="headerlink" title="拍摄"></a>拍摄</h1><h1 id="调色"><a href="#调色" class="headerlink" title="调色"></a>调色</h1><p><a href="https://mp.weixin.qq.com/s/e5lL1hzyc8I8jOcTVlqOBQ" target="_blank" rel="noopener">vsco操作攻略</a></p><p><a href="https://zhuanlan.zhihu.com/p/3062355" target="_blank" rel="noopener">vsco调色拍摄学习</a></p><p><a href="https://mp.weixin.qq.com/s/Tx0ucS-A3zyBvHKga5M8rg" target="_blank" rel="noopener">vsco滤镜推荐</a></p><h1 id="摄影书籍"><a href="#摄影书籍" class="headerlink" title="摄影书籍"></a>摄影书籍</h1><p><a href="https://mp.weixin.qq.com/s/wxEyxZtioGp0IxY9uRSdOQ" target="_blank" rel="noopener">10 本好看又实用的摄影书</a></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190606141525105.png" alt="image-20190606141525105"></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190606141530303.png" alt="image-20190606141530303"></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190606141606340.png" alt="image-20190606141606340"></p>]]></content>
      
      
      <categories>
          
          <category> 摄影 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>数学基础知识</title>
      <link href="/p/ccc1.html"/>
      <url>/p/ccc1.html</url>
      
        <content type="html"><![CDATA[<h1 id="正则"><a href="#正则" class="headerlink" title="正则"></a>正则</h1><ul><li>Tikhonov正则</li></ul><p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/37f3753e1ac34f985393aa606a63bd77e72e0ad6" alt="{\displaystyle \|A\mathbf {x} -\mathbf {b} \|_{2}^{2}+\|\Gamma \mathbf {x} \|_{2}^{2}}"></p><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><ul><li>lower semicontinuous这个性质的作用在哪里。好像通常用在证明收敛性。</li><li>PCA是什么，有什么应用</li><li>不同的空间。把图像函数f定义在某个空间上是为了measure，为什么要measure，有哪些typical space</li><li>SVD去噪</li><li>欧拉方程：欧拉方程是泛函极值条件的微分表达式</li><li>tensor</li></ul><h1 id="Norm"><a href="#Norm" class="headerlink" title="Norm"></a>Norm</h1><p><a href="https://medium.com/@montjoile/l0-norm-l1-norm-l2-norm-l-infinity-norm-7a7d18a4f40c" target="_blank" rel="noopener">不同的norm</a></p><p>[semi-norm和norm]</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190625043131777.png" alt="image-20190625043131777"></p><h1 id="证明解的存在性"><a href="#证明解的存在性" class="headerlink" title="证明解的存在性"></a>证明解的存在性</h1><ul><li><p>一个函数在某个空间内有界的意思</p><p>$0&lt;c_{1} \leq u_{n} \leq c_{2}, \text{which implies that u n is bounded in} L^{1}(\Omega)$</p><p>$\left\{u_{n}\right\} \text { is bounded in } B V(\Omega)$</p></li><li><p>泛函， is bounded below, we can choose a minimizing sequence $\left\{u_{n} : n=1,2, \cdots\right\} \in \overline{S}(\Omega)$</p></li><li><p>序列的强收敛和弱收敛</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190725143410105.png" alt="image-20190725143410105"></p></li><li><p>Fatous’ lemma</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190725145706825.png" alt="image-20190725145706825"></p></li></ul><h1 id="各类函数空间"><a href="#各类函数空间" class="headerlink" title="各类函数空间"></a>各类函数空间</h1><h2 id="l-p-空间"><a href="#l-p-空间" class="headerlink" title="$l_p$空间"></a>$l_p$空间</h2><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190725171210467.png" alt="image-20190725171210467"></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190725171030761.png" alt="image-20190725171030761"></p><h2 id="W-1-1-Omega"><a href="#W-1-1-Omega" class="headerlink" title="$W^{1, 1}(\Omega)$"></a>$W^{1, 1}(\Omega)$</h2><p>usually defined as all functions $v \in L^{1}(\Omega)$, with weak derivatives of first order and these derivatives shall belong to $L^{1}(\Omega)$.</p><p>The space $W^{1, \infty}(\Omega)$ is usually defined as all functions $v \in L^{\infty}(\Omega)$with weak derivatives of first order<br>and these derivatives shall belong to $L^{\infty}(\Omega) .$</p><h2 id="BV空间"><a href="#BV空间" class="headerlink" title="BV空间"></a>BV空间</h2><p>The space $[\mathrm{BV}(\Omega)]^{m}$ with $|u|_{\mathrm{BV}(\Omega)} :=\int_{\Omega}|u| d x+|D u|(\Omega)$ is a Banach space.</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190726181150976.png" alt="image-20190726181150976"></p><h2 id="BH空间"><a href="#BH空间" class="headerlink" title="BH空间"></a>BH空间</h2><h1 id="证明收敛速度"><a href="#证明收敛速度" class="headerlink" title="证明收敛速度"></a>证明收敛速度</h1><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/2019-08-12-044904.png" alt="image-20190724181456673"></p><ul><li><p>converge sublinearly</p><p>$\lim _{k \rightarrow \infty} \frac{\left|x_{k+1}-L\right|}{\left|x_{k}-L\right|}=1$</p></li><li><p><em>converge linearly</em> </p><p>$\lim _{k \rightarrow \infty} \frac{\left|x_{k+1}-L\right|}{\left|x_{k}-L\right|}=\mu, \mu \in(0,1)$ </p></li><li><p><em>converge superlinearly</em> </p><p>$\lim _{k \rightarrow \infty} \frac{\left|x_{k+1}-L\right|}{\left|x_{k}-L\right|}=0$</p></li><li><p><em>Q-linear convergence</em>: distinguish superlinear rates of convergence. </p><p>$\lim _{k \rightarrow \infty} \frac{\left|x_{k+1}-L\right|}{\left|x_{k}-L\right|^{q}}&lt;M$</p></li><li><p>Monotone operator</p></li></ul><h1 id="傅立叶变换"><a href="#傅立叶变换" class="headerlink" title="傅立叶变换"></a>傅立叶变换</h1><p><a href="https://blog.csdn.net/daduzimama/article/details/80394596" target="_blank" rel="noopener">傅立叶的平移不变性</a></p><h1 id="Sup-Inf-上确界和下确界"><a href="#Sup-Inf-上确界和下确界" class="headerlink" title="Sup/Inf 上确界和下确界"></a>Sup/Inf 上确界和下确界</h1><p>A lower bound <em>a</em> of <em>S</em> is called an <em>infimum</em> (or <em>greatest lower bound</em>, or <em>meet</em>) of <em>S</em> if</p><h1 id="lim-sup-lim-inf-上极限和下极限"><a href="#lim-sup-lim-inf-上极限和下极限" class="headerlink" title="lim sup/lim inf 上极限和下极限"></a>lim sup/lim inf 上极限和下极限</h1><ul><li><p>定义</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190819114518366.png" alt="image-20190819114518366"></p></li><li><p>例子</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190819114532956.png" alt="image-20190819114532956"></p></li><li><p>lim inf</p></li></ul><h1 id="Semi-continuous"><a href="#Semi-continuous" class="headerlink" title="Semi-continuous"></a>Semi-continuous</h1><ul><li><p>Upper continuous</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190819115355401.png" alt="image-20190819115355401"></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190819120747816.png" alt="image-20190819120747816"></p><p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c162e36dc4e659870ca5da160550ad211f7d0fdb" alt="\limsup _{x\to a}f(x)=\lim _{\varepsilon \to 0}(\sup\{f(x):x\in E\cap B(a;\varepsilon )\setminus \{a\}\})"></p></li><li><p>Lower continuous</p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190819115500045.png" alt="image-20190819115500045"></p><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190819120723940.png" alt="image-20190819120723940"></p><p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/31c4d641e50ec391188344d30b67688c84586237" alt="\liminf _{x\to a}f(x)=\sup _{\varepsilon &gt;0}(\inf\{f(x):x\in E\cap B(a;\varepsilon )\setminus \{a\}\})."></p></li></ul><h1 id="Minimizing-sequence"><a href="#Minimizing-sequence" class="headerlink" title="Minimizing sequence"></a>Minimizing sequence</h1><p><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190819154433741.png" alt="image-20190819154433741"></p>]]></content>
      
      
      <categories>
          
          <category> 数学 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>python语法学习</title>
      <link href="/p/e35e.html"/>
      <url>/p/e35e.html</url>
      
        <content type="html"><![CDATA[<h1 id="执行参数"><a href="#执行参数" class="headerlink" title="执行参数"></a>执行参数</h1><ul><li><p>store_true </p><p>是指带触发action时为真，不触发则为假，2L说的代码去掉default初始化，其功能也不会变化</p><p>parser.add_argument(‘-c’, action=’store_true’)</p><p>#python <a href="https://link.zhihu.com/?target=http%3A//test.py/" target="_blank" rel="noopener">test.py</a> -c         =&gt; c是true（触发）</p><p>#python <a href="https://link.zhihu.com/?target=http%3A//test.py/" target="_blank" rel="noopener">test.py </a>            =&gt; c是false（无触发）</p><p>链接：<a href="https://www.zhihu.com/question/56692630/answer/358222352" target="_blank" rel="noopener">https://www.zhihu.com/question/56692630/answer/358222352</a></p></li></ul><h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><h2 id="类的定义"><a href="#类的定义" class="headerlink" title="类的定义"></a>类的定义</h2><p><a href="https://blog.csdn.net/dcrmg/article/details/75041125" target="_blank" rel="noopener">类的定义</a></p><h2 id="下划线的含义"><a href="#下划线的含义" class="headerlink" title="下划线的含义"></a>下划线的含义</h2><ul><li><p>变量</p><ul><li>前带_的变量:  标明是一个私有变量, 只用于标明, 外部类还是可以访问到这个变量 _</li><li>_ 前带两个_ ,后带两个_ 的变量:  标明是内置变量,</li><li>大写加下划线的变量:  标明是 不会发生改变的全局变量</li></ul></li><li><p>函数:</p><ul><li>前带_的变量: 标明是一个私有函数, 只用于标明,_</li><li>_  前带两个_ ,后带两个_ 的函数:  标明是特殊函数</li></ul></li></ul><h2 id="参数的定义"><a href="#参数的定义" class="headerlink" title="参数的定义"></a>参数的定义</h2><p>Positional argument v.s. keyword argument </p><p>In other words, keyword arguments are only “optional” because they will be set to their default value if not specifically supplied. </p><p><a href="https://docs.python.org/2/library/argparse.html" target="_blank" rel="noopener">多参数的输入</a></p><h2 id="不同数据类型的size"><a href="#不同数据类型的size" class="headerlink" title="不同数据类型的size"></a>不同数据类型的size</h2><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY/006tNc79gy1g333jkjg64j313s0l6jug.jpg" alt="image-20190116150303644"></p><h2 id="list-列表"><a href="#list-列表" class="headerlink" title="list 列表"></a>list 列表</h2><p>创建列表：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">files = []</span><br><span class="line">files.append(os.path.splitext(i))</span><br></pre></td></tr></table></figure><p><a href="https://blog.csdn.net/Yeoman92/article/details/56289287" target="_blank" rel="noopener">理解Python中列表，元组，字典，集合的使用</a></p><p>列表的读取方式： files[1]</p><h2 id="numpy数组"><a href="#numpy数组" class="headerlink" title="numpy数组"></a>numpy数组</h2><p><a href="https://blog.csdn.net/Baoli1008/article/details/50531684" target="_blank" rel="noopener">Python Numpy 数组的初始化和基本操作</a></p><p><a href="https://blog.csdn.net/skyecs/article/details/79444841" target="_blank" rel="noopener">numpy设置输出精度</a></p><p><a href="https://blog.csdn.net/u011630575/article/details/78604226" target="_blank" rel="noopener">numpy 中的深浅复制</a> “等于赋值”相当于标签</p><p>1）当浅复制的值是不可变对象（数值，字符串，元组）时和“等于赋值”的情况一样，对象的id值与浅复制原来的值相同。</p><p>2）当浅复制的值是可变对象（列表和元组）时会产生一个“不是那么独立的对象”存在。有两种情况</p><h2 id="不同数据类型"><a href="#不同数据类型" class="headerlink" title="不同数据类型"></a>不同数据类型</h2><p>查看数据类型：type(object)</p><div class="table-container"><table><thead><tr><th>列表</th><th>可重复，类型可不同，可以遍历</th><th>extend (扩展) ：以列表增加</th><th>append (追加)：不同类型的数据</th><th>[‘a’, ‘b’, ‘c’, 1, 2, [1, 2]]</th></tr></thead><tbody><tr><td>元组</td><td>可重复，类型可不同；可以遍历</td><td>只读的，不能修改</td><td></td><td>tuple1 = (1,2,’a’,4,’5’,6)</td></tr><tr><td><u>numpy的数组</u></td><td>类型一样</td><td></td><td></td><td>b = np.array([6, 7, 8])</td></tr><tr><td>字典</td><td>键和值，可以不同类型，无序存储</td><td>可变；从字典中删除元素 del dict1[‘sex’]；清除所有元素dict1.clear()；<u>增加元素</u></td><td></td><td></td></tr><tr><td>集合</td><td>键，无序组合</td><td>可以增加删除元素set2.add(10)，set2.remove(6)，set2.discard(6)(可以删除空元素); 不同的集合支持union(联合), intersection(交), difference(差)和sysmmetric difference(对称差集)等数学运算；</td><td>不支持 索引, 分片, 或其它类序(sequence-like）</td><td>可将元祖和列表转化为集合set2 = set(list1)</td></tr></tbody></table></div><p>可变：列表、字典、集合（存在固定集合frozenset）</p><p>不可变：元组、int、 string、 float</p><blockquote><p> 当传过来的是可变类型(list,dict)时，我们在函数内部修改就会影响函数外部的变量。而传入的是不可变类型时在函数内部修改改变量并不会影响函数外部的变量，因为修改的时候会先复制一份再修改。</p></blockquote><h2 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h2><ul><li>获取文件内的文件名字</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">path = <span class="string">"d:\\data"</span>                           <span class="comment"># 设置路径</span></span><br><span class="line">dirs = os.listdir(path)                    <span class="comment"># 获取指定路径下的文件</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> dirs:                             <span class="comment"># 循环读取路径下的文件并筛选输出</span></span><br><span class="line">    <span class="keyword">if</span> os.path.splitext(i)[<span class="number">1</span>] == <span class="string">".csv"</span>:   <span class="comment"># 筛选csv文件</span></span><br><span class="line">        <span class="keyword">print</span> i</span><br></pre></td></tr></table></figure><ul><li>组成路径名字</li></ul><h1 id="库"><a href="#库" class="headerlink" title="库"></a>库</h1><h2 id="Import"><a href="#Import" class="headerlink" title="Import"></a>Import</h2><ul><li>模块和包：包是为了解决模块重命名的问题。</li></ul><p>模块：就是一些.py文件，可以包含函数、变量、类等符号； </p><p>包：由模块及子包组成 </p><p>在模块A中 from math import sqrt，那么sqrt函数会直接导入到当前的命名空间中来，并没有创建新的命名空间 。所以就可以在A直接使用sqrt()函数了。在某模块A中import math时，会在A中<strong>创建一个命名空间</strong>，并在这个命名空间中<strong>执行math.py当中的代码</strong>，并且在A中<strong>创建了math这个名称来引用这个命名空间。</strong></p><ul><li>单独导入包名(import package)不会导入包中所包含的所有子模块。<ul><li>包的init.py文件为空时，导入包名没法使用包内的子包及模块 </li><li>包的init.py并不为空 ，该文件可以初始化，导入一些常用的包**</li></ul></li></ul><h2 id="库的升级"><a href="#库的升级" class="headerlink" title="库的升级"></a>库的升级</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --upgrade requests  // mac,linux,unix 在命令前加 sudo -H</span><br></pre></td></tr></table></figure><h1 id="Python-迭代器与生成器"><a href="#Python-迭代器与生成器" class="headerlink" title="Python 迭代器与生成器"></a>Python 迭代器与生成器</h1><p><a href="https://www.cnblogs.com/wj-1314/p/8490822.html" target="_blank" rel="noopener">生成器和迭代器的关系</a>: 生成器是迭代器的一种</p><p>生成器通过一个函数创建列表，但是不一次性创建完毕，因而节省内存，并且表现得却像是迭代器。</p><p><strong>可迭代对象</strong>（可以用在 for 语句进行循环的对象）</p><p>1.数据类型（列表、元组、字符串、字典等）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span><span class="keyword">for</span> i <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]:</span><br><span class="line">    print(i)</span><br><span class="line"><span class="number">2.</span>obj = &#123;<span class="string">"a"</span>: <span class="number">123</span>, <span class="string">"b"</span>: <span class="number">456</span>&#125;</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> obj:</span><br><span class="line">    print(k)</span><br></pre></td></tr></table></figure><p>2.自己创建的迭代器</p><p>迭代器的创建方法:</p><ul><li><p>为容器对象添加 <strong>iter</strong>() 和 <strong>next</strong>() 方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Container</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, start = <span class="number">0</span>, end = <span class="number">0</span>)</span>:</span></span><br><span class="line">        self.start = start</span><br><span class="line">        self.end = end</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"[LOG] I made this iterator!"</span>)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__next__</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"[LOG] Calling __next__ method!"</span>)</span><br><span class="line">        <span class="keyword">if</span> self.start &lt; self.end:</span><br><span class="line">            i = self.start</span><br><span class="line">            self.start += <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> i</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> StopIteration()</span><br><span class="line">c = Container(<span class="number">0</span>, <span class="number">5</span>)</span><br></pre></td></tr></table></figure></li><li><p>内置函数 iter() 将可迭代对象转化为迭代器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ita = iter([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">print(type(ita))</span><br><span class="line">ita = iter([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">print(type(ita))</span><br><span class="line">print(type([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]))</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">list_iterator</span>'&gt;</span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> '<span class="title">list</span>'&gt;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>生成器（generator）</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">container</span><span class="params">(start, end)</span>:</span></span><br><span class="line">    <span class="keyword">while</span> start &lt; end:</span><br><span class="line">        <span class="keyword">yield</span> start</span><br><span class="line">        start += <span class="number">1</span></span><br><span class="line">c = container(<span class="number">0</span>, <span class="number">5</span>)</span><br><span class="line">Python</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">generator</span>'&gt;</span></span><br></pre></td></tr></table></figure></li></ul><h1 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h1><h2 id="split"><a href="#split" class="headerlink" title="split"></a>split</h2><p>通过指定分隔符对字符串进行切片，如果参数num 有指定值，则仅分隔 num 个子字符串</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line">str = <span class="string">"Line1-abcdef \nLine2-abc \nLine4-abcd"</span>;</span><br><span class="line"><span class="keyword">print</span> str.split( );</span><br><span class="line"><span class="keyword">print</span> str.split(<span class="string">' '</span>, <span class="number">1</span> );</span><br></pre></td></tr></table></figure><h2 id="find"><a href="#find" class="headerlink" title="find"></a>find</h2><p>检测字符串中是否包含子字符串 str ，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，如果包含子字符串返回开始的索引值，否则返回-1。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">str.find(str, beg=<span class="number">0</span>, end=len(string))</span><br></pre></td></tr></table></figure><h2 id="print"><a href="#print" class="headerlink" title="print"></a>print</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'t=&#123;&#125;,loss=&#123;:.6f&#125;'</span>.format(t,loss))</span><br></pre></td></tr></table></figure><h3 id="numpy的输出"><a href="#numpy的输出" class="headerlink" title="numpy的输出"></a>numpy的输出</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用set_printoptions设置输出的精度</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x=np.random.random(<span class="number">10</span>)</span><br><span class="line">np.set_printoptions(precision=<span class="number">3</span>)</span><br><span class="line">print(x)</span><br><span class="line"><span class="comment"># 抑制使用对小数的科学记数法</span></span><br><span class="line">y=np.array([<span class="number">1.5e-10</span>,<span class="number">1.5</span>,<span class="number">1500</span>])</span><br><span class="line">print(y)</span><br><span class="line"><span class="comment"># [  1.500e-10   1.500e+00   1.500e+03]</span></span><br><span class="line">np.set_printoptions(suppress=<span class="literal">True</span>)</span><br><span class="line">print(y)</span><br></pre></td></tr></table></figure><h2 id="合并两个矩阵"><a href="#合并两个矩阵" class="headerlink" title="合并两个矩阵"></a>合并两个矩阵</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#hstack()在行上合并 这个实验结果不对 </span></span><br><span class="line">np.hstack((a,b))  </span><br><span class="line"><span class="comment">#vstack()在列上合并  </span></span><br><span class="line">np.vstack((a,b))</span><br></pre></td></tr></table></figure><h2 id="squeeze"><a href="#squeeze" class="headerlink" title="squeeze"></a><a href="https://blog.csdn.net/zenghaitao0128/article/details/78512715" target="_blank" rel="noopener">squeeze</a></h2><p><strong>语法</strong>：numpy.squeeze(a,axis = None)</p><p>1）a表示输入的数组；<br>2）axis用于指定需要删除的维度，但是指定的维度必须为单维度，否则将会报错；<br>3）axis的取值可为None 或 int 或 tuple of ints, 可选。若axis为空，则删除所有单维度的条目；</p><p>从数组的形状中删除单维度条目，即把shape中为1的维度去掉</p><p><strong>作用</strong>：从数组的形状中删除单维度条目，即把shape中为1的维度去掉</p><p><strong>例子：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">e  = np.arange(<span class="number">10</span>).reshape(<span class="number">1</span>,<span class="number">10</span>,<span class="number">1</span>)</span><br><span class="line">e: array([[[<span class="number">0</span>],</span><br><span class="line">        [<span class="number">1</span>],</span><br><span class="line">        [<span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>],</span><br><span class="line">        [<span class="number">4</span>],</span><br><span class="line">        [<span class="number">5</span>],</span><br><span class="line">        [<span class="number">6</span>],</span><br><span class="line">        [<span class="number">7</span>],</span><br><span class="line">        [<span class="number">8</span>],</span><br><span class="line">        [<span class="number">9</span>]]])</span><br><span class="line"></span><br><span class="line">np.squeeze(e)</span><br><span class="line">e: array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"><span class="comment">#正常显示图示案例</span></span><br><span class="line"><span class="comment">#通过np.squeeze()函数转换后，要显示的数组变成了秩为1的数组，即（5，）</span></span><br><span class="line">plt.plot(np.squeeze(squares))    </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h1 id="库-1"><a href="#库-1" class="headerlink" title="库"></a>库</h1><p>numpy：提供很多矩阵的操作</p><h1 id="python的注释格式"><a href="#python的注释格式" class="headerlink" title="python的注释格式"></a>python的注释格式</h1><p><a href="https://blog.csdn.net/teacher20133/article/details/79894828" target="_blank" rel="noopener">python的注释格式</a></p><h1 id="Python-图像"><a href="#Python-图像" class="headerlink" title="Python 图像"></a>Python 图像</h1><ul><li><p>读取图像: cv2 ski..</p></li><li><p>PIL库的使用</p><p>import matplotlib</p><p><a href="https://www.jianshu.com/p/e8d058767dfa" target="_blank" rel="noopener">Image读出来的是PIL的类型，而skimage.i的对比</a></p><p><a href="https://mp.weixin.qq.com/s/9mCTh3PVMaCiP6bHIE50iA" target="_blank" rel="noopener">PIL拆分、合并、合成视频</a></p></li><li><p>用PIL显示图像</p></li><li><p>对图像加噪声、滤波复原</p><p><a href="https://www.cnblogs.com/lynsyklate/p/8047510.html" target="_blank" rel="noopener">https://www.cnblogs.com/lynsyklate/p/8047510.html</a></p></li></ul><h1 id="Debug"><a href="#Debug" class="headerlink" title="Debug"></a>Debug</h1><ul><li>[x] 文件阅读时，出现无法创建文件的问题。（该文件被另一进程阅读中）</li></ul><blockquote><p>why can the same file not opened by several processes?</p><p><a href="https://github.com/wqn628" target="_blank" rel="noopener">@wqn628</a> Because that requires the hdf5-library to be built with parallel extensions. You can open an HDF5-file for read-only in multiple processes, but you cannot open it for read/write in more than one process unless the library has been built with parallel enabled.<br>The reason for this is because HDF5-files write to the file the moment you close them, not the moment you tell them to write. Therefore, in serial, corruption would be very likely.</p><p>The best way to deal with this is by simply opening the HDF5-file for read-only in both Python scripts. That should work perfectly fine.</p></blockquote><ul><li>[x] NoneType之所以出现，该参数没有被创建或者赋值，只被取了名字。</li></ul><blockquote><p>要理解这个，首先要理解Python对象，python对象具有三个特性：身份、类型、值。<br>  这三个特性在对象创建时被赋值。只有值可以改变，其他只读。类型本身也是对象。<br>  Null与None是Python的特殊类型，Null对象或者是None Type，它只有一个值None.<br>  它不支持任何运算也没有任何内建方法. None和任何其他的数据类型比较永远返回False。<br>  None有自己的数据类型NoneType。你可以将None复制给任何变量，但是你不能创建其他NoneType对象。<br>  一句话总结：Null对象是python对象，又叫做NoneType，None是这个对象的值。<br>  看过了NoneType的解释，之所以出现None就很好理解了。 </p></blockquote><ul><li><p>要正确定位bug出现的位置，之前那个logwrite没有定位准确，导致找不到原因。</p></li><li><p>要关注错误信息。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第一个博客搭建</title>
      <link href="/p/9748.html"/>
      <url>/p/9748.html</url>
      
        <content type="html"><![CDATA[<h1 id="Github搭建博客"><a href="#Github搭建博客" class="headerlink" title="Github搭建博客"></a>Github搭建博客</h1><ul><li>解决数学公式的显示问题(文件助手)</li><li>github搭建结构的基本框架(文件助手)</li><li>git的使用，廖雪峰</li></ul><h1 id="图片显示问题"><a href="#图片显示问题" class="headerlink" title="图片显示问题"></a>图片显示问题</h1><ul><li><p>新浪图片外链在博客中无法显示的原因</p></li><li><p>新浪图床直接访问没有权限：Access Denied You don’t have permission to access</p></li><li><p><a href="https://www.jianshu.com/p/dbc945b05d55" target="_blank" rel="noopener">Mac下iPic的使用方法</a></p></li><li><p>不同的图床<br><a href="https://juejin.im/post/5a71ac325188257350518a23" target="_blank" rel="noopener">不同的图床</a></p><p><a href="https://zhuanlan.zhihu.com/p/34747279" target="_blank" rel="noopener">七牛云的API</a></p><p><a href="https://toolinbox.net/iPic/AddQiniuImageHost.html" target="_blank" rel="noopener">iPic中添加七牛</a></p><p>阿里云：<a href="https://oss.console.aliyun.com/overview" target="_blank" rel="noopener">https://oss.console.aliyun.com/overview</a></p></li><li><p>图床跑路怎么办</p><p><a href="https://github.com/wisp-x/lsky-pro" target="_blank" rel="noopener">https://github.com/wisp-x/lsky-pro</a></p><p><a href="https://blog.csdn.net/OBKoro1/article/details/90899857" target="_blank" rel="noopener">解决替换图床的脚本</a></p></li></ul><h1 id="公式的显示问题"><a href="#公式的显示问题" class="headerlink" title="公式的显示问题"></a>公式的显示问题</h1><h1 id="博客list"><a href="#博客list" class="headerlink" title="博客list"></a>博客list</h1><h1 id="多端访问"><a href="#多端访问" class="headerlink" title="多端访问"></a>多端访问</h1><p><a href="https://www.appinn.com/source-git-client-code-editor/" target="_blank" rel="noopener">iphone/ipad</a></p>]]></content>
      
      
      <categories>
          
          <category> 其他 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>去噪传统方法论文综述</title>
      <link href="/p/8245.html"/>
      <url>/p/8245.html</url>
      
        <content type="html"><![CDATA[<h1 id="期刊会议"><a href="#期刊会议" class="headerlink" title="期刊会议"></a><a href="https://www.zhihu.com/question/37687006" target="_blank" rel="noopener">期刊会议</a></h1><ul><li><p>计算机视觉期刊</p><p>A类</p><ul><li>TPAMI: IEEE Trans on Pattern Analysis and Machine Intelligence</li><li>IJCV: International Journal of Computer Vision</li><li>TIP: IEEE Transactions on Image Processing</li></ul><p>B类</p><ul><li>CVIU: Computer Vision and Image Understanding</li><li>Pattern Recognition</li></ul><p>C类</p><ul><li>IET-CVI: IET Computer Vision</li><li>IVC: Image and Vision Computing</li><li>IJPRAI: International Journal of Pattern Recognition and Artificial Intelligence</li><li>Machine Vision and Applications</li><li>PRL: Pattern Recognition Letters</li></ul></li><li><p>计算机视觉会议</p><p>A类</p><ul><li>ICCV: International Conference on Computer Vision</li><li>CVPR: International Conference on Computer Vision and Pattern Recognition</li><li>AAAI: AAAI Conference on Artificial Intelligence</li><li>ICML: International Conference on Machine Learning</li><li>NIPS: Annual Conference on Neural Information Processing Systems</li><li>ACM MM: ACM International Conference on Multimedia</li></ul><p>B类</p><ul><li>ECCV: European Conference on Computer Vision</li></ul><p>C类</p><ul><li>ACCV: Asian Conference on Computer Vision</li><li>ICPR: International Conference on Pattern Recognition</li><li>BMVC: British Machine Vision Conference</li></ul></li><li><p>应用数学期刊</p><p><a href="https://www.springer.com/computer/image+processing/journal/10851" target="_blank" rel="noopener">JMIV</a>: Journal of Mathematical Imaging and Vision</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1g346nrzv99j31og09uq53.jpg" alt="image-20190517120613341"></p></li><li><p>应用数学会议</p></li><li><p>检索工具</p><p>期刊影响因子查询网站：<a href="http://www.letpub.com.cn/index.php?journalid=3328&amp;page=journalapp&amp;view=detail" target="_blank" rel="noopener">中文</a>、 <a href="https://jcr.clarivate.com/JCRLandingPageAction.action?Init=Yes&amp;SrcApp=IC2LS&amp;SID=J2-4XwAp32l42uZt12TwkA6PPRWUdDytSwG-18x2dEBNx2FAmx2Bx2BLS9TPTpUU0DGKQx3Dx3DNs8V1Mx2BQp597TwzF85F1aAx3Dx3D-WwpRYkX4Gz8e7T4uNl5SUQx3Dx3D-wBEj1mx2B0mykql8H4kstFLwx3Dx3D" target="_blank" rel="noopener">英文网站</a></p></li><li><p>出版商、数据库、检索工具</p><ul><li><p>IEEE和Springer是<u>出版商</u>，并且拥有自己的数据库和检索工具。</p><p>如：IEEE有IEEExplorer检索。 其他数据库自己（比如EI, EBSCOhost等等）可以抓取出版商数据库里面的文章。比如EngineeringVillage (EI)在IEEExplorer抓取文章的内容；这时候作者的文章就能在EI里面查到了。</p></li><li><p>Google/Google Scholar/Scirus/ScienceDirect/IEEExplorer/ISI这些都是检索工具</p></li><li><p>SCI(Science Citation Index)是影响因子，也是ISI（Institute Scientific Information）做的数据库。</p><p>SCI不是出版商，只是数据库，不是具体某篇文章内容版权的拥有者；所以在SCI里面，能看到只是题目+摘要+参考文献。SCI的内容不是原始文献全文，卖点是每年推出JCR，里面给出影响因子。</p></li><li><p><a href="https://zhuanlan.zhihu.com/p/27674513" target="_blank" rel="noopener">SIAM简介</a>：国际工业与应用数学<u>协会</u>(SIAM), 旗下出版有应用数学相关的许多国际著名期刊杂志</p></li></ul></li></ul><h1 id="文献链接"><a href="#文献链接" class="headerlink" title="文献链接"></a>文献链接</h1><p><a href="http://bbs.cvmart.net/topics/302/cvpr2019paper" target="_blank" rel="noopener">2019 CVPR 汇总</a></p><h1 id="变分算法"><a href="#变分算法" class="headerlink" title="变分算法"></a>变分算法</h1><ul><li><p>total variation</p><p>TV-based image restoration: Rudin Osher and Fatermi in 1992. </p><p><strong>优点：</strong>preserves edges well, but has sometimes undesirable staircase effect, namely the trans- formation of smooth regions into piecewise constant regions (stairs), which implied that the finer details in the original im- age may not be recovered satisfactorily. </p><p><strong>缺点：</strong>staircasing</p><p>什么是staircasing。如何发生。在哪些情况下更容易发生。</p><p>除了non-local mean和BM3D，都是oversmoothed。</p><p><strong>改进：几大类方法</strong></p><blockquote><p>高阶全变分模 型 [8] 、广义全变分模型 [9] 和自适应全变分模型 [5] 等</p><p>[7] L.I. Rudin, S.Osher, and E. Fatemi. Nonlinear total variation based noise removal algorithms. Physica D(Nonlinear phenomena), 1992, 60(1 /2 /3 /4) : 259-268.</p><p>[8] Y. You and M. Kaveh. Fourth-Order partial differential equations for noise removal. IEEE trans on image processing, 2000, 9(10) : 1723-1730.</p><p>[9] B. Kristian, K. Karl, and P. Thomas. Total generalized variation. SIAM Journal on imaging sciences, 2010, 3(3):492-526.</p><p>[5] P. Blomgren, T. Chan, P. Mulet, and C. Wong. Total variation image restoration: numerical methods and extensions. In IEEE international conferance on image processing, pages III, 384-387, 1997.</p></blockquote></li><li><p>基于小波框架的变分模型 [14-19]</p><ul><li><p>14、Chan, Raymond H., et al. “Wavelet algorithms for high-resolution image reconstruction.” <em>SIAM Journal on Scientific Computing</em> 24.4 (2003): 1408-1432</p></li><li><p>17、Chan, Raymond, Lixin Shen, and Zuowei Shen. “A framelet-based approach for image inpainting.” <em>Res. Rep</em> 4 (2005): 325. </p></li><li><p>16、Dong, Bin, and Zuowei Shen. “MRA based wavelet frames and applications.” <em>IAS Lecture Notes Series, Summer Program on “The Mathematics of Image Processing”, Park City Mathematics Institute</em> 19 (2010).</p></li><li><p>15、Cai, Jian-Feng, Stanley Osher, and Zuowei Shen. “Split Bregman methods and frame based image restoration.” <em>Multiscale modeling &amp; simulation</em> 8.2 (2009): 337-369.</p></li><li><p>19、Cai, Jian-Feng, et al. “Image restoration: total variation, wavelet frames, and beyond.” <em>Journal of the American Mathematical Society</em> 25.4 (2012): 1033-1089.</p></li><li><p>20、Cai, Jian-Feng, et al. “Data-driven tight frame construction and image denoising.” <em>Applied and Computational Harmonic Analysis</em> 37.1 (2014): 89-105.</p><p>最近建立了小波框架和 变分模型之间的联系。 这种联系给出了基于小波框 架的变分模型优于其他某些变分模型的理论依据， 即基于小波框架的变分模型可以根据潜在的解的奇 点的顺序，在给定图像的不同区域中自适应地选择微 分算子。又基于图像数据结构特征， 提出了一种数据驱动紧 框架， 该框架比以往的模型更能精确地重构图像。</p></li></ul></li></ul><h1 id="去噪"><a href="#去噪" class="headerlink" title="去噪"></a>去噪</h1><blockquote><p>不同的滤波器用于不同的噪声，某一个降噪滤波器很难符所有的噪声。</p><p>首先，说一下<strong>噪声的类型</strong>，噪声的分类和该噪声的分布符合什么模型有关，<strong>常见的噪声有高斯白噪声、椒盐噪声、泊松分布噪声、指数分布噪声</strong>等。</p><p>其次，采用的滤波器<strong>有空域滤波器</strong>，比如均值滤波器、中值滤波器、低通滤波器、高斯滤波等；<strong>频域滤波器</strong>，比如小波变换、傅里叶变换、余弦变换等；<strong>形态学滤波器</strong>，主要是通过膨胀和腐蚀等形态学操作进行去噪。</p><p>第三，对应场合。一般平时见的比较多是是高斯白噪声，像用均值滤波、中值滤波、高斯滤波可以去噪。还有在低照度下，比如晚上拍照时的图像，一般属于泊松分布的噪声，可以采用一些3d去噪算法，比如效果不错的BM3D算法。像椒盐噪声，一般用中值滤波基本可以去噪。</p></blockquote><h2 id="文献回顾以及代码"><a href="#文献回顾以及代码" class="headerlink" title="文献回顾以及代码"></a>文献回顾以及代码</h2><p><a href="https://github.com/wenbihan/reproducible-image-denoising-state-of-the-art" target="_blank" rel="noopener">github去噪技术的方法和代码实现总结</a></p><p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1g3a5q3a892j30xc0ovmzs.jpg" alt="图像去噪方法汇总"></p><ul><li><p>滤波法：空间域和变换域</p><ul><li><p>(空间域) Gaussian filter</p></li><li><p>(转化域) Wavelet-based(详见Tight-frame): tight frame</p></li></ul></li><li><p>小波变化文献回顾</p></li><li><p>马尔可夫场</p></li></ul><p><a href="http://deanhan.com/2018/04/22/MRF/" target="_blank" rel="noopener">Markov denoising 理解</a></p><ul><li><p>全变分模型（变分法的一种）</p><ul><li><p>ROF模型, 1992</p><p> L. Rudin, S. Osher, E. Fatemi, Nonlinear Total Variation based noise removal algorithm, Physica D 60 259-268, 1992. <a href="http://www.math-info.univ-paris5.fr/~lomn/Cours/ECE/PhysicaRudinOsher.pdf" target="_blank" rel="noopener"><strong>++paper</strong></a></p><script type="math/tex; mode=display"> \min _{u} \int_{\Omega}\left(\alpha|\nabla u|+\frac{1}{2}(u-z)^{2}\right)</script></li><li><p><a href="http://manu46.magtech.com.cn/ces/CN/article/downloadArticleFile.do?attachType=PDF&amp;id=10254" target="_blank" rel="noopener">与ROF相关联的偏微分方程以及推导</a></p><p>目标方程：</p><script type="math/tex; mode=display">\begin{array}{l}{J[u(x, y)]=\iint_{\Omega}|\nabla u(x, y)| \mathrm{d} x \mathrm{d} y+\quad \frac{\lambda}{2} \iint_{\Omega}\left(u(x, y)-u^{0}(x, y)\right)^{2} \mathrm{d} x \mathrm{d} y}\end{array}</script><p>该泛函是</p><script type="math/tex; mode=display">J[u(x, y)]=\iint_{\Omega} F\left(x, y, u, \frac{\partial u}{\partial x}, \frac{\partial u}{\partial y}\right) \mathrm{d} x \mathrm{d} y</script><p>型的泛函，其中(式1)</p><script type="math/tex; mode=display">\begin{aligned} F=&|\nabla u(x, y)|+\frac{\lambda}{2}\left(u(x, y)-u^{0}(x, y)\right)^{2}= \\&\sqrt{\left(\frac{\partial u(x, y)}{\partial x}\right)^{2}+\left(\frac{\partial u(x, y)}{\partial y}\right)^{2}}+\frac{\lambda}{2}\left(u(x, y)-u^{0}(x, y)\right)^{2} \end{aligned}$$ {222}该类函数求极值的必要条件，即欧拉-拉格朗日方程(PDE):</script><p>F_{H}-\frac{\partial}{\partial x}\left\{F_{p}\right\}-\frac{\partial}{\partial y}\left\{F_{q}\right\}=0</p><script type="math/tex; mode=display">其中, $p=\frac{\partial u(x, y)}{\partial x}, q=\frac{\partial u(x, y)}{\partial y}​$.对于式1，有$F_{H}=\lambda\left(u-u^{0}\right), F_{p}=\frac{\frac{\partial u}{\partial x}}{|\nabla u|}, F_{q}=\frac{\frac{\partial u}{\partial y}}{|\nabla u|}$, 代入后有：</script><p>\begin{array}{l}{\lambda\left(u-u^{0}\right)-\left\{\frac{\partial}{\partial x}\left\{\left(\frac{\frac{\partial u}{\partial x}}{|\nabla u|}\right)\right\}+\frac{\partial}{\partial y}\left\{\frac{\frac{\partial u}{\partial y}}{|\nabla u|}\right\}\right\}=0} \\ {\Rightarrow \lambda\left(u-u^{0}\right)-\left(\frac{\partial}{\partial x}, \frac{\partial}{\partial y}\right) \cdot\left(\frac{\frac{\partial u}{\partial x}}{|\nabla u|}, \frac{\frac{\partial u}{\partial y}}{|\nabla u|}\right)=0} \\ {\Rightarrow \lambda\left(u-u^{0}\right)-\left(\frac{\partial}{\partial x}, \frac{\partial}{\partial y}\right) \cdot\left(\frac{1}{|\nabla u|}\left(\frac{\partial u}{\partial x}, \frac{\partial u}{\partial y}\right)\right)=0} \\ {\Rightarrow \lambda\left(u-u^{0}\right)-\nabla \cdot\left(\frac{\nabla u}{|\nabla u|}\right)=0}\end{array}</p><script type="math/tex; mode=display">其中，$\nabla=\left(\frac{\partial}{\partial x}, \frac{\partial}{\partial y}\right)$为梯度算子。TV复原模型的欧拉一拉格朗日方程为 ：</script><p>-\nabla \cdot\left(\frac{\nabla u}{|\nabla u|}\right)+\lambda\left(u-u^{0}\right)=0<br>$$</p></li><li><p>using a gradient projection method.</p></li><li><p>缺点：阶梯块效应 </p><p>表现形式：</p><p>产生原因：</p><p>改进方法 可以分为三类：(1) 对l_1进行改进 (2) 高阶变分 (3) </p><p>高阶全变分模型[8]、广义全变分模型[9]和自适应全变分模型[5]</p><p>(在谋篇中文期刊看到过)</p></li><li><p>二阶(高阶)方法改进staircasing</p><ul><li><p>局限性：通常需要更复杂的边界条件以及结果很可能会过光滑</p></li><li><p>(二阶) G. Geman and G. Reynolds, 1992, IEEE Trans. Pattern Anal. Mach. Intel.</p><p>《Constrained restoration and the recovery of discontinuities》</p></li><li><p>(二阶) Chambolle and Lions, 1997, Numer. Math.</p><p><a href="http://www.math.ucla.edu/~lvese/285j.1.09f/ChambolleLions.pdf" target="_blank" rel="noopener">《Image recovery via total variation minimization and related problems》</a>: Chambolle and Lions do this by minimizing the inf-convolution of the TV norm and a second order functional. </p><script type="math/tex; mode=display">\begin{array}{l}{\min _{u_{1}, u_{2}} \int_{\Omega}\left|\nabla u_{1}\right|+\alpha\left|d^{2} u_{2}\right|+\lambda\left|u_{1}+u_{2}-u_{0}\right|^{2}} \\ {=\min _{u, v} \int_{\Omega}|\nabla u-\nabla v|+\alpha|\nabla(\nabla v)|+\lambda\left|u-u_{0}\right|^{2}}\end{array}</script><script type="math/tex; mode=display">\min _{u} \int_{\Omega}\left(\alpha \left|d^{2} u\right|+|\nabla u|+\frac{1}{2}(u-z)^{2}\right)</script><ul><li><p>(母鸡) P. Blomgren, T. F. Chan, and P. Mulet, 1997</p><p>《Extensions to total variation denoising》: The approach is performed by redefining the Total Variation functional R(u) in view of the properties of TV-norm and H1-seminorm. However, it is not completely clear how to choose a function Φ, which makes the regularizing functional R(u) being convex. </p></li><li><p>(四阶)  Chan T, Marquina A, Mulet P.,  2000, SIAM J Sci Comput,</p><p>《High-order total variation-based image restoration》: ”In this paper we present an improved model, constructed by adding a nonlinear fourth order diffusive term to the Euler–Lagrange equations of the variational TV model. “</p><script type="math/tex; mode=display">\int_{\Omega}\left(\alpha|\nabla u|_{\beta}+\mu \Phi(|\nabla u|)(\mathcal{L}(u))^{2}+\frac{1}{2}(u-z)^{2}\right)</script><p>where, $\mathcal{L}(u)​$ is an elliptic operator and $\Phi(|\nabla u|)​$ is  the adaptive function. This model retain the good properties of the TV functional and <strong>penalize “wrong” edges created in regions which “should” be smooth</strong>. The adaptive functional, in which the action of the second order term is lessened where the gradient is large(avoid oversmooth).</p></li><li><p>(二阶) O. M. Lysaker and X.-C. Tai, Int. J. Comp. Vis., 2006</p><p>《Iterative image restoration combining total variation minimization and a second-order functional》:Instead of combing TV norm and second order derivatives within one regularization functional, <strong>Lysaker and Tai [5]</strong> use two regularization functionals.</p><p>两个式子，单独的两个regularization</p></li><li><p>(四阶）Li F, Shen C, Fan J, 2007, J Vis Commun Image R</p><p>《Image restoration combining a total variational filter and a fourth-order filter》</p></li><li><p>(母鸡，higher-order)Liu G, Huang T, Liu J, 2014, Comput Math Appl</p><p>《High-order TVL1-based images restoration and spatially adapted regularization parameter selection》    </p></li></ul></li><li><p><strong>TGV</strong>, Bredies, K., Kunisch, K., &amp; Pock, T. (2010),  <em>SIAM Journal on Imaging Sciences</em></p><script type="math/tex; mode=display">\mathrm{TGV}_{\alpha}^{k}=\left(\sum_{l=0}^{k-1} I_{K_{\alpha_{l}}^{l}}\right)^{*}</script><script type="math/tex; mode=display">\operatorname{TGV}_{\alpha}^{k}(u)=\underset{w_{0}+\ldots+u_{k-1}=u \atop l=0, \ldots, k-1}{\inf } \sum_{l=0}^{k-1} \alpha_{l}\left\|\nabla^{k-l} u_{l}+w_{l}\right\|_{1}</script><p>《Total generalized variation.》 <a href="https://www.mathworks.com/matlabcentral/fileexchange/49717-image-denoising-by-total-generalized-variation-via-fft" target="_blank" rel="noopener">code link here</a>,  <a href="https://imsc.uni-graz.at/mobis/publications/SFB-Report-2009-038.pdf" target="_blank" rel="noopener">paper link</a></p><p>limitation: converge slowly</p><p>一个加速版本：K. Shirai, M. Okuda, (2014), “FFT based solution for multivariable l2 equations using KKT system  via FFT and efficient pixel-wise inverse calculation,” <em>IEEE ICASSP</em>, <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6854076" target="_blank" rel="noopener">paper link</a></p><p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1g3b56ub0boj30iy0723yn.jpg" alt></p><p>A. Beck, and M. Teboulle, A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems, SIAM J. Imaging Sci., Vol. 2, 183–202, 2009.</p></li><li><p>inﬁmal convolution</p></li><li><p>Euler’s elastica</p></li><li><p>K Papafitsoros, (2014), <em>JMIV</em></p><p>《A combined first and second order variational approach for image reconstruction. 》</p><script type="math/tex; mode=display">J(u)=\frac{1}{2}\left\|u_{0}-T u\right\|_{2}^{2}+\alpha\|\nabla u\|_{1}+\beta\left\|\nabla^{2} u\right\|_{1}</script></li><li><p>从MAP的角度出发</p><ul><li><p>C. Louchet and L. Moisan， 2008</p><p>《Total variation denoising using posterior expectation》: Louchet and Moisan proposed an alternative to the minimization of the total variation by considering the TV-LSE filter.</p></li><li><p>C. Louchet and L. Moisan， 2014</p><p>《Total Variation Denoising using Iterated Conditional Expectation》</p></li></ul></li><li><p>分析了staircasing产生的原因</p><ul><li><p>M. Nikolova, 2000, SIAM J. Appl. Math</p><p>《Local strong homogeneity of a regularized estimator》：Nikolova proves that the staircasing effect is related to the non-differentiability of the total variation term</p></li></ul></li></ul></li><li><p>增加细节的改进：non-local+TV的方法.</p><ul><li><p>NLTV, Gilboa and Osher, 2004, Multiscale Model. Simul.</p><p>《Nonlocal operators with applications to image processing》</p><script type="math/tex; mode=display">J_{\mathrm{NLTV}}(u)+\lambda\|u-I\|^{2}</script></li><li><script type="math/tex; mode=display">\int_{\mathcal{P}} \sqrt{\int_{\mathcal{B}}(u(p)-u(p+q))^{2} v(p, q) \mathrm{d} q \mathrm{d} p}</script></li><li><p>NLTVG, Peyré, G., Bougleux, S., Cohen, L.D, 2011, Inverse Probl. Imaging</p><p>《Non-local regularization of inverse problems.》</p></li><li><p>RNLTV, Z Li, F Malgouyres, T Zeng，2017,  JMIV</p><p>《Regularized Non-local Total Variation and Application in Image Restoration》</p></li></ul></li></ul></li><li><p>基于图像的自相似性:  <a href="https://zhuanlan.zhihu.com/p/45631464" target="_blank" rel="noopener">两种图像降噪方法论文解读以及代码实现</a></p><ul><li><p>Non-local means, 2005, <a href="https://www.mathworks.com/help/images/ref/imnlmfilt.html" target="_blank" rel="noopener">code link here</a></p><p>Buades, A., Coll, B., &amp; Morel, J. M. (2005, June). <strong>A non-local algorithm for image denoising.</strong> In <em>2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05)</em> (Vol. 2, pp. 60-65). IEEE.（BM3D）</p><p>Exploit the inter-patch correlations</p></li><li><p>BM3D, 2007, <a href="http://www.cs.tut.fi/~foi/GCF-BM3D/index.html#ref_software" target="_blank" rel="noopener">code link</a></p><p>Dabov, K., Foi, A., Katkovnik, V., &amp; Egiazarian, K. (2007). <strong>Image denoising by sparse 3-D transform-domain collaborative filtering.</strong> Image Processing, IEEE Transactions on 16 (8), pp. 2080-2095.</p><p> inter-patch correlations；wavelet shrinkage</p></li><li><p>LSSC(Learned Simultaneous Sparse Coding), 2009</p><p>Mairal, J., Bach, F. R., Ponce, J., Sapiro, G., &amp; Zisserman, A. (2009, September). <strong>Non-local sparse models for image restoration.</strong> In <em>ICCV</em> (Vol. 29, pp. 54-62).</p><p>这个算法是NL-means，LSC(Learned Sparse Coding), Block matching 3D的相结合</p></li></ul></li><li><p>基于稀疏表达（在变换域）</p><p>There exists a transform T such that applying T to patches will admit a sparse representation.</p><p>Wavelet transform    稀疏表达</p><p>Wavelet thresholding   属于一种滤波法</p></li><li><p>基于马尔可夫场</p></li><li><p>基于深度学习</p><p><a href="https://blog.csdn.net/geekmanong/article/details/50572148" target="_blank" rel="noopener">论文总结</a></p><p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1g3a5quqvmaj30xa0osgnx.jpg" alt></p></li></ul><h2 id="高斯噪声"><a href="#高斯噪声" class="headerlink" title="高斯噪声"></a>高斯噪声</h2><p>均值为0，平方差为$\sigma^2$的高斯白噪声。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 调用imnoise</span><br><span class="line">g = imnoise(I, (noise_level/<span class="number">255</span>)^<span class="number">2</span>)</span><br><span class="line">g = I + <span class="built_in">sqrt</span>((noise_level/<span class="number">255</span>)^<span class="number">2</span>)*<span class="built_in">randn</span>(M,N);</span><br><span class="line">其中的I是经过im2double(I) <span class="comment">% I = I/255归一化的。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="string">'gaussian'</span> <span class="comment">% Gaussian white noise</span></span><br><span class="line">    b = a + <span class="built_in">sqrt</span>(p4)*<span class="built_in">randn</span>(sizeA) + p3;</span><br><span class="line">    </span><br><span class="line"># 直接</span><br><span class="line">g = I + sigma * <span class="built_in">randn</span>(M,N);</span><br><span class="line">其中I是归一化后的，sigma = noise_level/<span class="number">255</span>;</span><br><span class="line"># 如果I是[0,255]之间的原图。</span><br><span class="line">g = I + alpha * <span class="built_in">randn</span>(<span class="built_in">size</span>(S)); </span><br><span class="line">那么，alpha = sigma*<span class="number">255</span>;</span><br></pre></td></tr></table></figure><h2 id="斑点噪声（乘性噪声）"><a href="#斑点噪声（乘性噪声）" class="headerlink" title="斑点噪声（乘性噪声）"></a>斑点噪声（乘性噪声）</h2><ul><li>噪声模型诶</li></ul><script type="math/tex; mode=display">f=u n</script><script type="math/tex; mode=display">p(f | u, L)=\frac{2 L^{L}}{\Gamma(L) u^{2 L}} f^{2 L-1} e^{-\frac{L f^{2}}{u^{2}}}</script><ul><li><p>TV去噪模型</p><ul><li><p>（AA模型）G. Aubert and J. Aujol. (2008). A variational approach to remove multiplicative noise. SIAM J. Appl. Math., 68:925–946, .</p><script type="math/tex; mode=display">\inf _{u \in S(\Omega)} \int_{\Omega}\left(\log (A u)+\frac{f}{A u}\right) d x+\lambda \int_{\Omega}|D u|</script></li><li><p>Dong, Y., &amp; Zeng, T. (2013). A convex variational model for restoring blurred images with multiplicative noise. <em>SIAM Journal on Imaging Sciences</em>, <em>6</em>(3), 1598-1625.</p><script type="math/tex; mode=display">\inf _{u \in \overline{S}(\Omega)} E(u) :=\int_{\Omega}\left(\log u+\frac{f}{u}\right) d x+\alpha \int_{\Omega}\left(\sqrt{\frac{u}{f}}-1\right)^{2} d x+\lambda \int_{\Omega}|D u|</script></li><li><p>Fang, F., Fang, Y., &amp; Zeng, T. (2018). On the Convex Model of Speckle Reduction: IVLOPDE, Bergen, Norway, August 29 – September 2, 2016. <a href="https://doi.org/10.1007/978-3-319-91274-5_6" target="_blank" rel="noopener">https://doi.org/10.1007/978-3-319-91274-5_6</a></p></li></ul></li></ul><h2 id="泊松噪声"><a href="#泊松噪声" class="headerlink" title="泊松噪声"></a><strong>泊松噪声</strong></h2><ul><li><p>泊松噪声<strong>既不是加性噪声，也不是乘性噪声</strong>，而是一种信号依赖噪声。</p></li><li><p>加噪模型：f= 10*poissrnd(u/10)，noiselevel=10</p><script type="math/tex; mode=display">\operatorname{Pr}(\boldsymbol{g} | \boldsymbol{f})=\prod_{i, j} \frac{\left[\boldsymbol{f}_{i, j}\right]^{g_{i, j}} \exp \left(-\boldsymbol{f}_{i, j}\right)}{\left(\boldsymbol{g}_{i, j}\right) !}</script></li><li><p>TV去噪</p><ul><li>Ｃsisｚár [１] 最早提出了 Kullbaｃk－Leibler （ KL )－divergenｃe 保真项用于去除 灰色图像中的泊松噪声Ｃsisｚár I． Wｈy least squares and ｍaxiｍuｍ entrｏpy Ａn Ａxiｏｍatiｃ Ａpprｏaｃｈ tｏ Inferenｃe fｏr linear Inverse Ｐrｏbleｍs[J]． Ａnnals ｏf Statistiｃs ， １９９１ ， １９ （ ４ ） : ２０3２－２０６６</li><li>Luisier 等 [２] 在小波变换中构 造了一个 SURE 估计量用于泊松噪声的去除。</li><li>Gｏng 等 [3] 提出了一个 l １ +l ２ 保真项去除泊松噪声及一切未 知噪声。</li><li><p>Zｈang 等学者 [４－5] 使用重新赋权的 l ２ 方 法逼近 KL－divergenｃe 保真项</p></li><li><p>Wen, Y., Chan, R. H., &amp; Zeng, T. (2016). Primal-dual algorithms for total variation based image restoration under Poisson noise. <em>Science China Mathematics</em>, <em>59</em>(1), 141-160.</p><ul><li><p>描述了ADMM算法和Primal Dual的算法解决以下问题</p><p>Using the Bayesian rule, the Poisson image restoration problem can be represented as a minimization problem</p></li></ul></li></ul><script type="math/tex; mode=display">\min _{f \in S} \Psi(\boldsymbol{f}) \equiv D_{K L}(H \boldsymbol{f}+\boldsymbol{b}, \boldsymbol{g})+\lambda \operatorname{TV}(\boldsymbol{f})</script><script type="math/tex; mode=display">D_{K L}(\boldsymbol{z}, \boldsymbol{g})=\left\langle\boldsymbol{g}, \ln \frac{\boldsymbol{g}}{\boldsymbol{z}}\right\rangle+\langle\mathbf{1}, \boldsymbol{z}-\boldsymbol{g}\rangle</script></li><li><p><a href="http://www.cs.tut.fi/~foi/invansc/" target="_blank" rel="noopener">code link: BM3D for Poisson</a></p></li></ul><h2 id="椒盐噪声"><a href="#椒盐噪声" class="headerlink" title="椒盐噪声"></a>椒盐噪声</h2><ul><li><p>噪声模型</p><p>讲一部分像素变成0或者255</p></li><li><p>TV去噪</p><ul><li><p>（Nikolova in 2004）</p><script type="math/tex; mode=display">\underset{u \in \mathbb{R}^{\Omega}}{\operatorname{argmin}}\|u-v\|_{1}+\lambda \sum_{i} \phi(\nabla u(i))</script></li><li><p>$\underset{u \in \mathbb{R}^{\Omega}}{\operatorname{argmin}}|u-v|_{0}+\lambda \sum_{i} \phi(\nabla u(i))$（因为nonconvex，先研究了第一个替代问题，之后出现对该问题求解）</p></li><li><p><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Yuan_L0TV_A_New_2015_CVPR_paper.pdf" target="_blank" rel="noopener">2015 CVPR: A New Method for Image Restoration in the Presence of<br>Impulse Noise</a> with <a href="https://github.com/peisuke/L0TV" target="_blank" rel="noopener">code:C</a></p></li><li><p>[2019 JMIV: Mixing Non-Local and TV-Lp methods]</p></li><li><p>Chan提出了先试用noise detector的方法</p></li></ul></li><li><p>NL-means approach</p><ul><li>[2016 JSC] Removing mixture of gaussian and impulse noise by patch-based weighted means</li></ul></li><li>2019 JMIV: Mixing Non-Local and TV-Lp methods</li></ul><h1 id="去模糊"><a href="#去模糊" class="headerlink" title="去模糊"></a>去模糊</h1><ul><li><p>文献</p><ul><li><p>An image sharpening Operator Combined with Framelet for Image Deblurring</p><ul><li><p>提出的模型</p><script type="math/tex; mode=display">\min _{u} \mathcal{J}(u) \equiv \frac{\lambda}{2}\|A u-f\|_{2}^{2}+\|W u\|_{1}+\mu\|u-g\|_{1}</script></li><li><p>采用变分法，正则项选择选择了Tight frame：|WtW|=1</p></li><li><p>将一个sharpen算子和传统tight frame的方法结合一起：用一个方法计算出有助于sharp的图像g, 并用L1-nirm去靠近。（和去模糊的构造正解之间的关系？待解决）</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1g3m23i2605j30qc0fe0xa.jpg" alt="image-20190601134500471"></p><p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1g3m23ice0rj30qw06o407.jpg" alt="image-20190601134302067"></p></li></ul></li></ul></li></ul><h1 id="超分辨"><a href="#超分辨" class="headerlink" title="超分辨"></a>超分辨</h1><ul><li><p>文献</p><ul><li><p>[2019 CVPR] Deep Plug-and-Play Super-Resolution for Arbitrary Blur Kernels </p><p>提出了一个新的SR degradation模型：ADMM和DNN的结合</p></li></ul></li></ul><h1 id="待读文章"><a href="#待读文章" class="headerlink" title="待读文章"></a>待读文章</h1><ul><li>Fooling automated surveillance cameras: adversarial patches to attack person detection（对抗性补丁）<ul><li><a href="https://www.toutiao.com/i6683309485538148878/?tt_from=weixin_moments&amp;utm_campaign=client_share&amp;wxshare_count=2&amp;from=timeline&amp;share_type=original&amp;timestamp=1556438502&amp;app=news_article&amp;utm_source=weixin_moments&amp;isappinstalled=0&amp;utm_medium=toutiao_android&amp;req_id=20190428160142010022056040158C1D8&amp;group_id=6683309485538148878&amp;pbid=6684376147831522823" target="_blank" rel="noopener">微信推送：包括论文地址和代码地址</a></li><li><strong>对抗性补丁”(adversarial patch)</strong>，正是这块补丁 “欺骗” 了 AI 系统</li></ul></li></ul><h1 id="如何写一篇优秀的论文"><a href="#如何写一篇优秀的论文" class="headerlink" title="如何写一篇优秀的论文"></a>如何写一篇优秀的论文</h1><p>1.紧跟细分领域研究前沿，确定研究角度</p><p>要做到这一点，最简单的方法是找一篇权威的综述类文章，可以是中文的，最好是英文的。根据综述中提到的作者、引用的文献，不断抽丝拨茧，去搜索下载原文进行研读，并且<strong>形成你自己对这个领域的文献综述</strong>。</p><p>2.熟练掌握一套实证研究方法和工具</p><p>3.不断模仿优秀的论文</p><p>如果你想在A类中文核心期刊上发表论文，那么你就必须要在《管理世界》《管理评论》等A类期刊上下载优秀论文，模仿他们的遣词用句，假设推导、假设检验、研究方法、结果探讨等等。</p><p>4.永远记住：一切初稿都是狗屎，修改一篇文章远比写一篇新的文章付出的心血要多。</p><p>一篇文章写完后，千万不要急需发表，修改工作十分重要。首先，打印出来，自己逐句逐字认认真真通读一遍，把不通顺的语句，错别字，标点符号等全部改正，保证不出现低级错误。</p><p>5.保持足够的耐心</p><h1 id="论文表达摘录"><a href="#论文表达摘录" class="headerlink" title="论文表达摘录"></a>论文表达摘录</h1><p><a href="https://wenku.baidu.com/view/657973c9a1c7aa00b52acb09.html" target="_blank" rel="noopener">论文句式摘要</a></p><p><a href="https://wenku.baidu.com/view/c545632027284b73f24250cc?pcf=2&amp;re=view" target="_blank" rel="noopener">英文科技写作句型和词汇表达总结(2010-)</a></p><ul><li><p>插入语</p><ul><li><p>有必要提一句 </p><p>It’s necessary to mention that；For completion, we remark that…</p></li><li><p>值得注意的是</p><p>It should be noted that; It is noteworthy that;It’s worth nothing that; It must be noted that;Significantly</p></li></ul></li><li><p>说贡献</p><ul><li>To the best of our knowledge, the deﬁnition of discrete TV-seminorm (3) as well as the role of the Raviart–Thomas ﬁnite element space to establish dual representation (4) are novel contributions of the present work.</li></ul></li><li><p>描述一个方法</p><ul><li><p>改造性强 </p><p>The primal-dual algorithm proposed in this paper can be<br><strong>easily adapted to</strong> different problems, is easy to implement and can be effectively accelerated on parallel hardware such as graphics processing units (GPUs). </p></li><li><p>评论一个方法的影响力大/效果好</p><p>achieve/provide/reach remarkable performance on the .. problem</p><p>is an efficient network that provide an end-to-end mapping/estimation between the ..</p></li></ul></li><li><p>很多方法被提出</p><p><strong>To avoid</strong> the heuristic edge selection step, <strong>numerous algorithms</strong> based on natural image prior <strong>have been proposed,</strong> including normalized sparsity [16], L0 gradients [38] and dark channel prior [27]. </p><p>Recent <strong>years have witnessed significant advances</strong> in sin-<br>gle image deblurring. We focus our discussion on recent optimization-based and learning-based methods.</p><p>Thus, <strong>it is of great interest to develop</strong> a general image prior which is able to deal with different scenarios with the MAP framework</p></li><li><p>图片名称</p><p>Figure 7: Some examples of RCF. <strong>From top to bottom:</strong> BSDS500 [2], NYUD [49], Multicue-Boundary [41], and Multicue-Edge [41]. <strong>From left to right:</strong> origin image, ground truth, RCF edge map, origin image, ground truth, and RCF edge map.</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> denoising </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>latex使用笔记</title>
      <link href="/p/5904.html"/>
      <url>/p/5904.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>latex使用笔记</p></blockquote><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.douban.com/note/264288981/" target="_blank" rel="noopener">学术写作利器——LaTeX入门笔记整理（不定期更新，附加使用心得)</a></p><h1 id="特殊符号"><a href="#特殊符号" class="headerlink" title="特殊符号"></a>特殊符号</h1><p>$8^{\circ}$: 8^{\circ}  (可以通过自定义来简化，\def\degree{${}^{\circ}$} ，90\degree )</p><p>$8^{\circ}C$: 8^{\circ}C</p><h1 id="自定义命令符"><a href="#自定义命令符" class="headerlink" title="自定义命令符"></a>自定义命令符</h1><ul><li><p>自定义颜色</p><p><a href="https://www.sojson.com/rgb.html" target="_blank" rel="noopener">RGB颜色查询</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">\usepackage&#123;xcolor&#125;</span><br><span class="line">\definecolor&#123;myorange&#125;&#123;rgb&#125;&#123;1, 0.44, 0.11&#125;</span><br><span class="line">\newcommand&#123;\grammar&#125;[1]&#123;\textcolor&#123;myorange&#125;&#123;#1&#125;&#125;</span><br></pre></td></tr></table></figure></li></ul><h1 id="画图"><a href="#画图" class="headerlink" title="画图"></a>画图</h1><ul><li><p>在线画图连接：</p><p><a href="https://www.draw.io/" target="_blank" rel="noopener">神经网络</a></p></li></ul><h1 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h1><ul><li><p>调整图片大小至页面宽度</p><p>\includegraphics[<strong>width=\textwidth</strong>]{images/EdgeNet2.png}</p></li><li><p>单栏图片插入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">% For one-column wide figures use</span><br><span class="line">\begin&#123;figure&#125;</span><br><span class="line">% Use the relevant command to insert your figure file.</span><br><span class="line">% For example, with the graphicx package use</span><br><span class="line">  \includegraphics&#123;example.eps&#125;</span><br><span class="line">% figure caption is below the figure</span><br><span class="line">\caption&#123;Please write your figure caption here&#125;</span><br><span class="line">\label&#123;fig:1&#125;       % Give a unique label</span><br><span class="line">\end&#123;figure&#125;</span><br></pre></td></tr></table></figure></li><li><p>双栏图片插入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">% For two-column wide figures use</span><br><span class="line">\begin&#123;figure*&#125;</span><br><span class="line">% Use the relevant command to insert your figure file.</span><br><span class="line">% For example, with the graphicx package use</span><br><span class="line">  \includegraphics[width=0.75\textwidth]&#123;example.eps&#125;</span><br><span class="line">% figure caption is below the figure</span><br><span class="line">\caption&#123;Please write your figure caption here&#125;</span><br><span class="line">\label&#123;fig:2&#125;       % Give a unique label</span><br><span class="line">\end&#123;figure*&#125;</span><br></pre></td></tr></table></figure></li><li><p>多张图片并列插入</p><p>使用subfigure，如果想换行，在图片后面加上回车键</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;figure&#125;[htbp]</span><br><span class="line">\centering</span><br><span class="line">\subfigure[pic1.]&#123;</span><br><span class="line">\begin&#123;minipage&#125;[t]&#123;0.25\linewidth&#125;</span><br><span class="line">\centering</span><br><span class="line">\includegraphics[width=1in]&#123;images/MSRB1.png&#125;</span><br><span class="line">%\caption&#123;fig1&#125;</span><br><span class="line">\end&#123;minipage&#125;%</span><br><span class="line">&#125;%</span><br><span class="line">\subfigure[pic2.]&#123;</span><br><span class="line">\begin&#123;minipage&#125;[t]&#123;0.25\linewidth&#125;</span><br><span class="line">\centering</span><br><span class="line">\includegraphics[width=1in]&#123;images/MSRB1.png&#125;</span><br><span class="line">%\caption&#123;fig2&#125;</span><br><span class="line">\end&#123;minipage&#125;%</span><br><span class="line">&#125;%</span><br><span class="line">[回车]</span><br><span class="line">\subfigure[pic3.]&#123;</span><br><span class="line">\begin&#123;minipage&#125;[t]&#123;0.25\linewidth&#125;</span><br><span class="line">\centering</span><br><span class="line">\includegraphics[width=1in]&#123;images/MSRB1.png&#125;</span><br><span class="line">%\caption&#123;fig2&#125;</span><br><span class="line">\end&#123;minipage&#125;</span><br><span class="line">&#125;%</span><br><span class="line">\subfigure[pic4.]&#123;</span><br><span class="line">\begin&#123;minipage&#125;[t]&#123;0.25\linewidth&#125;</span><br><span class="line">\centering</span><br><span class="line">\includegraphics[width=1in]&#123;images/MSRB1.png&#125;</span><br><span class="line">%\caption&#123;fig2&#125;</span><br><span class="line">\end&#123;minipage&#125;</span><br><span class="line">&#125;%</span><br><span class="line">[回车]</span><br><span class="line">\centering</span><br><span class="line">\caption&#123; pics&#125;</span><br><span class="line">\end&#123;figure&#125;</span><br></pre></td></tr></table></figure><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY%E2%9D%A4/006tNc79gy1g37p8vf4a0j30ks098gm1.jpg" alt="image-20190517171605725"></p></li><li><p>一列多张图</p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY%E2%9D%A4/006tNc79gy1g3ns17k15zj30y60owjxz.jpg" alt="Screen Shot 2019-05-26 at 1.22.47 PM"></p></li><li><p>去掉图片的序列号</p><p>利用minipage下的\centerline以及subfigure*。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">\documentclass[a4paper,UTF8]&#123;article&#125;</span><br><span class="line">\usepackage&#123;ctex&#125;</span><br><span class="line">\usepackage&#123;caption&#125;</span><br><span class="line">\usepackage&#123;graphicx&#125;</span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">\begin&#123;figure&#125;[ht]</span><br><span class="line">\begin&#123;minipage&#125;&#123;0.48\linewidth&#125;</span><br><span class="line">\centerline&#123;\includegraphics[width=1\textwidth]&#123;a1.jpg&#125;&#125;</span><br><span class="line">\centerline&#123;伤心图&#125;</span><br><span class="line">\end&#123;minipage&#125;</span><br><span class="line">\qquad</span><br><span class="line">\begin&#123;minipage&#125;&#123;0.48\linewidth&#125;</span><br><span class="line">\centerline&#123;\includegraphics[width=1\textwidth]&#123;a2.jpg&#125;&#125;</span><br><span class="line">\centerline&#123;开心图&#125;</span><br><span class="line">\end&#123;minipage&#125;</span><br><span class="line">\caption*&#123;都是表情图&#125;</span><br><span class="line">\end&#123;figure&#125;</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure></li><li><p><a href="https://blog.csdn.net/u011089523/article/details/83444612" target="_blank" rel="noopener">设置caption中的字体大小</a></p></li><li><p>控制图片插到的位置</p><p>其中[htbp]就是浮动格式 “h 当前位置。将图形放置在正文文本中给出该图形环境的地方。如果本页所剩的页面不够，这一参数将不起作用。 t 顶部。将图形放置在页面的顶部。</p><p> b 底部。将图形放置在页面的底部。 p 浮动页。将图形放置在一只允许有浮动对象的页面上。” </p></li></ul><h1 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h1><ul><li><p><a href="http://www.tablesgenerator.com/" target="_blank" rel="noopener">在线画表格</a>，转化成latex代码</p></li><li><p><a href="https://blog.csdn.net/JueChenYi/article/details/77116011" target="_blank" rel="noopener">参考博客</a></p></li><li><p>例子(摘自论文<a href="https://arxiv.org/pdf/1710.04026.pdf" target="_blank" rel="noopener">FFDNet</a>)</p><p><a href="https://ws1.sinaimg.cn/large/006tNc79gy1g37p8ux09hj313c0rgk7f.jpg" target="_blank" rel="noopener">https://ws1.sinaimg.cn/large/006tNc79gy1g37p8ux09hj313c0rgk7f.jpg</a></p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY%E2%9D%A4/006tNc79gy1g37p8ux09hj313c0rgk7f.jpg" alt="image-20190519150204300"></p></li><li><p><a href="https://blog.csdn.net/chichoxian/article/details/79692593" target="_blank" rel="noopener">三线表</a></p></li><li><p>latex和matlab表格的连接</p><ul><li><a href="https://www.ilovematlab.cn/thread-246712-1-1.html" target="_blank" rel="noopener">matlab的输出模式规范成[&amp;&amp;\\\]的模式</a></li><li><a href="https://blog.csdn.net/robert_chen1988/article/details/79121377" target="_blank" rel="noopener">latex引用包，把csv读取成表格模式</a></li></ul></li><li><p><a href="https://blog.csdn.net/wh1312142954/article/details/80641292" target="_blank" rel="noopener">表格溢出</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;table*&#125;[!t]</span><br><span class="line">\centering</span><br><span class="line">\caption&#123;***&#125;</span><br><span class="line">\label&#123;***&#125;</span><br><span class="line">\resizebox&#123;\textwidth&#125;&#123;!&#125;&#123;</span><br><span class="line">\begin&#123;tabular&#125;&#123;***&#125;</span><br><span class="line">***</span><br><span class="line">\end&#123;tabular&#125;&#125;</span><br><span class="line">\end&#123;table*&#125;</span><br></pre></td></tr></table></figure></li></ul><h1 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h1><ul><li><p>公式溢出的问题</p><ul><li>\! 缩小间距</li><li>换行</li></ul></li><li><p>多行公式对齐，并显示一个序号</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">\documentclass[review]&#123;elsarticle&#125;</span><br><span class="line">\usepackage&#123;amsmath&#125;</span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">\begin&#123;equation&#125; \label&#123;eqn2&#125;</span><br><span class="line">  \begin&#123;split&#125;</span><br><span class="line">  n&amp;=\left[\frac&#123;b-a&#125;&#123;0.01&#125;\right]+1,    \\</span><br><span class="line">  S&amp;=\frac&#123;1&#125;&#123;n&#125;\sum\limits_&#123;j=1&#125;^&#123;n&#125;(\lambda_&#123;0j&#125;-\lambda_&#123;j&#125;).</span><br><span class="line">  \end&#123;split&#125;</span><br><span class="line">\end&#123;equation&#125;</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdn.net/20170903144702234?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXkyMDExNTU0OQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="img"></p></li></ul><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><ul><li><p>同一处引用多个参考文献</p><p>方法一：加包 \usepackage{cite}  ,处理多个文献命令：\cite{name1,name2,…,nameN}</p><p>方法二：不加包，\cite{name1},\cite{name2}.</p></li><li><p>数学公式的引用</p><p>加载 amsmath 工具包，使用 \eqref  命令。效果如下：</p><p>As the choice of parameter in the TV model (3)</p></li></ul><h1 id="中文编译"><a href="#中文编译" class="headerlink" title="中文编译"></a>中文编译</h1><p><a href="https://www.overleaf.com/learn/latex/Chinese" target="_blank" rel="noopener">sharelatex官方文件</a></p><ol><li><p>点击menu，将编译器转换XeLatex</p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/FYY%E2%9D%A4/006tNc79gy1g3ns16yf03j31im0su12g.jpg" alt="image-20190530181843298"></p></li></ol><h1 id="debug"><a href="#debug" class="headerlink" title="debug"></a>debug</h1><ul><li><p>begin{equation*} 环境不存在的问题</p><p>\usepackage{amsmath}</p></li><li><p>\bibliography{reference.bib}没有反应的时候</p><p>可能是因为没有定义引用的格式</p><p>\bibliographystyle{spbasic}      % basic style, author-year citations<br>\bibliographystyle{spmpsci}      % mathematics and physical sciences<br>\bibliographystyle{spphys}       % APS-like style for physics</p></li><li><p>图片和表格引用的时候显示不对</p><p>Figure \ref{}; Table \ref{}</p><p>解决：因为把\label插在了\caption之前，默认需要在\caption之后。</p></li></ul><ul><li><p>图片插入到了reference中</p><p>将htbp转化成H, 不可以是h. 如：\begin{figure}[H]</p><p>需要头文件：\usepackage{float}</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 软件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> latex </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习网络学习</title>
      <link href="/p/b08c.html"/>
      <url>/p/b08c.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>网络架构学习</p></blockquote><h1 id="课程链接"><a href="#课程链接" class="headerlink" title="课程链接"></a>课程链接</h1><p>-<a href="https://mp.weixin.qq.com/s/0eKvZy_L_Ql99IJTmCh-VA" target="_blank" rel="noopener">tensorflow中文版教程</a></p><h1 id="最新资讯和链接"><a href="#最新资讯和链接" class="headerlink" title="最新资讯和链接"></a>最新资讯和链接</h1><p><a href="https://mp.weixin.qq.com/s/27pcokMV0eYJubPoJjq5hg" target="_blank" rel="noopener">近期必读的10篇ACL 2019【图神经网络（GNN）+NLP】相关论文和代码</a></p><h1 id="卷积神经网络CNN"><a href="#卷积神经网络CNN" class="headerlink" title="卷积神经网络CNN"></a>卷积神经网络CNN</h1><ul><li><p>文献</p><p><strong>AlexNet</strong></p><p><strong>VGG</strong></p><p><strong>ResNet</strong> He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition. InProceedings of the IEEE conference on computer vision and pattern recognition 2016 (pp. 770-778).</p></li></ul><h3 id="Alex-net"><a href="#Alex-net" class="headerlink" title="Alex net"></a>Alex net</h3><p><a href="https://blog.csdn.net/u012679707/article/details/80870625" target="_blank" rel="noopener">Alex net之前的工作以及AlexNet中的创新点</a></p><p><a href="https://zhuanlan.zhihu.com/p/22734982" target="_blank" rel="noopener">论文笔记</a></p><h3 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h3><h3 id="RESNET"><a href="#RESNET" class="headerlink" title="RESNET"></a>RESNET</h3><p>ResNet, 2015, 微软亚洲研究院的何凯明等人提出</p><p>He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition. InProceedings of the IEEE conference on computer vision and pattern recognition 2016 (pp. 770-778).</p><p><strong>主要贡献：</strong>网络层数从32层提到152层</p><p><strong>特点：</strong></p><ol><li><p>网络较瘦，控制了参数数量；</p></li><li><p>存在明显层级，特征图个数逐层递进，保证输出特征表达能力；</p></li><li><p>使用了较少的池化层，大量使用下采样，提高传播效率；</p></li><li><p>没有使用Dropout，利用BN和全局平均池化进行正则化，加快了训练速度；</p></li><li><p>层数较高时减少了3x3卷积个数，并用1x1卷积控制了3x3卷积的输入输出特征图数量，称这种结构为“瓶颈”(bottleneck)。</p></li></ol><p><strong>残差单元：</strong> 克服了梯度消失的问题</p><h2 id="卷积神经网络中的组成"><a href="#卷积神经网络中的组成" class="headerlink" title="卷积神经网络中的组成"></a>卷积神经网络中的组成</h2><h4 id="步长和补零"><a href="#步长和补零" class="headerlink" title="步长和补零"></a>步长和补零</h4><p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1g30q089fiwj30s00f0tbp.jpg" alt="image-20190116203754878"></p><h4 id="卷积核：三维结构"><a href="#卷积核：三维结构" class="headerlink" title="卷积核：三维结构"></a>卷积核：三维结构</h4><p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1g30q07ezv5j30q40l8n0w.jpg" alt="image-20190116201711290"></p><h4 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h4><p>池化层的输入一般来源于上一个卷积层，主要作用是提供了很强的鲁棒性（例如max-pooling是取一小块区域中的最大值，此时若此区域中的其他值略有变化，或者图像稍有平移，pooling后的结果仍不变），并且减少了参数的数量，防止过拟合现象的发生。池化层一般没有参数，所以反向传播的时候，只需对输入参数求导，不需要进行权值更新。</p><h4 id="Inception模块"><a href="#Inception模块" class="headerlink" title="Inception模块"></a>Inception模块</h4><p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1g30q06hft4j316u0u07ea.jpg" alt="image-20190116215438302"></p><h4 id="bottle-layer的作用"><a href="#bottle-layer的作用" class="headerlink" title="bottle layer的作用"></a>bottle layer的作用</h4><h1 id="循环神经网络RNN-4-30"><a href="#循环神经网络RNN-4-30" class="headerlink" title="循环神经网络RNN 4.30"></a>循环神经网络RNN 4.30</h1><ul><li><p>阅读</p><ul><li><a href="https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html" target="_blank" rel="noopener">Pytorch Example: A character-level RNN 识别名字的种类</a></li></ul></li><li><p>前馈神经网络的局限</p><ul><li><p>节点之间没有联系</p></li><li><p>输入和输出的维度固定。无法处理变长的序列数据？维度改变的时序问题</p><p>时序的长度是什么？一个字符串的长度？</p></li><li><p>每次输出只依赖于当前输入</p></li></ul></li><li><p>循环神经网络的难点</p><p>按照时序反向传播的时候存在梯度爆炸和梯度消失。解决办法：引入门控机制。</p></li><li><p><a href="https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html" target="_blank" rel="noopener">A character-level RNN </a></p></li></ul><h1 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h1><h1 id="对抗神经网络GAN"><a href="#对抗神经网络GAN" class="headerlink" title="对抗神经网络GAN"></a>对抗神经网络GAN</h1><ul><li><p>阅读</p><ul><li><p><a href="https://www.msra.cn/zh-cn/news/features/gan-20170511" target="_blank" rel="noopener">什么是生成式对抗网络GAN</a></p></li><li><p><a href="http://www.sohu.com/a/130252639_473283" target="_blank" rel="noopener">2017王飞跃等：生成式对抗网络 GAN 的研究进展与展望</a><a href="https://www.msra.cn/zh-cn/news/features/gan-20170511" target="_blank" rel="noopener">https://www.msra.cn/zh-cn/news/features/gan-20170511</a>)</p></li><li><p><a href="https://arxiv.org/pdf/1904.08653.pdf" target="_blank" rel="noopener">2019论文：图像补丁躲过图像识别</a>（19.05.02）<a href="https://gitlab.com/EAVISE/adversarial-yolo" target="_blank" rel="noopener">code</a></p></li></ul></li><li><p><strong>生成对抗网络的工作原理</strong>：一个是摄影师（男生），一个是摄影师的女朋友（女生）。男生一直试图拍出像众多优秀摄影师一样的好照片，而女生一直以挑剔的眼光找出“自己男朋友”拍的照片和“别人家的男朋友”拍的照片的区别。于是两者的交流过程类似于：男生拍一些照片 -&gt;女生分辨男生拍的照片和自己喜欢的照片的区别-&gt;男生根据反馈改进自己的技术，拍新的照片-&gt;女生根据新的照片继续提出改进意见-&gt;……，这个过程直到均衡出现：即女生不能再分辨出“自己男朋友”拍的照片和“别人家的男朋友”拍的照片的区别。</p></li><li><p><strong>生成对抗网络的工作原理</strong>：以图像生成模型举例。假设我们有一个图片生成模型（generator），它的目标是生成一张真实的图片。与此同时我们有一个图像判别模型（discriminator），它的目标是能够正确判别一张图片是生成出来的还是真实存在的。那么如果我们把刚才的场景映射成图片生成模型和判别模型之间的博弈，就变成了如下模式：生成模型生成一些图片-&gt;判别模型学习区分生成的图片和真实图片-&gt;生成模型根据判别模型改进自己，生成新的图片-&gt;····<strong>（训练过程由生成模型和判别模型组成）</strong></p></li><li><p>最简单的数据<strong>生成模型</strong>：如果有数据集S={x1，…xn}，假设这些数据的分布P{X}服从g(x;θ)，在观测数据上通过最大化似然函数得到θ的值，即最大似然法：<script type="math/tex">\max _{\theta} \sum_{i=1}^{n} \log g\left(x_{i} ; \theta\right)​</script>。当这个<strong>生成模型是</strong>神经网络的时候，就是<strong>生成式对抗网络（GAN）</strong></p></li><li><p>文献综述</p></li></ul><h1 id="网络绘图"><a href="#网络绘图" class="headerlink" title="网络绘图"></a>网络绘图</h1><p>画图软件</p><ul><li><p><strong>Visio</strong></p><p><img src="../../../../Library/Application Support/typora-user-images/image-20190514135849553.png" alt="image-20190514135849553"></p><p><img src="../../../../Library/Application Support/typora-user-images/image-20190514135858557.png" alt="image-20190514135858557"></p></li><li><p><strong>NN-SVG</strong>，适合卷积神经网络, <a href="http://alexlenail.me/NN-SVG/LeNet.html" target="_blank" rel="noopener">在线链接</a></p><p><img src="../../../../Library/Application Support/typora-user-images/image-20190514135655177.png" alt="image-20190514135655177"></p></li><li><p><strong>PlotNeuralNet</strong>，基于Latex，<a href="github链接-&lt;https://github.com/HarisIqbal88/PlotNeuralNet">github的链接</a>，导出pdf</p><p><img src="../../../../Library/Application Support/typora-user-images/image-20190514133839750.png" alt="image-20190514133839750"></p></li><li><p>提供很多<strong>模版</strong>的<strong>在线</strong>画图<a href="https://www.draw.io/" target="_blank" rel="noopener">网页</a></p><p><img src="../../../../Library/Application Support/typora-user-images/image-20190514135511723.png" alt="image-20190514135511723"></p></li></ul><p>神经网络的例子</p><ul><li><p>Edge detection: HED</p><p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1g30r10uhfrj30n60q4k2e.jpg" alt="Edge detection: HED"></p><p>multi-scale: 不同大小的卷积核</p><p>multi-level:</p><p>receptive field: 网络层次越深，越大，越抽象</p><p>weighted-fusion layer:</p></li><li><p>MSRB</p></li></ul><ul><li><p>MSRB for SR</p><p><img src="../../../../Library/Application Support/typora-user-images/image-20190514132028216.png" alt="image-20190514132028216"></p></li><li><p>MSRB for denoising</p><p><img src="../../../../Library/Application Support/typora-user-images/image-20190514131803277.png" alt="image-20190514131803277"></p></li><li><p>SR: MSRN</p></li></ul><h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><ul><li><p>DNN（Deep Neural Network）和Deep CNN的区别</p><p>过去传统的神经网络ANN（Artifical Neural Network），都是层次较少的网络型结构，所以又被称为浅层网络（shallow neural network），DNN与传统SNN的区别就在于其网络层次结构更多，等复杂，因此由于其层次更多，在图论上说就是图的深度更深，所以被冠名为深度神经网络（Deep Neural Network)</p><p>Deep CNN是使用了卷积的网络。DNN是最基本的网络结构。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch学习笔记</title>
      <link href="/p/ef8a.html"/>
      <url>/p/ef8a.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>Pytorch学习笔记——随时更新</p></blockquote><h1 id="Pytorch环境"><a href="#Pytorch环境" class="headerlink" title="Pytorch环境"></a>Pytorch环境</h1><ul><li><p>查看pytorch版本</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(torch.__version__)</span><br><span class="line"><span class="number">0.4</span><span class="number">.0</span></span><br><span class="line"><span class="comment"># 更新之后</span></span><br></pre></td></tr></table></figure></li><li><p>更新pytorch</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda update pytorch torchvision</span><br></pre></td></tr></table></figure></li></ul><p>Backward Propagation 算法</p><p><a href="https://blog.csdn.net/u010976453/article/details/54381248" target="_blank" rel="noopener">机器学习中的线性代数之矩阵求导</a></p><p><a href="https://blog.csdn.net/xidianliutingting/article/details/51673207" target="_blank" rel="noopener">向量，标量对向量求导数</a></p><h1 id="GPU"><a href="#GPU" class="headerlink" title="GPU"></a>GPU</h1><ol><li><p>查看cuda以及pytorch版本</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(torch.cuda.current_device()) </span><br><span class="line"><span class="keyword">import</span> pytorch</span><br><span class="line">print(torch.__version__)</span><br></pre></td></tr></table></figure></li><li><p>指定cuda</p></li><li><p>指定torch的设备</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">torch.device(<span class="string">'cuda'</span>,<span class="number">0</span>) <span class="keyword">or</span> torch.device(<span class="string">'cuda:0'</span>) <span class="keyword">or</span></span><br><span class="line">var = torch.device(<span class="string">'cuda:0'</span>)</span><br><span class="line">a = torch.randn((<span class="number">2</span>,<span class="number">3</span>),device=var)</span><br><span class="line">b = torch.randn(<span class="number">2</span>,<span class="number">3</span>).to_sparse().requires_grad_(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">torch.randn((<span class="number">2</span>,<span class="number">3</span>), <span class="string">'cuda:1'</span>), </span><br><span class="line"></span><br><span class="line">cuda1= torch.device(<span class="string">'cuda:1'</span>)， torch.randn((<span class="number">2</span>,<span class="number">3</span>), device=cuda1)</span><br></pre></td></tr></table></figure></li><li><p><a href="https://zhuanlan.zhihu.com/p/31936740" target="_blank" rel="noopener">数据迁徙：将Pytorch模型从CPU转换成GPU</a></p></li></ol><h1 id="Tensor张量"><a href="#Tensor张量" class="headerlink" title="Tensor张量"></a>Tensor张量</h1><ol><li><p>通过pytorch创建张量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(M,N）.type(dtype)</span><br><span class="line"><span class="comment"># 原来是通过numpy创建数组, numpy提供了很多矩阵数学计算</span></span><br><span class="line">x = np.random.randn(N, I)</span><br></pre></td></tr></table></figure></li><li><p>将张量放在GPU上<img src="https://ws4.sinaimg.cn/large/006tNc79gy1g30qn2yrggj30mi09z3zv.jpg" alt="tensor"></p></li><li><p>张量在cpu和gpu之间的转换</p><p>从cpu –&gt; gpu，使用<code>data.cuda()</code><br>从gpu –&gt; cpu，使用<code>data.cpu()</code></p></li><li><p><a href="randonhttps://blog.csdn.net/g11d111/article/details/80896137" target="_blank" rel="noopener">张量之间的转换</a></p></li><li><p>tensor的创建</p><p>直接创建：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.tensor([..]).type(..)</span><br><span class="line">torch.FloatTensor()</span><br></pre></td></tr></table></figure><p>创建随机矩阵：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dtype = torch.Floatensor </span><br><span class="line">dtype = torch.cuda.Floatensor </span><br><span class="line">torch.randn((M,N),type(dtype)</span><br></pre></td></tr></table></figure><p> 从其他数据类型:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = [[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]]</span><br><span class="line">tensor = torch.FloatTensor(data)</span><br></pre></td></tr></table></figure></li><li><p>找出其中最大元素</p><p>torch.max(input)</p></li></ol><h1 id="矩阵操作"><a href="#矩阵操作" class="headerlink" title="矩阵操作"></a>矩阵操作</h1><ul><li><p>增加维度</p></li><li><p>减少维度</p></li></ul><h1 id="Pytorch可视化"><a href="#Pytorch可视化" class="headerlink" title="Pytorch可视化"></a>Pytorch可视化</h1><p>利用tensorboard画图</p><ol><li><p><a href="https://blog.csdn.net/weixin_37978645/article/details/80807156" target="_blank" rel="noopener">通过logger文件可视化训练过程</a>、<a href="https://www.tensorflow.org/guide/summaries_and_tensorboard?hl=zh-cn" target="_blank" rel="noopener">官网</a>、<a href="https://blog.csdn.net/u010099080/article/details/77426577" target="_blank" rel="noopener">别人写的tensorflow下比较具体的可视化</a></p></li><li><p>出现的问题</p><p>端口冲突通过指定端口解决：</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=/tmp   --port=8008 <span class="comment">#绝对路径</span></span><br><span class="line">tensorboard --logdir=./tmp  --port=8008 <span class="comment">#相对路径</span></span><br></pre></td></tr></table></figure><p> <a href="https://stackoverflow.com/questions/45095820/tensorboard-command-not-found?rq=1" target="_blank" rel="noopener">tensorbard命令无法找到</a>：</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m tensorboard.main --logdir=~/my/training/dir</span><br></pre></td></tr></table></figure><p>进入目录：</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip show tensorflow</span><br><span class="line"><span class="built_in">cd</span> /home/abc/xy/.<span class="built_in">local</span>/lib/python2.7/site-packages</span><br><span class="line">python main.py --logdir=/path/to/log_file/</span><br></pre></td></tr></table></figure><p> 路径的名称要小心，路径得是根目录, 不需要引号</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yyfang@mai:~$  ge/ERRNet_Code/logs --port=8008</span><br></pre></td></tr></table></figure></li><li><p>可视化</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> iteration % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">    print(<span class="string">"===&gt; Epoch[&#123;&#125;](&#123;&#125;/&#123;&#125;): Loss: &#123;:.6f&#125;"</span>.format(epoch, iteration, len(training_data_loader),loss.data.item()))</span><br><span class="line">    info = &#123; <span class="string">'loss'</span>: loss.data.item()&#125;</span><br><span class="line">    itera = (epoch<span class="number">-1</span>)*len(training_data_loader)+iteration</span><br><span class="line">    <span class="keyword">for</span> tag, value <span class="keyword">in</span> info.items():</span><br><span class="line">        logger.scalar_summary(tag, value, itera)</span><br><span class="line">        <span class="keyword">for</span> tag, value <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">            <span class="comment">#                 print(value.grad)</span></span><br><span class="line">            logger.histo_summary(tag, to_np(value), itera)</span><br><span class="line">            logger.histo_summary(tag+<span class="string">'/grad'</span>, to_np(value.grad), iteration)               </span><br><span class="line"></span><br><span class="line">            images = input  * <span class="number">255.</span> <span class="comment"># ?[0,1]?????[0,255]??</span></span><br><span class="line">            images[images &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">            images[images &gt; <span class="number">255.</span>] = <span class="number">255.</span></span><br><span class="line">            a =to_np(images.view(<span class="number">-1</span>, <span class="number">64</span>, <span class="number">64</span>)[:<span class="number">8</span>])</span><br><span class="line">            <span class="comment">#             info_input = &#123;'input': to_np(images.view(-1, 64, 64)[:2])&#125;</span></span><br><span class="line">            imagelabel = label  * <span class="number">255.</span> <span class="comment"># ?[0,1]?????[0,255]??</span></span><br><span class="line">            imagelabel[imagelabel &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">            imagelabel[imagelabel &gt; <span class="number">255.</span>] = <span class="number">255.</span></span><br><span class="line">            b = to_np(imagelabel.view(<span class="number">-1</span>, <span class="number">64</span>, <span class="number">64</span>)[:<span class="number">8</span>])</span><br><span class="line">            c = np.hstack((a,b))</span><br><span class="line">            <span class="comment">#             print(images)</span></span><br><span class="line">            info_label = &#123;<span class="string">'inpput/label'</span>: c&#125;    </span><br><span class="line">            <span class="keyword">for</span> tag, images <span class="keyword">in</span> info_label.items():</span><br><span class="line">                logger.image_summary(tag, images, itera)</span><br><span class="line">                <span class="comment">#             for tag, images in info_label.items():</span></span><br><span class="line">                <span class="comment">#                  logger.image_summary(tag, images, iteration)</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> iteration % <span class="number">5000</span> == <span class="number">0</span>:</span><br><span class="line">                    number = opt.number</span><br><span class="line">                    save_checkpoint_iter(model, number)</span><br><span class="line">                    opt.number += <span class="number">1</span></span><br></pre></td></tr></table></figure><h1 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h1><ol><li><p>训练集(train set) 验证集(validation set) 测试集(test set）</p><p>training set： 用来训练模型</p><p>validation set : 用来做model selection（往往我们需要对多种模型进行训练，训练完之后就会得到多个模型的结果，我们希望从这些训练好的模型中选择最适合的模型）</p><p>test set : 用来评估所选出来的model的实际性能</p></li><li><p>几个常用数据集</p><p>BSD500： </p><p>DIV2K：</p></li></ol><h1 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h1><ul><li><p>矩阵相乘/点乘</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">data = [[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]]</span><br><span class="line">tensor = torch.FloatTensor(data)</span><br><span class="line"><span class="comment"># numpy</span></span><br><span class="line">np.matmual(data, data)</span><br><span class="line"><span class="comment"># tensor</span></span><br><span class="line">torch.mm(tensor, tensor) <span class="comment"># 矩阵相乘</span></span><br><span class="line">tensor.mm(tensor.t())</span><br><span class="line">torch.mul(tensor,tenor.t()) <span class="comment">#点乘</span></span><br><span class="line">tensor.mul(tensor)</span><br></pre></td></tr></table></figure></li><li><p>将数组截取到一个区间</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">h_relu = h.clamp(min=<span class="number">0</span>)</span><br><span class="line">h_relu2  = torch.clamp(h, min=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></li><li><p><a href="https://docs.fast.ai/torch_core.html#to_np" target="_blank" rel="noopener">To_np函数</a>: 转化数据类型</p><p>包含在库<a href="https://docs.fast.ai/overview.html#core" target="_blank" rel="noopener">fastai</a>中</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fastai.basics <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure></li></ul><h1 id="网络结构-nn包"><a href="#网络结构-nn包" class="headerlink" title="网络结构-nn包"></a>网络结构-nn包</h1><p><a href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#linear-layers" target="_blank" rel="noopener">torch_nn中文文档</a></p><ul><li><p>torch.nn的线形层</p></li><li><p>torch.nn的卷积层</p><p>卷积核的大小: [out_Channel, in_Channel, kernel_size, kernel_size]</p><p>bias的大小:[out_Channel]</p></li><li><p>继承nn.modle自定义模块</p></li><li><p>问题</p><ul><li><p>如何初始化model中的参数</p></li><li><p>为什么需要model.zero_grad之后再backward(), 例如</p><p>model.zero_grad()</p><p>optimizer.zero_grad()</p></li></ul></li></ul><h1 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h1><p>optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)</p><h1 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h1><ul><li>如何自定义损失函数</li></ul><h1 id="并行运算Parallel"><a href="#并行运算Parallel" class="headerlink" title="并行运算Parallel"></a>并行运算Parallel</h1><p>pytorch中如果使用DataParallel，<strong>那么保存的模型key值前面会多出’modules.’</strong>，这样如果训练的时候使用的是多GPU，而测试的时候使用的是单GPU，模型载入就会出现问题。</p><h1 id="例子：设置GPU和预训练模型"><a href="#例子：设置GPU和预训练模型" class="headerlink" title="例子：设置GPU和预训练模型"></a>例子：设置GPU和预训练模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"> criterion =  nn.MSELoss(size_average=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置GPU</span></span><br><span class="line"> print(<span class="string">"===&gt; Setting GPU"</span>)</span><br><span class="line"> <span class="keyword">if</span> cuda:</span><br><span class="line">     <span class="comment"># 调用多个GPU</span></span><br><span class="line">     model = nn.DataParallel(model, device_ids=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]).cuda()</span><br><span class="line">     <span class="comment"># 调用单个GPU model = model.cuda()</span></span><br><span class="line">     criterion = criterion.cuda()</span><br><span class="line"> <span class="keyword">else</span>:</span><br><span class="line">     model = model.cpu()</span><br><span class="line"></span><br><span class="line"> <span class="comment"># 加载预预训练好的模型及权重</span></span><br><span class="line"> <span class="keyword">if</span> opt.pretrained:</span><br><span class="line">     <span class="keyword">if</span> os.path.isfile(opt.pretrained):</span><br><span class="line">         print(<span class="string">"=&gt; loading model '&#123;&#125;'"</span>.format(opt.pretrained))</span><br><span class="line">         weights = torch.load(opt.pretrained)</span><br><span class="line">         model.load_state_dict(weights[<span class="string">'model'</span>].state_dict())</span><br><span class="line">     <span class="keyword">else</span>:</span><br><span class="line">         print(<span class="string">"=&gt; no model found at '&#123;&#125;'"</span>.format(opt.pretrained))</span><br><span class="line">         </span><br><span class="line"> <span class="comment"># 保存模型的参数</span></span><br><span class="line"> <span class="comment"># Save checkpoint</span></span><br><span class="line">     save_file = os.path.join(TMP_DIR, <span class="string">'checkpoint_epoch&#123;&#125;.pth'</span>.format(epoch))</span><br><span class="line">     save_checkpoint(&#123;</span><br><span class="line">         <span class="string">'epoch'</span>: epoch,</span><br><span class="line">         <span class="string">'state_dict'</span>: model.state_dict(),</span><br><span class="line">         <span class="string">'optimizer'</span>: optimizer.state_dict()</span><br><span class="line">                      &#125;, filename=save_file)</span><br></pre></td></tr></table></figure><h1 id="Debug"><a href="#Debug" class="headerlink" title="Debug"></a>Debug</h1><ul><li><p>Anaconda中，import和实际的不符</p><p>Anaconda清除历史，否则同一个格子刷新，并不会影响前面已经import的内容</p></li><li><p>torch版本带来的bug</p><p>loss.data[0] -&gt;loss.data.item()</p></li><li><p>Mac air(未解决)</p><p>载入模型参数时报错（在ubuntu下不报错，ubuntu的版本是1.0.1.post2, air下是0.4.0）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AttributeError: Can&apos;t get attribute &apos;_rebuild_parameter&apos; on &lt;module &apos;torch._utils&apos; from &apos;/Users/yingyingfang/anaconda3/lib/python3.6/site-packages/torch/_utils.py&apos;&gt;</span><br></pre></td></tr></table></figure></li><li><p>Ubuntu下训练RCF模型时报错（解决）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">expected object of backend cpu but got backend cuda <span class="keyword">for</span> argument <span class="comment">#2 'weight'</span></span><br><span class="line"><span class="comment"># 解决办法</span></span><br><span class="line">input=input.cuda()</span><br><span class="line">net = net.cuda()</span><br><span class="line">net(input)</span><br></pre></td></tr></table></figure></li><li><p>如何提高训练速度</p><ul><li>并行运算</li></ul></li><li><p>RuntimeError: Input type (torch.cuda.DoubleTensor) and weight type (torch.cuda.FloatTensor) should be the same</p><p>产生原因：创建了一个高斯随机分布之后？</p><p>解决办法：将数据类型转换成FloatTensor即可，如下，加一行代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_label_batch = torch.from_numpy(train_label_batch)</span><br><span class="line">train_label_batch = train_label_batch.type(torch.FloatTensor)  <span class="comment"># 转Float</span></span><br><span class="line">train_label_batch = train_label_batch.cuda()  <span class="comment"># 转cuda</span></span><br></pre></td></tr></table></figure></li><li><p><a href="https://discuss.pytorch.org/t/how-to-solve-the-problem-of-runtimeerror-all-tensors-must-be-on-devices-0/15198" target="_blank" rel="noopener">RuntimeError: all tensors must be on devices[0]</a></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu服务器</title>
      <link href="/p/6fe1.html"/>
      <url>/p/6fe1.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>服务器学习</p></blockquote><h1 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h1><p>在服务器里切换界面：alt+tab</p><h1 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h1><p>使用命令<a href></a>的命令。</p><p><a href="https://zhuanlan.zhihu.com/p/36801617" target="_blank" rel="noopener">看完这篇Linux基本的操作就会了</a></p><p><a href="https://github.com/jlevy/the-art-of-command-line/blob/master/README-zh.md" target="_blank" rel="noopener">https://github.com/jlevy/the-art-of-command-line/blob/master/README-zh.md</a></p><p><a href="https://linuxjourney.com/" target="_blank" rel="noopener">一个学习linux的网站</a></p><p><a href="https://github.com/skywind3000/awesome-cheatsheets/blob/master/languages/bash.sh" target="_blank" rel="noopener">命令行清单</a></p><h1 id="定义变量"><a href="#定义变量" class="headerlink" title="定义变量"></a>定义变量</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">your_name=&quot;qinjx&quot;</span><br></pre></td></tr></table></figure><p>用引号，等号旁边不能有空格。否则会被看成无法识别的命令</p><p>命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。<br>中间不能有空格，可以使用下划线（_）。<br>不能使用标点符号。<br>不能使用bash里的关键字（可用help命令查看保留关键字）</p><h1 id="文件处理"><a href="#文件处理" class="headerlink" title="文件处理"></a>文件处理</h1><h2 id="显示隐藏文件"><a href="#显示隐藏文件" class="headerlink" title="显示隐藏文件"></a>显示隐藏文件</h2><p>ls -a</p><p>桌面面可视化窗口，进入ctrl  + h ，则显示隐藏文件</p><h2 id="创建目录"><a href="#创建目录" class="headerlink" title="创建目录"></a>创建目录</h2><p>Mkdir</p><h2 id="复制删除文件"><a href="#复制删除文件" class="headerlink" title="复制删除文件"></a>复制删除文件</h2><p>cp</p><p>rm</p><h2 id="下载文件"><a href="#下载文件" class="headerlink" title="下载文件"></a>下载文件</h2><p>ftp下载</p><p>​    如果下载<a href="https://www.baidu.com/s?wd=ftp%E6%9C%8D%E5%8A%A1%E5%99%A8&amp;tn=24004469_oem_dg&amp;rsv_dl=gh_pl_sl_csd" target="_blank" rel="noopener">ftp服务器</a>上的文件，可以用ftp命令。然后用get命令下载文件</p><p>网址下载</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip</span><br><span class="line">1.Wget常用参数</span><br><span class="line">　　◆-b：后台下载，Wget默认的是把文件下载到当前目录。</span><br><span class="line">　　◆-O：将文件下载到指定的目录中。</span><br><span class="line">　　◆-P：保存文件之前先创建指定名称的目录。</span><br><span class="line">　　◆-t：尝试连接次数，当Wget无法与服务器建立连接时，尝试连接多少次。</span><br><span class="line">　　◆-c：断点续传，如果下载中断，那么连接恢复时会从上次断点开始下载。</span><br><span class="line">　　◆-r：使用递归下载</span><br></pre></td></tr></table></figure><p>git下载</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone &lt;https://github.com/LimBee/NTIRE2017.git&gt;</span><br></pre></td></tr></table></figure><h2 id="解压文件"><a href="#解压文件" class="headerlink" title="解压文件"></a>解压文件</h2><p><a href> Unzip </a> <a href="https://www.cnblogs.com/chinareny2k/archive/2010/01/05/1639468.html" target="_blank" rel="noopener">https://www.cnblogs.com/chinareny2k/archive/2010/01/05/1639468.html</a>)</p><p><a href="baidu.com">test</a> </p><h2 id="查看动态文件"><a href="#查看动态文件" class="headerlink" title="查看动态文件"></a>查看动态文件</h2><p><a href="http://www.cnblogs.com/peida/archive/2012/11/07/2758084.html" target="_blank" rel="noopener">tail命令</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1、tail -f filename</span><br><span class="line">说明：监视filename文件的尾部内容（默认10行，相当于增加参数 -n 10），刷新显示在屏幕上。退出，按下CTRL+C。</span><br><span class="line">2、tail -n 20 filename</span><br><span class="line">说明：显示filename最后20行。</span><br></pre></td></tr></table></figure><h2 id="文件编辑"><a href="#文件编辑" class="headerlink" title="文件编辑"></a>文件编辑</h2><h3 id="vim"><a href="#vim" class="headerlink" title="vim"></a>vim</h3><p>在vi中按u可以撤销一次操作; Ctrl+r 恢复上一步被撤销的操作</p><p> <a href="https://m.pythontab.com/article/47" target="_blank" rel="noopener">vim常用命令之多行注释和多行删除</a></p><h1 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h1><ul><li><p>命令</p><blockquote><p>fg、bg、jobs、&amp;、ctrl + z都是跟系统任务有关的，虽然现在基本上不怎么需要用到这些命令，但学会了也是很实用的</p><p>1.&amp; 最经常被用到</p><p>这个用在一个命令的最后，可以把这个命令放到后台执行</p><p>2.ctrl + z</p><p>可以将一个正在前台执行的命令放到后台，并且暂停</p><p>3.jobs</p><p>查看当前有多少在后台运行的命令</p><p>4.fg</p><p>将后台中的命令调至前台继续运行</p><p>如果后台中有多个命令，可以用 fg %jobnumber将选中的命令调出，%jobnumber是通过jobs命令查到的后台正在执行的命令的序号(不是pid)</p><p>5.bg</p><p>将一个在后台暂停的命令，变成继续执行</p><p>如果后台中有多个命令，可以用bg %jobnumber将选中的命令调出，%jobnumber是通过jobs命令查到的后台正在执行的命令的序号(不是pid)</p></blockquote></li></ul><h2 id="后台执行进程"><a href="#后台执行进程" class="headerlink" title="后台执行进程"></a>后台执行进程</h2><p><a href="https://blog.csdn.net/liuyanfeier/article/details/62422742" target="_blank" rel="noopener">linux后台执行命令：&amp;和nohup</a> </p><p>command &amp;：关掉屏幕，进程结束，不占用屏幕而已 </p><p>nohup commnd &amp;：真正在后台执行 </p><p>PS：需要用户交互的命令不要放在后台执行。 有大量的输出，就进行重定向。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yyfang@mai:~/Documents/Deeplearning_edge/ERRNet_edge/ERRNet_Code$ nohup python main.py --cuda --dataset=<span class="string">"../../../dataset/data_edge_35.h5"</span> &gt;result.txt 2&gt;&amp;1 &amp;</span><br><span class="line">[1] 22223</span><br></pre></td></tr></table></figure><p>显示最后的十行</p><h2 id="监视进程"><a href="#监视进程" class="headerlink" title="监视进程"></a>监视进程</h2><p><a href="https://blog.csdn.net/shenhuan1104/article/details/75808146" target="_blank" rel="noopener">https://blog.csdn.net/shenhuan1104/article/details/75808146</a></p><p>查看进程 ps -aux | grep xrdp</p><p>杀死进程 $ kill -s 9 进程号</p><p><strong>管道符“|”用来隔开两个命令，管道符左边命令的输出会作为管道符右边命令的输入。</strong></p><p>把ps的查询结果通过管道给grep查找包含特定字符串的进程。</p><p>$ ps -ef | grep firefox</p><h2 id="监视GPU"><a href="#监视GPU" class="headerlink" title="监视GPU"></a>监视GPU</h2><p>3.监视GPU的使用情况 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ nvidia-smi </span><br><span class="line">$ watch -n 10 nvidia-smi %10s钟输出一次</span><br></pre></td></tr></table></figure><p>指定GPU</p><h1 id="启用相关软件和程序"><a href="#启用相关软件和程序" class="headerlink" title="启用相关软件和程序"></a>启用相关软件和程序</h1><h3 id="matlab"><a href="#matlab" class="headerlink" title="matlab"></a>matlab</h3><p><a href="https://blog.csdn.net/u013066730/article/details/80944063" target="_blank" rel="noopener">https://blog.csdn.net/u013066730/article/details/80944063</a></p><p>命令行之行matlab</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">2.运行m文件</span><br><span class="line">如果m文件名为matlabfile.m</span><br><span class="line">(1)方法一</span><br><span class="line">进入m文件所在目录后，运行</span><br><span class="line">$ matlab -nodesktop -nosplash -r matlabfile</span><br><span class="line">只用文件名matlabfile，不能添加.m</span><br></pre></td></tr></table></figure><ul><li><p><a href="https://blog.csdn.net/brandyzhaowei/article/details/7895298" target="_blank" rel="noopener">更改快捷键</a></p><p><img src="https://blog-w.oss-cn-beijing.aliyuncs.com/2019-07-21-082015.png" alt="image-20190721160134598"></p><p><img src="/Users/yyf/Library/Application%20Support/typora-user-images/image-20190721161114733.png" alt="image-20190721161114733"></p></li></ul><h3 id="anaconda"><a href="#anaconda" class="headerlink" title="anaconda"></a>anaconda</h3><p>在终端输入anaconda-navigator</p><p>退出base</p><h2 id="执行python"><a href="#执行python" class="headerlink" title="执行python"></a>执行python</h2><p><strong>参数输入</strong></p><p>Positional argument v.s. keyword argument </p><p>In other words, keyword arguments are only “optional” because they will be set to their default value if not specifically supplied. </p><p><a href="https://docs.python.org/2/library/argparse.html" target="_blank" rel="noopener">多参数输入</a></p><h1 id="远程连接"><a href="#远程连接" class="headerlink" title="远程连接"></a>远程连接</h1><p>xrdp 服务相关</p><h1 id="SSD管理"><a href="#SSD管理" class="headerlink" title="SSD管理"></a>SSD管理</h1><p>预处理数据的时候，要检查硬盘是否有足够大的空间</p><p>df -h</p><h1 id="GPU"><a href="#GPU" class="headerlink" title="GPU"></a>GPU</h1><p>由显卡和GPU组成 相当于内存和CPU的区别</p><p>当显卡内存不够时，和<strong>batchsize</strong>有关和数据集的大小没有关系，一块显卡，64*64的batchsize=16而不能设置成32</p><h1 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h1><p>配置anaconda环境变量，在终端输入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export PATH=~/anaconda/bin:$PATH</span><br></pre></td></tr></table></figure><p>显示当前conda版本信息，在终端输入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda --version</span><br></pre></td></tr></table></figure><p>之后我们再次输入命令列出Anaconda自带的包，在终端输入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda list</span><br></pre></td></tr></table></figure><h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><ul><li><p>远程桌面死机</p><p>知道服务器远程桌面的服务所使用的协议，关掉相应进程即可。</p><p>不知道的情况下，可猜测对方所使用的进程（例如猜测使用xrdp）</p><p>如果是xrdp的话这行命令应该会有超过一个的结果：ps -aux | grep xrdp  <img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190506123440339.png" alt="image-20190506123440339">yyfang@mai:~$ kill 22722 # 对应的进程是启动桌面</p></li><li><p>查看服务器容量</p><ul><li><p><u>如何调出这个显示，代表的是什么容量，应该没有包括数据的大小</u><img src="/Users/yyf/Library/Application Support/typora-user-images/image-20190613135253231.png" alt="image-20190613135253231"></p></li><li><p><a href="http://www.runoob.com/linux/linux-comm-du.html" target="_blank" rel="noopener">Linux du 命令</a></p><p>du -sh 查看当前目录的大小</p><p>du -h test 方便阅读的格式显示test目录所占空间情况</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># du log2012.log </span><br><span class="line">300     log2012.log</span><br><span class="line"># du -h test</span><br><span class="line">608K    test/test6</span><br><span class="line">308K    test/test4</span><br><span class="line">4.0K    test/scf/lib</span><br><span class="line">4.0K    test/scf/service/deploy/product</span><br><span class="line">4.0K    test/scf/service/deploy/info</span><br><span class="line">12K     test/scf/service/deploy</span><br><span class="line">16K     test/scf/service</span><br><span class="line">4.0K    test/scf/doc</span><br><span class="line">4.0K    test/scf/bin</span><br><span class="line">32K     test/scf</span><br><span class="line">8.0K    test/test3</span><br><span class="line">1.3M    test</span><br></pre></td></tr></table></figure></li></ul></li></ul><h1 id="服务器上文件"><a href="#服务器上文件" class="headerlink" title="服务器上文件"></a>服务器上文件</h1><h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><p>网上下载的一些数据集</p><ul><li>train: 生成的一些.h5训练数据<ul><li>test.h5 用ljc的边缘，未归一化，用了400张图</li><li>poisson10.h5 noiselevel=10的泊松噪声 </li></ul></li></ul><h2 id="Edge-net"><a href="#Edge-net" class="headerlink" title="Edge_net"></a>Edge_net</h2><ul><li><p>generate_data: 生成.h5数据</p></li><li><p>Loggers05</p><ul><li>Poisson10_… 10:22PM开始</li></ul></li><li><p>/python/compare_models: 不同的.pth</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 服务器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>富士X100：慢拍的优雅</title>
      <link href="/p/b371.html"/>
      <url>/p/b371.html</url>
      
        <content type="html"><![CDATA[<h1 id="相机成像原理"><a href="#相机成像原理" class="headerlink" title="相机成像原理"></a>相机成像原理</h1><p>小孔成像：进光、倒立</p><p>孔太大了无法成像，每个点包含了整个成像物； 小孔变小，图像会更清晰，光线变暗</p><p>相机的光圈类比于小孔</p><h1 id="闪光灯的作用"><a href="#闪光灯的作用" class="headerlink" title="闪光灯的作用"></a>闪光灯的作用</h1><ul><li><p>在光线充足的地方：增加光效，突出立体感</p></li><li><p>在光线不足的地方：补光</p></li><li><p>逆光时：人物的面部光线更为柔和</p></li><li><p>X100下具有自动曝光功能。<u>菜单的位置</u>：闪光灯的自动模式，闪光灯的力度大小，配合闪光灯的消除红眼</p></li></ul><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1g2z1bmakzgj30sf063q96.jpg" alt="闪光灯"></p><h1 id="测光模式"><a href="#测光模式" class="headerlink" title="测光模式"></a>测光模式</h1><ul><li><p>X100具有<strong>多重、点测光、平均</strong>三种测光模式。</p></li><li><p>多重测光是点和平均的中和。夜晚时，画面容易偏亮。</p></li><li><p>点测光的特点：适合拍摄主题明显的画面，营造氛围。当测光在亮部时，整体会偏暗；当测光在暗部时，整体会偏亮。(点测光下，可以改变测光点吗：半自动测光）</p></li><li><p>平均测光的特点：适合拍摄静物和风景。测光平均值比较稳定。画面容易偏暗</p></li></ul><p><strong>注意：</strong>MF模式下，测光方式不影响曝光画面。由光圈快门决定。</p><h1 id="曝光补偿"><a href="#曝光补偿" class="headerlink" title="曝光补偿"></a>曝光补偿</h1><ul><li><p>增加曝光补偿：<img src="https://ws4.sinaimg.cn/large/006tNc79gy1g30qhuv2h6j30z005qdi9.jpg" alt="增加曝光"></p><p>例子：</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1g2znkirdrij30wy0f6gre.jpg" alt="增加曝光的例子"></p></li><li><p>降低曝光补偿：</p><p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1g2znrfh1gwj314605awkd.jpg" alt="降低曝光"></p></li></ul><h1 id="白平衡"><a href="#白平衡" class="headerlink" title="白平衡"></a>白平衡</h1><ul><li><p>作用：增加氛围；中和不正常的光线</p></li><li><p>几种调节方式：自动白平衡、自定义白平衡、白平衡偏移</p></li><li><p>白平衡偏移：<img src="https://ws2.sinaimg.cn/large/006tNc79gy1g2z21yi6maj30nt0dgmzs.jpg" alt="白平衡偏移色彩对应"></p></li></ul><h1 id="不同场景的拍摄"><a href="#不同场景的拍摄" class="headerlink" title="不同场景的拍摄"></a>不同场景的拍摄</h1><p>夕阳的拍摄技巧</p><p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1g2z1nev269j30nt0fh4g2.jpg" alt="夕阳"></p><h1 id="色彩的学习"><a href="#色彩的学习" class="headerlink" title="色彩的学习"></a>色彩的学习</h1><ul><li><p><a href="https://m.lizhiweike.com/classroom/11584842" target="_blank" rel="noopener">课堂链接</a></p></li><li><p>色彩的饱和度：所含彩色强度的浓度。</p></li><li><p>色彩的明度：色彩的亮度。其中黄色明度最高，紫色明度最低，绿、红、蓝、橙的明度相近，为中间明度。</p></li><li><p>色彩的搭配方式</p><p>单色、对比色、分离补色、冷暖色</p></li></ul><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><ul><li><a href="https://www.zhihu.com/question/22878394" target="_blank" rel="noopener">全画幅和半画幅的区别</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 摄影 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Mac快捷键以及一些快速操作</title>
      <link href="/p/5d54.html"/>
      <url>/p/5d54.html</url>
      
        <content type="html"><![CDATA[<h1 id="快捷打开方式终端"><a href="#快捷打开方式终端" class="headerlink" title="快捷打开方式终端"></a>快捷打开方式终端</h1><ul><li>打开Mac下自带的软件 <strong>Automator</strong></li></ul><p><img src="https://ww2.sinaimg.cn/large/006tKfTcgy1fckb184f74j319v0q01kx.jpg" alt></p><ul><li>新建文稿</li></ul><p><img src="https://ww1.sinaimg.cn/large/006tKfTcgy1fckb6zzo28j30mo0fvgn7.jpg" alt></p><ul><li>创建一个服务</li></ul><p><img src="https://ww1.sinaimg.cn/large/006tKfTcgy1fckb93qmy5j30g00fh0vq.jpg" alt></p><p><img src="https://ww2.sinaimg.cn/large/006tKfTcgy1fckbfe8o0zj30t10lb0wv.jpg" alt></p><p><img src="https://ww1.sinaimg.cn/large/006tKfTcgy1fckbff4e7pj30t10lbwis.jpg" alt></p><ul><li>修改框内的脚本</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">on run &#123;input, parameters&#125;</span><br><span class="line">tell application &quot;Terminal&quot;</span><br><span class="line">reopen</span><br><span class="line">activate</span><br><span class="line">end tell</span><br><span class="line">end run</span><br></pre></td></tr></table></figure><ul><li>运行：<code>command + R</code>，如果没有问题，则会打开终端</li></ul><p><img src="https://ww2.sinaimg.cn/large/006tKfTcgy1fckaqdd2m1j30t10lb42a.jpg" alt></p><p><img src="https://ww3.sinaimg.cn/large/006tKfTcgy1fckaq4nn9hj30iy0daaan.jpg" alt></p><p>保存：<code>Command + S</code>，将其命名为<code>打开终端</code>或你想要的名字</p><p>设置快捷键</p><p>在 <strong>系统偏好设置</strong> -&gt; <strong>键盘设置</strong> -&gt; <strong>快捷键</strong> -&gt; <strong>服务</strong></p><p>选择我们创建好的 ‘<strong>打开终端</strong>‘，设置你想要的快捷键，比我我设置了<code>⌘+空格</code></p><p><img src="https://ww4.sinaimg.cn/large/006tKfTcgy1fckbvaixhnj30kw0ihq67.jpg" alt></p><p>到此，设置完成。</p><p>聪明的你也许会发现，这个技巧能为所有的程序设置快捷启动。</p><p>将脚本中的 <code>Terminal</code> 替换成 其他程序就可以</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">on run &#123;input, parameters&#125;</span><br><span class="line">    tell application &quot;Terminal&quot;</span><br><span class="line">        reopen</span><br><span class="line">        activate</span><br><span class="line">    end tell</span><br><span class="line">end run</span><br></pre></td></tr></table></figure><h1 id="黑技能"><a href="#黑技能" class="headerlink" title="黑技能"></a>黑技能</h1><p>既然学了 <code>Automator</code> ，那就在附上一个黑技能吧。为你的代码排序。在 <strong>Xcode8</strong>以前，有个插件能为代码快速排序，不过时过境迁~ 对于没用的插件而且又有患有强迫症的的小伙伴，只能手动排序了（😂）.</p><p>首先还是创建一个服务</p><p>创建一个<code>Shell</code>脚本，</p><p>勾选:<code>用输出内容替换所选文本</code></p><p>输入：<code>sort|uniq</code> </p><p>保存： 存为<code>Sort &amp; Uniq</code></p><p><img src="https://ww4.sinaimg.cn/large/006tKfTcgy1fckd40rgwmj30rt0ildiy.jpg" alt></p><p><strong>选中你的代代码</strong> -&gt; <strong>鼠标右键</strong> -&gt; <strong>Servies</strong> -&gt; <strong>Sort&amp;Uniq</strong></p><p><img src="https://ww2.sinaimg.cn/large/006tKfTcgy1fckd6tx1dzj30h90b7mzm.jpg" alt></p><p>排序后的代码：</p><p><img src="https://ww3.sinaimg.cn/large/006tKfTcgy1fckd6lak55j309j05y3yo.jpg" alt></p><h1 id="Mac的一些快捷操作"><a href="#Mac的一些快捷操作" class="headerlink" title="Mac的一些快捷操作"></a>Mac的一些快捷操作</h1><ul><li><p>增加文件的快捷方式</p><p>按下option+cmd，将文件拖到桌面，产生有箭头标记的文件夹。</p></li><li><p>谷歌浏览器打开刚关闭的页面: cmd+shift+T</p></li></ul><h1 id="Terminal"><a href="#Terminal" class="headerlink" title="Terminal"></a>Terminal</h1><ul><li><p>删除文件夹（无论文件夹是否为空），使用 -rf 命令即可。</p><p>使用这个rm -rf的时候一定要格外小心，删除之后没办法在垃圾站找回。</p></li></ul><h1 id="RDP复制粘贴问题"><a href="#RDP复制粘贴问题" class="headerlink" title="RDP复制粘贴问题"></a>RDP复制粘贴问题</h1><p><a href="https://www.technipages.com/unable-to-copy-and-paste-to-remote-desktop-session" target="_blank" rel="noopener">https://www.technipages.com/unable-to-copy-and-paste-to-remote-desktop-session</a> windows</p>]]></content>
      
      
      <categories>
          
          <category> 软件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mac </tag>
            
            <tag> 效率 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
