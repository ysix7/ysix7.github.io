<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[图像处理相关问题综述]]></title>
    <url>%2Fp%2F23e4.html</url>
    <content type="text"><![CDATA[deblur Learning a Discriminative Prior for Blind Image Deblurring $$ \min {I, k}|I \otimes k-B|{2}^{2}+\gamma|k|_{2}^{2}+p(I) $$ The key to the success of this framework lies on the latentimage prior p(I), which favors clear images over blurredimages when minimizing (2). Therefore, the image priorp(I) should have lower responses for clear images andhigher responses for blurred images. test $a+b=\beta$ super-resolution Deep Plug-and-Play Super-Resolution for Arbitrary Blur Kernels Reference在图像处理领域的不同的研究问题]]></content>
  </entry>
  <entry>
    <title><![CDATA[穿搭]]></title>
    <url>%2Fp%2F5122.html</url>
    <content type="text"><![CDATA[复古look：brands]]></content>
      <categories>
        <category>生活</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[hexo博客搭建]]></title>
    <url>%2Fp%2F7ab7.html</url>
    <content type="text"><![CDATA[安装node.js https://nodejs.org/en/ sudo npm install –unsafe-perm –verbose -g hexo；hexo version 测试 自带了git，否则需要安装 初始化博客文件夹 123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install 测试生成网页 123hexo s 重新编译，并在本地显示hdxo g 重新编译hexo d 上传至github 选主题https://hexo.io/themes/ 下载 git clone https://github.com/theme-next/hexo-theme-next 将它放到theme下，并重命名 修改 站点配置文件_config.yml中的主题 12345# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/# theme: landscapetheme: next 重新编译 ![image-20190806232759873](/Users/yyf/Library/Application Support/typora-user-images/image-20190806232759873.png) 修改主题风格 生成的github文件我的github链接：https://github.com/ysix7/ysix7.github.io/tree/master/2019 参考blog： https://hellozhaozheng.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/ 本地更新文件![image-20190807010049690](/Users/yyf/Library/Application Support/typora-user-images/image-20190807010049690.png) Hero s 本地看 新增的功能分级目录：https://blog.csdn.net/wugenqiang/article/details/88609066 新增分类：http://www.iooeo.com/2017/07/20/Hexo-%E6%96%B0%E5%BB%BA%E8%8F%9C%E5%8D%95-menu-%E5%AD%98%E6%94%BE%E5%BD%92%E6%A1%A3/ Tags深度学习：pytorch，python, 机器学习，服务器 美食类：西安,香港.. 软件：latex 图形处理：denoising,segmentation 主页自定义12345678npm install --save hexo-generator-searchnpm install hexo-generator-searchdb --save 添加本地搜索npm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --save 生成sitemap，用来被百度谷歌收录npm install --save hexo-symbols-count-time 添加统计字数npm install hexo-generator-index --savenpm install hexo-generator-index-pin-top --save 博客置顶npm install hexo-abbrlink --save 优化链接 主题配置文件 头像 ：theme-source-imgs ![image-20190813002011973](/Users/yyf/Library/Application Support/typora-user-images/image-20190813002011973.png) 页面左上角图标 链接：https://www.iconfont.cn/home/index?spm=a313x.7781069.1998910419.2 文件保存位置： ![image-20190813002701508](/Users/yyf/Library/Application Support/typora-user-images/image-20190813002701508.png) 分类图标 链接：http://fontawesome.dashgame.com/ ![image-20190813002106807](/Users/yyf/Library/Application Support/typora-user-images/image-20190813002106807.png) 开启站内搜索 ![image-20190813003015418](/Users/yyf/Library/Application Support/typora-user-images/image-20190813003015418.png) 开启公式 公式：scaffolds-post.md中修改默认模版 模板里面只写mathjax: ，只在需要公式的地方写true。模版中写true，会导致网页显示变慢。 ![image-20190813002414041](/Users/yyf/Library/Application Support/typora-user-images/image-20190813002414041.png) 修改页边距]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>%2Fp%2F0.html</url>
    <content type="text"><![CDATA[Opening今天我讲的内容是第十六章，图模型。主要包含三个基本问题：图模型的结构、推断、学习。表示问题，利用图结构表示彼岸两之间的依赖关系 推断问题，推断预测变量的后验分布。在观测到部分变量e时候，计算其它变量的某个子集 q = {q 1 , q 2 , · · · , q n } 的后验概率 p(q|e)。以及学习问题, 图结构的学习和图中参数的学习。 ![image-20190805205029413](/Users/yyf/Library/Application Support/typora-user-images/image-20190805205029413.png) ![image-20190805183117338](/Users/yyf/Library/Application Support/typora-user-images/image-20190805183117338.png) 在前面几周，已经介绍了一些推断的方法，以及参数的学习方法，例如EM算法。今天，我将首先补充一下图结构的知识。并通过举例一些实际应用例子，来看图结构如何协同推断和学习来解决一个问题，如同如文本分类、以及图像去噪。 有向图结构 图结构分为无向图和有向图 有向图：Directed Graphical model，也称为贝叶斯网络（Bayesian Network），或信念网络（Belief Network） 无向图： ![image-20190805194737417](/Users/yyf/Library/Application Support/typora-user-images/image-20190805194737417.png) 有向图的联合分布 以图(a)为例，p(x1,x2,x3,x4)=p(x1)p(x2|x1)p(x3|x1,x2)p(x4|x1,x2,x3 )。 根据性质$X_{2} \perp X_{3} | X_{1}$, $p\left(x_{2} | x_{1}, x_{3}\right)=p\left(x_{2} | x_{1}\right)$, 以及图结构上的独立性， 我们有p(x2|x1)=p(x2|x1,x3) ，p(x4|x3,x2)=p(x4|x3,x2,x1) 因此右边可以简化为p(x1)p(x2|x1 )p(x3|x1)p(x4|x2, x3) For any acyclic Bayesian network G, the joint probability distribution of X can be decomposed into a multiplicative form of the local conditional probability of each random variable X. In this graph, then the 对于任意一个无环贝叶斯网络G，X 的联合概率分布可以分解为每个随机变量 $X_k$ 的局部条件概率的连乘形式$$p(\mathbf{x})=\prod_{k=1}^{K} p\left(x_{k} | \mathbf{x}{\pi{k}}\right)$$其中$x_{\pi k}$表示节点k的父节点。P(Xk|Xπk)是局部条件概率 根据这个公式：我们遍历图（a）中的每一个节点，即可以得到联合分布 p(x)=p(x1)p(x3|x1)p(x2|x1)p(x4|x3,x2). ——和我们之前的结果一样。 ![image-20190805202457364](/Users/yyf/Library/Application Support/typora-user-images/image-20190805202457364.png) 现在我们来讨论用一个图结构来表示概率分布的优点。 假设X1 , X2 , X3 , X4 是二值变量，在没有图中变量依赖关系的情况下，可以用一个联合概率表来显式地记录每一种取值的概率P(X)，共需要2^4 −1 = 15个参数。如果我们用4 个表格来记录这 4 个局部条件概率的乘积，只需要 1 + 2 + 2 + 4 = 9 个独立参数。 因此当概率模型中的变量数量比较多时，其条件依赖关系也比较复杂。使用图结构的方式可以将概率模型可视化，，以一种直观、简单的方式描述出随机变量之间的条件独立性的性质，并可以将一个复杂的联合概率模型分解为一些简单条件概率模型的组合。 Therefore, when the number of variables in the probability model is relatively large, the conditional dependence is also complicated. The use of graph structure can visualize the probability model, describe the nature of conditional independence between random variables in an intuitive and simple way, and decompose a complex joint probability model into some simple conditional probability models. combination. 几种常见的有向图（不讲） 很多经典的机器学习模型可以使用有向图模型来描述，比如朴素贝叶斯分类器、隐马尔可夫模型、深度信念网络等。各自具有特定的结构，适用于不同的任务。 ![image-20190805211242662](/Users/yyf/Library/Application Support/typora-user-images/image-20190805211242662.png) ![image-20190805211207481](/Users/yyf/Library/Application Support/typora-user-images/image-20190805211207481.png) 有向图—文本分类 图结构：一个常用的有向图结构，朴素贝叶斯模型。 参数的学习 后验分布可以分解为 这里我要强调一下两个概念。生成模型和判别模型的区别。 生成模型和判别模型的区别我们经常提到的生成模型和判别模型。我们可能通常错误的以为生成模型就是图像应用中数据重建的意思，其实不然。生成模型除了重建也可以用来判别。 简单来说。生成模型是计算一个p(x,y)的联合分布，而判别模型是生成p(y|x)， ![image-20190805232955885](/Users/yyf/Library/Application Support/typora-user-images/image-20190805232955885.png) 两个模型的应用。生成模型和判别模型都可以用来进行分类问题。 ![image-20190805233143964](/Users/yyf/Library/Application Support/typora-user-images/image-20190805233143964.png) ![image-20190805233307927](/Users/yyf/Library/Application Support/typora-user-images/image-20190805233307927.png) ![image-20190805233213328](/Users/yyf/Library/Application Support/typora-user-images/image-20190805233213328.png) ![image-20190805233118468](/Users/yyf/Library/Application Support/typora-user-images/image-20190805233118468.png) 两个模型的建模以及我的总结 ![image-20190805233903604](/Users/yyf/Library/Application Support/typora-user-images/image-20190805233903604.png) 有向图—高斯混合模型高斯混合模型（Gaussian Mixture Model，GMM)。假设样本 x 是从 K 个高斯分布中生成的。 高斯混合模型的概率密度函数为：$p(x)=\sum_{k=1}^{K} \pi_{k} \mathcal{N}\left(x | \mu_{k}, \sigma_{k}\right)​$ 有向图结构的定义：Y-&gt;X 在这个图中，我们定义$P(X|Y=k)=\mathcal{N}\left(x | \mu_{k}, \sigma_{k}\right)$, $P(Y=k)=\pi_k, \sum_{k=1}^{K} \pi_{k}=1$. 根据这个图：我们可以得到x的边际概率：$p(x)=\sum_{k=1}^{K} \pi_{k} \mathcal{N}\left(x | \mu_{k}, \sigma_{k}\right)​$ 参数估计：用最大似然的方法来进行参数估计，给定N 个训练样本D = {x (i) }, 1 ≤ i ≤ N，其训练集的对数边际似然为 $\mathcal{L}(\mathcal{D} | \theta)=\frac{1}{N} \sum_{i=1}^{N}\left(\log p\left(\mathbf{x}^{(i)}, \theta\right)\right.$,并通过EM算法来求解获得参数$u_k,\sigma_k,\pi_k$, 推断：计算后验分布 p(Y=k|x)$\pi_{k} \mathcal{N}\left(x^{(n)} | \mu_{k}, \sigma_{k}\right)​$ ![image-20190805231018118](/Users/yyf/Library/Application Support/typora-user-images/image-20190805231018118.png) 无向图结构 应用场景 我们可以看到，在有向图中，通常存在明确方向上的因果关系。当相互的作用并没 有本质性的指向，或者是明确的双向相互作用时，使用无向模型更加合适。作为一个这种情况的例子，假设我们希望对三个二值随机变量建模。X1-X2-X3。其中X1，X2，X3分别代表你的室友，你和你的同事是否😷。我们假设，你的室友和同事 并不认识，所以他们不太可能直接相互传染一些疾病，因而我们的模型中两者之间没有直接的连接。然而，你传染给你的室友和你的室友传染给你都是非常容易的，所以模型不存在一个明确的单向箭头。并且，你的室友和你很有可能其中之一将感冒传染给你，然后通过你再传染给了另一个人。 现在我们来考虑三者健康状况的联合分布。p(X1,X2,X3) 无向图的联合分布的分解方式 无向图模型，也称为马尔可夫随机场（Markov Random Field，MRF）或 马尔可夫网络（Markov Network） 无向图的联合分布方式：对于一个马尔可夫随机场G,当p(x)可以表示为,一系列定义在最大团上的非负函数的乘积形式,即$$p(\mathbf{x})=\frac{1}{Z} \prod_{c \in \mathcal{C}} \phi_{c}\left(\mathbf{x}_{c}\right)$$。其中：最大团（Maximal Clique）就是其中的点是全连接的子集，并且无法被一个更大的团包含。对于 图中的每一个团C，一个 因子（factor）ϕ(C)(也称为 团势能（clique potential)，衡量了团中变量每一种可能的联合状态所对应的密切程度，因而必须为0。为了归一化 ![image-20190805215740555](/Users/yyf/Library/Application Support/typora-user-images/image-20190805215740555.png) 例子中的计算方法 在我们这个模型中，我们可以为你和你的室友定义这样一个势能函数。 ![image-20190805215043749](/Users/yyf/Library/Application Support/typora-user-images/image-20190805215043749.png) 状态为 1 代表了健康的状态，相对的状态为 0 则表示不好的健康状态（即感染 了感冒）。你们两个通常都是健康的，所以对应的状态拥有最高的密切程度。两个人 中只有一个人是生病的密切程度是最低的，因为这是一个很罕见的状态。两个人都生病的状态（通过一个人来传染给了另一个人）有一个稍高的密切程度，尽管仍然 不及两个人都健康的密切程度。 同样地，我们可以为你和你的同事定义一个。 现在我们可以得到非归一化的概率分布。如hc=0，hy=1，hx=1的情况下，p；hc=0，hy=1，hx=1的情况下，p。和我们预设的情形相符合。 无向图中联合分布的能量表达方法 现在我们返回到这个联合分布的定义。我们注意到，为了有效定义每一种情况，势能函数必须大于0. 由于势能函数必须为正的，因此我们一般定义为$\phi_{c}\left(\mathbf{x}{c}\right)=\exp \left(-E{c}\left(\mathbf{x}{c}\right)\right)$，其中E(xc)为能量函数（energy function) 。因此，无向图上定义的概率分布可以表示为：$$\begin{aligned} P(\mathbf{x}) &amp;=\frac{1}{Z} \prod{c \in \mathcal{C}} \exp \left(-E_{c}\left(\mathbf{x}{c}\right)\right) \ &amp;=\frac{1}{Z} \exp \left(\sum{c \in \mathcal{C}}-E_{c}\left(\mathbf{x}_{c}\right)\right)\&amp;=\frac{1}{Z} \exp \left(-E\left(\mathbf{x}\right)\right)\end{aligned}$$这种形式的分布又称为玻尔兹曼分布（Boltzmann Distribution）。任何一个无向图模型都可以用公式(11.21) 来表示其联合概率。服从式 (16.7) 形式的任意分布都是 玻尔兹曼分布（Boltzmann distribution） 的一个实例。正是基于这个原因， 我们把许多基于能量的模型称为玻尔兹曼机（Boltzmann Machine）。现在我们来讲一个基于无向图的应用，去噪。 常见的无向图(不讲) ![image-20190805211429187](/Users/yyf/Library/Application Support/typora-user-images/image-20190805211429187.png) 总结 利用图模型的局部马尔可夫性，我们可以对多变量的联合概率进行简化，从而降低建模的复杂度。（可加到有向图的后面）Using the local Markov property of the graph model, we can simplify the joint probability of multivariates, thus reducing the complexity of modeling. (can be added to the back of the directed graph) 局部马尔可夫性质：对一个更一般的贝叶斯网络，其局部马尔可夫性质为：每个随机变量在给定父节点的情况下，条件独立于它的非后代节点。对与一个无向图而言，即一个变量 Xk 在给定它的邻居的情况下独立于所有其它变量。 #无向图—图像去噪 无向图：图像去噪。 基于马尔科夫随机场的图像去噪方法+python代码 马尔可夫去噪+matlab：能量函数有点不同 受限玻耳兹曼机A widely used model of Undirected graph is Boltzman’s machine。 下面我们有请Ms Tang，来介绍some details about the Boltzman’s machine and its extentions in deep learning models. 玻耳兹曼机是一个无向图 发展：1986Hinton发明了玻耳兹曼机-&gt;2002Hinton发明了CD(对比散度)来计算梯度-&gt;2006Hinton提出了受限玻耳兹曼机 模型构建：Introduction to Restricted Boltzmann Machines Using PyTorch、英文原文 计算原理：预备知识、梯度上升法、评价效果的方法 代码：受限玻耳兹曼姬重构：tf版本、受限玻耳兹曼姬重构：pytorch版本、Introduction to Restricted Boltzmann Machines Using PyTorch、pytorch-rbm、 受限玻耳兹曼姬和深度学习的关系]]></content>
  </entry>
  <entry>
    <title><![CDATA[生成模型vs判别模型]]></title>
    <url>%2Fp%2F44f5.html</url>
    <content type="text"><![CDATA[不同的应用判别式模型，这种模型的形式主要是根据原始图像推测图像具备的一些性质，例如根据数字图像推测数字的名称，根据自然场景图像推测物体的边界；而生成模型恰恰相反，通常给出的输入是图像具备的性质，而输出是性质对应的图像。这种生成模型相当于构建了图像的分布，因此利用这类模型，我们可以完成图像自动生成（采样）、图像信息补全等工作。 生成模型可以用来重构、也可以用来判别。当用于判别时 生成模型可以是监督的，也可以是无监督的？ 常用的生成网络：VAE、GAN、GAN 问题生成模型的输入是什么？ 参考 十个生成模型(GANs)的最佳案例和原理 | 代码+论文 GNN论文分门别类，16大应用200+篇论文最新推荐]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[胰脏分割-Unet相关论文]]></title>
    <url>%2Fp%2Ff54.html</url>
    <content type="text"><![CDATA[胰脏分割 从coarse到fine Attention U-net： 关注点在前景，比Unet多了attention gate； Unet图像分割综述 https://zhuanlan.zhihu.com/p/43422162 U-Net论文 U-Net论文笔记 U-Net论文笔记 U-Net论文笔记知乎 论文清单需要补充一些常用层的作用：如up，downsample，deconvolution，pooling, batch normalization normalization有很多方法，VGG-Net，Stride ![image-20190731201343360](/Users/yyf/Library/Application Support/typora-user-images/image-20190731201343360.png)]]></content>
      <categories>
        <category>图像处理</category>
      </categories>
      <tags>
        <tag>segmentation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[淘宝收藏]]></title>
    <url>%2Fp%2F4dde.html</url>
    <content type="text"><![CDATA[裤裤 短裤 ![image-20190720152120722](/Users/yyf/Library/Application Support/typora-user-images/image-20190720152120722.png) 衣服 一家红裙子店]]></content>
      <categories>
        <category>生活</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Proof_解的存在性]]></title>
    <url>%2Fp%2Fe1d.html</url>
    <content type="text"><![CDATA[目录 存在性：存在收敛的序列 唯一性，凸性 解存在性证明例子1 证明 $\inf _{\Omega} f \leq u^{*} \leq \sup _{\Omega} f$ 通过有界性说明 证明有界性 BV的有界性 解存在性证明例子2问题的转化1.原问题：The natural space for the functional H to be deﬁned in, is $W^{2,1}(\Omega)$$$\begin{aligned} H(u)=&amp; \frac{1}{2} \int_{\Omega}\left(u_{0}-T u\right)^{2} d x+\alpha \int_{\Omega} f(\nabla u) d x +\beta \int_{\Omega} g\left(\nabla^{2} u\right) d x \end{aligned}$$缺点：this space is not reﬂexive(自反空间), and thus existence of minimisers cannot be guaranteed. 每个有限维赋范向量空间都是自反空间。 所有的希尔伯特空间都是自反空间。比如说，$\mathrm{L}^2$空间是自反空间。 2.Extended problem：extend the functional H in (3.5) to $\mathrm{BH}(\Omega)$$$H_{e x}(u)=\left{\begin{array}{l}{\frac{1}{2} \int_{\Omega}\left(u_{0}-T u\right)^{2} d x+\alpha \int_{\Omega} f(\nabla u) d x} \ {+\beta \int_{\Omega} g\left(\nabla^{2} u\right) d x \quad \text { if } u \in W^{2,1}(\Omega)} \ {+\infty \text { if } f \in \mathrm{BH}(\Omega) \backslash W^{2,1}(\Omega)}\end{array}\right.$$缺点：$H_{ex}$ is not sequentially lower semicontinuous with respect to the strict topology in BH(Ω) and hence it is neither with respect to the $weak^∗$ topology in $[\mathrm{BH}(\Omega)]^{n}$ 为什么需要lower semicontinuous? $BH$空间, $\mathrm{BH}(\Omega)=\left{u \in W^{1,1}(\Omega) : \nabla u \in[\mathrm{BV}(\Omega)]^{2}\right}$ the $weak^∗$ topology in BH(Ω) provides a good compactness property which is inherited from the weak ∗ topology in $[\mathrm{BV}(\Omega)]^{n}$ 3.Relaxed functional$$\begin{aligned} \overline{H_{e x}}(u) :=&amp; \frac{1}{2} \int_{\Omega}\left(u_{0}-T u\right)^{2} d x+\alpha \int_{\Omega} f(\nabla u) d x \ &amp;+\beta g\left(D^{2} u\right)(\Omega) \=&amp; \frac{1}{2} \int_{\Omega}\left(u_{0}-T u\right)^{2} d x+\alpha \int_{\Omega} f(\nabla u) d x \ &amp;+\beta \int_{\Omega} g\left(\nabla^{2} u\right) d x \ &amp;+\beta \int_{\Omega} g_{\infty}\left(\frac{D^{s} \nabla u}{\left|D^{s} \nabla u\right|}\right) d\left|D^{s} \nabla u\right| \end{aligned}$$ Relaxed function： ![image-20190816101314838](/Users/yyf/Library/Application Support/typora-user-images/image-20190816101314838.png) ![image-20190816101458245](/Users/yyf/Library/Application Support/typora-user-images/image-20190816101458245.png) 优点： lower semicontinuous。 Theorem 3.6 The functional $\overline{H_{e x}}(u)$ is lower semicontinuous with respect to the strict topology in $\mathrm{BH}(\Omega)$. which means, $\overline{H_{e x}}(u)\le\lim_{k\to\infty}\inf\overline{H_{e x}}(u_k)$, when $u_k\to u$, in $\mathrm{BH}{(\Omega)}$ Also, $\overline{H_{e x}}(u)\le\lim_{k\to\infty}\inf\overline{H_{e x}}(u_k)$, when $u_k\rightarrow^{w^*} u$, in $\mathrm{BH}{(\Omega)}$ 证明步骤目标方程：$\inf {u \in \mathrm{BH}(\Omega)} \overline{H{e x}}(u)$ 取一个minimizing sequence ${u_k}$ 证明${u_k}$ is bounded in BH(Ω). 利用BH的compactness, 得到$u_k\rightarrow u$ weakly 在BH空间 利用${H_{ex}}$的下半连续性，得到 $\overline{H_{e x}}(u)\le\lim_{k\to\infty}\inf\overline{H_{e x}}(u_k)$ which implies that(因为$u_k$minimizing): $u=\min {u \in \mathrm{BH}(\Omega)} \overline{H{e x}}(u)$ 利用 property of the relaxed functional：$\min _{x \in X} F(x)=\inf _{x \in X} F(x)$ 问题：？那不是只能说明F存在下界？ inf F(x) = min F(x) 级数的收敛级数：一个有穷或无穷的序列的和称为级数。根据项数分为：有穷级数和无穷级数 无穷级数的收敛性：如果当$n$趋于正无穷大时，趋向一个有限的极限。如果当趋于正无穷大时，趋向一个有限的极限： 条件收敛：如果任意项级数收敛，而级数发散，则称级数条件收敛。 绝对收敛：如果级数收敛，则称级数绝对收敛。绝对收敛-&gt;条件收敛 收敛级数的性质：当趋向无限大时，任何一个收敛级数的通项都趋于0： 序列的收敛性有界 定义 Thus a sequence f = (a0, a1, a2, …) is bounded if there exists a real number M such that 实数中的定义 如果存在一个实数 k，使得对于所有 S 中的 s 有 k ≥ s，实数集合 S 被称为“上有界”的，这个数 k 被称为 S 的上界。可用类似的定义术语“下有界”和下界。 度量空间中的定义 度量空間 (M, d) 的子集S 是有界的，如果它包含在有限半徑的球內，就是說如果對於所有 S 中的 s，存在 M 中的 x 並且 r &gt; 0，使得 d(x, s) &lt; r。M 是有界度量空間（或 d 是有界度量），如果 M 作為自身的子集是有界的。 空间 向量空间、函数空间 Lp空间 Lp空间是由p次可积函数组成的空间；对应的ℓp空间是由p次可和序列组成的空间，有时叫做勒贝格空间。 Sobolev spaces: $W^{1,1}$, $W^{2,1}$ ![image-20190816001648069](/Users/yyf/Library/Application Support/typora-user-images/image-20190816001648069.png) Equipped with the norm becomes a Banach space. Banach空间：完备(柯西收敛即收敛)+赋范, 属于Hilbert空间 A Banach space is a vector space X over any scalar field K, which is equipped with a norm and which is complete with respect to the distance function induced by the norm, that is to say, for every Cauchy sequence ${x_n}$ in X, there exists an element x in X such that $\lim {n \rightarrow \infty} x{n}=x$ BV空间 One variable ![image-20190816150519847](/Users/yyf/Library/Application Support/typora-user-images/image-20190816150519847.png) Functions of bounded variation, BV functions, are functions whose distributional derivative is a finite[5] Radon measure. $|u|{\mathrm{BV}(\Omega)} :=\int{\Omega}|u| d x+|D u|(\Omega)$ $BV^2$空间 $|u|{\mathrm{BV}(\Omega)} :=\int{\Omega}|u| d x+|D u|(\Omega)$ BH空间, 属于Banach空间 $\mathrm{BH}(\Omega)=\left{u \in W^{1,1}(\Omega) : \nabla u \in[\mathrm{BV}(\Omega)]^{2}\right}$ $\mathrm{BH}(\Omega)$ is a Banach space equipped with the norm $|u|{B H(\Omega)}=|u|{B V(\Omega)}+\left|D^{2} u\right|(\Omega)$. Deﬁnition 3.1 ($Weak^∗$ Convergence in BH(Ω)) We say that $(u_k ),k\in N$ converges to $u$ $weakly^∗$ in $\mathrm{BH}(\Omega)$ if $u_{k} \rightarrow u, \quad \text {in} L^{1}(\Omega)$ and $\nabla u_{k} \rightarrow \nabla u \quad \text {weakly }^{*} \text { in }[\mathrm{BV}(\Omega)]^{2},\text{as } k \rightarrow \infty$ or in other words:$$\begin{array}{l}{\left|u_{k}-u\right|{L^{1}(\Omega)} \rightarrow 0} \ {\left|\nabla u{k}-\nabla u\right|{\left[L^{1}(\Omega)\right]^{2}} \rightarrow 0} \ {\int{\Omega} \phi d D^{2} u_{k} \rightarrow \int_{\Omega} \phi d D^{2} u, \quad \forall \phi \in C_{0}(\Omega)}\end{array}$$ Theorem 3.2 (Compactness in $\mathrm{BH}(\Omega)$): 可根据bounded得到收敛的序列 Suppose that the sequence $\left(u_{k}\right){k \in \mathbb{N}}$ is bounded in $\mathrm{BH}(\Omega)$. Then there exists a subsequence $\left(u{k_{\ell}}\right){\ell \in \mathbb{N}}$ and a function $u \in \mathrm{BH}(\Omega)$ such that $\left(u{k_{\ell}}\right)_{\ell \in \mathbb{N}}$ converges to u $weakly^∗$ in $\mathrm{BH}(\Omega)$. Deﬁnition 3.3 (Strict Convergence in BH(Ω)) We say that $(u_k ),k\in N$ converges to $u$ $strictly$ in $\mathrm{BH}(\Omega)$ if $u_{k} \rightarrow u, \quad \text {in } L^{1}(\Omega)$ and ![image-20190816013439422](/Users/yyf/Library/Application Support/typora-user-images/image-20190816013439422.png) the weak ∗ topology in BH(Ω) provides a good compactness property which is inherited from the weak ∗ topology in [BV(Ω)] n. Compactness：可根据bounded得到收敛的序列 Lebesgue space 就是Lp空间？ 各类空间 ![image-20190816101107875](/Users/yyf/Library/Application Support/typora-user-images/image-20190816101107875.png) 序列 柯西序列 定义： 和收敛序列的关系：任何收敛数列必然是柯西列，任何柯西列必然是有界序列。 无限维度中的有界序列具体含义：见“有界” 柯西列是否一定是收敛的？ 序列收敛的定义 收敛(强)：定义在norm 弱(weak)收敛：定义在内积 weak*收敛： 实数序列收敛的判别方法 Bolzano-Weierstrass: 任一有限维实向量空间$\mathbb {R} ^{n}$中的有界序列都至少包含一个收敛的子列。 有界不一定收敛 有界序列是什么意思？ 有界序列 Theorem 3.2 (Compactness in $\mathrm{BH}(\Omega)$) Suppose that the sequence $(u_k){k \in N}$ is bounded in $\mathrm{BH}(\Omega)$. Then there exists a subsequence $\left(u{k_{\ell}}\right){\ell \in \mathbb{N}}$ and a function $u \in \mathrm{BH}(\Omega)$ such that $\left(u{k_{\ell}}\right)_{\ell \in \mathbb{N}}$ converges to $u$ weakly∗ in $\mathrm{BH}(\Omega)$. ##不同的收敛速度 converge sublinearly $\lim {k \rightarrow \infty} \frac{\left|x{k+1}-L\right|}{\left|x_{k}-L\right|}=1$ converge linearly $\lim {k \rightarrow \infty} \frac{\left|x{k+1}-L\right|}{\left|x_{k}-L\right|}=\mu, \mu \in(0,1)$ converge superlinearly $\lim {k \rightarrow \infty} \frac{\left|x{k+1}-L\right|}{\left|x_{k}-L\right|}=0$ Q-linear convergence: distinguish superlinear rates of convergence. $\lim {k \rightarrow \infty} \frac{\left|x{k+1}-L\right|}{\left|x_{k}-L\right|^{q}}&lt;M$ Monotone operator ##不同的收敛模式 强收敛 弱收敛 ![image-20190725143410105](/Users/yyf/Library/Application Support/typora-user-images/image-20190725143410105.png) 补充Fatous lemma![image-20190725145706825](/Users/yyf/Library/Application Support/typora-user-images/image-20190725145706825.png) Lower semicontinuous##Distributional derivative weak derivative ![image-20190816143252525](/Users/yyf/Library/Application Support/typora-user-images/image-20190816143252525.png) ![image-20190816143354216](/Users/yyf/Library/Application Support/typora-user-images/image-20190816143354216.png) Reference Distributions and distributional derivatives Distributional Derivative 问题 minimizing sequence? K-SVD code 证明relax一下]]></content>
      <categories>
        <category>数学</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[自编码器]]></title>
    <url>%2Fp%2F221.html</url>
    <content type="text"><![CDATA[参考 自编码器是什么？有什么用？这里有一份入门指南（附代码） 发展 自编码器 整个自编码器可以用函数g(f(x)) = r来描述，其中输出r与原始相近。 作用 如果自编码器的唯一目的是让输出值等于输入值，那这个算法将毫无用处。事实上，我们希望通过训练输出值等于输入值的自编码器，让潜在表征h将具有价值属性。自编码器能从数据样本中进行无监督学习，这意味着可将这个算法应用到某个数据集中，来取得良好的性能，且不需要任何新的特征工程，只需要适当地训练数据。 实现 限制h的维度使其小于输入x，这种情况下称作有损自编码器。通过训练有损表征，使得自编码器能学习到数据中最重要的特征。 正则 应用 第一是数据去噪，第二是为进行可视化而降维。设置合适的维度和稀疏约束，自编码器可以学习到比PCA等技术更有意思的数据投影。 种类 香草自编码器 多层自编码器 卷积自编码器 正则自编码器：使用损失函数来鼓励模型学习其他特性 常用两种正则自编码器 稀疏自编码器：通过对损失函数施加惩罚项 降噪自编码器：是通过改变损失函数的重构误差项来学习一些有用信息。 去噪自编码器DAE]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[概率图模型]]></title>
    <url>%2Fp%2Fd0e9.html</url>
    <content type="text"><![CDATA[统计学知识 极大似然估计与最大后验概率估计 极大似然估计：p(X=头痛|Y=中风)=0.8 P(X=头痛|Y=感冒)=0.5 P(X=头痛|Y=) X=头痛 Y=argmaxP(X=头痛|Y) Y=中风 最大后验概率：Y = argmax p(Y|X=头痛)=P(X|Y)P(Y) 生成模型和判别模型的区别 判别模型 p(y|x), 给一个X，判断y=1的值。 生产模型 p(y|x)等价于p(x|y)p(y)=p(x,y)。需要构造一个p(x|y=1)p(y=1)的根据黄牛特征得到的黄牛模型，p(x|y=0)p(y=0)的水牛模型，比较联合概率密度。 ![image-20190805094448732](/Users/yyf/Library/Application Support/typora-user-images/image-20190805094448732.png) 深度学习中的生成模型：深度学习的三大生成模型：VAE、GAN、GAN、十个生成模型(GANs)的最佳案例和原理、 概率图模型 structured probabilistic models.概率图模型：用图论表现随机变量之间的条件依赖关系的建模方法。典型的概率图模型包括贝叶斯网络和马尔可夫随机场，分别对应着有向图模型和无向图模型。 它们提供了将概率模型的结构可视化的简单方式，而对图形的观察可以加深对模型性质的认识，其中最主要的性质就是变量之间的条件独立性。此外，概率图模型还可以表示学习和推断过程中的复杂计算，隐式地承载了图形背后的数学表达。 优点：图模型建模方式的优点是：多变量分布通常可以表示为一些局部函数（local functions）的乘积，而每个局部函数依赖于更小的变量子集。通过因子化（factorization）和条件独立性（conditional independence），使得复杂的多变量分布可以用少得多的参数进行刻画。 ![image-20190729131441690](/Users/yyf/Library/Application Support/typora-user-images/image-20190729131441690.png) ![image-20190729131908499](/Users/yyf/Library/Application Support/typora-user-images/image-20190729131908499.png) 1、概率模型是利用训练样本数据，通过学习条件概率分布P(X|Y)来进行推断决策，而非概率模型是通过学习得到决策函数Y=f(X)来进行决策。 2、生成模型的目标是求联合概率分布P(X,Y)，然后由条件公式求取条件概率分布P(X|Y)。即P(X|Y) = P(X,Y) / P(X)。 3、判别模型是由训练数据直接求取决策函数Y=f(x)或者条件分布P(X|Y)。它并不需要关心X与Y之间的生成关系，它关心的是对于给定输入X应该得到怎么样的输出Y。 4、机器学习大部分模型都是判别模型，判别模型得到条件概率或者决策函数直接用于预测，准确率会更高；而生成模型用于数据预测，所以它的应用领域会更加广泛。 5、常见的判别模型有：K近邻、SVM、决策树、感知机、线性判别分析（LDA）、线性回归、传统的神经网络、逻辑斯蒂回归、boosting、条件随机场 常见的生成模型有：朴素贝叶斯、隐马尔可夫模型、高斯混合模型、文档主题生成模型（LDA）、限制玻尔兹曼机 作者：decan5958来源：CSDN原文：https://blog.csdn.net/decan5958/article/details/76607082 深度学习和概率图模型的关系 参考 深度学习之外的人工智能——概率图模型 与深度学习的关系 两者者使用 同的基本计算工具：近似推断？损失函数？学习过程？ 深度学习潜变量：比可观察变量更多；不包含特定含义； 概率图模型潜变量：数量通常很少；通常被赋予一些特定含义； 深度学习的连接方式：其他单元组全连接 概率图的连接方式：具有非常少的连接， 并且每个变量的连接选择可以单独设计。 模型结构的设计与推断算法的选择紧密相关。图模型的传统方法通常旨在保持精确 推断的可解性。 推断方式：什么是推断？作用？ 图模型的传统方法通常旨在保持精确推断的可解性。 大规模图模型和深度图模型最大的区别之一就是深度学习中几乎从来不会使用环状信念传播。相反的，许多深度学习模型可以设计来加速 Gibbs 采样或者变分推断。 图模型如何用于深度学习的典型例子：受限玻尔兹曼机（Restricted Boltzmann Machine, RBM） 特点：它的单元被分成很大的组，这种组称作层，层之间 的连接由矩阵描述，连通性相对密集。该模型被设计为能够进行高效的 Gibbs 采样， 并且模型设计的重点在于以很高的自由度来学习潜变量。 标准的 RBM 是具有二值的可见和隐藏单元的基于能量的模型。其能量函数为$E(\boldsymbol{v}, \boldsymbol{h})=-\boldsymbol{b}^{\top} \boldsymbol{v}-\boldsymbol{c}^{\top} \boldsymbol{h}-\boldsymbol{v}^{\top} \boldsymbol{W h}$ ##概率图(结构化)模型的优点 显著降低表示概率分布、学习和推断的成本。如有向图中的参数表示。1+4+4+9的例子 有向模型中采样还可以被加速，但是对于无向模型情况则较为复杂。？ ##概率图模型的应用 MRF去噪：无向图中的马尔可夫模型？ 能否看到一个具体的学习、建模过程。 有向图模型/贝叶斯网络/信念网络 有向图模型以及联合分布 ![image-20190729142335602](/Users/yyf/Library/Application Support/typora-user-images/image-20190729142335602.png) 常见的有向图：sigmoid 信念网络、朴素贝叶斯分类器、隐马尔可夫模型(HMM) ![image-20190730121750632](/Users/yyf/Library/Application Support/typora-user-images/image-20190730121750632.png) 一个能看懂的HMM例子：每天观察一个病人的状态 无向图/马尔可夫随机场/马尔可夫网 常见的无向图：对数线性模型、条件随机场(CRF） 无向图模型 ![image-20190729142122283](/Users/yyf/Library/Application Support/typora-user-images/image-20190729142122283.png) 无向图的联合概率可以分解为一系列定义在最大团上的非负函数的乘积形式。 ![image-20190729142014942](/Users/yyf/Library/Application Support/typora-user-images/image-20190729142014942.png) 组成：配分函数$Z=\int \tilde{p}(\mathbf{x}) d \mathbf{x}$。 常见的无向图：条件随机场, 词性分类 条件随机场进行词性分类 线性链条件随机场-tutorial（一） 线性链条件随机场-tutorial（二） 常见的无向图：去噪 基于马尔科夫随机场的图像去噪方法+python代码 马尔可夫随机场彩色图去噪 马尔可夫去噪+matlab：能量函数有点不同 采样去获取满足一个分布的样本。 例如：需要获得一个泊松分布，知道某事件符合此分布的话，可以通过采集这个事件的信息，来获得样本。 拒绝采样：利用一个容易获取样本的分布q，先获得一个样本，再通过判断$\alpha(\hat{x})=\frac{\hat{p}(\hat{x})}{k q(\hat{x})}$，来决定是否留下这个样本x Gibbs采样：一种满足稳态转移的马尔可夫采样法。 参考： 直观理解概率图模型中的采样(sampling)技术 浅谈Gibbs 一篇MCMC解释的不错的文章 问题：和推断的关系？ 蒙特卡洛采样、非数学话的解释蒙特卡洛采样、 推断利用图的结构，来计算出一些变量的后验信息 ![image-20190729194524762](/Users/yyf/Library/Application Support/typora-user-images/image-20190729194524762.png) 推断和最大似然任务的关系：在计算最大对数似然函数的时候，中间步骤需要一些变量的后验信息。 例子：EM算法 本质是最大化似然函数：$p(\mathbf{x|\theta})$ 通过隐含结点z，来表示x的编辑概率：$p(\mathbf{x} | \theta)=\sum_{\mathbf{Z}} p(\mathbf{x}, \mathbf{z} | \theta)$ 通过变分函数q(z)(z的先验信息)，来获得一个下界。 EM迭代q和$\theta$, 使得$p(x|\theta)$越来越小. 其中每一次迭代时的$ q(\mathbf{z})=p(\mathbf{z} | \mathbf{x}, \theta)$，因此需要计算$p(z|x)$。此时用到的就是推断。根据图的定义，$p(x|z)和p(x),p(z)$是已知的。 学习如上述的EM算法，学习参数的优化算法。 玻耳兹曼机(RBM)参考一个写的不错的受限玻尔兹曼机（RBM）学习笔记 博客：算法描述 对上一个博客的笔记：对比散度(CD)算法 code: RBM-for-MNIST 其他： 如何使用TensorFlow和VAE模型生成手写数字 free energy的推算 特点：它的单元被分成很大的组，这种组称作层，层之间 的连接由矩阵描述，连通性相对密集。该模型被设计为能够进行高效的 Gibbs 采样， 并且模型设计的重点在于以很高的自由度来学习潜变量。 马尔可夫去噪+matlab：能量函数有点不同 我对玻耳兹曼姬的理解：求出转移的条件概率以后，GIbbs采样，通过一系列的往返操作，可以采出满足p（V）分布的样本。再通过gibbs采样，获得满足p(v)的样本。 采样： 推断和采样的关系 什么时候需要采样 其他参考联合概率、边际概率、条件概率 一个完整的概率图模型笔记、这系列相关的一个博客 概率图模型的讲解 隐马尔可夫(HMM)模型 CPD(conditional probability distribution)概率图模型]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生活中的英文口语]]></title>
    <url>%2Fp%2Fef9c.html</url>
    <content type="text"><![CDATA[重读音动词+介词： 轻轻带过介词，如look at 重读介词如：take off 动词+名词: 日常摘录关于吃饭、点餐、结账6/13 续杯、点餐 split the fare I have a god feeling I could tell]]></content>
      <categories>
        <category>语言</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[粤语口语]]></title>
    <url>%2Fp%2F39a8.html</url>
    <content type="text"><![CDATA[粤语学习笔记 广东话和普通话的区别https://wenku.baidu.com/view/33face69011ca300a6c390cf.html粤语口语https://hal.archives-ouvertes.fr/hal-00271141/document 学粤语的一个不错的网页，中文大学链接 https://www.ilc.cuhk.edu.hk/chinese/canton_express/others/download.html j带头的字 今 jin-&gt;gen 尽量 jin-&gt;zen 叫jiao-&gt;gao 静候 jing-&gt;zeng 自由：zi-&gt;zei you 坚持：jian-&gt;gin ci 枯枝-&gt;fuzi 收成：sou seng 这一次：zeiyici 你要：nei you 失守 sei sou 始终 si zhong 成-&gt;seng 记载-&gt;gei zai]]></content>
      <categories>
        <category>语言</category>
      </categories>
      <tags>
        <tag>粤语</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[presentation常用英文口语]]></title>
    <url>%2Fp%2F9de6.html</url>
    <content type="text"><![CDATA[英语pre摘录 It’s been a while 有阵子了 It all boils down to realizing that it is natural (and interesting!) to consider different topologies on the same set 𝑋, each of which comes with a notion of convergence.这一切归结为 我的声音够大吗 你可以重复一下这个问题吗 我没有想过这个问题，但是我觉得 介绍下一位演讲嘉宾 对这部一部分你们应该有更深的印象 术语Maximum a posteriori estimation MAP posteriori probability 后验概率 ReferencePresentation English(英语 演讲用到的各种表达) Presentation实用表达总结]]></content>
      <categories>
        <category>语言</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图形边缘提取]]></title>
    <url>%2Fp%2Fbe62.html</url>
    <content type="text"><![CDATA[参考资料 Edge detection ppt Edge detection blog Edge detection matlab 图像的二阶信息 传统数学方法发展过程 一阶、二阶、优点、缺点、鲁棒性 canny Sobel code++ I. Sobel. Camera models and machine perception. Technical report, DTIC Document, 1970. thresholding the gradient map. Canny：an extension of Sobel, more robust to noise. code++ J. Canny. A computational approach to edge detection. IEEE TPAMI, 8(6):679–698, 1986. Gaussian smoothing as a preprocessing step Laplacian: 用一个线性算子即可 Ansitropic nabla^2 = uxx+uyy. (右边取绝对值) ![image-20190623174549671](/Users/yyf/Library/Application Support/typora-user-images/image-20190623174549671.png) 深度学习方法 Xie, S., Tu, Z.: Holistically-nested edge detection. In: Proceedings of the IEEE international conference on computer vision, pp. 1395–1403 (2015) Liu, Y., Cheng, M.M., Hu, X., Wang, K., Bai, X.: Richer convolutional features for edge detection. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 3000–3009 (2017) Laplacian的方法边缘加强去噪二阶算子或者一阶算子 边缘 二阶算子对应其他边缘 如canny边缘或者sobel边缘 能否有这个结果]]></content>
      <categories>
        <category>图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mac/ipad/iphone软件清单]]></title>
    <url>%2Fp%2F44bc.html</url>
    <content type="text"><![CDATA[#Mac软件工具 Ipad软件工具做笔记功能 notability功能介绍]]></content>
      <categories>
        <category>软件</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Semismooth牛顿法]]></title>
    <url>%2Fp%2F157d.html</url>
    <content type="text"><![CDATA[参考文献 A highly efficient semismooth Newton augmented Lagrangianmethod for solving Lasso problems，论文代码 A sparse semismooth Newton based proximalmajorization-minimization algorithm for nonconvexsquare-root-loss regression problems, h(Ax)+p(x) 论文中的模型：Primal/Dual$$\text { (P) } \max -{f(x)=h(\mathcal{A} x)-\langle c, x\rangle+ p(x)}$$ $$\text { (P) } \min {f(x)=h(\mathcal{A} x)-\langle c, x\rangle+p(x)}$$ $$\text { (D) } \min \left{h^{}(y)+p^{}(z) | \mathcal{A}^{*} y+z=c\right}$$ where, $\mathcal{A} \in R^{MN}​$, $p, h : \mathcal{Y} \rightarrow \Re \text { and } p : \mathcal{X} \rightarrow(-\infty,+\infty]​$ are two closed proper convex functions. 对于Dual问题： $h^$ is essentially smooth with $\nabla h^{}$ is locally Lipschitz continuous and directionally diﬀerentiable on int $\operatorname{int}\left(\operatorname{dom} h^{*}\right)$. 对偶问题的拉格朗日$l​$和增广拉格朗日$\mathcal{L}​$$$l(y, z, x)=h^{}(y)+p^{}(z)-\left\langle x, \mathcal{A}^{*} y+z-c\right\rangle, \quad \forall(y, z, x) \in \mathcal{Y} \times \mathcal{X} \times \mathcal{X}$$ $$\begin{aligned}\mathcal{L}_{\sigma}(y, z ; x) &amp;=l(y, z, x)+\frac{\sigma}{2}\left|\mathcal{A}^{} y+z-c\right|^{2}, \quad \forall(y, z, x) \in \mathcal{Y} \times \mathcal{X} \times \mathcal{X}\&amp;=h^{}(y)+p^{}(z)+\frac{\sigma}{2}\left|\mathcal{A}^{} y+z-c-\frac{x}{\sigma}\right|^{2}-\frac{1}{2 \sigma}|x|^{2}\end{aligned}$$ 算法框架（第一层循环） ![image-20190625062337998](/Users/yyf/Library/Application Support/typora-user-images/image-20190625062337998.png) 将(18)中的拉格朗日方程转化成单变量拉格朗日方程 Define $\min {y, z} \Psi(y, z) :=\mathcal{L}{\sigma}(y, z ; \tilde{x})​$ Define $\psi(y) :=\inf _{z} \Psi(y, z)​$ （18）中的拉格朗日转化成单变量光滑方程$$\begin{aligned} \Psi(y) &amp;=\inf {z}{ h^{}(y)+p^{}(z)+\frac{\sigma}{2}\left|\mathcal{A}^{} y+z-c-\frac{x}{\sigma}\right|^{2}-\frac{1}{2 \sigma}|x|^{2}} \&amp;=h^(y)+\sigma \inf _{z}\left{\frac{1}{\sigma} p^(z)+\frac{1}{2}\left|z-(c-A^*y+\frac{x}{\sigma})\right|^{2}\right}-\frac{1}{2 \sigma}|x|^{2} \ &amp;=h^(y)+\sigma M{\frac{1}{\sigma}}p^(c-A^*y+\frac{x}{\sigma})-\frac{1}{2 \sigma}|x|^{2} \end{aligned})$$with $z = \arg\min_z p^(z)/\sigma+\frac{1}{2}\left|z-(c-A^y+\frac{x}{\sigma})\right|^{2}=\operatorname{Prox}_{p^{} / \sigma}\left(x / \sigma-\mathcal{A}^{*} \overline{y}+c\right)$ . $\psi(y)$ is a smooth function whose gradient is derived as: $$\begin{aligned} \nabla\Psi(y) &amp;= \nabla h^{}(y)-\mathcal{A} \operatorname{Prox}_{\sigma p}\left(\tilde{x}-\sigma\left(\mathcal{A}^{} y-c\right)\right)\end{aligned}$$ 将 $z =\operatorname{Prox}_{p^{} / \sigma}\left(x / \sigma-\mathcal{A}^{} \overline{y}+c\right)​$ 代入 (18) 得到 $$\psi(y)=h^{}(y)+p^{}\left(\operatorname{Prox}{p^{} / \sigma}\left(x / \sigma-\mathcal{A}^{} y+c\right)\right)+\frac{1}{2 \sigma}\left|\operatorname{Prox}{\sigma p}\left(x-\sigma\left(\mathcal{A}^{*} y-c\right)\right)\right|^{2}-\frac{1}{2 \sigma}|x|^{2}$$ Moreau-Yosida regularization and proximal mapping$$M_{\lambda} f(x) :=\min {u} f(u)+\frac{1}{2 \lambda}|u-x|{2}^{2}$$ $$\nabla M_{\lambda} f(x)=\frac{1}{\lambda}\left(x-\operatorname{Prox}_{\lambda f}(x)\right)$$ $$\operatorname{Prox}_{\lambda f}(x) :=\arg \min _{u \in \mathcal{X}} f(x)+\frac{1}{2 \lambda}|u-x|^{2}$$ $$\operatorname{Prox}{\lambda p}(x)+\lambda \operatorname{Prox}{p^{}(x) / \lambda}(x / \lambda)=x\operatorname{Prox}{\lambda p}(x)+\lambda \operatorname{Prox}{p^{}(x) / \lambda}(x / \lambda)=x$$ $\min {y, z} \Psi(y, z) $等价于以下单变量非线形方程 (22)$$\nabla\Psi(y)=0$$whose the generalized Hessian of $\Psi$ at y is defined as$$\hat{\partial}^{2} \psi(y) :=\partial\left(\nabla h^{*}\right)(y)+\sigma \mathcal{A} \partial \operatorname{Prox}{\sigma p}\left(\tilde{x}-\sigma\left(\mathcal{A}^{} y-c\right)\right) \mathcal{A}^{}$$Defining the $H \in \partial^{2} h^{}(y)$ and $U \in \partial \operatorname{Prox}_{\sigma p}\left(\tilde{x}-\sigma\left(\mathcal{A}^{} y-c\right)\right)$, then, we have$$V :=H+\sigma \mathcal{A} U \mathcal{A}^{*}$$ 利用牛顿法和Hessian 矩阵求解非线形等式(22) (第二层循环) 寻找方向$d$：$V_{j} d+\nabla \psi\left(y^{j}\right)=0$（24） $V \in \hat{\partial}^{2} \psi(y)$, $\hat{\partial}^{2} \psi(y) :=\partial\left(\nabla h^{}\right)(y)+\sigma \mathcal{A} \partial \operatorname{Prox}_{\sigma p}\left(\tilde{x}-\sigma\left(\mathcal{A}^{} y-c\right)\right) \mathcal{A}^{*}$ $V :=H+\sigma \mathcal{A} U \mathcal{A}^{*}​$ 步长：set $\alpha_{j}=\delta^{m_{j}}​$ $y^{j}+\delta^{m} d^{j} \in \operatorname{int}\left(\operatorname{dom} h^{*}\right) \quad \text { and } \quad \psi\left(y^{j}+\delta^{m} d^{j}\right) \leq \psi\left(y^{j}\right)+\mu \delta^{m}\left\langle\nabla \psi\left(y^{j}\right), d^{j}\right\rangle​$ 更新：$y^{j+1}=y^{j}+\alpha_{j} d^{j}$ 迭代终止条件：$\nabla \psi\left(y^{j}\right)$ is sufficiently small 求解线性问题（24）$V_{j} d=-\nabla \psi\left(y^{j}\right)​$ 方法一：利用$V_j​$的稀疏性求出解析解$$\left(H+\sigma A U A^{T}\right) d=-\nabla \psi(y), H = LL^T$$ $$\left(I_{m}+\sigma\left(L^{-1} A\right) U\left(L^{-1} A\right)^{T}\right)\left(L^{T} d\right)=-L^{-1} \nabla \psi(y)$$ 考虑简化后的情况：$$\left(I_{m}+\sigma A U A^{T}\right) d=-\nabla \psi(y)$$ $$\mbox{with } A U A^{T}=(A U)(A U)^{T}=A_{\mathcal{J}} A_{\mathcal{J}}^{T}$$ $$\left(I_{m}+\sigma A U A^{T}\right)^{-1}=\left(I_{m}+\sigma A_{\mathcal{J}} A_{\mathcal{J}}^{T}\right)^{-1}=I_{m}-A_{\mathcal{J}}\left(\sigma^{-1} I_{r}+A_{\mathcal{J}}^{T} A_{\mathcal{J}}\right)^{-1} A_{\mathcal{J}}^{T}$$ 维度降低：利用U是一个对角由0和1组成的对角矩阵，$\mathcal{O}\left(m^{2} n\right)$-&gt;$\mathcal{O}\left(m^{2} r\right)$-&gt;$\mathcal{O}\left(r^{2} m\right)$ ![image-20190627171823537](/Users/yyf/Library/Application Support/typora-user-images/image-20190627171823537.png) 方法二：Pcg 循环（第三层循环） Do $V_jd^j​$ Until $\left|V_{j} d^{j}+\nabla \psi\left(y^{j}\right)\right| \leq \min \left(\overline{\eta},\left|\nabla \psi\left(y^{j}\right)\right|^{1+\tau}\right)​$ 尝试过的加速办法： 与$\tau$的大小有关 将该循环写成c语言 每次牛顿迭代从上一次d的结果开始。在算法快收敛的时候可以加速。 速度分析 循环一：lnexact Lagrangian methd 循环二：牛顿法迭代求解问题（22） 影响循环二迭代次数的因素： 1.该循环的中止条件: $\left|\nabla \psi_{k}\left(y^{k+1}\right)\right|$ 足够小 2.循环三中的精度$\tau$：该循环的收敛速度与循环三中pcg的精度有关$$\left|y^{j+1}-\overline{y}\right|=O\left(\left|y^{j}-\overline{y}\right|^{1+\tau}\right)$$ 循环三(若使用pcg的方法求解(24))： 影响循环三迭代次数的因素: $\tau$的大小 1.该循环终止条件：$\left|V_{j} d^{j}+\nabla \psi\left(y^{j}\right)\right| \leq \min \left(\overline{\eta},\left|\nabla \psi\left(y^{j}\right)\right|^{1+\tau}\right),\tau=(0,1]$ h(x)+p(Bx) 目标方程： $\min|y-g|+\lambda|\nabla y|_1$ 无法套用论文中$h(Ay)+p(y)​$的Dual方法的原因： 如果$p(y)=\lambda|\nabla y|_1​$，那么p*的显式无法表达。 如果$h(Ay)=\lambda|\nabla y|_1, A=\nabla$, 那么依然无法将问题转化成单变量的smooth问题，因为h项会被保留 $\nabla$的矩阵形式 (补充) 提出模型 $h(y)+p(By), h(y)=|Ay-g|, p(Bx)=|\nabla y|_1​$，$B=\nabla​$ （P）$\min h(y)+p(By)​$, $h(y)=|Ay-g|​$, $p(Bx)=|\nabla y|_1​$ （D）$\min \left{h^{}(y)+p^{}(z) | \mathcal{B}^{} z+y=c\right}$, $h^{}(y)=\frac{1}{2}|b+y|^{2}-\frac{1}{2}|b|^{2}$, $p^{*}(z)=I\left{|z|_{\infty} \leq \lambda\right}$ 对于D问题，无法转化成单变量的smooth方程，推导见附录(待补充)。因此选择该模型的主问题。 对于(P) $h(y)+p(By)​$，转化成单变量的smooth方程 增广拉格朗日：$\mathcal{L}_{\sigma}(y, z ; x) :=h(y)+p(z)+&lt;x, \mathcal{B} y-z&gt;+\frac{\sigma}{2}|\mathcal{B} y-z|^{2}​$ ​ $=h(y)+p(z)+\frac{\sigma}{2}\left|\mathcal{B} y+\frac{x}{\sigma}-z\right|^{2}-\frac{1}{2 \sigma}|x|^{2}​$ 转化后的单变量方光滑方程： $\mathcal{L}{\sigma}(y ; x) :=h(y)+p\left(\operatorname{Prox} \frac{p}{\sigma}\left(\mathcal{B} y+\frac{x}{\sigma}\right)\right)+\frac{1}{2 \sigma}\left|\operatorname{Prox}{\sigma p^{*}}\left(\sigma\left(\mathcal{B} y+\frac{x}{\sigma}\right)\right)\right|^{2}-\frac{1}{2 \sigma}|x|^{2}, \overline{z}=\operatorname{Prox}_{\frac{p}{\sigma}}\left(\mathcal{B} y+\frac{x}{\sigma}\right)$ $\nabla \mathcal{L}{\sigma}(y) :=\nabla h(y)+\mathcal{B}^{*} \operatorname{Prox}{\sigma p^{*}}(\sigma(\mathcal{B} y+\frac{x}{\sigma})$ $\partial\left(\nabla \mathcal{L}{\sigma}(y)\right) :=\partial(\nabla h(y))+\sigma \mathcal{B}^{*} \partial \operatorname{Prox}{\sigma p^{}}\left(\sigma\left(\mathcal{B} y+\frac{x}{\sigma}\right)\right) \mathcal{B}\=\partial(\nabla h(y))+\sigma \mathcal{B}^{}\left(I-\partial \operatorname{Prox}_{\frac{p}{\sigma}}\left(\mathcal{B} y+\frac{x}{\sigma}\right)\right) \mathcal{B}​$ 求解$V_{j} d=-\nabla \psi\left(y^{j}\right)​$ 方法一：求逆 其中, $\partial \operatorname{Prox}{\sigma p^{}}\left(\sigma\left(\mathcal{B} y+\frac{x}{\sigma}\right)\right)​$的稀疏性随着图像的平滑减弱，因此直接利用该稀疏矩阵求逆，*计算立马随着噪声的减弱而变慢**。相反，$\partial \operatorname{Prox}{\frac{p}{\sigma}}\left(\mathcal{B} y+\frac{x}{\sigma}\right)​$的稀疏性随着图像的平滑变稀疏。 $\left(A^TA+\sigma \mathcal{B}^\mathcal{B}-\sigma \mathcal{B}^{}\partial \operatorname{Prox}_{\frac{p}{\sigma}}\left(\mathcal{B} y+\frac{x}{\sigma}\right)\mathcal{B}\right)d=-\nabla \psi\left(y^{j}\right) ​$ Denote $U =\partial \operatorname{Prox}_{\frac{p}{\sigma}}\left(\mathcal{B} y+\frac{x}{\sigma}\right)​$ , $b =-\nabla \psi\left(y^{j}\right) ​$ we have $\left(A^TA+\sigma \mathcal{B}^\mathcal{B}-\sigma \mathcal{B}^{}U\mathcal{B}\right)d=-\nabla \psi\left(y^{j}\right) ​$ 如果没有U，就可以使用FFT快速变化，因为B可以当作[-1 1]构成的卷积 如果对可以对$A^TA+\sigma \mathcal{B}^*\mathcal{B}$进行$LL^T$的分解。可将原问题转化成以下形式后求逆$$\left(I_{m}+\sigma\left(L^{-1} A\right) U\left(L^{-1} A\right)^{T}\right)\left(L^{T} d\right)=-L^{-1} \nabla \psi(y)$$例如在TV denoising的情况下：$A=I$，$B=[B1, B2]$, 则需对$I+\sigma B^*B$进行分解 (目前没有实现这个分解, 所以使用pcg求解该线性等式) 方法二：Pcg 循环（第三层循环） Do $V_jd^j​$ Until $\left|V_{j} d^{j}+\nabla \psi\left(y^{j}\right)\right| \leq \min \left(\overline{\eta},\left|\nabla \psi\left(y^{j}\right)\right|^{1+\tau}\right)​$ 尝试过的加速办法： 将该循环写成c语言 加速的办法，每次牛顿迭代从上一次d的结果开始。在算法快收敛的时候可以加速 实验结果与实验设置 循环一：lnexact Lagrangian methd 循环二：牛顿法迭代求解问题（22） 设置循环二的中止条件为: $\left|\nabla \psi_{k}\left(y^{k+1}\right)\right|$ &lt;{0.005} ps：如果在小于0.005前达到收敛，则终止循环二，进入循环一的下一轮迭代 该循环的收敛速度与循环三中pcg的精度有关:$$\left|y^{j+1}-\overline{y}\right|=O\left(\left|y^{j}-\overline{y}\right|^{1+\tau}\right)$$ 循环三(pcg)： 影响循环三迭代次数的因素: $\tau​$的大小 该循环终止条件：$\left|V_{j} d^{j}+\nabla \psi\left(y^{j}\right)\right| \leq \min \left(\overline{\eta},\left|\nabla \psi\left(y^{j}\right)\right|^{1+\tau}\right),\tau=(0,1]$ $\tau=1$:循环三循环(大概20)次，循环二收敛需要*次，循环一需要*次 $\tau=2$:循环三循环*次，循环二收敛需要*次，循环一需要*次 (实验结果需要补充) 实验中存在的问题 循环二和循环三之间的收敛速度没有满足理论值：$$\left|y^{j+1}-\overline{y}\right|=O\left(\left|y^{j}-\overline{y}\right|^{1+\tau}\right)$$ ​ 具体的说，循环1中的中间几次迭代中，循环二的收敛速度很慢，没有达到理论值，甚至比线性收敛还要慢。 ​ （循环二的收敛图需要补充）​ Non-convex model1. General Model A nonconvex problem (square-root regression problem) (3) $$\min {\beta \in \Re^{n}}{g(\beta) :=\underbrace{h(X \beta)}{f(\beta)}+\underbrace{p(\beta)-q(\beta)}_{r(\beta)}}$$ ​ $p : \Re^{n} \rightarrow(-\infty,+\infty] \text { is a proper closed convex function }​$ ​ $q : \Re^{n} \rightarrow \Re \text { is a finite-valued (smooth, not essential) convex function. }$ ​ $ \text {The proximal functions of h and p to be (strongly) semismooth.}$ Examples （等待补充） 因为原general model (3) 转化成模型 (10)/(P): $\text { Given } \sigma&gt;0, \tau&gt;0, \tilde{\beta} \in \mathbb{R}^{n}, \tilde{v} \in \mathbb{R}^{n}, \text { and }\tilde{b} \in \mathbb{R}^{m}$$$\begin{aligned} \min _{\beta \in \mathbb{R}^{n}}{h(\beta ; \sigma, \tau, \tilde{\beta}, \tilde{v}, \tilde{b}) :=&amp;|X \beta-b|+\lambda p(\beta)-q(\tilde{\beta})-\langle\tilde{v}, \beta-\tilde{\beta}\rangle \ &amp;+\frac{\sigma}{2}|\beta-\tilde{\beta}|^{2}+\frac{\tau}{2}|X \beta-\tilde{b}|^{2} } \end{aligned}$$(1) Linearize the concave term: $-q(\beta)$. 因为此项nonconvex (2) Add the proximal term：$\frac{\tau}{2}|X \beta-X \tilde{\beta}|^{2}$. 因为$h(\cdot)$和$p(\beta)$是nonsmooth $\beta^{k+1}=\operatorname{Prox}_{\lambda p / \sigma^{2, k}}\left(\beta^{k}+\left(\nabla q\left(\beta^{k}\right)-X^{T} u^{k+1}\right) / \sigma^{2, k}\right)​$ 问题 $\frac{\sigma}{2}|\beta-\tilde{\beta}|$的作用：因为是PPA算法 $\frac{\tau}{2}|X \beta-\tilde{b}|^{2}$这个Proximal项的由来 针对该非凸模型的算法，解的唯一性和算法的收敛性能否被证明？只要是非凸问题，都无法保障解的唯一性？那么该算法的优点？ 该类问题本来的解法 2. SSN-based PPM Algorithm PPM algorithm： Proximal majorization-minimization Initialize: $\beta^{0} \approx \underset{\beta \in \mathbb{R}^{n}}{\operatorname{argmin}}\left{h\left(\beta ; \sigma^{1}, \tau^{1}, 0,0, b\right)\right}​$ Iteration: step 1 $\beta^{k+1}=\underset{\beta \in \mathbb{R}^{n}}{\operatorname{argmin}}\left{h\left(\beta ; \sigma^{2, k}, \tau^{2, k}, \beta^{k}, \nabla q\left(\beta^{k}\right), X \beta^{k}\right)+\left\langle\delta^{k}, \beta-\beta^{k}\right\rangle\right}$ ​ step 2 $\sigma^{2, k+1}=\rho_{k} \sigma^{2, k}, \tau^{2, k+1}=\rho_{k} \tau^{2, k}\text { with } \rho_{k} \in(0,1)​$ Until: If $β_{k+1}​$ satisﬁes a prescribed stopping criterion, terminate; Step 1: solve the dual of the (10) which is（12）$$\begin{aligned} \min {u \in \mathbb{R}^{m}} &amp;\left{\varphi(u) :=\langle u, b\rangle+\frac{\tau}{2}\left|\tau^{-1} u+\tilde{b}-b\right|^{2}-\left|\operatorname{Prox}{\tau^{-1}|\cdot|}\left(\tau^{-1} u+\tilde{b}-b\right)\right|\right.\ &amp;-\frac{1}{2 \tau}\left|\operatorname{Prox}{\tau \delta{B}}(u+\tau(\tilde{b}-b))\right|^{2}+\frac{\sigma}{2}\left|\tilde{\beta}+\sigma^{-1}\left(\tilde{v}-X^{T} u\right)\right|^{2} \ &amp;-\lambda p\left(\operatorname{Prox}{\sigma^{-1} \lambda p}\left(\tilde{\beta}+\sigma^{-1}\left(\tilde{v}-X^{T} u\right)\right)\right)-\frac{1}{2 \sigma}\left|\operatorname{Prox}{\sigma(\lambda p) *}\left(\sigma \tilde{\beta}+\tilde{v}-X^{T} u\right)\right|^{2} } \end{aligned} (12)$$with $\overline{y}=\operatorname{Prox}{\tau^{-1}| |}\left(\tau^{-1} \overline{u}+\tilde{b}-b\right), \quad \overline{\beta}=\operatorname{Prox}{\sigma^{-1} \lambda p}\left(\tilde{\beta}+\sigma^{-1}\left(\tilde{v}-X^{T} \overline{u}\right)\right)​$. and $\beta^{k+1}=\operatorname{Prox}_{\lambda p / \sigma^{2, k}}\left(\beta^{k}+\left(\nabla q\left(\beta^{k}\right)-X^{T} u^{k+1}\right) / \sigma^{2, k}\right)​$ (12) 的推导过程 令$y=X \beta-b$将(10)转化成约束问题(11)$$\min _{\beta \in \mathbb{R}^{n}, y \in \mathbb{R}^{m}}\left{|X\beta-b|+\lambda p(\beta)-\langle\tilde{v}, \beta-\tilde{\beta}\rangle+\frac{\sigma}{2}|\beta-\tilde{\beta}|^{2}+\frac{\tau}{2}|y+b-\tilde{b}|^{2} \right}\\text{subject to }X \beta-b=y\$$ 将约束问题转化成Lagrangian： $L(y,\beta; u) = \left{|y|+\lambda p(\beta)-\langle\tilde{v}, \beta-\tilde{\beta}\rangle+\frac{\sigma}{2}|\beta-\tilde{\beta}|^{2}+\frac{\tau}{2}|y+b-\tilde{b}|^{2} - &lt;u, X \beta-y-b&gt;\right}​$ (11) Dual function of (11)$$g(u):=\inf _{y,\beta} L(y, \beta;u)$$ 对$L(y,\beta; u) ​$进行配方$$\begin{aligned}L(y,\beta; u)&amp;= |y|+\lambda p(\beta)-\langle\tilde{v}, \beta-\tilde{\beta}\rangle+\frac{\sigma}{2}|\beta-\tilde{\beta}|^{2}+\frac{\tau}{2}|y+b-\tilde{b}|^{2} - \langle u, y-X \beta+b\rangle\&amp;={|y|+\frac{\tau}{2}|y+b-\tilde{b}|^{2}-\langle u,y\rangle}+{\lambda p(\beta)-\langle\tilde{v}, \beta-\tilde{\beta}\rangle+\frac{\sigma}{2}|\beta-\tilde{\beta}|^{2}+\langle X^T u,\beta\rangle}-\langle u,b\rangle\&amp;={|y|+\frac{\tau}{2}|y+b-\tilde{b}-\frac{u}{\tau}|^{2}}-\frac{u^2}{2\tau}+\langle \tilde b,u\rangle+{\lambda p(\beta)+\frac{\sigma}{2}|\beta-\tilde{\beta}|^{2}+\langle X^Tu-\tilde{v}, \beta-\tilde{\beta}\rangle+\langle \tilde{\beta},X^Tu\rangle}\&amp;={|y|+\frac{\tau}{2}|y+b-\tilde{b}+\frac{u}{\tau}|^{2}}+{\lambda p(\beta) + \frac{\sigma}{2}|\beta-\tilde{\beta}+\frac{X^Tu-\tilde{v}}{\sigma}|^{2}}…\&amp;-\frac{u^2}{2\tau}+\langle \tilde b,u\rangle+\langle\tilde{\beta},X^Tu\rangle-|\frac{X^Tu-\tilde{v}}{\sigma}|^2 \\end{aligned}$$ (12) 的求解：A semismooth Newton‘s method 最小化（12）等价于（12）的一阶条件$$\nabla \varphi(u)=\operatorname{Prox}{\tau^{-1} |}\left(\tau^{-1} u+\tilde{b}-b\right)-X \operatorname{Prox}{\sigma^{-1} \lambda p}\left(\tilde{\beta}+\sigma^{-1}\left(\tilde{v}-X^{T} u\right)\right)+b\\nabla \varphi(u)=0\qquad(13)\$$ Solve nonlinear equation（13）by pcg $\hat{\partial}^{2} \varphi(u) :=\sigma^{-1} X \partial \operatorname{Prox}{\sigma^{-1} \lambda p}\left(\tilde{\beta}+\sigma^{-1}\left(\tilde{v}-X^{T} u\right)\right) X^{T}+\tau^{-1} \partial \operatorname{Prox}{\tau^{-1} |}\left(\tau^{-1} u+\tilde{b}-b\right)$ $H:=\sigma^{-1} X U X^{T}+\tau^{-1} V \in \hat{\partial}^{2} \varphi(u)​$ ![image-20190707021520501](/Users/yyf/Library/Application Support/typora-user-images/image-20190707021520501.png) 3. Problem4. Our case For the ROF model: $h(X\beta)=|\nabla \beta|_1$ $p(\beta)=|\beta-b|_2^2,q(\beta)=0​$ 附录 转化成smooth单变量方程的推导过程$$\begin{aligned} \Psi(\hat{y}, \hat{z}) &amp;=\inf {z} \Psi(\hat{u}, z) \ &amp;=G(\hat{y})+\sigma \inf _{z}\left{\frac{1}{\sigma} F(z)+\frac{1}{2}\left|z-K \hat{y}-\frac{x}{\sigma}\right|^{2}\right}-\frac{1}{2 \sigma}|x|^{2} \ &amp;=G(\hat{y})+\sigma M(F / \sigma)(K \hat{y}+x)-\frac{1}{2 \sigma}|x|^{2} \end{aligned}$$Using the Moreau-Yosida regularization:$$M{\lambda} f(x) :=\min {u} f(u)+\frac{1}{2 \lambda}|u-x|{2}^{2}$$ $$\nabla M_{\lambda} f(x)=\frac{1}{\lambda}\left(x-\operatorname{Prox}_{\lambda f}(x)\right)$$ $h(y)+p(By)$对偶问题无法转化成单变量smooth的原因$$\begin{array}{c}{\partial \psi(z)=\partial p^{}(z)-\underline{A x}+\sigma\left(\mathcal{A}^{} z+y-c\right)} \ {0 \in \partial \psi(\overline{z})} \ {0 \in \partial p^{}(\overline{z})-\mathcal{A} x+\sigma\left(\mathcal{A}^{} \overline{z}+y-c\right)} \ {0 \in \sigma\left(\frac{\partial p^{}(\overline{z})}{\sigma}+\mathcal{A}^{} z-\left(c-y+\frac{1}{\sigma} \mathcal{A} x\right)\right)}\end{array}$$$z$无法用proximal表示]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[变分不等式的收敛性证明]]></title>
    <url>%2Fp%2Ff8c4.html</url>
    <content type="text"><![CDATA[变分不等式变分不等式(VI)的定义： ![image-20190710190816957](/Users/yyf/Library/Application Support/typora-user-images/image-20190710190816957.png) 最优化问题的转化： ​ $x^{*}=\arg \min _{x \in X} f(x)​$ ​ 等价于满足$\operatorname{VI}(\nabla f, X)​$即 ​ $\nabla f\left(x^{}\right)^{T}\left(x^{\prime}-x^{}\right) \geq 0, \forall x^{\prime} \in X$ 优化问题 $$x^{*} \in \arg \min {\theta(x)+f(x) | x \in \mathcal{X}}$$ ​ 其中$f(x),\theta(x)$是convex function, $\theta$不一定可微, 等价于：$$x^{} \in \mathcal{X}, \quad \theta(x)-\theta\left(x^{}\right)+\left(x-x^{}\right)^{T} \nabla f\left(x^{}\right) \geq 0, \quad \forall x \in \mathcal{X}$$ ![image-20190710201934772](/Users/yyf/Library/Application Support/typora-user-images/image-20190710201934772.png) ​ ​ ​ 优化问题转化VI不等式问题将不同的优化问题转化成等价的VI问题： 一元约束问题$\min {\theta(x) | A x=b, x \in \mathcal{X}}$ 等价于拉格朗日：$L(x, \lambda)=\theta(x)-\lambda^{T}(A x-b), \quad(x, \lambda) \in \mathcal{X} \times \Re^{m}$ 转化后等于VI inequality：$w^{} \in \Omega, \quad \theta(x)-\theta\left(x^{}\right)+\left(w-w^{}\right)^{T} F\left(w^{}\right) \geq 0, \quad \forall w \in \Omega$ 二元三元。。 min-max问题: $\min {x \in \mathcal{X}} \max _{y \in \mathcal{Y}}\left{\mathcal{L}(x, y)=\theta{1}(x)-y^{T} A x-\theta_{2}(y)\right}$ PPA的收敛性用PI不等式证明方程：$$\min {\theta(x)+f(x) | x \in \mathcal{X}}$$where θ(x) and f(x) are convex but θ(x) is not necessary smooth, X is a closed convex set. ![image-20190710204453147](/Users/yyf/Library/Application Support/typora-user-images/image-20190710204453147.png) 定义 Monotone operator 单调函数（x-y）（F（x）-F(y)）&gt;0， 则F是单调函数 凸函数满足的性质$$(x-y)^{T}(\nabla f(x)-\nabla f(y)) \geq 0$$We say the gradient rf of the convex function f is a monotone operator. min max Lagrangian 和 max min Lagrangian的关系]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[L1算法综述]]></title>
    <url>%2Fp%2F65b3.html</url>
    <content type="text"><![CDATA[Preliminaries lowercontinuity 一阶算法 Proximal point algorithm Gradient projection method. Dual-projection An Algorithm for Total Variation Minimization and Applications ALM和PPA ReferenceADMM（1975，1976，2011） Gabay, D., and Mercier, B., A dual algorithm for the solution of nonlinear variational problems via finite-element approximations, Comp. Math. Appl., 2 (1976), pp. 17-40. Glowinski, R., and Marrocco, A., Sur lapproximation par elements finis dordre un, et la resolution par penalisation-dualite dune classe de problemes de Dirichlet nonlineaires, Rev. Francaise dAut. Inf. Rech. Oper., R-2 (1975), pp. 41-76. Existing convergence theory for ADMM Eckstein, J., and Bertsekas, D., On the Douglas-Rachford splitting method and the proximal point algorithm for maximal monotone operators, Mathematical Programming 55, NorthHolland, 1992. Boyd, S., Parikh, N., Chu, E., Peleato, B., &amp; Eckstein, J. (2011). Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends® in Machine learning, 3(1), 1-122. Split Bregman Bregman distance图像复原. Osher, S., Burger, M., Goldfarb, D., Xu, J., &amp; Yin, W. (2005). An iterative regularization method for total variation-based image restoration. Multiscale Modeling &amp; Simulation, 4(2), 460-489. 也是利用了Bregman distance 处理denoising 首次提出。Goldstein, T., &amp; Osher, S. (2009). The split Bregman method for L1-regularized problems. SIAM journal on imaging sciences, 2(2), 323-343. 和ADMM的等价性。Esser, E. (2009). Applications of Lagrangian-based alternating direction methods and connections to split Bregman. CAM report, 9, 31. Split Bregman（1967，2009） 发展过程 Bregman Iteration to unconstrained problem Bregman Iteration to constrained problem Split Bregman to two variable problem Bregman证明 Goldstein, T., &amp; Osher, S. (2009). The split Bregman method for L1-regularized problems. SIAM journal on imaging sciences, 2(2), 323-343. Bregman distance 1.Bregman Iteration直接解决的问题: [21]有convergence的证明；[4]中提出Bregman Iteration ![image-20190625042850317](/Users/yyf/Library/Application Support/typora-user-images/image-20190625042850317.png) 结论：通过Bregman Iteration, 解converge到(2.1)的最小，且满足H(u)=0 Theorem 2.1: H(u)收敛到0[21] ![image-20190625050639305](/Users/yyf/Library/Application Support/typora-user-images/image-20190625050639305.png) 2.Bregman iteration for constrained optimization problems （2.4）$$\min _{u} E(u) \text { such that } \mathrm{Au}=\mathrm{b}$$ ​ 将其转化为无约束问题(2.5)(等价，当lambda很大的情况下，但是lambda很大是不好求解)$$\min {u} E(u)+\frac{\lambda}{2}|A u-b|{2}^{2}$$​ 使用Bregman Iteration：[30] and [21] ![image-20190625043847524](/Users/yyf/Library/Application Support/typora-user-images/image-20190625043847524.png) 当A是线性的时候可以将其简化为 ![image-20190625045710093](/Users/yyf/Library/Application Support/typora-user-images/image-20190625045710093.png) ​ 利用Bregman iteration获得(2.5)的解；根据Theorem 2.1, 这个解满足Au=b； 根据这个性质证明这个解是(2.4)的最小解, Theorem 2.2就是解的等价性证明 （问题）：意味着任何一个lambda下的2.5的解，都等价于(2.4)的解。 Bregman的优点：收敛快(原因见appendix); 可以保持$\lambda$是常数，不需要变大，因此稳定。 对于这个约束问题，和其他方法的比较： ![image-20190625063509825](/Users/yyf/Library/Application Support/typora-user-images/image-20190625063509825.png) ![image-20190625063519479](/Users/yyf/Library/Application Support/typora-user-images/image-20190625063519479.png) Split Bregman for l1-regularized optimization problem (1.1) $$\min _{u}|\Phi(u)|+H(u)$$ where |·| denotes the l1-norm, and both |Φ(u)| and H(u) are convex functions, Φ(·) to be diﬀerentiable. 引入一个变量d, 转化成一个约束问题 (3.1) $\min _{u, d}|d|+H(u) \text { such that } d=\Phi(u)​$ 转化成一个无约束问题 (3.2) $\min {u, d}|d|+H(u)+\frac{\lambda}{2}|d-\Phi(u)|{2}^{2}$ 套用(2.6-2.8)并转化成(2.9-2.10)的形式，得到the Split Bregman Iteration ![image-20190625054707041](/Users/yyf/Library/Application Support/typora-user-images/image-20190625054707041.png) 通过iteratively minimizing解决（3.7） ![image-20190625054906321](/Users/yyf/Library/Application Support/typora-user-images/image-20190625054906321.png) 整个算法 ![image-20190625055124896](/Users/yyf/Library/Application Support/typora-user-images/image-20190625055124896.png) 内循环N=1即可，直观理解 ![image-20190625055357144](/Users/yyf/Library/Application Support/typora-user-images/image-20190625055357144.png) Application ![image-20190625055621617](/Users/yyf/Library/Application Support/typora-user-images/image-20190625055621617.png) ![image-20190625055607524](/Users/yyf/Library/Application Support/typora-user-images/image-20190625055607524.png) ADMM和Split bregman的关系 和Split Bregman的等价性proof Applications of Lagrangian-Based Alternating Direction Methods and Connections to Split Bregman [2009] ADMM 最早分别由 Glowinski &amp; Marrocco 及 Gabay &amp; Mercier 于 1975 年和 1976 年提出，并被 Boyd 等人于 2011 年重新综述并证明其适用于大规模分布式优化问题。由于 ADMM 的提出早于大规模分布式计算系统和大规模优化问题的出现，所以在 2011 年以前，这种方法并不广为人知。 ADMM是一种ALM的方法。PPA也是。 Related Algorithm ![image-20190723150552390](/Users/yyf/Library/Application Support/typora-user-images/image-20190723150552390.png) 来自Dual ascent+approximate Primal ascent，因为函数不具有连续性，有很多断掉的极大值点。 ![image-20190723175554735](/Users/yyf/Library/Application Support/typora-user-images/image-20190723175554735.png) ![image-20190723175611856](/Users/yyf/Library/Application Support/typora-user-images/image-20190723175611856.png) PPA（1976）Primal-dual（2011） A First-Order Primal-Dual Algorithm for Convex Problems with Applications to Imaging 二阶算法Inexact Lagrangian + 牛顿法 A highly eﬃcient semismooth Newton augmented Lagrangian method for solving Lasso problems code++ 无约束问题转化成约束问题$$\text { (P) } \max -{f(x)=h(\mathcal{A} x)-\langle c, x\rangle+ p(x)}$$ $$\text { (P) } \min {f(x)=h(\mathcal{A} x)-\langle c, x\rangle+p(x)}$$ $$\text { (P) } \max -{f(x)=h(\mathcal{A} x)-\langle c, x\rangle+ p(x)}$$ $$\text { (D) } \min \left{h^{}(y)+p^{}(z) | \mathcal{A}^{*} y+z=c\right}$$ 从(P)到(D)的转化过程：与增广拉格朗日的关系？ Assumption:![image-20190625062450759](/Users/yyf/Library/Application Support/typora-user-images/image-20190625062450759.png) 算法基础：An inexact augmented Lagrangian method for (D)[42]: $\lambda$是越来越大的$$l(y, z, x)=h^{}(y)+p^{}(z)-\left\langle x, \mathcal{A}^{*} y+z-c\right\rangle, \quad \forall(y, z, x) \in \mathcal{Y} \times \mathcal{X} \times \mathcal{X}$$ $$\mathcal{L}_{\sigma}(y, z ; x) :=l(y, z, x)+\frac{\sigma}{2}\left|\mathcal{A}^{*} y+z-c\right|^{2}, \quad \forall(y, z, x) \in \mathcal{Y} \times \mathcal{X} \times \mathcal{X}$$ ![image-20190625062337998](/Users/yyf/Library/Application Support/typora-user-images/image-20190625062337998.png) 算法核心 将(18) 转化成 (22) ![image-20190625063019627](/Users/yyf/Library/Application Support/typora-user-images/image-20190625063019627.png) ![image-20190625063050310](/Users/yyf/Library/Application Support/typora-user-images/image-20190625063050310.png) 解决（22）：Ax = 0 的方法 牛顿法法 收敛性分析 应用：Yuan, Y., Sun, D., &amp; Toh, K. C. (2018). An efficient semismooth Newton based algorithm for convex clustering. arXiv preprint arXiv:1802.07091. Nonconvex + 牛顿法 目标问题：square-root regression problem$$\min _{\beta \in \mathbb{R}^{n}}{g(\beta) :=|X \beta-b|+\lambda p(\beta)-q(\beta)}$$ 收敛性证明一般流程：解的存在性、唯一性到算法的收敛性 先证明解的存在性、通过严格凸问题得到解的唯一性、假设存在唯一解，然后收敛到最小解 例子： 存在性证明：A CONVEX VARIATIONAL MODEL FOR RESTORING BLURRED IMAGES WITH MULTIPLICATIVE NOISE; On the convex model of speckle reduction ![image-20190625072208966](/Users/yyf/Library/Application Support/typora-user-images/image-20190625072208966.png) ![image-20190625072239269](/Users/yyf/Library/Application Support/typora-user-images/image-20190625072239269.png) 唯一性：A CONVEX VARIATIONAL MODEL FOR RESTORING BLURRED IMAGES WITH MULTIPLICATIVE NOISE; On the convex model of speckle reduction 收敛性： 问题 牛顿法中，P和D之间与拉格朗日的关系 semismooth到底什么意思 在Split Bregman中，Split Bregman下的任何lambda都是原约束问题的解？]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[美食地图]]></title>
    <url>%2Fp%2Facef.html</url>
    <content type="text"><![CDATA[尖沙咀 海港城旁边： DFS，Aqua spirit， 把地铁口也标上 买小熊饼干：在美丽华商厦，是个类似重庆大楼的开放的楼 旺记冰室/一兰拉面： 妈咪鸡蛋仔和薯条/； 冰淇淋；送他们上船； 点心：好运添，唐宫小聚（新式） 火锅：火水爐冰室火鍋 旺角 https://www.openrice.com/zh/hongkong/r-%E7%81%AB%E6%B0%B4%E7%88%90%E5%86%B0%E5%AE%A4%E7%81%AB%E9%8D%8B-%E6%97%BA%E8%A7%92-%E6%B8%AF%E5%BC%8F-%E7%81%AB%E9%8D%8B-r544211/reviews ![image-20190623004929530](/Users/yyf/Library/Application Support/typora-user-images/image-20190623004929530.png) 岛上拍照![191563885086_.pic](/Users/yyf/Library/Containers/com.tencent.xinWeChat/Data/Library/Application Support/com.tencent.xinWeChat/2.0b4.0.9/fe11254b8abd42aa6171c5844ef84c2e/Message/MessageTemp/9e20f478899dc29eb19741386f9343c8/Image/191563885086_.pic.jpg) 购物![201563885236_.pic](/Users/yyf/Library/Containers/com.tencent.xinWeChat/Data/Library/Application Support/com.tencent.xinWeChat/2.0b4.0.9/fe11254b8abd42aa6171c5844ef84c2e/Message/MessageTemp/9e20f478899dc29eb19741386f9343c8/Image/201563885236_.pic.jpg) 清单去一个岛徒步/长洲岛/西贡，晚上坐船吃冰淇淋：夏天小清新风 去吃茶餐厅 去坐傍晚的叮叮车，吃shakeshack 去逛香港的超市，买寿司当晚餐，咸蛋黄鸡蛋仔 吃大排档：晚上 搬家+看演唱会 点心：周记点点心， 西安 西安及周边100公里内有哪些冷门但非常值得一去的地方？ 西安值得吃的地方 西安有哪些可以安静地待一下午的地方？ 踩过的雷：top1的六🈴️汤包 市区： 大雁塔：美术馆、回民街、洒金桥、钟鼓楼 西安明城墙： 推荐环墙一周的自行车。西安城墙是中国现存规模最大、保存最完整的古代城垣。现存城墙为眀代建筑,全长13.7千米,位于西安市中心,送我们过去的司机师傅说起城墙那种油然而生发自內心的自豪感满满都是 大明宫遗址公园：这个是热门，但冷门玩法是傍晚去 八仙宫古玩市场，八仙庵，，离永兴坊不远 顺城巷：一侧是巍巍古城墙，一侧是秀丽端庄的明清古建。、食店、酒吧、咖啡屋，更有一些秦腔或相声曲艺社，院门半掩静待听客到访。 环城公园：以护城河为线，在城墙根下围绕着明城墙修建的环城公园，是西安本地人运动、散步、休闲的好去处 较远： 秦岭：东梁山(冷门)；黑河；楼观台；黎元坪。 西岳庙。一般游客都会去华山,很少会去西岳庙。但是西岳庙有着非常精美的明清建筑,而且面积 巨大,文革期间用作军营所以保存的不错,不过这里和华山是联票,如果去华山的话一定要抽时间 去西岳庙。 碑林博物馆。这个根本就不算冷门,不过还是小众一些,书法爱好者的圣地。而且这里面还有昭陵 骏和景云钟。里面的佛像石刻更是精美绝伦。另外碑林旁边有一个卧龙寺,是陕西第一所寺庙, 也可以看看。 关中民俗艺术博物院。坐标南五台 坐标南五台。是一家私人关中民俗博物院,建筑精美,藏品丰富。 很感激有这样的收藏家能够将关中民俗有条理的收藏保存,对外开放, 门票略贵,120元,但还是非常值得去感受一下,尤其是如果身边有外国友人,非常推荐带他们来 这里,绝对会对西安、对中国会有更深一层的认识。 ![image-20190706003050116](/Users/yyf/Library/Application Support/typora-user-images/image-20190706003050116.png) 西安吃的马峰小炒（好吃！！但拍得不好看，见谅）： ![image-20190706004524589](/Users/yyf/Library/Application Support/typora-user-images/image-20190706004524589.png) 定家小酥肉 地址：酿皮隔壁 东南亚甑糕 西羊市 面：马虎面馆 连锁店，马虎面馆 连锁店，英子牛肉面 景观路 夜宵：小佐烤肉(开元路总店) 咖啡馆、小情调 曼蒂广场 人不多的一个商场,店其实也不多。但是艺术感很强,经常有一些画或雕塑的小展览。里面的虫儿 咖啡、均记咖啡的装修风格我都很喜欢。就连这里的米家大雨泡馍都是咖啡馆式的木质深色装修风 格,很是雅致,如果请人吃泡馍还不想环境脏乱差的话可以考虑这里。 陕西省图书馆。 曲江书城 书城提供很多座位、小沙发，看书很惬意。 ![image-20190706005746707](/Users/yyf/Library/Application Support/typora-user-images/image-20190706005746707.png)]]></content>
      <categories>
        <category>生活</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[模仿胶片色调]]></title>
    <url>%2Fp%2F3acf.html</url>
    <content type="text"><![CDATA[# 06-14 课程链接：https://m.lizhiweike.com/classroom/12544288 https://pan.baidu.com/s/1QCXJhicXgzQgHirQioIPSw 密码：4yqr 快速模仿胶片色调 @修图师李新颖 时尚博主：小象王国、fashionmodels 摄影师：张家诚 同学们，你们已经看完了这5个摄影师的作品了吧，其实呢，我们除了一些技法上还有思路上的提升，其实我们审美上的一个提升也是非常重要的，那么我们如何去提升审美呢？下面我介绍给大家一些提升自己的方法。 识一些国外的就是国际的，嗯比较厉害的摄影师的名字从认识摄影师的名字开始，然后呢，嗯，如果说你们一开始不知道一些国际摄影师的名字，那么我们可以在国内的一些微博啊，比如说微博博主分享一些时尚大片的微博，博主比如说小象王国啊，还有一个fashion models，然后呢，这两个时尚博主他也是会经常的分享一些国外的大片。 他分享的一些时尚大片的，他会艾特出来摄影师，然后我们找到我们喜欢的摄影师的名字去进行一个标记，然后去给摄影师的作品进行一个分类，比如说嗯，我们首先就是这个摄影师的名字进行一个标记，然后呢，我们再去把他的作品进行一个搜集，比如说那个海边的场景我们给它归类一个文件夹海边，然后呢，我们室内的文件夹就给它归类为室内，然后呢，我们那个草地的，然后就把作品分类为草地，这样子呢，可以有效的去提升我们找片子的效率。 两个时尚博主是我比较经常看的，他不止会分享一些时尚的大片，还会分享一些时尚的资讯，会让我在一个视觉啊，然后呢，还有我的那个审美上面会带给我一些新的灵感 收集摄影师的名字。多看国际标准的摄影作品。如何提高审美，每日不断的阅读，不断的去提升自己的眼界，开拓自己的视野。阅读方式也很重要，要找到自己喜欢的照片，有目的的去欣赏，这很重要。从以下几点进行欣赏。看片的话不是盲目的去看片子，看片子的话要就是有目的的去欣赏去分析 舒服的调子、光影层次、情绪、构图 、肢体语言、有趣的色彩对比、有创意有趣味性的画面或者干净、简洁、统一的画面 王家卫的风格都是色彩比较浓郁的，我们模拟的时候要嗯，要加一些大量的色温，或者是在曲线给他多加红啊，然后加黄就可以模拟出来王家卫那种嗯特别浓郁的色彩，然后记得按不给他，嗯，暗部的话加氢，然后呢加那个黄。 提灰：色阶、可选颜色、曲线都可以提灰 ![image-20190614200158279](/Users/yyf/Library/Application Support/typora-user-images/image-20190614200158279.png) 视频中提及的高光、中间调、暗部等小知识，大家可以看下下方这张图~ 胶片照片的特点：高光比较柔，高光比较暗，暗部比较扎实，和中间调比较高亮有对比，线条明显，色彩多乱；胶片会色偏（红色往黄色偏） 数码照片的特点：过渡比较平缓，对比度低，像素高，细节多，丢失光感和立体感；质感退化 数码相机到胶片照片：质感退化，高光调暗，中间调提亮，暗部压实；曝光拉高 中间调提亮 ![image-20190614201512008](/Users/yyf/Library/Application Support/typora-user-images/image-20190614201512008.png) 厚重，就是明暗差别大，就像上妆重，高光特别亮，中间调特别暗 1.先调光影 减少对比度 增加曝光 色彩曲线：加深暗部（将曲线底部往右平移），提高中间调（把中间点固定在原来的位置），降低高光(降低) ![image-20190614202553695](/Users/yyf/Library/Application Support/typora-user-images/image-20190614202553695.png) 调色彩，色偏 前期 模仿胶片的照片，前期拍摄的话尽量顺光顺光拍摄，然后呢，尽量曝光稍微亮一点，不要就是曝光稍微要高一档，不要说太低了。]]></content>
      <categories>
        <category>摄影</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[健身清单]]></title>
    <url>%2Fp%2F4221.html</url>
    <content type="text"><![CDATA[健身list 臀部 天鹅颈 双下巴 脖子]]></content>
      <categories>
        <category>生活</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[电影清单]]></title>
    <url>%2Fp%2Fab3e.html</url>
    <content type="text"><![CDATA[32部无论是色彩、构图还是场景都超棒的好电影]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>电影</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小波域图像去噪]]></title>
    <url>%2Fp%2F2812.html</url>
    <content type="text"><![CDATA[变换变换的作用：方便压缩、计算等 如：方便计算的特征向量基础，Tv=cv。eigenvector basis就是组成T的向量，T就是转换。 变换有：傅立叶变换、小波变换（傅立叶变化不属于小波变化。傅立叶变换和小波变换同属于变换） 傅立叶变换 特点：是正交基。正交基方便求出基的系数。 局限性 最擅长的是把一维的，类三角波连续变量函数信号映射到一维系数序列上，但对于突变信号或任何高维的非三角波信号则几乎无能为力。 如： 小波变换 参考 小波变换完美通俗讲解系列之 （一） 小波变换完美通俗讲解系列之 （二） 波的定义 波：在时间域或者空间域的震荡方程 小波：集中在时域某一点的波；优点，能够分析瞬时时变信号；实现，通过对小波的伸缩平移对函数信号进行多尺度细分。 小波的特点 两两正交，归一化。 小波级数的展开同时在时域和频率上进行，也就是对应伸缩(频域)和平移(覆盖时域)，傅立叶变换只在频域。 小波的构成：父小波和母小波的平移伸缩；scaling function+wavelet function(mother) mother wavelet：母小波 father wavelet：scaling function/父小波/尺度函数 对任意V_j的function可以分解为： （1）scaling fucntion的形式：$$\begin{array}{c}{\varphi_{j, k}} \end{array}$$（2）第二种就是它上一个子空间的basis以及上一级子空间的wavelet function$$\begin{array}{c}{\varphi_{j-1, k}} \ {\psi_{j-1, k}}\end{array}$$（3）一直利用上上..级的scaling function，则得到小波展开形式：$$f(t)=\sum_{k=-\infty}^{\infty} c_{k} \varphi(t-k)+\sum_{k=-\infty}^{\infty} \sum_{j=0}^{\infty} d_{j, k} \psi\left(2^{j} t-k\right)$$其中，$\varphi(t)$是父小波，$\psi_{j, k}(t)$是母小波。scaling function不是凭空插进去的，而是通过不断的嵌套迭代出来的 为什么使用第3种方式（小波变换）来表达信号 计算 那为什么我们最后选定的是这种选取方式呢?实际上，刚才介绍的这个性质已经告诉我们，对于任何的scale j0，我们都可以给我们的signal space找到一组orthonormal basis，这个basis是通过组合scale j0上的scaling function以及所有在scale j，j&gt;j0上的wavelets得到的。这样，基于这个orthonormal basis，所有信号空间中的信号都可以写成组成这个basis的functions的线性组合：$$\begin{array}{l}{c_{j_{0}, k}=\left\langle s(n), \varphi_{j_{0}, k}(n)\right\rangle} \ { d_{j, k}=\left\langle s(n), \psi_{j, k}(n)\right\rangle}\end{array}$$ 两种函数相当于高通滤波和低通滤波的作用 wavelet function和scaling function背后的物理意义了：wavelet function等同于对信号做高通滤波保留变化细节，而scaling function等同于对信号做低通滤波保留平滑的shape! scaling function 和 MRA的关系(scaling function在小波变换中的作用和意义） 在不同的子空间，对于同一个信号就有不同的诠释。诠释最好的当然是V3，完全不损失细节。这就是多解析度的意义。我们可以有嵌套的，由scaling function演变的basis function集合，每一个集合都提供对原始信号的某种近似，解析度越高，近似越精确。 物理意义：做低通滤波 小波变换的计算复杂度(还没理解) 从信号算出展开系数a需要很方便。普遍情况下，小波变换的复杂度是O(Nlog(N))，和FFT相当。有不少很快的变换甚至可以达到O(N)，也就是说，计算复杂度和信号长度是线性的关系。小波变换的等式定义，可以没有积分，没有微分，仅仅是乘法和加法即可以做到，和现代计算机的计算指令完全match。 哈尔小波是小波变换的一种。以哈尔小波为例 如：[9 7 3 5 ]-&gt;[8 4 1 -1]-&gt;[6 2 1 -1] 小波变换的基本流程 选取合适的wavelet function和scaling function，从已有的信号中，反算出系数c和d。 对系数做对应处理 从处理后的系数中重新构建信号。 小波变换的应用：系数处理 应用有压缩、去噪、水印、图像融合等等 例如：比如图像或者视频压缩，就希望选取能将能量聚集到很小一部分系数中的小波，然后抛弃那些能量很小的小波系数，只保留少数的这些大头系数，再反变换回去。这样的话，图像信号的能量并没有怎么丢失，图像体积却大大减小了。 小波去噪的原理 小波分解树(以Haar小波为例) 由高频和低频组成 Matlab的实现（未完成，参考《图像处理中的数学》） wavedec2 小波域去噪综述 问题：是否所有小波域下的去噪方法都利用了稀疏性，所有小波转化都是为了得到稀疏性？ 小波域的图像降噪 基于filter,（利用sparsity） H. Zhang, Aria Nosratinia, and R. O. Wells, Jr., “Image denoising via wavelet-domain spatially adaptive FIR Wiener filtering”, in IEEE Proc. Int. Conf. Acoust., Speech, Signal Processing, Istanbul, Turkey, June 2000. 利用小波奇异检测特性将信号与噪声分开。Mallat, 1992。计算量大，收敛缓慢，产生振荡和不稳定 Mallat, S., &amp; Hwang, W. L. (1992). Singularity detection and processing with wavelets. IEEE transactions on information theory, 38(2), 617-643. 利用小波系数阈值收缩法来分开信号和噪声。Donoho，1992。Gibbs phenomena in the neighborhood of discontinuities – 即不连续点周围的信号能量会在一定尺度的范围上来回波动-to the lack of translation invariance of the wavelet basis。 (都不是MRA-based tight frame，那么是MRA-based tight frame什么又是其他tight frame) 改进Gibbs：R.R. Coifman and D.L. Donoho提出了平移不变量算法可有效地避免这种现象的发生 首先让含有噪声的原始信号进行多次循环平移（比如进行 n 次）,其次运用阈值算法对平移后的信号进行去噪处理,然后再平均去噪的信号,此称为“平移-去噪-平均”的平移不变量算法的原理。$$\overline{T}\left(x,\left(S_{h}\right){h \in H{n}}\right)=A v e_{h \in H_{k}} S_{-h}\left(T\left(S_{h}(x)\right)\right)$$[57] R.R. Coifman and D.L. Donoho, Translation-invariant de-noising, Lecture Notes in Statistics-New York-Springer Verlag (1995), 125–125. 贝叶斯方法去噪(利用sparsity了没有？)，需要利用先验证模型 先验模型是小波系数先验模型：利用联合分布，GGD 先验模型是小波系数的空间局部作用关系（马尔可夫模型）：HMM （基于框架的wavelet frame在图像还原中有很大的应用，谁最先先提出的）: wavelet frame. （还有一种说法）引自基于稀疏表示的小波去噪_朱杰.pdf 基于多尺度分析的紧框架结构 (MRA-based tight frame method): The community’s effort to develop redundant wavelet systems that have sparse approximations for various classes of functions has led to the development of the MRA-based wavelet frames.（those tight wavelet frames generated via a multiresolution analysis）（详见基于小波框架的变分模型） tight wavelet frame: 是一种变分法，因为u = Wt (Wu). u在W下不唯一。所以有三种方法来获取目标图像的稀疏近似值。 Therefore, there are three formulations for the sparse approximation of the underlying images; namely, the analysis based approach, the synthesis based approach and the balanced approach. Analysis based：The analysis based approach was ﬁrst proposed in [84, 170]. $$\min {u \in \mathbb{R}^{n}} \frac{1}{2}|A u-f|{D}^{2}+|\mbox{diag}(\lambda) W u|_{1}$$ [170] J.L. Starck, M. Elad, and D.L. Donoho, Image decomposition via the combination of sparse representations and a variational approach, IEEE transactions on image processing 14 (2005), no. 10, 1570–1582. [84] M. Elad, J.L. Starck, P. Querre, and D.L. Donoho, Simultaneous cartoon and texture image inpainting using morphological component analysis (MCA), Applied and Computational Harmonic Analysis 19 (2005), no. 3, 340–358. synthesis based: The synthesis based approach was first introduced in [66, 86, 87, 90, 91].$$\min {\alpha \in \mathbb{R}^{m}} \frac{1}{2}\left|A W^{\top} \alpha-f\right|{D}^{2}+|\mbox{diag}(\lambda) \alpha|_{1}$$[90]M.A.T. Figueiredo and R.D. Nowak, An EM algorithm for wavelet-based image restoration, IEEE Transactions on Image Processing 12 (2003), no. 8, 906–916. [91]A bound optimization approach to wavelet-based image deconvolution, Image Processing, 2005. ICIP 2005. IEEE International Conference on, vol. 2, IEEE, 2005, pp. II–782. [86] M.J. Fadili and J.L. Starck, Sparse representations and bayesian image inpainting, Proc. SPARS 5 (2005). [66] I. Daubechies, G. Teschke, and L. Vese, Iteratively solving linear inverse problems under general convex constraints, Inverse Problems and Imaging 1 (2007), no. 1, 29. [87]MJ Fadili, J.L. Starck, and F. Murtagh, Inpainting and zooming using sparse representations, The Computer Journal 52 (2009), no. 1, 64. balanced method：The balanced approach was ﬁrst used in [34, 36] for high resolution image reconstruction.$$\min {\alpha \in \mathbb{R}^{m}} \frac{1}{2}\left|A W^{\top} \alpha-f\right|{D}^{2}+\frac{\kappa}{2}\left|\left(I-W W^{\top}\right) \alpha\right|{2}^{2}+|\mbox{diag}(\lambda) \alpha|{1}$$求解算法：the proximal forward and backward splitting algorithm [34]R.H. Chan, T.F. Chan, L. Shen, and Z. Shen, Wavelet algorithms for high-resolution image reconstruction, SIAM Journal on Scientiﬁc Computing 24 (2003), no. 4, 1408–1432. [36]Tight frame: an eﬃcient way for high-resolution image reconstruction, Applied and Computational Harmonic Analysis 17 (2004), no. 1, 91–115. 小波域去噪综述 小波域去噪是利用信号稀疏表达的一个代表性的方法。此类方法主要就是对图像转化到小波域后的系数进行处理，再将处理后的小系数还原到空间域，从而得到复原后的图像。小波域的去噪方法大致可以分为三类：奇异值检测、阈值收缩以及基于贝叶斯的模型。其中小波阈值去噪由Do在在1992提出来， 是最被广为学习的一种方法。它的工作原理是根据噪声和自然图像在频率段不同的表现形式(噪声呈现出高频小幅值)，通过设定阈值将噪声从噪声图像中区分出来，并将噪声系数还原为0，从而消除噪声。大量论文针对阈值的选择进行了研究。然而，通过阈值收缩的方法，在去噪的同时容易抹去一些图像的高频信息，因此在图像不连续的区域容易产生振铃(Gibbs)的缺陷。R.R. Coifman and D.L. Donoho提出一种平移不变量算法，可有效减少此类缺陷。另一方面，随着框架理论的发展，小波紧框架系统被证明了是一种有效的稀疏逼近分段光滑图像的系统。因此，小波紧框架变换在图像恢复问题中应用十分广泛 [] 。( 基于多尺度分析的小波紧框架开始被成功地用于解决图像复原问题。基于小波框架的变分模型[14-19]被成功应用于图像去噪中，其中稀疏性的特点作为约束项。)然而，需要处理的图像是多种多样的，并没有一个静态的小波紧帧系统能够很好地处理恢复它们。因此Cai在[1]中提出了一种由图片数据驱动的设计tight frame wavelet的方法，来解决一类tight frame只能解决一类图片的问题。 [1] Cai, J. F., Ji, H., Shen, Z., &amp; Ye, G. B. (2014). Data-driven tight frame construction and image denoising. one of the most studied coefficients with small magnitude can be considered as pure noise and should be set to zero. redundant wavelet systems that have sparse approximations for various classes of functions has led to the development of the MRA-based wavelet frames A number of papers were proposed to select the threshold.a number of methods differs in the selection of the threshold parameter. As for the coeﬃcients with small magnitude can be considered as pure noise and should be set to zero The sparsity is later incorporated in the variational method. The most investigated domain in denoising using Wavelet Transform is the non-linear coefficient thresholding based methods. Most of the wavelet shrinkage literature is based on methods for choosing the optimal threshold which can be adaptive or non-adaptive to the image. generates spurious blips, better known as artifacts wavelet thresholding是由Donoho首先在1992提出来的，在这之前在wavelet domain的去噪也是有的。如H. Zhang, Aria Nosratinia, and R. O. Wells, Jr., “Image denoising via wavelet-domain spatially adaptive FIR Wiener filtering”, in IEEE Proc. Int. Conf. Acoust., Speech, Signal Processing, Istanbul, Turkey, June 2000. Wavelet-based denoising aims to decompose the signal into the by high-frequency filter and low-frequency filter. {As for the coeﬃcients with small magnitude can be considered as pure noise and should be set to zero.} As for the detail coeﬃcients of the noise presented as high frequency with small magnitude while a clean image tend to be many zeros. Thus stronger sparse expression: wavelet tight frame (limitation: not adaptive, a class of ) 小波阈值去噪 问题 小波阈值去噪，选择的是哪种小波变换，属于tight frame吗，那么属于MRA-based tight frame吗。 原理 The coefficients of the wavelet transform are usually sparse. That is, most of the coefficients in a noiseless wavelet transform are effectively zero. Therefore, we may reformulate the problem of recovering f as one of recovering the coefficients of f which are relatively ”stronger” than the Gaussian white noise background. That is, coefficients with small magnitude can be considered as pure noise and should be set to zero. The approach in which each coefficient is compared with a threshold in order to decide whether it constitute a desirable part of the original signal or not, is called waveletthresholding. 过程 transform-based thresholding working in three steps: Transform the noisy data into an orthogonal domain. Apply soft or hard thresholding to the resulting coefficients, thereby suppressingthose coefficients smaller than a certain amplitude. Transform back into the original domain. 两种分类方法 全局阈值和自适应阈值 软阈值和硬阈值 soft-thresholding几乎用于所有的算法。Hard-thresholding会产生一种spurious blips的缺陷，as a result of unsuccessful attempts of removing moderately large noise coefficients。 阈值的选择影响很大 Large threshold lead to the details lost. Small threshold lead to the noise unclean. Reviews of literature：(1990s) Wavelet thresholding and wavelet shrinkage：VisuShrink，SureShrink，BayesShrink, NeighBlock [VisuShrink 1994] David L. Donoho and Jain M. Johnstone. Ideal spatial adaptation by wavelet shrinkage. Biometrika, 81(3):425–455, 1994. 3 全局阈值 [SureShrink 1995] David L. Donoho and Iain M. Johnstone. Adapting to unknown smoothness via wavelet shrinkage. Journal of the American Statistical Association, pages 1200–1224, 1995. 第一个adaptive [BayesShrink 2000] Martin Vetterli S Grace Chang, Bin Yu. Adaptive wavelet thresholding for image denoising and compression. IEEE Transactions on Image Processing, 9(9):1532–1546, Sep 2000 [NeighBlock 2001] T.T. Cai and B.W. Silverman. Incorporating information on neighbouring coefficients into wavelet estimation. Sankhya, Series A, 63, 2001 小波变分模型基于小波框架的变分模型[14-19]被成功应用于图像去噪中。 研究表明，基于小波框架的变分模型比其他变分模型 例如 ROF 模型更好，这是因为小波框架的多分辨率结构和冗余。 Chan, R. H., Chan, T. F., Shen, L., &amp; Shen, Z. (2003). Wavelet algorithms for high-resolution image reconstruction. SIAM Journal on Scientific Computing, 24(4), 1408-1432. Cai, J. F., Osher, S., &amp; Shen, Z. (2009). Split Bregman methods and frame based image restoration. Multiscale modeling &amp; simulation, 8(2), 337-369. Dong, B., &amp; Shen, Z. (2010). MRA based wavelet frames and applications. IAS Lecture Notes Series, Summer Program on “The Mathematics of Image Processing”, Park City Mathematics Institute, 19． Chan, R., Shen, L., &amp; Shen, Z. (2005). A framelet-based approach for image inpainting. Res. Rep, 4, 325. tight-frame Cai, J. F., Osher, S., &amp; Shen, Z. (2009). Linearized Bregman iterations for frame-based image deblurring. SIAM Journal on Imaging Sciences, 2(1), 226-252. J.-F. Cai, S. Osher, and Z. Shen, “Split Bregman methods and frame based image restoration,” Multiscale Model. Simul., vol. 8, no. 2, pp. 337–369, Dec. 2010. Cai, J. F., Dong, B., Osher, S., &amp; Shen, Z. (2012). Image restoration: total variation, wavelet frames, and beyond. Journal of the American Mathematical Society, 25(4), 1033-1089. Cai, J. F., Ji, H., Shen, Z., &amp; Ye, G. B. (2014). Data-driven tight frame construction and image denoising. Applied and Computational Harmonic Analysis, 37(1), 89-105. 最近建立了小波框架和变分模型之间的联系，并提出了一种数据驱动紧框架， 该框架比以往的模型更能精确地重构图像。code++ 提出了一种从图片本身设计tight frame wavelet的方法。来解决一类tight frame只能解决一类图片的问题。 代码实现 小波去噪的基本原理 影响去噪的因素 域值的选择，小波的选择，分解层次的选择 [2014 Cai] 《MRA-Based Wavelet Frames and Applications》[cam11-22] on wavelet frame based image restoration [35, 36, 37, 38, 39, 40, 41, 42, 43, 21]. Split Bregman methods and frame based image restoration. Therefore, there are mainly three formulations utilizing the sparseness of the wavelet frame coeﬃcients, namely analysis based approach, synthesis based approach, and balanced approach. Detailed and integrated descriptions of the three approaches can be found in [34]. [34] 一本书 B. Dong and Z. Shen, “MRA Based Wavelet Frames and Applications,” IAS Lecture Notes Series, Summer Program on “The Mathematics of Image Processing”, Park City Mathematics Institute, 2010 The analysis based approach was ﬁrst proposed in [84, 170]. [84] M. Elad, J.L. Starck, P. Querre, and D.L. Donoho, Simultaneous cartoon and texture image inpainting using morphological component analysis (MCA), Applied and Computational Harmonic Analysis 19 (2005), no. 3, 340–358. [170] J.L. Starck, M. Elad, and D.L. Donoho, Image decomposition via the combination of sparse representations and a variational approach, IEEE transactions on image processing 14 (2005), no. 10, 1570–1582. 讲述了一种结合变分和转换与 去噪综述 参考文献： Survey of Image Denoising Techniques 小波域图像降噪概述 B. Dong and Z. Shen, “MRA Based Wavelet Frames and Applications,” IAS Lecture Notes Series, Summer Program on “The Mathematics of Image Processing”, Park City Mathematics Institute, 2010 模极大，域值，平移不变 NLM，BM3D去噪原理 维纳滤波器的时域解 维纳滤波的频域解(尚未找到) 低通滤波 小波变换去噪基础知识整理 综述 根据不同去噪方法的实现原理，我们将去噪方法大致分为以下五类：传统滤波法，基于稀疏表达约束法，基于图像自相似的方法，变分法，基于马尔可夫模型的法，以及目前的深度学习方法。每一类方法都可以在空间域以及转化域来实现。 传统滤波法包括均值滤波，中值滤波 [3] ，卡尔曼滤波 [4] ，维纳滤波[5]等。 均值滤波(Mean)是一种最简单的滤波器，其利用邻域内像素的平均值作为替换值来消除图像的孤立点噪声。通常伴有过模糊的问题。另一种均值滤波通过，通过对样本多次观察取平均来降噪。 维纳滤波(Weiner)是由Weinar在二十世纪四十年代提出来，通过最小均方差寻找准则，从噪声图像中提取最佳线性滤波的方法，因此也叫最小均方滤波/最佳线性滤波器。$$\begin{array}{c}{y(n)=\hat{s}(n)=\sum_{m=0}^{+\infty} h(m) x(n-m)} \ \min_{x}{E\left[e^{2}(n)\right]=E\left[\left(s(n)-\sum_{m=0}^{+\infty} h(m) x(n-m)\right)^{2}\right]}\end{array}$$其中h(m)是无污染信号，x(n)是线性滤波。 Wiener, Norbert (1949), Extrapolation, Interpolation, and Smoothing of Stationary Time Series. New York: Wiley. 比均值滤波的效果好，在高斯噪声中的效果最好，计算量大。也不能用于噪声为非平稳的随机过程 中值滤波器(Median)是一种非线性滤波，最早由Tukey和 Pratt在1974和1978年提出 [1] [2]，并被广泛用于去噪问题[3]。这个方法，用领域内像素的中值作为像素值。最显著的优点是在临近像素显著不同区域内，让像素的灰度值与其邻近像素更加接近。缺点，在纹理复杂的图像中依然有模糊的问题。在点线尖的纹理较多的地方表现不好。 The one-dimensional median filter was devised by Tukey [1]. Some discussion of it, and an extension to two dimensions, is given by Pratt [2]. [1] Tukey. J.W. Exploratory Data Analysis. Addison-Wesley, Reading, Mass., 1974. [2] William K. Pratt, Digital image processing, John Wiley &amp; Sons, Inc., New York, NY, 1978 [3] Brownrigg D R K, “The Weighted Median Filter,” Communications of the Acm,1984, 27(8):807-818. 其他的滤波还有在转化域的低通滤波法，通过去掉傅立叶变换后中的高频成分，逆转化后得到复原图像。 Adel Sedra &amp; Peter Brackett， Filter Theory and Design, Active and Passive,Matrix Publisher, Oregon 1978 小波域去噪见小波域去噪综述 变分法是另外一大类重要的分支。它将病体问题转化成一个最小化方程问题。目标方程由一个包真项和正则项组成，保真项是 ，正则项，去噪的结果就是通过优化算法获得的方程解。在不同的正则项中，全变分最受欢迎。 空间域：全变分 基于小波框架的变分模型(是不是都属于wavelet frame) NLM是第一个基于相似块的较为现代的方法。是在2005年由Baudes首先提出用来去噪的方法[1]。他通过搜寻与目标像素具有相似块的相似点作为参考值，对这些选择的像素点均值，权重由相似度决定，对目标像素进行去噪。与传统的滤波法不同，该方法利用了整幅图像的冗余性，比较好地去掉图像中存在的高斯噪声。 [1] Buades, A., Coll, B., &amp; Morel, J. M. (2005, June). A non-local algorithm for image denoising. In 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05) (Vol. 2, pp. 60-65). IEEE.（BM3D） [2] Dabov, K., Foi, A., Katkovnik, V., &amp; Egiazarian, K. (2007). Image denoising by sparse 3-D transform-domain collaborative filtering. Image Processing, IEEE Transactions on 16 (8), pp. 2080-2095. patch-based methods 为了完备性，其他去噪方法还有基于马尔可夫模型的等。现在的方法大多是将这几类方法进行结合使用，来获得更好的效果。例如，最先进的BM3D主要就是NLM，小波滤波和维尼滤波的组合。整个过程有两步组成，第一个流程首先通过NLM相似块分组，第对每一个相似块组进行小波硬阈值处理后逆转换回图像块，将这些块进行加权后融合到原来的位置，得到初步去噪结果。第二个流程对噪声图和初步去噪结果分别进行相思的分组, 从离散余弦变换后的噪声块中提取维纳滤波系数对初步去噪块进行滤波处理后，逆转化后融合成最后的去噪结果。 补充 基于稀疏表达（sparsity approximation）的去噪方法https://wenku.baidu.com/view/ed8fc817c5da50e2524d7fe6.html 基于全局图像稀疏去噪 基于稀疏字典的图像去噪方法 见小波域的去噪综述 MGA 去噪方法中的稀疏性应用 ICA 去噪方法中的稀疏性应用 2010 年， Anjali 等人对 ICA 技术去噪进行了综述，指出 Fourier 方法局限于频率，小波变换虽能同时在空间域与频率 域，但都不具有数据的自适应性； 而 ICA 方法能从高阶去分析 多方向数据内在的适应性，噪声被认为是高斯随机变量，而图 ［61］ 像数据则是非高斯随机变量 马尔可夫模型 MRA，Wavelet frame, MRA-based wavelet frame，MRA-based tight wavelet frame(generalization) 的发展过程 小波分析已用于多个领域，如信号处理，图像分析等方面，而框架理论是小波分析的一个重要工具。框架理论最初是由 Duffin 和 Schaffcf 在 1952 年研究非调和 Fourier 级数时提出来的，在最开始提出的时 候，框架并没有广泛地引起其他学者的研究兴趣。直到 1986 年，Daubechies、Grossmann 和 Meyer 对框架理论有了突破性的研究，至此框架理论才开始吸引了大批学者的关注。近些年来，在框架理论的研究 过程中，用到了算子理论以及 Banach 空间理论。直到 D. R. I. Arson、Deguang Han 和 Xingde Dai 等人把 算子代数理论运用到框架的研究中，框架理论研究才更上了一个层次，并从整体上把握和研究了框架和 基的性质 。至此，结合了算子理论的框架理论快速发展，其性质以及应用得到更加广泛地研究与推广。 Tight frame,1952, Duffin [80] R.J. Duﬃn and A.C. Schaeﬀer, A class of nonharmonic Fourier series, Transactions of the American Mathematical Society 72 (1952), no. 2, 341–366. Wavelet frames (without a multiresolution structure) (see e.g. [61, 132]), [61]Ten lectures on wavelets, vol. CBMS-NSF Lecture Notes, SIAM, nr. 61, Society for Industrial Mathematics, 1992. [132] A wavelet tour of signal processing, vol. 2nd ed. New York: Academic, Academic press, 1999 and Applications: eg. Tight wavelet frames derived from over sampled orthonormal wavelet basis are already used in noise removal by [57, 77]. [57] R.R. Coifman and D.L. Donoho, Translation-invariant de-noising, Lecture Notes in Statistics-New York-Springer Verlag (1995), 125–125. [77] De-noising by soft-thresholding, IEEE transactions on information theory 41 (1995), no. 3, 613–627. De-Noising using the traditional orthogonal wavelet transform. MRA这个概念由Mallat在1989提出。最常用來分析離散小波變換〈DWT〉或是驗證快速小波轉換〈FWT〉理論的方法 [131] S.G. Mallat, Multiresolution approximations and wavelet orthonormal bases of L 2 (R), Transactions of the American Mathematical Society 315 (1989), no. 1, 69–87. MRA-based compactly supported orthonormal wavelet systems, Daubechies [60]. MRA-based compactly supported orthonormal wavelets of [60]. [60] Daubechies, Orthonormal bases of compactly supported wavelets, Commun. Pure Appl. Math. 41 (1988), no. 7, 909–996. MRA-based tight wavelet frames.(a generalization) , 所以也有不是MRA-based [158] Aﬃne Systems in L 2 (R d ): The Analysis of the Analysis Operator, Journal of Functional Analysis 148 (1997), no. 2, 408–447. MRA-based wavelet 论文中在第五章介绍了不同应用中的具体模型 We discuss the model proposed in [18] on blind deblurring (motion deblurring to be speciﬁc) problems. we present a frame based image segmentation model with a fast algorithm for the general image segmentation problems of [71]. we discuss the model proposed by [112] on reconstruction of scenes (visible surfaces) from scattered, noisy and possibly sparse range data (point clouds). 问题 在做wavelet domain denoising的综述中，从来没有提到变分模型；wavelet frame的综述中，从来没有提到过thresholding的方法。 框架理论最初是由 Duffin 和 Schaffcf 在 1952 年研究非调和 Fourier 级数时提出来的，在最开始提出的时 候，框架并没有广泛地引起其他学者的研究兴趣。直到 1986 年，Daubechies、Grossmann 和 Meyer 对框 架理论有了突破性的研究，至此框架理论才开始吸引了大批学者的关注。近些年来，在框架理论的研究 过程中，用到了算子理论以及 Banach 空间理论。直到 D. R. I. Arson、Deguang Han 和 Xingde Dai 等人把 算子代数理论运用到框架的研究中，框架理论研究才更上了一个层次，并从整体上把握和研究了框架和 基的性质 。至此，结合了算子理论的框架理论快速发展，其性质以及应用得到更加广泛地研究与推广。 基于稀疏表示的小波去噪，是否有不基于稀疏的小波去噪，我感觉小波就是利用了稀疏 。那么稀疏除了小波域，还有没有其他方法 傅立叶变化,余弦变化,小波变化同属于转化，都是在搞基。其中小波的特点是稀疏。 紧框架也是一种转化，特点是冗余基，系属性更好。框架理论：包括傅立叶变化，小波变化。 基于多解析度的紧框架：具有快速重构和分解的优点。 MRA，Wavelet frame, MRA-based wavelet frame，MRA-based tight wavelet frame(generalization) 的发展过程 图像有哪些wavelet transformation有哪些，tight frame有哪些，怎么样算属于MRA(Multi-resolution Analysis) 如何选择这些不同的变换 (2D)DT-CWT是什么、(1D)DT-WT 这两个是什么，如何用matlab实现，应该是MRA-based tight frame的一种 基于小波框架的变分模型哪篇论文中最先提出。参照MRA-Based Wavelet Frames and Applications的文献回顾即可 $$\left(\mathrm{P}{1}\right) \quad \min _{x \in \mathbb{R}^{n}}|x|{\ell_{1}} \quad \text { subject to } \quad y=\Phi x$$ 未选中什么是振铃现象，什么是Gibbs现象，图像中如何表现 两者形容的是同一种现象。振铃效应（Ringingeffect）是影响复原图像质量的众多因素之一，其典型表现是在图像灰度剧烈变化的邻域出现类吉布斯（Gibbs）分布 所谓“振铃”，就是指输出图像的灰度剧烈变化处产生的震荡，就好像钟被敲击后产生的空气震荡。如下图： CWT是什么：continuous wavelet transform 图像有哪些wavelet transformation，去噪应该选择哪种转变（Haar是一种） 是否所有小波域下的去噪方法都利用了稀疏性，所有小波转化都是为了得到稀疏性？ 实验记录利用non-convex tight frame去噪记录 参考文献：Please cite as: A. Parekh and I. W. Selesnick. Convex Denoising Using Non-convex Tight Frame Regularization, IEEE Signal Processing Letters, 22(10): 1786-1790, Oct. 2015. 参考代码：https://github.com/aparek/cncTightFrame/blob/master/Documentation/demo2D.pdf 结论1: tf在噪声50的情况下，不能必过TV，会有模糊的效果。 L1-tightframe 0.8/0.9/1.0 nonconvex tightframe 1.0/1.1/1.2 结论2: 在噪声低15的情况下 nonconvex的正则项可以超过TV 结论3: 在噪声35的情况下，复杂的图像很模糊，但是psnr依旧可以超过TV， PSNR_x = 25.9576 26.2444 26.1463 25.9175 25.6507 25.3786 换个W个会好些吗 参考文献 小波、框架 A short introduction to frames, Gabor systems, and wavelet systems 一个较好理解小波的ppt]]></content>
      <categories>
        <category>图像处理</category>
      </categories>
      <tags>
        <tag>denoising</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[菜谱Collection]]></title>
    <url>%2Fp%2Fc077.html</url>
    <content type="text"><![CDATA[简单食材菜谱 鸡蛋 不同鸡蛋的特色 芙蓉蛋炒饭 蒸蛋：以蛋水比例1:1.5，混合拂勻。用隔篩把蛋液注入碟內，再以小匙勺掉小氣泡。用錫紙蓋着。以中火隔水蒸5分鐘即成，加麻油、豉油同吃。 温泉蛋/水波蛋的做法 牛肉 牛柳 金针菇肥牛卷 番茄肥牛汤 日式肥牛 7分鐘搞懂牛排部位！ 带子 急冻带子菜谱 豆腐带子：带子热水泡20分钟，煎带子，放豆瓣酱，放豆腐，放水煮2-3分钟，收汁。 香煎带子：放油煎子，翻两次面即可，锁住肉里的汁。差不多煎熟的时候，放蒜蓉，为了有蒜香的同时不煎糊蒜蓉。 莴笋带子 鸡肉 葱烧鸡 虾 煮冷冻虾 西班牙蒜虾 冻冻虾除腥：咖哩粉，淀粉，挑的时候要挑急速冷冻的 快手菜 麻婆豆腐 醋溜金针菇 意大利醋凉拌西红柿 皮蛋豆腐 水煮/蒜蓉西兰花 番茄炒鸡蛋、菠萝咕噜肉、茄子鱼 辛拉面的做法 乌冬的做法 纳豆拌饭 油淋茄子 早餐 手抓饼 牛油果温泉蛋吐司 葱油面 Foodie Travel艾格吃饱了：上海馆子 艾格吃饱了：杭州馆子 西安小六汤包]]></content>
      <categories>
        <category>生活</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[美妆笔记]]></title>
    <url>%2Fp%2F13be.html</url>
    <content type="text"><![CDATA[刷头 基础刷头 眼影刷包括：大号打底铺色(偏硬, 比较宽)，晕染(偏软一点)，眼线刷(偏硬)。 眼妆 眼妆的步骤 眼影-眼线-假睫毛-夹睫毛-睫毛液 防晒-隔离(修正肤色、保湿等不同作用)-遮瑕-粉底液-眼妆-鼻影-修容-定妆 (眉毛在哪一步) 眼线的画法 假睫毛的粘贴 睫毛夹 遮泪沟 工具，innisfree遮瑕刷，橘色套装也包含 一支遮瑕膏层层叠加法 歌剧魅影6色遮瑕，橘色刷子 遮瑕评测 发色2019流行“不饱和发色” 2019年最夯最显白的TOP10发色！ 面膜推荐CNP黄色和蓝色 墨镜选择不同脸型选择墨镜]]></content>
      <categories>
        <category>生活</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[理财知识]]></title>
    <url>%2Fp%2Fe897.html</url>
    <content type="text"><![CDATA[信用卡 信用卡周期 statement balance是上个周期的欠款 account balance是目前总欠款 = 上个周期的欠款+上个周期-到当日的欠款 我的还款方式。月尾付account balance 付完之后account balance何时更新。假设6.3号付了account balance，6.3号之前信用卡还有一笔支出，还未显示在account balance中。都是按照出帐日期算的。 current balance是按照出帐日期算的，并不是按照消费当天的日期算的。如果消费当日在上一个周期，而出帐日是在下个周期，则属于下个周期。一般出帐时间需要两天。 保险知识 some links 对保险的初步认识 医疗险0免赔额比1w免赔额好吗 社保和其他保险 香港保险和内地保险 我们家的保险 老爸的保险 公司的社会养老保险：五险一金 新华保险：寿险（ 交完了） ![image-20190616124252625](/Users/yyf/Library/Application Support/typora-user-images/image-20190616124252625.png) ![image-20190616125033031](/Users/yyf/Library/Application Support/typora-user-images/image-20190616125033031.png) 老妈的保险 生日： 社会养老保险：包括养老保险+医疗保险 ![image-20190616123942874](/Users/yyf/Library/Application Support/typora-user-images/image-20190616123942874.png) 我 我的中国平安的人身保险 ![551560660438_.pic_hd copy](/Users/yyf/Library/Mobile Documents/comapplePreview/Documents/551560660438_.pic_hd copy.jpg) 我妈考虑想买的 新华康健华贵B：这款百万医疗很平常 新华康健华贵B保障范围和投保须知(案例) ![image-20190616125154325](/Users/yyf/Library/Application Support/typora-user-images/image-20190616125154325.png)]]></content>
      <categories>
        <category>生活</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[少女私房照]]></title>
    <url>%2Fp%2F7d48.html</url>
    <content type="text"><![CDATA[#拍摄主题 港风阴天 香港雨天：文礼阁的雨，地上的水圈 寝室仙女的私房照One year ending Project 1: 留学少女私房照 简介 港风留学少女相（私房照），体现和屋子的这个互动，作为我们这一年生活来的记录和留念，体现港风生活。 要求 力求拍出性感不色情的感觉。并且包含生活中最典型的场景。有港风味。不做作 场景设计 菲：做牛排（厨房），寝室准头搞怪那一下（看剧少女） 圈：晾衣服，回家的时候 玥：床上起身或梳妆台前。 大王：厨房，蒜蓉，和她的泡面锅。（拍摄的时候要注意，不要显得生活太过心酸和贫瘠，要有高大上的部分，如维尼饼干） Idea 一张生活照，一张出门前的照，形成对比。内容比较有趣。 前一秒晾衣的邋遢女孩，出门的精致女孩，身份切换。 步骤（1）找摄影师作品，看别人拍摄的作品，找到与自己符合或者相近的照片。前期可以用来模仿。 （2）了解私房照以及港风照的拍摄技巧，需要与后期调色符合。 （3）解决屋子里光线不足的情况 （4）设计方案：场景、服饰、妆容 （5）约拍 作品日系生活照 最美私房照 人物和情绪 拍摄调色vsco操作攻略 vsco调色拍摄学习 vsco滤镜推荐 #摄影书籍 10 本好看又实用的摄影书 ![image-20190606141525105](/Users/yyf/Library/Application Support/typora-user-images/image-20190606141525105.png) ![image-20190606141530303](/Users/yyf/Library/Application Support/typora-user-images/image-20190606141530303.png) ![image-20190606141606340](/Users/yyf/Library/Application Support/typora-user-images/image-20190606141606340.png)]]></content>
      <categories>
        <category>摄影</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数学基础知识]]></title>
    <url>%2Fp%2Fccc1.html</url>
    <content type="text"><![CDATA[正则 Tikhonov正则 问题 lower semicontinuous这个性质的作用在哪里。好像通常用在证明收敛性。 PCA是什么，有什么应用 不同的空间。把图像函数f定义在某个空间上是为了measure，为什么要measure，有哪些typical space SVD去噪 欧拉方程：欧拉方程是泛函极值条件的微分表达式 tensor 一 Norm不同的norm [semi-norm和norm] ![image-20190625043131777](/Users/yyf/Library/Application Support/typora-user-images/image-20190625043131777.png) #证明解的存在性 一个函数在某个空间内有界的意思 $0&lt;c_{1} \leq u_{n} \leq c_{2}, \text{which implies that u n is bounded in} L^{1}(\Omega)$ $\left{u_{n}\right} \text { is bounded in } B V(\Omega)$ 泛函， is bounded below, we can choose a minimizing sequence $\left{u_{n} : n=1,2, \cdots\right} \in \overline{S}(\Omega)$ 序列的强收敛和弱收敛 ![image-20190725143410105](/Users/yyf/Library/Application Support/typora-user-images/image-20190725143410105.png) Fatous’ lemma ![image-20190725145706825](/Users/yyf/Library/Application Support/typora-user-images/image-20190725145706825.png) 各类函数空间 $l_p$空间 ![image-20190725171210467](/Users/yyf/Library/Application Support/typora-user-images/image-20190725171210467.png) ![image-20190725171030761](/Users/yyf/Library/Application Support/typora-user-images/image-20190725171030761.png) $W^{1, 1}(\Omega)$ is usually defined as all functions $v \in L^{1}(\Omega)$, with weak derivatives of first order and these derivatives shall belong to $L^{1}(\Omega)$. The space $W^{1, \infty}(\Omega)$ is usually defined as all functions $v \in L^{\infty}(\Omega)$with weak derivatives of first orderand these derivatives shall belong to $L^{\infty}(\Omega) .$ BV空间，BH空间 The space $[\mathrm{BV}(\Omega)]^{m}$ with $|u|{\mathrm{BV}(\Omega)} :=\int{\Omega}|u| d x+|D u|(\Omega)$ is a Banach space. ![image-20190726181150976](/Users/yyf/Library/Application Support/typora-user-images/image-20190726181150976.png) 证明收敛速度 converge sublinearly $\lim {k \rightarrow \infty} \frac{\left|x{k+1}-L\right|}{\left|x_{k}-L\right|}=1$ converge linearly $\lim {k \rightarrow \infty} \frac{\left|x{k+1}-L\right|}{\left|x_{k}-L\right|}=\mu, \mu \in(0,1)$ converge superlinearly $\lim {k \rightarrow \infty} \frac{\left|x{k+1}-L\right|}{\left|x_{k}-L\right|}=0$ Q-linear convergence: distinguish superlinear rates of convergence. $\lim {k \rightarrow \infty} \frac{\left|x{k+1}-L\right|}{\left|x_{k}-L\right|^{q}}&lt;M$ Monotone operator 傅立叶变换傅立叶的平移不变性]]></content>
      <categories>
        <category>数学</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python语法学习]]></title>
    <url>%2Fp%2Fe35e.html</url>
    <content type="text"><![CDATA[执行参数 store_true 是指带触发action时为真，不触发则为假，2L说的代码去掉default初始化，其功能也不会变化 parser.add_argument(‘-c’, action=’store_true’) #python test.py -c =&gt; c是true（触发） #python test.py =&gt; c是false（无触发） 链接：https://www.zhihu.com/question/56692630/answer/358222352 数据结构类的定义类的定义 下划线的含义 变量 前带_的变量: 标明是一个私有变量, 只用于标明, 外部类还是可以访问到这个变量 _ _ 前带两个_ ,后带两个_ 的变量: 标明是内置变量, 大写加下划线的变量: 标明是 不会发生改变的全局变量 函数: 前带的变量: 标明是一个私有函数, 只用于标明, _ 前带两个_ ,后带两个_ 的函数: 标明是特殊函数 参数的定义Positional argument v.s. keyword argument In other words, keyword arguments are only “optional” because they will be set to their default value if not specifically supplied. 多参数的输入 不同数据类型的size list 列表创建列表： 12files = []files.append(os.path.splitext(i)) 理解Python中列表，元组，字典，集合的使用 列表的读取方式： files[1] numpy数组Python Numpy 数组的初始化和基本操作 numpy设置输出精度 numpy 中的深浅复制 “等于赋值”相当于标签 1）当浅复制的值是不可变对象（数值，字符串，元组）时和“等于赋值”的情况一样，对象的id值与浅复制原来的值相同。 2）当浅复制的值是可变对象（列表和元组）时会产生一个“不是那么独立的对象”存在。有两种情况 不同数据类型查看数据类型：type(object) 列表 可重复，类型可不同，可以遍历 extend (扩展) ：以列表增加 append (追加)：不同类型的数据 [‘a’, ‘b’, ‘c’, 1, 2, [1, 2]] 元组 可重复，类型可不同；可以遍历 只读的，不能修改 tuple1 = (1,2,’a’,4,’5’,6) numpy的数组 类型一样 b = np.array([6, 7, 8]) 字典 键和值，可以不同类型，无序存储 可变；从字典中删除元素 del dict1[‘sex’]；清除所有元素dict1.clear()；增加元素 集合 键，无序组合 可以增加删除元素set2.add(10)，set2.remove(6)，set2.discard(6)(可以删除空元素); 不同的集合支持union(联合), intersection(交), difference(差)和sysmmetric difference(对称差集)等数学运算； 不支持 索引, 分片, 或其它类序(sequence-like） 可将元祖和列表转化为集合set2 = set(list1) 可变：列表、字典、集合（存在固定集合frozenset） 不可变：元组、int、 string、 float 当传过来的是可变类型(list,dict)时，我们在函数内部修改就会影响函数外部的变量。而传入的是不可变类型时在函数内部修改改变量并不会影响函数外部的变量，因为修改的时候会先复制一份再修改。 文件操作 获取文件内的文件名字 123456import ospath = "d:\\data" # 设置路径dirs = os.listdir(path) # 获取指定路径下的文件for i in dirs: # 循环读取路径下的文件并筛选输出 if os.path.splitext(i)[1] == ".csv": # 筛选csv文件 print i 组成路径名字 库Import 模块和包：包是为了解决模块重命名的问题。 模块：就是一些.py文件，可以包含函数、变量、类等符号； 包：由模块及子包组成 在模块A中 from math import sqrt，那么sqrt函数会直接导入到当前的命名空间中来，并没有创建新的命名空间 。所以就可以在A直接使用sqrt()函数了。在某模块A中import math时，会在A中创建一个命名空间，并在这个命名空间中执行math.py当中的代码，并且在A中创建了math这个名称来引用这个命名空间。 单独导入包名(import package)不会导入包中所包含的所有子模块。 包的init.py文件为空时，导入包名没法使用包内的子包及模块 包的init.py并不为空 ，该文件可以初始化，导入一些常用的包** 库的升级1pip install --upgrade requests // mac,linux,unix 在命令前加 sudo -H Python 迭代器与生成器生成器和迭代器的关系: 生成器是迭代器的一种 生成器通过一个函数创建列表，但是不一次性创建完毕，因而节省内存，并且表现得却像是迭代器。 可迭代对象（可以用在 for 语句进行循环的对象） 1.数据类型（列表、元组、字符串、字典等） 123451.for i in [1, 2, 3]: print(i)2.obj = &#123;"a": 123, "b": 456&#125;for k in obj: print(k) 2.自己创建的迭代器 迭代器的创建方法: 为容器对象添加 iter() 和 next() 方法 12345678910111213141516class Container: def __init__(self, start = 0, end = 0): self.start = start self.end = end def __iter__(self): print("[LOG] I made this iterator!") return self def __next__(self): print("[LOG] Calling __next__ method!") if self.start &lt; self.end: i = self.start self.start += 1 return i else: raise StopIteration()c = Container(0, 5) 内置函数 iter() 将可迭代对象转化为迭代器 1234567ita = iter([1, 2, 3])print(type(ita))ita = iter([1, 2, 3])print(type(ita))print(type([1, 2, 3]))&lt;class 'list_iterator'&gt;&lt;class 'list'&gt; 生成器（generator） 1234567def container(start, end): while start &lt; end: yield start start += 1c = container(0, 5)Python&lt;class 'generator'&gt; 函数split通过指定分隔符对字符串进行切片，如果参数num 有指定值，则仅分隔 num 个子字符串 1234#!/usr/bin/pythonstr = "Line1-abcdef \nLine2-abc \nLine4-abcd";print str.split( );print str.split(' ', 1 ); find检测字符串中是否包含子字符串 str ，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，如果包含子字符串返回开始的索引值，否则返回-1。 1str.find(str, beg=0, end=len(string)) print1print('t=&#123;&#125;,loss=&#123;:.6f&#125;'.format(t,loss)) numpy的输出1234567891011# 使用set_printoptions设置输出的精度import numpy as npx=np.random.random(10)np.set_printoptions(precision=3)print(x)# 抑制使用对小数的科学记数法y=np.array([1.5e-10,1.5,1500])print(y)# [ 1.500e-10 1.500e+00 1.500e+03]np.set_printoptions(suppress=True)print(y) 合并两个矩阵1234#hstack()在行上合并 这个实验结果不对 np.hstack((a,b)) #vstack()在列上合并 np.vstack((a,b)) squeeze语法：numpy.squeeze(a,axis = None) 1）a表示输入的数组；2）axis用于指定需要删除的维度，但是指定的维度必须为单维度，否则将会报错；3）axis的取值可为None 或 int 或 tuple of ints, 可选。若axis为空，则删除所有单维度的条目； 从数组的形状中删除单维度条目，即把shape中为1的维度去掉 作用：从数组的形状中删除单维度条目，即把shape中为1的维度去掉 例子： 123456789101112131415161718e = np.arange(10).reshape(1,10,1)e: array([[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]]])np.squeeze(e)e: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])#正常显示图示案例#通过np.squeeze()函数转换后，要显示的数组变成了秩为1的数组，即（5，）plt.plot(np.squeeze(squares)) plt.show() 库numpy：提供很多矩阵的操作 python的注释格式python的注释格式 Python 图像 读取图像: cv2 ski.. PIL库的使用 import matplotlib Image读出来的是PIL的类型，而skimage.i的对比 PIL拆分、合并、合成视频 用PIL显示图像 对图像加噪声、滤波复原 https://www.cnblogs.com/lynsyklate/p/8047510.html Debug 文件阅读时，出现无法创建文件的问题。（该文件被另一进程阅读中） why can the same file not opened by several processes? @wqn628 Because that requires the hdf5-library to be built with parallel extensions. You can open an HDF5-file for read-only in multiple processes, but you cannot open it for read/write in more than one process unless the library has been built with parallel enabled.The reason for this is because HDF5-files write to the file the moment you close them, not the moment you tell them to write. Therefore, in serial, corruption would be very likely. The best way to deal with this is by simply opening the HDF5-file for read-only in both Python scripts. That should work perfectly fine. NoneType之所以出现，该参数没有被创建或者赋值，只被取了名字。 要理解这个，首先要理解Python对象，python对象具有三个特性：身份、类型、值。 这三个特性在对象创建时被赋值。只有值可以改变，其他只读。类型本身也是对象。 Null与None是Python的特殊类型，Null对象或者是None Type，它只有一个值None. 它不支持任何运算也没有任何内建方法. None和任何其他的数据类型比较永远返回False。 None有自己的数据类型NoneType。你可以将None复制给任何变量，但是你不能创建其他NoneType对象。 一句话总结：Null对象是python对象，又叫做NoneType，None是这个对象的值。 看过了NoneType的解释，之所以出现None就很好理解了。 要正确定位bug出现的位置，之前那个logwrite没有定位准确，导致找不到原因。 要关注错误信息。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[去噪传统方法论文综述]]></title>
    <url>%2Fp%2F8245.html</url>
    <content type="text"><![CDATA[期刊会议 计算机视觉期刊 A类 TPAMI: IEEE Trans on Pattern Analysis and Machine Intelligence IJCV: International Journal of Computer Vision TIP: IEEE Transactions on Image Processing B类 CVIU: Computer Vision and Image Understanding Pattern Recognition C类 IET-CVI: IET Computer Vision IVC: Image and Vision Computing IJPRAI: International Journal of Pattern Recognition and Artificial Intelligence Machine Vision and Applications PRL: Pattern Recognition Letters 计算机视觉会议 A类 ICCV: International Conference on Computer Vision CVPR: International Conference on Computer Vision and Pattern Recognition AAAI: AAAI Conference on Artificial Intelligence ICML: International Conference on Machine Learning NIPS: Annual Conference on Neural Information Processing Systems ACM MM: ACM International Conference on Multimedia B类 ECCV: European Conference on Computer Vision C类 ACCV: Asian Conference on Computer Vision ICPR: International Conference on Pattern Recognition BMVC: British Machine Vision Conference 应用数学期刊 JMIV: Journal of Mathematical Imaging and Vision 应用数学会议 检索工具 期刊影响因子查询网站：中文、 英文网站 出版商、数据库、检索工具 IEEE和Springer是出版商，并且拥有自己的数据库和检索工具。 如：IEEE有IEEExplorer检索。 其他数据库自己（比如EI, EBSCOhost等等）可以抓取出版商数据库里面的文章。比如EngineeringVillage (EI)在IEEExplorer抓取文章的内容；这时候作者的文章就能在EI里面查到了。 Google/Google Scholar/Scirus/ScienceDirect/IEEExplorer/ISI这些都是检索工具 SCI(Science Citation Index)是影响因子，也是ISI（Institute Scientific Information）做的数据库。 SCI不是出版商，只是数据库，不是具体某篇文章内容版权的拥有者；所以在SCI里面，能看到只是题目+摘要+参考文献。SCI的内容不是原始文献全文，卖点是每年推出JCR，里面给出影响因子。 SIAM简介：国际工业与应用数学协会(SIAM), 旗下出版有应用数学相关的许多国际著名期刊杂志 文献链接2019 CVPR 汇总 变分算法 total variation TV-based image restoration: Rudin Osher and Fatermi in 1992. 优点：preserves edges well, but has sometimes undesirable staircase effect, namely the trans- formation of smooth regions into piecewise constant regions (stairs), which implied that the finer details in the original im- age may not be recovered satisfactorily. 缺点：staircasing 什么是staircasing。如何发生。在哪些情况下更容易发生。 除了non-local mean和BM3D，都是oversmoothed。 改进：几大类方法 高阶全变分模 型 [8] 、广义全变分模型 [9] 和自适应全变分模型 [5] 等 [7] L.I. Rudin, S.Osher, and E. Fatemi. Nonlinear total variation based noise removal algorithms. Physica D(Nonlinear phenomena), 1992, 60(1 /2 /3 /4) : 259-268. [8] Y. You and M. Kaveh. Fourth-Order partial differential equations for noise removal. IEEE trans on image processing, 2000, 9(10) : 1723-1730. [9] B. Kristian, K. Karl, and P. Thomas. Total generalized variation. SIAM Journal on imaging sciences, 2010, 3(3):492-526. [5] P. Blomgren, T. Chan, P. Mulet, and C. Wong. Total variation image restoration: numerical methods and extensions. In IEEE international conferance on image processing, pages III, 384-387, 1997. 基于小波框架的变分模型 [14-19] 14、Chan, Raymond H., et al. “Wavelet algorithms for high-resolution image reconstruction.” SIAM Journal on Scientific Computing 24.4 (2003): 1408-1432 17、Chan, Raymond, Lixin Shen, and Zuowei Shen. “A framelet-based approach for image inpainting.” Res. Rep 4 (2005): 325. 16、Dong, Bin, and Zuowei Shen. “MRA based wavelet frames and applications.” IAS Lecture Notes Series, Summer Program on “The Mathematics of Image Processing”, Park City Mathematics Institute 19 (2010). 15、Cai, Jian-Feng, Stanley Osher, and Zuowei Shen. “Split Bregman methods and frame based image restoration.” Multiscale modeling &amp; simulation 8.2 (2009): 337-369. 19、Cai, Jian-Feng, et al. “Image restoration: total variation, wavelet frames, and beyond.” Journal of the American Mathematical Society 25.4 (2012): 1033-1089. 20、Cai, Jian-Feng, et al. “Data-driven tight frame construction and image denoising.” Applied and Computational Harmonic Analysis 37.1 (2014): 89-105. 最近建立了小波框架和 变分模型之间的联系。 这种联系给出了基于小波框 架的变分模型优于其他某些变分模型的理论依据， 即基于小波框架的变分模型可以根据潜在的解的奇 点的顺序，在给定图像的不同区域中自适应地选择微 分算子。又基于图像数据结构特征， 提出了一种数据驱动紧 框架， 该框架比以往的模型更能精确地重构图像。 去噪 不同的滤波器用于不同的噪声，某一个降噪滤波器很难符所有的噪声。 首先，说一下噪声的类型，噪声的分类和该噪声的分布符合什么模型有关，常见的噪声有高斯白噪声、椒盐噪声、泊松分布噪声、指数分布噪声等。 其次，采用的滤波器有空域滤波器，比如均值滤波器、中值滤波器、低通滤波器、高斯滤波等；频域滤波器，比如小波变换、傅里叶变换、余弦变换等；形态学滤波器，主要是通过膨胀和腐蚀等形态学操作进行去噪。 第三，对应场合。一般平时见的比较多是是高斯白噪声，像用均值滤波、中值滤波、高斯滤波可以去噪。还有在低照度下，比如晚上拍照时的图像，一般属于泊松分布的噪声，可以采用一些3d去噪算法，比如效果不错的BM3D算法。像椒盐噪声，一般用中值滤波基本可以去噪。 文献回顾以及代码github去噪技术的方法和代码实现总结 滤波法：空间域和变换域 (空间域) Gaussian filter (转化域) Wavelet-based(详见Tight-frame): tight frame 小波变化文献回顾 马尔可夫场 Markov denoising 理解 全变分模型（变分法的一种） ROF模型, 1992 L. Rudin, S. Osher, E. Fatemi, Nonlinear Total Variation based noise removal algorithm, Physica D 60 259-268, 1992. ++paper $$ \min {u} \int{\Omega}\left(\alpha|\nabla u|+\frac{1}{2}(u-z)^{2}\right) $$ 与ROF相关联的偏微分方程以及推导 目标方程：$$\begin{array}{l}{J[u(x, y)]=\iint_{\Omega}|\nabla u(x, y)| \mathrm{d} x \mathrm{d} y+\quad \frac{\lambda}{2} \iint_{\Omega}\left(u(x, y)-u^{0}(x, y)\right)^{2} \mathrm{d} x \mathrm{d} y}\end{array}$$该泛函是$$J[u(x, y)]=\iint_{\Omega} F\left(x, y, u, \frac{\partial u}{\partial x}, \frac{\partial u}{\partial y}\right) \mathrm{d} x \mathrm{d} y$$型的泛函，其中(式1)$$\begin{aligned} F=&amp;|\nabla u(x, y)|+\frac{\lambda}{2}\left(u(x, y)-u^{0}(x, y)\right)^{2}= \&amp;\sqrt{\left(\frac{\partial u(x, y)}{\partial x}\right)^{2}+\left(\frac{\partial u(x, y)}{\partial y}\right)^{2}}+\frac{\lambda}{2}\left(u(x, y)-u^{0}(x, y)\right)^{2} \end{aligned}$$ {222}该类函数求极值的必要条件，即欧拉-拉格朗日方程(PDE):$$F_{H}-\frac{\partial}{\partial x}\left{F_{p}\right}-\frac{\partial}{\partial y}\left{F_{q}\right}=0$$其中, $p=\frac{\partial u(x, y)}{\partial x}, q=\frac{\partial u(x, y)}{\partial y}​$. 对于式1，有$F_{H}=\lambda\left(u-u^{0}\right), F_{p}=\frac{\frac{\partial u}{\partial x}}{|\nabla u|}, F_{q}=\frac{\frac{\partial u}{\partial y}}{|\nabla u|}$, 代入后有：$$\begin{array}{l}{\lambda\left(u-u^{0}\right)-\left{\frac{\partial}{\partial x}\left{\left(\frac{\frac{\partial u}{\partial x}}{|\nabla u|}\right)\right}+\frac{\partial}{\partial y}\left{\frac{\frac{\partial u}{\partial y}}{|\nabla u|}\right}\right}=0} \ {\Rightarrow \lambda\left(u-u^{0}\right)-\left(\frac{\partial}{\partial x}, \frac{\partial}{\partial y}\right) \cdot\left(\frac{\frac{\partial u}{\partial x}}{|\nabla u|}, \frac{\frac{\partial u}{\partial y}}{|\nabla u|}\right)=0} \ {\Rightarrow \lambda\left(u-u^{0}\right)-\left(\frac{\partial}{\partial x}, \frac{\partial}{\partial y}\right) \cdot\left(\frac{1}{|\nabla u|}\left(\frac{\partial u}{\partial x}, \frac{\partial u}{\partial y}\right)\right)=0} \ {\Rightarrow \lambda\left(u-u^{0}\right)-\nabla \cdot\left(\frac{\nabla u}{|\nabla u|}\right)=0}\end{array}$$其中，$\nabla=\left(\frac{\partial}{\partial x}, \frac{\partial}{\partial y}\right)$为梯度算子。 TV复原模型的欧拉一拉格朗日方程为 ：$$-\nabla \cdot\left(\frac{\nabla u}{|\nabla u|}\right)+\lambda\left(u-u^{0}\right)=0$$ using a gradient projection method. 缺点：阶梯块效应 表现形式： 产生原因： 改进方法 可以分为三类：(1) 对l_1进行改进 (2) 高阶变分 (3) 高阶全变分模型[8]、广义全变分模型[9]和自适应全变分模型[5] (在谋篇中文期刊看到过) 二阶(高阶)方法改进staircasing 局限性：通常需要更复杂的边界条件以及结果很可能会过光滑 (二阶) G. Geman and G. Reynolds, 1992, IEEE Trans. Pattern Anal. Mach. Intel. 《Constrained restoration and the recovery of discontinuities》 (二阶) Chambolle and Lions, 1997, Numer. Math. 《Image recovery via total variation minimization and related problems》: Chambolle and Lions do this by minimizing the inf-convolution of the TV norm and a second order functional.$$\begin{array}{l}{\min {u{1}, u_{2}} \int_{\Omega}\left|\nabla u_{1}\right|+\alpha\left|d^{2} u_{2}\right|+\lambda\left|u_{1}+u_{2}-u_{0}\right|^{2}} \ {=\min {u, v} \int{\Omega}|\nabla u-\nabla v|+\alpha|\nabla(\nabla v)|+\lambda\left|u-u_{0}\right|^{2}}\end{array}$$ $$\min {u} \int{\Omega}\left(\alpha \left|d^{2} u\right|+|\nabla u|+\frac{1}{2}(u-z)^{2}\right)$$ (母鸡) P. Blomgren, T. F. Chan, and P. Mulet, 1997 《Extensions to total variation denoising》: The approach is performed by redefining the Total Variation functional R(u) in view of the properties of TV-norm and H1-seminorm. However, it is not completely clear how to choose a function Φ, which makes the regularizing functional R(u) being convex. (四阶) Chan T, Marquina A, Mulet P., 2000, SIAM J Sci Comput, 《High-order total variation-based image restoration》: ”In this paper we present an improved model, constructed by adding a nonlinear fourth order diffusive term to the Euler–Lagrange equations of the variational TV model. “$$\int_{\Omega}\left(\alpha|\nabla u|_{\beta}+\mu \Phi(|\nabla u|)(\mathcal{L}(u))^{2}+\frac{1}{2}(u-z)^{2}\right)$$where, $\mathcal{L}(u)​$ is an elliptic operator and $\Phi(|\nabla u|)​$ is the adaptive function. This model retain the good properties of the TV functional and penalize “wrong” edges created in regions which “should” be smooth. The adaptive functional, in which the action of the second order term is lessened where the gradient is large(avoid oversmooth). (二阶) O. M. Lysaker and X.-C. Tai, Int. J. Comp. Vis., 2006 《Iterative image restoration combining total variation minimization and a second-order functional》:Instead of combing TV norm and second order derivatives within one regularization functional, Lysaker and Tai [5] use two regularization functionals. 两个式子，单独的两个regularization (四阶）Li F, Shen C, Fan J, 2007, J Vis Commun Image R 《Image restoration combining a total variational filter and a fourth-order filter》 (母鸡，higher-order)Liu G, Huang T, Liu J, 2014, Comput Math Appl 《High-order TVL1-based images restoration and spatially adapted regularization parameter selection》 TGV, Bredies, K., Kunisch, K., &amp; Pock, T. (2010), SIAM Journal on Imaging Sciences$$\mathrm{TGV}{\alpha}^{k}=\left(\sum{l=0}^{k-1} I_{K_{\alpha_{l}}^{l}}\right)^{*}$$ $$\operatorname{TGV}{\alpha}^{k}(u)=\underset{w{0}+\ldots+u_{k-1}=u \atop l=0, \ldots, k-1}{\inf } \sum_{l=0}^{k-1} \alpha_{l}\left|\nabla^{k-l} u_{l}+w_{l}\right|_{1}$$ 《Total generalized variation.》 code link here, paper link limitation: converge slowly 一个加速版本：K. Shirai, M. Okuda, (2014), “FFT based solution for multivariable l2 equations using KKT system via FFT and efficient pixel-wise inverse calculation,” IEEE ICASSP, paper link A. Beck, and M. Teboulle, A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems, SIAM J. Imaging Sci., Vol. 2, 183–202, 2009. inﬁmal convolution Euler’s elastica K Papafitsoros, (2014), JMIV 《A combined first and second order variational approach for image reconstruction. 》$$J(u)=\frac{1}{2}\left|u_{0}-T u\right|{2}^{2}+\alpha|\nabla u|{1}+\beta\left|\nabla^{2} u\right|_{1}$$ 从MAP的角度出发 C. Louchet and L. Moisan， 2008 《Total variation denoising using posterior expectation》: Louchet and Moisan proposed an alternative to the minimization of the total variation by considering the TV-LSE filter. C. Louchet and L. Moisan， 2014 《Total Variation Denoising using Iterated Conditional Expectation》 分析了staircasing产生的原因 M. Nikolova, 2000, SIAM J. Appl. Math 《Local strong homogeneity of a regularized estimator》：Nikolova proves that the staircasing effect is related to the non-differentiability of the total variation term 增加细节的改进：non-local+TV的方法. NLTV, Gilboa and Osher, 2004, Multiscale Model. Simul. 《Nonlocal operators with applications to image processing》$$J_{\mathrm{NLTV}}(u)+\lambda|u-I|^{2}$$ $$\int_{\mathcal{P}} \sqrt{\int_{\mathcal{B}}(u(p)-u(p+q))^{2} v(p, q) \mathrm{d} q \mathrm{d} p}$$ NLTVG, Peyré, G., Bougleux, S., Cohen, L.D, 2011, Inverse Probl. Imaging 《Non-local regularization of inverse problems.》 RNLTV, Z Li, F Malgouyres, T Zeng，2017, JMIV 《Regularized Non-local Total Variation and Application in Image Restoration》 基于图像的自相似性: 两种图像降噪方法论文解读以及代码实现 Non-local means, 2005, code link here Buades, A., Coll, B., &amp; Morel, J. M. (2005, June). A non-local algorithm for image denoising. In 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05) (Vol. 2, pp. 60-65). IEEE.（BM3D） Exploit the inter-patch correlations BM3D, 2007, code link Dabov, K., Foi, A., Katkovnik, V., &amp; Egiazarian, K. (2007). Image denoising by sparse 3-D transform-domain collaborative filtering. Image Processing, IEEE Transactions on 16 (8), pp. 2080-2095. inter-patch correlations；wavelet shrinkage LSSC(Learned Simultaneous Sparse Coding), 2009 Mairal, J., Bach, F. R., Ponce, J., Sapiro, G., &amp; Zisserman, A. (2009, September). Non-local sparse models for image restoration. In ICCV (Vol. 29, pp. 54-62). 这个算法是NL-means，LSC(Learned Sparse Coding), Block matching 3D的相结合 基于稀疏表达（在变换域） There exists a transform T such that applying T to patches will admit a sparse representation. Wavelet transform 稀疏表达 Wavelet thresholding 属于一种滤波法 基于马尔可夫场 基于深度学习 论文总结 高斯噪声均值为0，平方差为$\sigma^2$的高斯白噪声。 1234567891011121314# 调用imnoiseg = imnoise(I, (noise_level/255)^2)g = I + sqrt((noise_level/255)^2)*randn(M,N);其中的I是经过im2double(I) % I = I/255归一化的。case 'gaussian' % Gaussian white noise b = a + sqrt(p4)*randn(sizeA) + p3; # 直接g = I + sigma * randn(M,N);其中I是归一化后的，sigma = noise_level/255;# 如果I是[0,255]之间的原图。g = I + alpha * randn(size(S)); 那么，alpha = sigma*255; 斑点噪声（乘性噪声） 噪声模型诶 $$f=u n$$ $$p(f | u, L)=\frac{2 L^{L}}{\Gamma(L) u^{2 L}} f^{2 L-1} e^{-\frac{L f^{2}}{u^{2}}}$$ TV去噪模型 （AA模型）G. Aubert and J. Aujol. (2008). A variational approach to remove multiplicative noise. SIAM J. Appl. Math., 68:925–946, .$$\inf {u \in S(\Omega)} \int{\Omega}\left(\log (A u)+\frac{f}{A u}\right) d x+\lambda \int_{\Omega}|D u|$$ Dong, Y., &amp; Zeng, T. (2013). A convex variational model for restoring blurred images with multiplicative noise. SIAM Journal on Imaging Sciences, 6(3), 1598-1625.$$\inf {u \in \overline{S}(\Omega)} E(u) :=\int{\Omega}\left(\log u+\frac{f}{u}\right) d x+\alpha \int_{\Omega}\left(\sqrt{\frac{u}{f}}-1\right)^{2} d x+\lambda \int_{\Omega}|D u|$$ Fang, F., Fang, Y., &amp; Zeng, T. (2018). On the Convex Model of Speckle Reduction: IVLOPDE, Bergen, Norway, August 29 – September 2, 2016. https://doi.org/10.1007/978-3-319-91274-5_6 泊松噪声 泊松噪声既不是加性噪声，也不是乘性噪声，而是一种信号依赖噪声。 加噪模型：f= 10*poissrnd(u/10)，noiselevel=10$$\operatorname{Pr}(\boldsymbol{g} | \boldsymbol{f})=\prod_{i, j} \frac{\left[\boldsymbol{f}{i, j}\right]^{g{i, j}} \exp \left(-\boldsymbol{f}{i, j}\right)}{\left(\boldsymbol{g}{i, j}\right) !}$$ TV去噪 Ｃsisｚár [１] 最早提出了 Kullbaｃk－Leibler （ KL )－divergenｃe 保真项用于去除 灰色图像中的泊松噪声Ｃsisｚár I． Wｈy least squares and ｍaxiｍuｍ entrｏpy Ａn Ａxiｏｍatiｃ Ａpprｏaｃｈ tｏ Inferenｃe fｏr linear Inverse Ｐrｏbleｍs[J]． Ａnnals ｏf Statistiｃs ， １９９１ ， １９ （ ４ ） : ２０3２－２０６６ Luisier 等 [２] 在小波变换中构 造了一个 SURE 估计量用于泊松噪声的去除。 Gｏng 等 [3] 提出了一个 l １ +l ２ 保真项去除泊松噪声及一切未 知噪声。 Zｈang 等学者 [４－5] 使用重新赋权的 l ２ 方 法逼近 KL－divergenｃe 保真项 Wen, Y., Chan, R. H., &amp; Zeng, T. (2016). Primal-dual algorithms for total variation based image restoration under Poisson noise. Science China Mathematics, 59(1), 141-160. 描述了ADMM算法和Primal Dual的算法解决以下问题 Using the Bayesian rule, the Poisson image restoration problem can be represented as a minimization problem $$\min {f \in S} \Psi(\boldsymbol{f}) \equiv D{K L}(H \boldsymbol{f}+\boldsymbol{b}, \boldsymbol{g})+\lambda \operatorname{TV}(\boldsymbol{f})$$ $$D_{K L}(\boldsymbol{z}, \boldsymbol{g})=\left\langle\boldsymbol{g}, \ln \frac{\boldsymbol{g}}{\boldsymbol{z}}\right\rangle+\langle\mathbf{1}, \boldsymbol{z}-\boldsymbol{g}\rangle$$ code link: BM3D for Poisson 椒盐噪声 噪声模型 讲一部分像素变成0或者255 TV去噪 （Nikolova in 2004） $$\underset{u \in \mathbb{R}^{\Omega}}{\operatorname{argmin}}|u-v|{1}+\lambda \sum{i} \phi(\nabla u(i))$$ $\underset{u \in \mathbb{R}^{\Omega}}{\operatorname{argmin}}|u-v|{0}+\lambda \sum{i} \phi(\nabla u(i))$（因为nonconvex，先研究了第一个替代问题，之后出现对该问题求解） 2015 CVPR: A New Method for Image Restoration in the Presence ofImpulse Noise with code:C [2019 JMIV: Mixing Non-Local and TV-Lp methods] Chan提出了先试用noise detector的方法 NL-means approach [2016 JSC] Removing mixture of gaussian and impulse noise by patch-based weighted means 2019 JMIV: Mixing Non-Local and TV-Lp methods 去模糊 文献 An image sharpening Operator Combined with Framelet for Image Deblurring 提出的模型$$\min {u} \mathcal{J}(u) \equiv \frac{\lambda}{2}|A u-f|{2}^{2}+|W u|{1}+\mu|u-g|{1}$$ 采用变分法，正则项选择选择了Tight frame：|WtW|=1 将一个sharpen算子和传统tight frame的方法结合一起：用一个方法计算出有助于sharp的图像g, 并用L1-nirm去靠近。（和去模糊的构造正解之间的关系？待解决） 超分辨 文献 [2019 CVPR] Deep Plug-and-Play Super-Resolution for Arbitrary Blur Kernels 提出了一个新的SR degradation模型：ADMM和DNN的结合 待读文章 Fooling automated surveillance cameras: adversarial patches to attack person detection（对抗性补丁） 微信推送：包括论文地址和代码地址 对抗性补丁”(adversarial patch)，正是这块补丁 “欺骗” 了 AI 系统 如何写一篇优秀的论文1.紧跟细分领域研究前沿，确定研究角度 要做到这一点，最简单的方法是找一篇权威的综述类文章，可以是中文的，最好是英文的。根据综述中提到的作者、引用的文献，不断抽丝拨茧，去搜索下载原文进行研读，并且形成你自己对这个领域的文献综述。 2.熟练掌握一套实证研究方法和工具 3.不断模仿优秀的论文 如果你想在A类中文核心期刊上发表论文，那么你就必须要在《管理世界》《管理评论》等A类期刊上下载优秀论文，模仿他们的遣词用句，假设推导、假设检验、研究方法、结果探讨等等。 4.永远记住：一切初稿都是狗屎，修改一篇文章远比写一篇新的文章付出的心血要多。 一篇文章写完后，千万不要急需发表，修改工作十分重要。首先，打印出来，自己逐句逐字认认真真通读一遍，把不通顺的语句，错别字，标点符号等全部改正，保证不出现低级错误。 5.保持足够的耐心 论文表达摘录论文句式摘要 英文科技写作句型和词汇表达总结(2010-) 插入语 有必要提一句 It’s necessary to mention that；For completion, we remark that… 值得注意的是 It should be noted that; It is noteworthy that;It’s worth nothing that; It must be noted that;Significantly 说贡献 To the best of our knowledge, the deﬁnition of discrete TV-seminorm (3) as well as the role of the Raviart–Thomas ﬁnite element space to establish dual representation (4) are novel contributions of the present work. 描述一个方法 改造性强 The primal-dual algorithm proposed in this paper can beeasily adapted to different problems, is easy to implement and can be effectively accelerated on parallel hardware such as graphics processing units (GPUs). 评论一个方法的影响力大/效果好 achieve/provide/reach remarkable performance on the .. problem is an efficient network that provide an end-to-end mapping/estimation between the .. 很多方法被提出 To avoid the heuristic edge selection step, numerous algorithms based on natural image prior have been proposed, including normalized sparsity [16], L0 gradients [38] and dark channel prior [27]. Recent years have witnessed significant advances in sin-gle image deblurring. We focus our discussion on recent optimization-based and learning-based methods. Thus, it is of great interest to develop a general image prior which is able to deal with different scenarios with the MAP framework 图片名称 Figure 7: Some examples of RCF. From top to bottom: BSDS500 [2], NYUD [49], Multicue-Boundary [41], and Multicue-Edge [41]. From left to right: origin image, ground truth, RCF edge map, origin image, ground truth, and RCF edge map.]]></content>
      <categories>
        <category>图像处理</category>
      </categories>
      <tags>
        <tag>denoising</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一个博客搭建]]></title>
    <url>%2Fp%2F9748.html</url>
    <content type="text"><![CDATA[Github搭建博客 解决数学公式的显示问题(文件助手) github搭建结构的基本框架(文件助手) git的使用，廖雪峰 图片显示问题 新浪图片外链在博客中无法显示的原因 新浪图床直接访问没有权限：Access Denied You don’t have permission to access Mac下iPic的使用方法 不同的图床不同的图床 七牛云的API iPic中添加七牛 阿里云：https://oss.console.aliyun.com/overview 图床跑路怎么办 https://github.com/wisp-x/lsky-pro 解决替换图床的脚本 公式的显示问题博客list多端访问iphone/ipad]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[latex使用笔记]]></title>
    <url>%2Fp%2F5904.html</url>
    <content type="text"><![CDATA[latex使用笔记 参考资料学术写作利器——LaTeX入门笔记整理（不定期更新，附加使用心得) 特殊符号$8^{\circ}$: 8^{\circ} (可以通过自定义来简化，\def\degree{${}^{\circ}$} ，90\degree ) $8^{\circ}C$: 8^{\circ}C 自定义命令符 自定义颜色 RGB颜色查询 123\usepackage&#123;xcolor&#125;\definecolor&#123;myorange&#125;&#123;rgb&#125;&#123;1, 0.44, 0.11&#125;\newcommand&#123;\grammar&#125;[1]&#123;\textcolor&#123;myorange&#125;&#123;#1&#125;&#125; 画图 在线画图连接： 神经网络 图片 调整图片大小至页面宽度 \includegraphics[width=\textwidth]{images/EdgeNet2.png} 单栏图片插入 123456789% For one-column wide figures use\begin&#123;figure&#125;% Use the relevant command to insert your figure file.% For example, with the graphicx package use \includegraphics&#123;example.eps&#125;% figure caption is below the figure\caption&#123;Please write your figure caption here&#125;\label&#123;fig:1&#125; % Give a unique label\end&#123;figure&#125; 双栏图片插入 123456789% For two-column wide figures use\begin&#123;figure*&#125;% Use the relevant command to insert your figure file.% For example, with the graphicx package use \includegraphics[width=0.75\textwidth]&#123;example.eps&#125;% figure caption is below the figure\caption&#123;Please write your figure caption here&#125;\label&#123;fig:2&#125; % Give a unique label\end&#123;figure*&#125; 多张图片并列插入 使用subfigure，如果想换行，在图片后面加上回车键 1234567891011121314151617181920212223242526272829303132333435\begin&#123;figure&#125;[htbp]\centering\subfigure[pic1.]&#123;\begin&#123;minipage&#125;[t]&#123;0.25\linewidth&#125;\centering\includegraphics[width=1in]&#123;images/MSRB1.png&#125;%\caption&#123;fig1&#125;\end&#123;minipage&#125;%&#125;%\subfigure[pic2.]&#123;\begin&#123;minipage&#125;[t]&#123;0.25\linewidth&#125;\centering\includegraphics[width=1in]&#123;images/MSRB1.png&#125;%\caption&#123;fig2&#125;\end&#123;minipage&#125;%&#125;%[回车]\subfigure[pic3.]&#123;\begin&#123;minipage&#125;[t]&#123;0.25\linewidth&#125;\centering\includegraphics[width=1in]&#123;images/MSRB1.png&#125;%\caption&#123;fig2&#125;\end&#123;minipage&#125;&#125;%\subfigure[pic4.]&#123;\begin&#123;minipage&#125;[t]&#123;0.25\linewidth&#125;\centering\includegraphics[width=1in]&#123;images/MSRB1.png&#125;%\caption&#123;fig2&#125;\end&#123;minipage&#125;&#125;%[回车]\centering\caption&#123; pics&#125;\end&#123;figure&#125; 一列多张图 去掉图片的序列号 利用minipage下的\centerline以及subfigure*。例如： 123456789101112131415161718\documentclass[a4paper,UTF8]&#123;article&#125;\usepackage&#123;ctex&#125;\usepackage&#123;caption&#125;\usepackage&#123;graphicx&#125;\begin&#123;document&#125;\begin&#123;figure&#125;[ht]\begin&#123;minipage&#125;&#123;0.48\linewidth&#125;\centerline&#123;\includegraphics[width=1\textwidth]&#123;a1.jpg&#125;&#125;\centerline&#123;伤心图&#125;\end&#123;minipage&#125;\qquad\begin&#123;minipage&#125;&#123;0.48\linewidth&#125;\centerline&#123;\includegraphics[width=1\textwidth]&#123;a2.jpg&#125;&#125;\centerline&#123;开心图&#125;\end&#123;minipage&#125;\caption*&#123;都是表情图&#125;\end&#123;figure&#125;\end&#123;document&#125; 设置caption中的字体大小 控制图片插到的位置 其中[htbp]就是浮动格式 “h 当前位置。将图形放置在正文文本中给出该图形环境的地方。如果本页所剩的页面不够，这一参数将不起作用。 t 顶部。将图形放置在页面的顶部。 b 底部。将图形放置在页面的底部。 p 浮动页。将图形放置在一只允许有浮动对象的页面上。” 表格 在线画表格，转化成latex代码 参考博客 例子(摘自论文FFDNet) https://ws1.sinaimg.cn/large/006tNc79gy1g37p8ux09hj313c0rgk7f.jpg 三线表 latex和matlab表格的连接 matlab的输出模式规范成[&amp;&amp;\\]的模式 latex引用包，把csv读取成表格模式 表格溢出 123456789\begin&#123;table*&#125;[!t]\centering\caption&#123;***&#125;\label&#123;***&#125;\resizebox&#123;\textwidth&#125;&#123;!&#125;&#123;\begin&#123;tabular&#125;&#123;***&#125;***\end&#123;tabular&#125;&#125;\end&#123;table*&#125; 公式 公式溢出的问题 \! 缩小间距 换行 多行公式对齐，并显示一个序号 12345678910\documentclass[review]&#123;elsarticle&#125;\usepackage&#123;amsmath&#125;\begin&#123;document&#125;\begin&#123;equation&#125; \label&#123;eqn2&#125; \begin&#123;split&#125; n&amp;=\left[\frac&#123;b-a&#125;&#123;0.01&#125;\right]+1, \\ S&amp;=\frac&#123;1&#125;&#123;n&#125;\sum\limits_&#123;j=1&#125;^&#123;n&#125;(\lambda_&#123;0j&#125;-\lambda_&#123;j&#125;). \end&#123;split&#125;\end&#123;equation&#125;\end&#123;document&#125; 引用 同一处引用多个参考文献 方法一：加包 \usepackage{cite} ,处理多个文献命令：\cite{name1,name2,…,nameN} 方法二：不加包，\cite{name1},\cite{name2}. 数学公式的引用 加载 amsmath 工具包，使用 \eqref 命令。效果如下： As the choice of parameter in the TV model (3) 中文编译sharelatex官方文件 点击menu，将编译器转换XeLatex debug begin{equation*} 环境不存在的问题 \usepackage{amsmath} \bibliography{reference.bib}没有反应的时候 可能是因为没有定义引用的格式 \bibliographystyle{spbasic} % basic style, author-year citations\bibliographystyle{spmpsci} % mathematics and physical sciences\bibliographystyle{spphys} % APS-like style for physics 图片和表格引用的时候显示不对 Figure \ref{}; Table \ref{} 解决：因为把\label插在了\caption之前，默认需要在\caption之后。 图片插入到了reference中 将htbp转化成H, 不可以是h. 如：\begin{figure}[H] 需要头文件：\usepackage{float}]]></content>
      <categories>
        <category>软件</category>
      </categories>
      <tags>
        <tag>latex</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习网络学习]]></title>
    <url>%2Fp%2Fb08c.html</url>
    <content type="text"><![CDATA[网络架构学习 课程链接-tensorflow中文版教程 最新资讯和链接近期必读的10篇ACL 2019【图神经网络（GNN）+NLP】相关论文和代码 卷积神经网络CNN 文献 AlexNet VGG ResNet He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition. InProceedings of the IEEE conference on computer vision and pattern recognition 2016 (pp. 770-778). Alex netAlex net之前的工作以及AlexNet中的创新点 论文笔记 VGGRESNETResNet, 2015, 微软亚洲研究院的何凯明等人提出 He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition. InProceedings of the IEEE conference on computer vision and pattern recognition 2016 (pp. 770-778). 主要贡献：网络层数从32层提到152层 特点： 网络较瘦，控制了参数数量； 存在明显层级，特征图个数逐层递进，保证输出特征表达能力； 使用了较少的池化层，大量使用下采样，提高传播效率； 没有使用Dropout，利用BN和全局平均池化进行正则化，加快了训练速度； 层数较高时减少了3x3卷积个数，并用1x1卷积控制了3x3卷积的输入输出特征图数量，称这种结构为“瓶颈”(bottleneck)。 残差单元： 克服了梯度消失的问题 ##卷积神经网络中的组成 ####步长和补零 ####卷积核：三维结构 ####池化层 池化层的输入一般来源于上一个卷积层，主要作用是提供了很强的鲁棒性（例如max-pooling是取一小块区域中的最大值，此时若此区域中的其他值略有变化，或者图像稍有平移，pooling后的结果仍不变），并且减少了参数的数量，防止过拟合现象的发生。池化层一般没有参数，所以反向传播的时候，只需对输入参数求导，不需要进行权值更新。 ####Inception模块 ####bottle layer的作用 #循环神经网络RNN 4.30 阅读 Pytorch Example: A character-level RNN 识别名字的种类 前馈神经网络的局限 节点之间没有联系 输入和输出的维度固定。无法处理变长的序列数据？维度改变的时序问题 时序的长度是什么？一个字符串的长度？ 每次输出只依赖于当前输入 循环神经网络的难点 按照时序反向传播的时候存在梯度爆炸和梯度消失。解决办法：引入门控机制。 A character-level RNN 强化学习对抗神经网络GAN 阅读 什么是生成式对抗网络GAN 2017王飞跃等：生成式对抗网络 GAN 的研究进展与展望https://www.msra.cn/zh-cn/news/features/gan-20170511) 2019论文：图像补丁躲过图像识别（19.05.02）code 生成对抗网络的工作原理：一个是摄影师（男生），一个是摄影师的女朋友（女生）。男生一直试图拍出像众多优秀摄影师一样的好照片，而女生一直以挑剔的眼光找出“自己男朋友”拍的照片和“别人家的男朋友”拍的照片的区别。于是两者的交流过程类似于：男生拍一些照片 -&gt;女生分辨男生拍的照片和自己喜欢的照片的区别-&gt;男生根据反馈改进自己的技术，拍新的照片-&gt;女生根据新的照片继续提出改进意见-&gt;……，这个过程直到均衡出现：即女生不能再分辨出“自己男朋友”拍的照片和“别人家的男朋友”拍的照片的区别。 生成对抗网络的工作原理：以图像生成模型举例。假设我们有一个图片生成模型（generator），它的目标是生成一张真实的图片。与此同时我们有一个图像判别模型（discriminator），它的目标是能够正确判别一张图片是生成出来的还是真实存在的。那么如果我们把刚才的场景映射成图片生成模型和判别模型之间的博弈，就变成了如下模式：生成模型生成一些图片-&gt;判别模型学习区分生成的图片和真实图片-&gt;生成模型根据判别模型改进自己，生成新的图片-&gt;····（训练过程由生成模型和判别模型组成） 最简单的数据生成模型：如果有数据集S={x1，…xn}，假设这些数据的分布P{X}服从g(x;θ)，在观测数据上通过最大化似然函数得到θ的值，即最大似然法：$$\max {\theta} \sum{i=1}^{n} \log g\left(x_{i} ; \theta\right)​$$。当这个生成模型是神经网络的时候，就是生成式对抗网络（GAN） 文献综述 网络绘图画图软件 Visio ![image-20190514135849553](../../../../Library/Application Support/typora-user-images/image-20190514135849553.png) ![image-20190514135858557](../../../../Library/Application Support/typora-user-images/image-20190514135858557.png) NN-SVG，适合卷积神经网络, 在线链接 ![image-20190514135655177](../../../../Library/Application Support/typora-user-images/image-20190514135655177.png) PlotNeuralNet，基于Latex，github的链接，导出pdf ![image-20190514133839750](../../../../Library/Application Support/typora-user-images/image-20190514133839750.png) 提供很多模版的在线画图网页 ![image-20190514135511723](../../../../Library/Application Support/typora-user-images/image-20190514135511723.png) 神经网络的例子 Edge detection: HED multi-scale: 不同大小的卷积核 multi-level: receptive field: 网络层次越深，越大，越抽象 weighted-fusion layer: MSRB MSRB for SR ![image-20190514132028216](../../../../Library/Application Support/typora-user-images/image-20190514132028216.png) MSRB for denoising ![image-20190514131803277](../../../../Library/Application Support/typora-user-images/image-20190514131803277.png) SR: MSRN #常见问题 DNN（Deep Neural Network）和Deep CNN的区别 过去传统的神经网络ANN（Artifical Neural Network），都是层次较少的网络型结构，所以又被称为浅层网络（shallow neural network），DNN与传统SNN的区别就在于其网络层次结构更多，等复杂，因此由于其层次更多，在图论上说就是图的深度更深，所以被冠名为深度神经网络（Deep Neural Network) Deep CNN是使用了卷积的网络。DNN是最基本的网络结构。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>网络结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch学习笔记]]></title>
    <url>%2Fp%2Fef8a.html</url>
    <content type="text"><![CDATA[Pytorch学习笔记——随时更新 Pytorch环境 查看pytorch版本 1234&gt;&gt;&gt; import torch&gt;&gt;&gt; print(torch.__version__)0.4.0# 更新之后 更新pytorch 1conda update pytorch torchvision Backward Propagation 算法 机器学习中的线性代数之矩阵求导 向量，标量对向量求导数 GPU 查看cuda以及pytorch版本 123print(torch.cuda.current_device()) import pytorchprint(torch.__version__) 指定cuda 指定torch的设备 12345678torch.device('cuda',0) or torch.device('cuda:0') orvar = torch.device('cuda:0')a = torch.randn((2,3),device=var)b = torch.randn(2,3).to_sparse().requires_grad_(True)torch.randn((2,3), 'cuda:1'), cuda1= torch.device('cuda:1')， torch.randn((2,3), device=cuda1) 数据迁徙：将Pytorch模型从CPU转换成GPU Tensor张量 通过pytorch创建张量 123x = torch.randn(M,N）.type(dtype)# 原来是通过numpy创建数组, numpy提供了很多矩阵数学计算x = np.random.randn(N, I) 将张量放在GPU上 张量在cpu和gpu之间的转换 从cpu –&gt; gpu，使用data.cuda()从gpu –&gt; cpu，使用data.cpu() 张量之间的转换 tensor的创建 直接创建： 12torch.tensor([..]).type(..)torch.FloatTensor() 创建随机矩阵： 123dtype = torch.Floatensor dtype = torch.cuda.Floatensor torch.randn((M,N),type(dtype) 从其他数据类型: 12data = [[1,2],[3,4]]tensor = torch.FloatTensor(data) 找出其中最大元素 torch.max(input) 矩阵操作 增加维度 减少维度 Pytorch可视化利用tensorboard画图 通过logger文件可视化训练过程、官网、别人写的tensorflow下比较具体的可视化 出现的问题 端口冲突通过指定端口解决： 12tensorboard --logdir=/tmp --port=8008 #绝对路径tensorboard --logdir=./tmp --port=8008 #相对路径 tensorbard命令无法找到： 1python3 -m tensorboard.main --logdir=~/my/training/dir 进入目录： 123pip show tensorflowcd /home/abc/xy/.local/lib/python2.7/site-packagespython main.py --logdir=/path/to/log_file/ 路径的名称要小心，路径得是根目录, 不需要引号 1yyfang@mai:~$ ge/ERRNet_Code/logs --port=8008 可视化 1234567891011121314151617181920212223242526272829303132if iteration % 100 == 0: print("===&gt; Epoch[&#123;&#125;](&#123;&#125;/&#123;&#125;): Loss: &#123;:.6f&#125;".format(epoch, iteration, len(training_data_loader),loss.data.item())) info = &#123; 'loss': loss.data.item()&#125; itera = (epoch-1)*len(training_data_loader)+iteration for tag, value in info.items(): logger.scalar_summary(tag, value, itera) for tag, value in model.named_parameters(): # print(value.grad) logger.histo_summary(tag, to_np(value), itera) logger.histo_summary(tag+'/grad', to_np(value.grad), iteration) images = input * 255. # ?[0,1]?????[0,255]?? images[images &lt; 0] = 0 images[images &gt; 255.] = 255. a =to_np(images.view(-1, 64, 64)[:8]) # info_input = &#123;'input': to_np(images.view(-1, 64, 64)[:2])&#125; imagelabel = label * 255. # ?[0,1]?????[0,255]?? imagelabel[imagelabel &lt; 0] = 0 imagelabel[imagelabel &gt; 255.] = 255. b = to_np(imagelabel.view(-1, 64, 64)[:8]) c = np.hstack((a,b)) # print(images) info_label = &#123;'inpput/label': c&#125; for tag, images in info_label.items(): logger.image_summary(tag, images, itera) # for tag, images in info_label.items(): # logger.image_summary(tag, images, iteration) if iteration % 5000 == 0: number = opt.number save_checkpoint_iter(model, number) opt.number += 1 数据集 训练集(train set) 验证集(validation set) 测试集(test set） training set： 用来训练模型 validation set : 用来做model selection（往往我们需要对多种模型进行训练，训练完之后就会得到多个模型的结果，我们希望从这些训练好的模型中选择最适合的模型） test set : 用来评估所选出来的model的实际性能 几个常用数据集 BSD500： DIV2K： 函数 矩阵相乘/点乘 123456789data = [[1,2],[3,4]]tensor = torch.FloatTensor(data)# numpynp.matmual(data, data)# tensortorch.mm(tensor, tensor) # 矩阵相乘tensor.mm(tensor.t())torch.mul(tensor,tenor.t()) #点乘tensor.mul(tensor) 将数组截取到一个区间 12h_relu = h.clamp(min=0)h_relu2 = torch.clamp(h, min=0) To_np函数: 转化数据类型 包含在库fastai中 1from fastai.basics import * 网络结构-nn包torch_nn中文文档 torch.nn的线形层 torch.nn的卷积层 卷积核的大小: [out_Channel, in_Channel, kernel_size, kernel_size] bias的大小:[out_Channel] 继承nn.modle自定义模块 问题 如何初始化model中的参数 为什么需要model.zero_grad之后再backward(), 例如 model.zero_grad() optimizer.zero_grad() 优化器optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) 损失函数 如何自定义损失函数 并行运算Parallelpytorch中如果使用DataParallel，那么保存的模型key值前面会多出’modules.’，这样如果训练的时候使用的是多GPU，而测试的时候使用的是单GPU，模型载入就会出现问题。 例子：设置GPU和预训练模型1234567891011121314151617181920212223242526272829 criterion = nn.MSELoss(size_average=False)# 设置GPU print("===&gt; Setting GPU") if cuda: # 调用多个GPU model = nn.DataParallel(model, device_ids=[0, 1, 2, 3]).cuda() # 调用单个GPU model = model.cuda() criterion = criterion.cuda() else: model = model.cpu() # 加载预预训练好的模型及权重 if opt.pretrained: if os.path.isfile(opt.pretrained): print("=&gt; loading model '&#123;&#125;'".format(opt.pretrained)) weights = torch.load(opt.pretrained) model.load_state_dict(weights['model'].state_dict()) else: print("=&gt; no model found at '&#123;&#125;'".format(opt.pretrained)) # 保存模型的参数 # Save checkpoint save_file = os.path.join(TMP_DIR, 'checkpoint_epoch&#123;&#125;.pth'.format(epoch)) save_checkpoint(&#123; 'epoch': epoch, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict() &#125;, filename=save_file) Debug Anaconda中，import和实际的不符 Anaconda清除历史，否则同一个格子刷新，并不会影响前面已经import的内容 torch版本带来的bug loss.data[0] -&gt;loss.data.item() Mac air(未解决) 载入模型参数时报错（在ubuntu下不报错，ubuntu的版本是1.0.1.post2, air下是0.4.0） 1AttributeError: Can&apos;t get attribute &apos;_rebuild_parameter&apos; on &lt;module &apos;torch._utils&apos; from &apos;/Users/yingyingfang/anaconda3/lib/python3.6/site-packages/torch/_utils.py&apos;&gt; Ubuntu下训练RCF模型时报错（解决） 12345expected object of backend cpu but got backend cuda for argument #2 'weight'# 解决办法input=input.cuda()net = net.cuda()net(input) 如何提高训练速度 并行运算 RuntimeError: Input type (torch.cuda.DoubleTensor) and weight type (torch.cuda.FloatTensor) should be the same 产生原因：创建了一个高斯随机分布之后？ 解决办法：将数据类型转换成FloatTensor即可，如下，加一行代码 123train_label_batch = torch.from_numpy(train_label_batch)train_label_batch = train_label_batch.type(torch.FloatTensor) # 转Floattrain_label_batch = train_label_batch.cuda() # 转cuda RuntimeError: all tensors must be on devices[0]]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu服务器]]></title>
    <url>%2Fp%2F6fe1.html</url>
    <content type="text"><![CDATA[服务器学习 快捷键在服务器里切换界面：alt+tab 链接使用命令的命令。 看完这篇Linux基本的操作就会了 https://github.com/jlevy/the-art-of-command-line/blob/master/README-zh.md 一个学习linux的网站 命令行清单 定义变量1your_name=&quot;qinjx&quot; 用引号，等号旁边不能有空格。否则会被看成无法识别的命令 命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。中间不能有空格，可以使用下划线（_）。不能使用标点符号。不能使用bash里的关键字（可用help命令查看保留关键字） 文件处理显示隐藏文件ls -a 桌面面可视化窗口，进入ctrl + h ，则显示隐藏文件 创建目录Mkdir 复制删除文件cp rm ##下载文件 ftp下载 ​ 如果下载ftp服务器上的文件，可以用ftp命令。然后用get命令下载文件 网址下载 12345678wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip1.Wget常用参数 ◆-b：后台下载，Wget默认的是把文件下载到当前目录。 ◆-O：将文件下载到指定的目录中。 ◆-P：保存文件之前先创建指定名称的目录。 ◆-t：尝试连接次数，当Wget无法与服务器建立连接时，尝试连接多少次。 ◆-c：断点续传，如果下载中断，那么连接恢复时会从上次断点开始下载。 ◆-r：使用递归下载 git下载 1git clone &lt;https://github.com/LimBee/NTIRE2017.git&gt; 解压文件 Unzip https://www.cnblogs.com/chinareny2k/archive/2010/01/05/1639468.html) test 查看动态文件tail命令 12341、tail -f filename说明：监视filename文件的尾部内容（默认10行，相当于增加参数 -n 10），刷新显示在屏幕上。退出，按下CTRL+C。2、tail -n 20 filename说明：显示filename最后20行。 文件编辑vim在vi中按u可以撤销一次操作; Ctrl+r 恢复上一步被撤销的操作 vim常用命令之多行注释和多行删除 进程 命令 fg、bg、jobs、&amp;、ctrl + z都是跟系统任务有关的，虽然现在基本上不怎么需要用到这些命令，但学会了也是很实用的 1.&amp; 最经常被用到 这个用在一个命令的最后，可以把这个命令放到后台执行 2.ctrl + z 可以将一个正在前台执行的命令放到后台，并且暂停 3.jobs 查看当前有多少在后台运行的命令 4.fg 将后台中的命令调至前台继续运行 如果后台中有多个命令，可以用 fg %jobnumber将选中的命令调出，%jobnumber是通过jobs命令查到的后台正在执行的命令的序号(不是pid) 5.bg 将一个在后台暂停的命令，变成继续执行 如果后台中有多个命令，可以用bg %jobnumber将选中的命令调出，%jobnumber是通过jobs命令查到的后台正在执行的命令的序号(不是pid) 后台执行进程linux后台执行命令：&amp;和nohup command &amp;：关掉屏幕，进程结束，不占用屏幕而已 nohup commnd &amp;：真正在后台执行 PS：需要用户交互的命令不要放在后台执行。 有大量的输出，就进行重定向。 12yyfang@mai:~/Documents/Deeplearning_edge/ERRNet_edge/ERRNet_Code$ nohup python main.py --cuda --dataset="../../../dataset/data_edge_35.h5" &gt;result.txt 2&gt;&amp;1 &amp;[1] 22223 显示最后的十行 监视进程https://blog.csdn.net/shenhuan1104/article/details/75808146 查看进程 ps -aux | grep xrdp 杀死进程 $ kill -s 9 进程号 管道符“|”用来隔开两个命令，管道符左边命令的输出会作为管道符右边命令的输入。 把ps的查询结果通过管道给grep查找包含特定字符串的进程。 $ ps -ef | grep firefox 监视GPU3.监视GPU的使用情况 12$ nvidia-smi $ watch -n 10 nvidia-smi %10s钟输出一次 指定GPU 启用相关软件和程序matlabhttps://blog.csdn.net/u013066730/article/details/80944063 命令行之行matlab 1234562.运行m文件如果m文件名为matlabfile.m(1)方法一进入m文件所在目录后，运行$ matlab -nodesktop -nosplash -r matlabfile只用文件名matlabfile，不能添加.m 更改快捷键 anaconda在终端输入anaconda-navigator 退出base 执行python参数输入 Positional argument v.s. keyword argument In other words, keyword arguments are only “optional” because they will be set to their default value if not specifically supplied. 多参数输入 远程连接xrdp 服务相关 SSD管理预处理数据的时候，要检查硬盘是否有足够大的空间 df -h GPU由显卡和GPU组成 相当于内存和CPU的区别 当显卡内存不够时，和batchsize有关和数据集的大小没有关系，一块显卡，64*64的batchsize=16而不能设置成32 环境变量配置anaconda环境变量，在终端输入： 1export PATH=~/anaconda/bin:$PATH 显示当前conda版本信息，在终端输入： 1conda --version 之后我们再次输入命令列出Anaconda自带的包，在终端输入： 1conda list 常见问题 远程桌面死机 知道服务器远程桌面的服务所使用的协议，关掉相应进程即可。 不知道的情况下，可猜测对方所使用的进程（例如猜测使用xrdp） 如果是xrdp的话这行命令应该会有超过一个的结果：ps -aux | grep xrdp ![image-20190506123440339](/Users/yyf/Library/Application Support/typora-user-images/image-20190506123440339.png)yyfang@mai:~$ kill 22722 # 对应的进程是启动桌面 查看服务器容量 如何调出这个显示，代表的是什么容量，应该没有包括数据的大小![image-20190613135253231](/Users/yyf/Library/Application Support/typora-user-images/image-20190613135253231.png) Linux du 命令 du -sh 查看当前目录的大小 du -h test 方便阅读的格式显示test目录所占空间情况 123456789101112131415# du log2012.log 300 log2012.log# du -h test608K test/test6308K test/test44.0K test/scf/lib4.0K test/scf/service/deploy/product4.0K test/scf/service/deploy/info12K test/scf/service/deploy16K test/scf/service4.0K test/scf/doc4.0K test/scf/bin32K test/scf8.0K test/test31.3M test 服务器上文件Dataset网上下载的一些数据集 train: 生成的一些.h5训练数据 test.h5 用ljc的边缘，未归一化，用了400张图 poisson10.h5 noiselevel=10的泊松噪声 Edge_net generate_data: 生成.h5数据 Loggers05 Poisson10_… 10:22PM开始 /python/compare_models: 不同的.pth]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[富士X100：慢拍的优雅]]></title>
    <url>%2Fp%2Fb371.html</url>
    <content type="text"><![CDATA[相机成像原理小孔成像：进光、倒立 孔太大了无法成像，每个点包含了整个成像物； 小孔变小，图像会更清晰，光线变暗 相机的光圈类比于小孔 闪光灯的作用 在光线充足的地方：增加光效，突出立体感 在光线不足的地方：补光 逆光时：人物的面部光线更为柔和 X100下具有自动曝光功能。菜单的位置：闪光灯的自动模式，闪光灯的力度大小，配合闪光灯的消除红眼 测光模式 X100具有多重、点测光、平均三种测光模式。 多重测光是点和平均的中和。夜晚时，画面容易偏亮。 点测光的特点：适合拍摄主题明显的画面，营造氛围。当测光在亮部时，整体会偏暗；当测光在暗部时，整体会偏亮。(点测光下，可以改变测光点吗：半自动测光） 平均测光的特点：适合拍摄静物和风景。测光平均值比较稳定。画面容易偏暗 注意：MF模式下，测光方式不影响曝光画面。由光圈快门决定。 曝光补偿 增加曝光补偿： 例子： 降低曝光补偿： 白平衡 作用：增加氛围；中和不正常的光线 几种调节方式：自动白平衡、自定义白平衡、白平衡偏移 白平衡偏移： 不同场景的拍摄夕阳的拍摄技巧 色彩的学习 课堂链接 色彩的饱和度：所含彩色强度的浓度。 色彩的明度：色彩的亮度。其中黄色明度最高，紫色明度最低，绿、红、蓝、橙的明度相近，为中间明度。 色彩的搭配方式 单色、对比色、分离补色、冷暖色 问题 全画幅和半画幅的区别]]></content>
      <categories>
        <category>摄影</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mac快捷键以及一些快速操作]]></title>
    <url>%2Fp%2F5d54.html</url>
    <content type="text"><![CDATA[在Mac下快速调出终端的方法是：为终端添加一个快捷键打开方式 为终端添加一个快捷键打开方式打开Mac下自带的软件 Automator 新建文稿 创建一个服务 修改框内的脚本 123456on run &#123;input, parameters&#125; tell application &quot;Terminal&quot; reopen activate end tellend run 运行：command + R，如果没有问题，则会打开终端 保存：Command + S，将其命名为打开终端或你想要的名字 设置快捷键 在 系统偏好设置 -&gt; 键盘设置 -&gt; 快捷键 -&gt; 服务 选择我们创建好的 ‘打开终端‘，设置你想要的快捷键，比我我设置了⌘+空格 到此，设置完成。 聪明的你也许会发现，这个技巧能为所有的程序设置快捷启动。 将脚本中的 Terminal 替换成 其他程序就可以 123456on run &#123;input, parameters&#125; tell application &quot;Terminal&quot; reopen activate end tellend run 黑技能既然学了 Automator ，那就在附上一个黑技能吧。为你的代码排序。在 Xcode8以前，有个插件能为代码快速排序，不过时过境迁~ 对于没用的插件而且又有患有强迫症的的小伙伴，只能手动排序了（😂）. 首先还是创建一个服务 创建一个Shell脚本， 勾选:用输出内容替换所选文本 输入：sort|uniq 保存： 存为Sort &amp; Uniq 选中你的代代码 -&gt; 鼠标右键 -&gt; Servies -&gt; Sort&amp;Uniq 排序后的代码： Mac的一些快捷操作 增加文件的快捷方式 按下option+cmd，将文件拖到桌面，产生有箭头标记的文件夹。]]></content>
      <categories>
        <category>软件</category>
      </categories>
      <tags>
        <tag>Mac</tag>
        <tag>效率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ReactiveCocoa 基础]]></title>
    <url>%2Fp%2F115c.html</url>
    <content type="text"><![CDATA[ReactiveCocoa基础 本文修改自最快让你上手ReactiveCocoa之基础篇 有关对 ReactiveCocoa 的看法可以看一下唐巧的这篇ReactiveCocoa 讨论会 ReactiveCocoa简介 ReactiveCocoa（简称为RAC）,是由Github开源的一个应用于iOS和OS开发的新框架,Cocoa是苹果整套框架的简称，因此很多苹果框架喜欢以Cocoa结尾。 在我们iOS开发过程中，当某些事件响应的时候，需要处理某些业务逻辑,这些事件都用不同的方式来处理。 比如按钮的点击使用action，ScrollView滚动使用delegate，属性值改变使用KVO等系统提供的方式。其实这些事件，都可以通过RAC处理 ReactiveCocoa为事件提供了很多处理方法，而且利用RAC处理事件很方便，可以把要处理的事情，和监听的事情的代码放在一起，这样非常方便我们管理，就不需要跳到对应的方法里。 非常符合我们开发中高聚合，低耦合的思想。 ReactiveCocoa编程思想在开发中我们也不能太依赖于某个框架，否则这个框架不更新了，导致项目后期没办法维护，比如之前Facebook提供的 Three20 框架，在当时也是神器，但是后来不更新了，也就没什么人用了。因此我感觉学习一个框架，还是有必要了解它的编程思想。 先简单介绍下目前咱们已知的编程思想: 响应式编程思想响应式编程思想：不需要考虑调用顺序，只需要知道考虑结果，类似于蝴蝶效应，产生一个事件，会影响很多东西，这些事件像流一样的传播出去，然后影响结果，借用面向对象的一句话，万物皆是流。 代表：KVO 链式编程思想链式编程 是将多个操作（多行代码）通过点号(.)链接在一起成为一句代码,使代码可读性好。如: 1make.add(1).add(2).sub(5).muilt(-4).divide(4); 特点：方法的返回值是block,block必须有返回值（本身对象），block参数（需要操作的值） 代表：masonry框架。 实现：模仿masonry，写一个加法计算器，练习链式编程思想。 NSObject+Caculator.h 12345678910# import &lt;Foundation/Foundation.h&gt;@class CaculatorMaker;@interface NSObject (Caculator)// 计算+ (int)makeCaculators:(void (^)(CaculatorMaker *))block; @end NSObject+Caculator.m 123456789101112@implementation NSObject (Caculator)+ (int)makeCaculators:(void (^)(CaculatorMaker *))block &#123; CaculatorMaker *mgr = [[CaculatorMaker alloc] init]; block(mgr); return (mgr.result);&#125;@end CaculatorMaker.h 123456789101112131415161718# import &lt;Foundation/Foundation.h&gt;@class CaculatorMaker;typedef CaculatorMaker *(^CasulatorBlock)(int);@interface CaculatorMaker : NSObject@property (nonatomic, assign) int result;// 算数方法- (CaculatorMaker *(^)(int))add;- (CasulatorBlock)sub;- (CasulatorBlock)muilt;- (CasulatorBlock)divide;@end CaculatorMaker.m 123456789101112131415161718192021222324252627282930313233343536373839404142434445# import &quot;CaculatorMaker.h&quot;@implementation CaculatorMaker- (CaculatorMaker *(^)(int))add &#123; return ^CaculatorMaker *(int value) &#123; _result += value; return self; &#125;;&#125;- (CasulatorBlock)sub &#123; return ^CaculatorMaker *(int value) &#123; _result -= value; return self; &#125;;&#125;- (CasulatorBlock)muilt &#123; return ^CaculatorMaker *(int value) &#123; _result *= value; return self; &#125;;&#125;- (CasulatorBlock)divide &#123; return ^CaculatorMaker *(int value) &#123; _result /= value; return self; &#125;;&#125;@end 使用： 12345678int result = [NSObject makeCaculators:^(CaculatorMaker *make) &#123; // ( 1 + 2 - 5 ) * (-4) / 4 make.add(1).add(2).sub(5).muilt(-4).divide(4); &#125;]; NSLog(@&quot;%d&quot;, result); 函数式编程思想函数式编程思想：是把操作尽量写成一系列嵌套的函数或者方法调用。 特点：每个方法必须有返回值（本身对象）,把函数或者Block当做参数,block参数（需要操作的值）block返回值（操作结果） 代表：ReactiveCocoa 实现：用函数式编程实现，写一个加法计算器,并且加法计算器自带判断是否等于某个值. 123456789101112131415Calculator *caculator = [[Calculator alloc] init];BOOL isqule = [[[caculator caculator:^int(int result) &#123; result += 2; result *= 5; return result; &#125;] equle:^BOOL(int result) &#123; return result == 10; &#125;] isEqule];NSLog(@&quot;%d&quot;, isqule); Calculator.h 12345678910111213#import &lt;Foundation/Foundation.h&gt;@interface Calculator : NSObject@property (nonatomic, assign) BOOL isEqule;@property (nonatomic, assign) int result;- (Calculator *)caculator:(int (^)(int result))caculator;- (Calculator *)equle:(BOOL (^)(int result))operation;@end Calculator.m 123456789101112131415161718192021#import &quot;Calculator.h&quot;@implementation Calculator- (Calculator *)caculator:(int (^)(int))caculator &#123; _result = caculator(_result); return self; &#125;- (Calculator *)equle:(BOOL (^)(int))operation &#123; _isEqule = operation(_result); return self;&#125;@end ReactiveCocoa 结合了这两种种编程风格： 函数式编程（Functional Programming） 响应式编程（Reactive Programming） 所以，你可能听说过 ReactiveCocoa 被描述为函数响应式编程（FRP）框架。 以后使用RAC解决问题，就不需要考虑调用顺序，直接考虑结果，把每一次操作都写成一系列嵌套的方法中，使代码高聚合，方便管理。 导入ReactiveCocoa ReactiveCocoa的GitHub地址 Objective-CReactiveCocoa 2.5版本以后改用了Swift，所以Objective-C项目需要导入2.5版本 CocoaPods集成： 12345678platform :ios, &apos;8.0&apos;target &apos;YouProjectName&apos; douse_frameworks!pod &apos;ReactiveCocoa&apos;, &apos;~&gt; 2.5&apos;end PS:新版本的CocoaPods需要加入 123target &apos;YouProjectName&apos; do ... end 这句话来限定项目，否则导入失败。 SwiftSwift项目导入2.5后的版本 12345678platform :ios, &apos;8.0&apos;target &apos;YouProjectName&apos; douse_frameworks!pod &apos;ReactiveCocoa&apos;end 使用时在全局头文件导入头文件即可 PrefixHeader.pch 123456#ifndef PrefixHeader_pch#define PrefixHeader_pch#import &lt;ReactiveCocoa/ReactiveCocoa.h&gt;#endif ReactiveCocoa常见类RACSiganl 信号类 信号类,一般表示将来有数据传递，只要有数据改变，信号内部接收到数据，就会马上发出数据。 注意： 信号类(RACSiganl)，只是表示当数据改变时，信号内部会发出数据，它本身不具备发送信号的能力，而是交给内部一个订阅者去发出。 默认一个信号都是冷信号，也就是值改变了，也不会触发，只有订阅了这个信号，这个信号才会变为热信号，值改变了才会触发。 如何订阅信号：调用信号RACSignal的subscribeNext就能订阅 使用： 1234567891011121314151617181920212223242526272829303132333435363738394041// RACSignal使用步骤： // 1.创建信号 + (RACSignal *)createSignal:(RACDisposable * (^)(id&lt;RACSubscriber&gt; subscriber))didSubscribe // 2.订阅信号,才会激活信号. - (RACDisposable *)subscribeNext:(void (^)(id x))nextBlock // 3.发送信号 - (void)sendNext:(id)value // RACSignal底层实现： // 1.创建信号，首先把didSubscribe保存到信号中，还不会触发。 // 2.当信号被订阅，也就是调用signal的subscribeNext:nextBlock // 2.2 subscribeNext内部会创建订阅者subscriber，并且把nextBlock保存到subscriber中。 // 2.1 subscribeNext内部会调用siganl的didSubscribe // 3.siganl的didSubscribe中调用[subscriber sendNext:@1]; // 3.1 sendNext底层其实就是执行subscriber的nextBlock // 1.创建信号 RACSignal *siganl = [RACSignal createSignal:^RACDisposable *(id&lt;RACSubscriber&gt; subscriber) &#123; // block调用时刻：每当有订阅者订阅信号，就会调用block。 // 2.发送信号 [subscriber sendNext:@1]; // 如果不在发送数据，最好发送信号完成，内部会自动调用[RACDisposable disposable]取消订阅信号。 [subscriber sendCompleted]; return [RACDisposable disposableWithBlock:^&#123; // block调用时刻：当信号发送完成或者发送错误，就会自动执行这个block,取消订阅信号。 // 执行完Block后，当前信号就不在被订阅了。 NSLog(@&quot;信号被销毁&quot;); &#125;]; &#125;]; // 3.订阅信号,才会激活信号. [siganl subscribeNext:^(id x) &#123; // block调用时刻：每当有信号发出数据，就会调用block. NSLog(@&quot;接收到数据:%@&quot;,x); &#125;]; RACSubscriber 表示订阅者的意思，用于发送信号，这是一个协议，不是一个类，只要遵守这个协议，并且实现方法才能成为订阅者。通过create创建的信号，都有一个订阅者，帮助他发送数据。 RACDisposable 用于取消订阅或者清理资源，当信号发送完成或者发送错误的时候，就会自动触发它。 使用场景：不想监听某个信号时，可以通过它主动取消订阅信号。 RACSubject RACSubject:信号提供者，自己可以充当信号，又能发送信号。 使用场景:通常用来代替代理，有了它，就不必要定义代理了。 RACReplaySubject 重复提供信号类，RACSubject的子类。 RACReplaySubject与RACSubject区别: RACReplaySubject可以先发送信号，在订阅信号，RACSubject就不可以。 使用场景一:如果一个信号每被订阅一次，就需要把之前的值重复发送一遍，使用重复提供信号类。 使用场景二:可以设置capacity数量来限制缓存的value的数量,即只缓充最新的几个值。 ACSubject 和 RACReplaySubject 简单使用： ACSubject 123456789101112131415161718192021222324 // RACSubject使用步骤// 1.创建信号 [RACSubject subject]，跟RACSiganl不一样，创建信号时没有block。// 2.订阅信号 - (RACDisposable *)subscribeNext:(void (^)(id x))nextBlock// 3.发送信号 sendNext:(id)value// RACSubject:底层实现和RACSignal不一样。// 1.调用subscribeNext订阅信号，只是把订阅者保存起来，并且订阅者的nextBlock已经赋值了。// 2.调用sendNext发送信号，遍历刚刚保存的所有订阅者，一个一个调用订阅者的nextBlock。// 1. 创建信号RACSubject *subject = [RACSubject subject];// 2.订阅信号[subject subscribeNext:^(id x) &#123; // block调用时机：当信号发出新值，就会调用 NSLog(@&quot;收到信号&quot;); &#125;];// 3.发送信号NSLog(@&quot;发送信号&quot;);[subject sendNext:@&quot;1&quot;]; 12345678910111213141516171819202122232425262728293031323334 // RACReplaySubject使用步骤:// 1.创建信号 [RACSubject subject]，跟RACSiganl不一样，创建信号时没有block。// 2.可以先订阅信号，也可以先发送信号。// 2.1 订阅信号 - (RACDisposable *)subscribeNext:(void (^)(id x))nextBlock// 2.2 发送信号 sendNext:(id)value// RACReplaySubject:底层实现和RACSubject不一样。// 1.调用sendNext发送信号，把值保存起来，然后遍历刚刚保存的所有订阅者，一个一个调用订阅者的nextBlock。// 2.调用subscribeNext订阅信号，遍历保存的所有值，一个一个调用订阅者的nextBlock// 如果想当一个信号被订阅，就重复播放之前所有值，需要先发送信号，在订阅信号。// 也就是先保存值，在订阅值。// 1.创建信号RACReplaySubject *replaySubject = [RACReplaySubject subject];// 3.先订阅信号[replaySubject subscribeNext:^(id x) &#123; NSLog(@&quot;第一个订阅者接受到的数据%@&quot;, x);&#125;];// 2.发送信号[replaySubject sendNext:@1];[replaySubject sendNext:@2];// 后订阅信号[replaySubject subscribeNext:^(id x) &#123; NSLog(@&quot;第二个订阅者接收到的数据%@&quot;,x);&#125;]; RACSubject替换代理（与block类似） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 需求: // 1.给当前控制器添加一个按钮，modal到另一个控制器界面 // 2.另一个控制器view中有个按钮，点击按钮，通知当前控制器步骤一：在第二个控制器.h，添加一个RACSubject代替代理。@interface TwoViewController : UIViewController@property (nonatomic, strong) RACSubject *delegateSignal;@end步骤二：监听第二个控制器按钮点击@implementation TwoViewController- (IBAction)notice:(id)sender &#123; // 通知第一个控制器，告诉它，按钮被点了 // 通知代理 // 判断代理信号是否有值 if (self.delegateSignal) &#123; // 有值，才需要通知 [self.delegateSignal sendNext:nil]; &#125;&#125;@end步骤三：在第一个控制器中，监听跳转按钮，给第二个控制器的代理信号赋值，并且监听.@implementation OneViewController - (IBAction)btnClick:(id)sender &#123; // 创建第二个控制器 TwoViewController *twoVc = [[TwoViewController alloc] init]; // 设置代理信号 twoVc.delegateSignal = [RACSubject subject]; // 订阅代理信号 [twoVc.delegateSignal subscribeNext:^(id x) &#123; NSLog(@&quot;点击了通知按钮 %@&quot;, x); &#125;]; // 跳转到第二个控制器 [self presentViewController:twoVc animated:YES completion:@&quot;hi&quot;];&#125;@end RACTuple 元组类,类似NSArray,用来包装值.(@[key, value]) RACSequence RAC中的集合类，用于代替NSArray,NSDictionary,可以使用它来快速遍历数组和字典。 使用场景：字典转模型 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// 1.遍历数组NSArray *numbers = @[@1,@2,@3,@4];// 这里其实是三步// 第一步: 把数组转换成集合RACSequence numbers.rac_sequence// 第二步: 把集合RACSequence转换RACSignal信号类,numbers.rac_sequence.signal// 第三步: 订阅信号，激活信号，会自动把集合中的所有值，遍历出来。[numbers.rac_sequence.signal subscribeNext:^(id x) &#123; NSLog(@&quot;%@&quot;, x);&#125;];// 2.遍历字典,遍历出来的键值对 都会包装成 RACTuple(元组对象) @[key, value]NSDictionary *dic = @&#123;@&quot;name&quot;: @&quot;BYqiu&quot;, @&quot;age&quot;: @18&#125;;[dic.rac_sequence.signal subscribeNext:^(RACTuple *x) &#123; // 解元组包，会把元组的值，按顺序给参数里的变量赋值 // 写法相当与 // NSString *key = x[0]; // NSString *value = x[1]; RACTupleUnpack(NSString *key, NSString *value) = x; NSLog(@&quot;key:%@, value:%@&quot;, key, value); &#125;];// 3.字典转模型NSString *filePath = [[NSBundle mainBundle] pathForResource:@&quot;flags.plist&quot; ofType:nil];NSArray *dicArray = [NSArray arrayWithContentsOfFile:filePath];NSMutableArray *items = [NSMutableArray array];// OC写法for (NSDictionary *dic in dicArray) &#123; //FlagItem *item = [FlagItem flagWithDict:dict]; //[items addObject:item];&#125;// RAC写法[dicArray.rac_sequence.signal subscribeNext:^(id x) &#123; // 利用RAC遍历， x：字典 //FlagItem *item = [FlagItem flagWithDict:x]; //[items addObject:item];&#125;];// RAC高级用法（函数式编程）NSArray *flags = [[dicArray.rac_sequence map:^id(id value) &#123; return [FlagItem flagWithDict:value]; &#125;] array]; RACCommand RAC中用于处理事件的类，可以把事件如何处理,事件中的数据如何传递，包装到这个类中，他可以很方便的监控事件的执行过程。 一、RACCommand使用步骤: 创建命令 initWithSignalBlock:(RACSignal * (^)(id input))signalBlock 在signalBlock中，创建RACSignal，并且作为signalBlock的返回值 执行命令 - (RACSignal *)execute:(id)input 二、RACCommand使用注意: signalBlock必须要返回一个信号，不能传nil. 如果不想要传递信号，直接创建空的信号[RACSignal empty]; RACCommand中信号如果数据传递完，必须调用[subscriber sendCompleted]，这时命令才会执行完毕，否则永远处于执行中。 RACCommand需要被强引用，否则接收不到RACCommand中的信号，因此RACCommand中的信号是延迟发送的。 三、RACCommand设计思想： 内部signalBlock为什么要返回一个信号，这个信号有什么用。 在RAC开发中，通常会把网络请求封装到RACCommand，直接执行某个RACCommand就能发送请求。 当RACCommand内部请求到数据的时候，需要把请求的数据传递给外界，这时候就需要通过signalBlock返回的信号传递了。 四、如何拿到RACCommand中返回信号发出的数据。 RACCommand有个执行信号源executionSignals，这个是signal of signals(信号的信号),意思是信号发出的数据是信号，不是普通的类型。 订阅executionSignals就能拿到RACCommand中返回的信号，然后订阅signalBlock返回的信号，就能获取发出的值。 五、监听当前命令是否正在执行executing 六、使用场景,监听按钮点击，网络请求 使用: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// 1.创建命令 RACCommand *command = [[RACCommand alloc] initWithSignalBlock:^RACSignal *(id input) &#123; NSLog(@&quot;执行命令&quot;); // 返回空信号 //return [RACSignal empty]; // 2.创建信号 传递数据 return [RACSignal createSignal:^RACDisposable *(id&lt;RACSubscriber&gt; subscriber) &#123; [subscriber sendNext:@&quot;请求数据&quot;]; // 注意：数据传递完，最好调用sendCompleted,这时命令才执行完毕 [subscriber sendCompleted]; return nil; &#125;]; &#125;]; // 强引用命令，不要被销毁，否则接收不到数据 _command = command; // 3.订阅RACCommand的信号 [command.executionSignals subscribeNext:^(id x) &#123; [x subscribeNext:^(id x) &#123; NSLog(@&quot;订阅RACCommand的信号: %@&quot;, x); &#125;]; &#125;]; // RAC高级用法 // switchToLatest:用于signal of signals，获取signal of signals发出的最新信号,也就是可以直接拿到RACCommand中的信号 [command.executionSignals.switchToLatest subscribeNext:^(id x) &#123; NSLog(@&quot;RAC高级用法: %@&quot;, x); &#125;]; // 4.监听命令是否执行完毕,默认会来一次，可以直接跳过，skip表示跳过第一次信号。 [[command.executing skip:1] subscribeNext:^(id x) &#123; if ([x boolValue] == YES) &#123; // 正在执行 NSLog(@&quot;正在执行&quot;); &#125; else &#123; // 执行完毕 NSLog(@&quot;执行完成&quot;); &#125; &#125;]; // 5.执行命名 [self.command execute:@1]; RACMulticastConnection 用于当一个信号，被多次订阅时，为了保证创建信号时，避免多次调用创建信号中的block，造成副作用，可以使用这个类处理。 注意：RACMulticastConnection通过RACSignal的-publish或者-muticast:方法创建. RACMulticastConnection使用步骤: 创建信号 + (RACSignal *)createSignal:(RACDisposable * (^)(id subscriber))didSubscribe 创建连接 RACMulticastConnection *connect = [signal publish]; 订阅信号,注意：订阅的不在是之前的信号，而是连接的信号。 [connect.signal subscribeNext:nextBlock] 连接 [connect connect] RACMulticastConnection底层原理: 创建connect，connect.sourceSignal -&gt; RACSignal(原始信号) connect.signal -&gt; RACSubject 订阅connect.signal，会调用RACSubject的subscribeNext，创建订阅者，而且把订阅者保存起来，不会执行block。 [connect connect]内部会订阅RACSignal(原始信号)，并且订阅者是RACSubject 订阅原始信号，就会调用原始信号中的didSubscribe didSubscribe，拿到订阅者调用sendNext，其实是调用RACSubject的sendNext RACSubject的sendNext,会遍历RACSubject所有订阅者发送信号。 因为刚刚第二步，都是在订阅RACSubject，因此会拿到第二步所有的订阅者，调用他们的nextBlock 需求：假设在一个信号中发送请求，每次订阅一次都会发送请求，这样就会导致多次请求。 解决：使用RACMulticastConnection就能解决. 问题：每次订阅一次都会发送请求 1234567891011121314151617181920// 创建请求信号RACSignal *signal = [RACSignal createSignal:^RACDisposable *(id&lt;RACSubscriber&gt; subscriber) &#123; NSLog(@&quot;发送请求&quot;); [subscriber sendNext:@1]; return nil;&#125;];// 订阅信号[signal subscribeNext:^(id x) &#123; NSLog(@&quot;接受数据: %@&quot;, x);&#125;];// 再次订阅信号，会再次执行发送请求，也就是每次订阅都会发送一次请求[signal subscribeNext:^(id x) &#123; NSLog(@&quot;接受数据: %@&quot;, x);&#125;]; 输出： 12342016-12-28 11:37:04.397 ReactiveCacoa[1505:340573] 发送请求2016-12-28 11:37:04.398 ReactiveCacoa[1505:340573] 接受数据: 12016-12-28 11:37:04.398 ReactiveCacoa[1505:340573] 发送请求2016-12-28 11:37:04.398 ReactiveCacoa[1505:340573] 接受数据: 1 可以发现每次订阅都会重新发送请求. 下面我们使用RACMulticastConnection： 12345678910111213141516171819202122232425RACSignal *signal = [RACSignal createSignal:^RACDisposable *(id&lt;RACSubscriber&gt; subscriber) &#123; NSLog(@&quot;发送请求&quot;); [subscriber sendNext:@1]; return nil;&#125;];// 创建连接RACMulticastConnection *connect = [signal publish];// 订阅信号// 注意：订阅信号，也不能激活信号，只是保存订阅者到数组，必须通过连接，当调用连接，就会一次性调用所有订阅者的SendNext[connect.signal subscribeNext:^(id x) &#123; NSLog(@&quot;订阅者1信号: %@&quot;, x);&#125;];[connect.signal subscribeNext:^(id x) &#123; NSLog(@&quot;订阅者2信号: %@&quot;, x);&#125;];// 连接、激活信号[connect connect]; 输出： 1232016-12-28 11:37:04.399 ReactiveCacoa[1505:340573] 发送请求2016-12-28 11:37:04.399 ReactiveCacoa[1505:340573] 订阅者1信号: 12016-12-28 11:37:04.399 ReactiveCacoa[1505:340573] 订阅者2信号: 1 RACScheduler RAC中的队列，用GCD封装的。 RACUnit 表⽰stream不包含有意义的值,也就是看到这个，可以直接理解为nil. RACEven 把数据包装成信号事件(signal event)。它主要通过RACSignal的-materialize来使用，然并卵。 ReactiveCocoa开发中常见用法 替换代理 替换KVO 监听事件 替换通知 监听文本框文字改变 统一处理多个网络请求 替换代理：rac_signalForSelector: rac_signalForSelector: 直接监听 Selector 事件的调用 应用场景：监听 RedViewController 中按钮的点击事件 btnTap: 跳转到RedViewController前，先使用rac_signalForSelector订阅rvc中的 btnTap: 点击事件 1234567891011121314// 使用segue跳转- (void)prepareForSegue:(UIStoryboardSegue *)segue sender:(id)sender &#123;- if ([segue.identifier isEqualToString:@&quot;goRedVC&quot;]) &#123; RedViewController *rvc = segue.destinationViewController; // 订阅rvc中的 btnTap: 点击事件 [[rvc rac_signalForSelector:@selector(btnTap:)] subscribeNext:^(id x) &#123; NSLog(@&quot;RedVC btnTap！&quot;); &#125;]; &#125;&#125; RedViewController.m 中的按钮事件 1234- (IBAction)btnTap:(id)sender &#123; NSLog(@&quot;!&quot;);&#125; 替换KVOrac_valuesForKeyPath: 123456// KVO// 监听 slider 的 value 变化[[self.slider rac_valuesForKeyPath:@&quot;value&quot; observer:nil] subscribeNext:^(id x) &#123; NSLog(@&quot;slider value Change：%@&quot;, x);&#125;]; 替换通知rac_addObserverForName 123456789101112// 原生的订阅通知[[NSNotificationCenter defaultCenter] addObserver:self selector:@selector(userDidChange:) name:kTTCurrentUserLoggedOffNotification object:nil]; // 使用RAC订阅通知 ，takeUntil限定信号的声明周期 [[[[NSNotificationCenter defaultCenter] rac_addObserverForName:UIApplicationDidEnterBackgroundNotification object:nil] takeUntil:[self rac_willDeallocSignal]] subscribeNext:^(id x) &#123; NSLog(@&quot;Notification received&quot;);&#125;]; 监听事件rac_signalForControlEvents: 12345// 监听 btn 的 UIControlEventTouchUpInside 点击事件[[self.btn rac_signalForControlEvents:UIControlEventTouchUpInside] subscribeNext:^(id x) &#123; NSLog(@&quot;btnTap&quot;);&#125;]; 监听 textField 文字变化rac_textSignal 1234[[self.textField rac_textSignal] subscribeNext:^(id x) &#123; NSLog(@&quot;textField change: %@&quot;, x);&#125;]; 统一处理多个网络请求rac_liftSelector: 1234567891011121314151617181920212223242526272829303132333435363738- (void)viewDidLoad &#123; [super viewDidLoad]; // 处理多个请求都返回结果的时候，统一处理 // 如同时进行多个网络请求，每个请求都正确返回时，再去刷新页面 RACSignal *signalOne = [RACSignal createSignal:^RACDisposable *(id&lt;RACSubscriber&gt; subscriber) &#123; // 网络请求1 // ... // 返回成功 [subscriber sendNext:@&quot;网络请求1 data&quot;]; return nil; &#125;]; RACSignal *signalTwo = [RACSignal createSignal:^RACDisposable *(id&lt;RACSubscriber&gt; subscriber) &#123; // 网络请求2 // ... // 返回成功 [subscriber sendNext:@&quot;网络请求2 data&quot;]; return nil; &#125;]; [self rac_liftSelector:@selector(updateWithR1:R2:) withSignalsFromArray:@[signalOne, signalTwo]]; &#125;// 更新界面- (void)updateWithR1:(id)r1 R2:(id)r2 &#123; NSLog(@&quot;R1:%@, R2：%@ 完成！&quot;, r1, r2); &#125; 注意： 替换KVO和 监听文本框文字改变 方法在创建监听方法时就会执行一次。 122016-12-28 16:53:50.746 ReactiveCacoa[4956:1246592] slider value Change：0.52016-12-28 16:53:50.748 ReactiveCacoa[4956:1246592] textField change: 使用rac_liftSelector时 @selector(updateWithR1:R2:)中的方 参数个数 要与 signal个数 相同，否则会被断言Crash！]]></content>
      <tags>
        <tag>iOS</tag>
        <tag>ReactiveCocoa</tag>
        <tag>函数式编程</tag>
        <tag>开源框架</tag>
      </tags>
  </entry>
</search>
